<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.27">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Séance 9: Apprentissage Non Supervisé – Machine Learning et Deep Learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./seance10.html" rel="next">
<link href="./seance8.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-8b4baf804e461d9b72633f0de59a0cac.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark-f1aadacce99040138bbb613f9330654f.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-8b4baf804e461d9b72633f0de59a0cac.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-670c757105cc8b81a53606a71844536c.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark-b7200e4a2f6cd71dc52354e94e906ccc.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="site_libs/bootstrap/bootstrap-670c757105cc8b81a53606a71844536c.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<!-- Google Translate Widget -->
</head><body class="nav-sidebar floating quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script><div id="google_translate_element"></div>

<script type="text/javascript">
function googleTranslateElementInit() {
  new google.translate.TranslateElement({
    pageLanguage: 'fr',
    includedLanguages: 'fr,en', // Seulement FR et EN
    layout: google.translate.TranslateElement.InlineLayout.SIMPLE,
    autoDisplay: false
  }, 'google_translate_element');
}
</script>

<script type="text/javascript" src="https://translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script>

<style>
/* Style pour le widget Google Translate - MODIFIÉ */
#google_translate_element {
  position: fixed;
  top: 10px;
  right: 10px;
  z-index: 9999;
  background: white;
  padding: 2px;
  border-radius: 20px; /* Forme arrondie */
  box-shadow: 0 1px 3px rgba(0,0,0,0.1);
  border: 1px solid #ddd;
}

/* Cacher le branding Google */
.goog-te-gadget {
  font-size: 0 !important;
}

.goog-te-gadget-simple {
  background-color: transparent !important;
  border: none !important;
  padding: 0 !important;
}

.goog-te-menu-value span {
  color: #333 !important;
  font-size: 13px !important;
}

.goog-te-menu-value {
  color: #333 !important;
  border: none !important;
  background: transparent !important;
  padding: 4px 10px !important;
  border-radius: 15px !important;
}

/* Style personnalisé - Afficher seulement FR/EN */
.goog-te-gadget .goog-te-menu-value span:first-child {
  display: none !important;
}

/* Remplacer le texte par FR/EN seulement */
.goog-te-gadget .goog-te-menu-value span:last-child {
  display: inline-block;
  min-width: 30px;
  text-align: center;
}

/* Cacher la flèche */
.goog-te-gadget .goog-te-menu-value span:last-child:after {
  content: '';
  display: none;
}

/* Correction pour l'affichage */
.goog-te-banner-frame.skiptranslate {
  display: none !important;
}

body {
  top: 0px !important;
}

/* Style pour le menu déroulant */
.goog-te-menu2 {
  border-radius: 10px !important;
  box-shadow: 0 2px 8px rgba(0,0,0,0.15) !important;
  border: 1px solid #eee !important;
  min-width: 60px !important;
}

.goog-te-menu2-item {
  padding: 8px 12px !important;
  font-size: 13px !important;
  text-align: center;
}

/* Garder seulement FR et EN dans le menu */
.goog-te-menu2-item div:first-child {
  font-weight: 500;
}
</style>






<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./seance1.html">Partie 1: Machine Learning Fondamental</a></li><li class="breadcrumb-item"><a href="./seance9.html"><span class="chapter-title">Séance 9: Apprentissage Non Supervisé</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Machine Learning et Deep Learning</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/nevermind78/Ml_DL" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Présentation du Cours</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Partie 1: Machine Learning Fondamental</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./seance1.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Séance 1: Introduction IA et Machine Learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./seance2.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Séance 2: Apprentissage Supervisé - Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./seance3.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Séance 3: TP1 - Pipeline de Classification Binaire</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./seance4.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Séance 4: TD1 - Modèles de Classification de Base</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./seance5.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Séance 5: TD2 - Critères d’Évaluation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./seance6.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Séance 6: TP2 - Classification Multi-classes &amp; Optimisation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./seance7.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Séance 7: Cours - Apprentissage Supervisé : Régression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./seance8.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Séance 8: TP3 - Régression &amp; Optimisation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./seance9.html" class="sidebar-item-text sidebar-link active"><span class="chapter-title">Séance 9: Apprentissage Non Supervisé</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./seance10.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Séance 10: TP4 - Clustering &amp; Réduction de Dimension</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#définitions-et-principes" id="toc-définitions-et-principes" class="nav-link active" data-scroll-target="#définitions-et-principes">Définitions et Principes</a></li>
  <li><a href="#clustering-regroupement" id="toc-clustering-regroupement" class="nav-link" data-scroll-target="#clustering-regroupement">Clustering (Regroupement)</a>
  <ul class="collapse">
  <li><a href="#k-means" id="toc-k-means" class="nav-link" data-scroll-target="#k-means">k-means</a></li>
  <li><a href="#dbscan-density-based-spatial-clustering" id="toc-dbscan-density-based-spatial-clustering" class="nav-link" data-scroll-target="#dbscan-density-based-spatial-clustering">DBSCAN (Density-Based Spatial Clustering)</a></li>
  <li><a href="#autres-méthodes" id="toc-autres-méthodes" class="nav-link" data-scroll-target="#autres-méthodes">Autres méthodes</a></li>
  </ul></li>
  <li><a href="#mesures-de-qualité" id="toc-mesures-de-qualité" class="nav-link" data-scroll-target="#mesures-de-qualité">Mesures de Qualité</a>
  <ul class="collapse">
  <li><a href="#silhouette-score" id="toc-silhouette-score" class="nav-link" data-scroll-target="#silhouette-score">Silhouette Score</a></li>
  <li><a href="#inertie-elbow-method" id="toc-inertie-elbow-method" class="nav-link" data-scroll-target="#inertie-elbow-method">Inertie (Elbow Method)</a></li>
  <li><a href="#davies-bouldin-index" id="toc-davies-bouldin-index" class="nav-link" data-scroll-target="#davies-bouldin-index">Davies-Bouldin Index</a></li>
  </ul></li>
  <li><a href="#applications-réelles" id="toc-applications-réelles" class="nav-link" data-scroll-target="#applications-réelles">Applications Réelles</a>
  <ul class="collapse">
  <li><a href="#segmentation-client" id="toc-segmentation-client" class="nav-link" data-scroll-target="#segmentation-client">Segmentation Client</a></li>
  <li><a href="#regroupement-de-documents" id="toc-regroupement-de-documents" class="nav-link" data-scroll-target="#regroupement-de-documents">Regroupement de Documents</a></li>
  <li><a href="#analyse-dimages" id="toc-analyse-dimages" class="nav-link" data-scroll-target="#analyse-dimages">Analyse d’Images</a></li>
  </ul></li>
  <li><a href="#réduction-de-dimension" id="toc-réduction-de-dimension" class="nav-link" data-scroll-target="#réduction-de-dimension">Réduction de Dimension</a>
  <ul class="collapse">
  <li><a href="#pourquoi-réduire-la-dimension" id="toc-pourquoi-réduire-la-dimension" class="nav-link" data-scroll-target="#pourquoi-réduire-la-dimension">Pourquoi réduire la dimension ?</a></li>
  <li><a href="#pca-principal-component-analysis" id="toc-pca-principal-component-analysis" class="nav-link" data-scroll-target="#pca-principal-component-analysis">PCA (Principal Component Analysis)</a></li>
  <li><a href="#t-sne-t-distributed-stochastic-neighbor-embedding" id="toc-t-sne-t-distributed-stochastic-neighbor-embedding" class="nav-link" data-scroll-target="#t-sne-t-distributed-stochastic-neighbor-embedding">t-SNE (t-Distributed Stochastic Neighbor Embedding)</a></li>
  </ul></li>
  <li><a href="#exercices-de-réflexion" id="toc-exercices-de-réflexion" class="nav-link" data-scroll-target="#exercices-de-réflexion">Exercices de Réflexion</a></li>
  <li><a href="#résumé-de-la-séance" id="toc-résumé-de-la-séance" class="nav-link" data-scroll-target="#résumé-de-la-séance">Résumé de la Séance</a></li>
  <li><a href="#lectures-complémentaires" id="toc-lectures-complémentaires" class="nav-link" data-scroll-target="#lectures-complémentaires">Lectures Complémentaires</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./seance1.html">Partie 1: Machine Learning Fondamental</a></li><li class="breadcrumb-item"><a href="./seance9.html"><span class="chapter-title">Séance 9: Apprentissage Non Supervisé</span></a></li></ol></nav>
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span class="chapter-title">Séance 9: Apprentissage Non Supervisé</span></h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Informations de la séance
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>Type</strong>: Cours</li>
<li><strong>Durée</strong>: 2h</li>
<li><strong>Objectifs</strong>: Obj8, Obj9</li>
</ul>
</div>
</div>
<section id="définitions-et-principes" class="level2">
<h2 class="anchored" data-anchor-id="définitions-et-principes">Définitions et Principes</h2>
<p>L’<strong>apprentissage non supervisé</strong> est un type d’apprentissage où le modèle apprend à partir de <strong>données non étiquetées</strong>, sans réponses connues.</p>
<p><strong>Objectif principal</strong>: Découvrir des structures, des patterns ou des regroupements naturels dans les données.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Pourquoi l’apprentissage non supervisé ?
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Les données étiquetées sont rares ou coûteuses à obtenir</li>
<li>Exploration de données inconnues</li>
<li>Réduction de dimension pour visualisation</li>
<li>Détection d’anomalies</li>
</ul>
</div>
</div>
</section>
<section id="clustering-regroupement" class="level2">
<h2 class="anchored" data-anchor-id="clustering-regroupement">Clustering (Regroupement)</h2>
<p>Le <strong>clustering</strong> consiste à regrouper des données similaires dans des clusters (groupes).</p>
<section id="k-means" class="level3">
<h3 class="anchored" data-anchor-id="k-means">k-means</h3>
<p>L’algorithme <strong>k-means</strong> est l’une des méthodes de clustering les plus populaires.</p>
<p><strong>Principe</strong>:</p>
<ol type="1">
<li>Choisir k points initiaux (centroïdes)</li>
<li>Assigner chaque point au centroïde le plus proche</li>
<li>Recalculer les centroïdes (moyenne des points du cluster)</li>
<li>Répéter jusqu’à convergence</li>
</ol>
<div id="e4f6d0c8" class="cell" data-execution_count="1">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Données non étiquetées</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.array([[<span class="dv">1</span>, <span class="dv">2</span>], [<span class="dv">1</span>, <span class="dv">4</span>], [<span class="dv">1</span>, <span class="dv">0</span>],</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>              [<span class="dv">10</span>, <span class="dv">2</span>], [<span class="dv">10</span>, <span class="dv">4</span>], [<span class="dv">10</span>, <span class="dv">0</span>]])</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Clustering avec k=2</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> kmeans.fit_predict(X)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Labels des clusters:"</span>, labels)</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Centroïdes:"</span>, kmeans.cluster_centers_)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p><strong>Avantages</strong>:</p>
<ul>
<li>Simple et rapide</li>
<li>Évolutif pour grands datasets</li>
<li>Résultats faciles à interpréter</li>
</ul>
<p><strong>Inconvénients</strong>:</p>
<ul>
<li>Nécessite de spécifier k</li>
<li>Sensible aux valeurs aberrantes</li>
<li>Suppose des clusters sphériques et de taille similaire</li>
</ul>
</section>
<section id="dbscan-density-based-spatial-clustering" class="level3">
<h3 class="anchored" data-anchor-id="dbscan-density-based-spatial-clustering">DBSCAN (Density-Based Spatial Clustering)</h3>
<p><strong>DBSCAN</strong> regroupe les points basés sur la densité.</p>
<p><strong>Paramètres clés</strong>:</p>
<ul>
<li><strong>eps</strong>: distance maximale entre deux points pour être considérés voisins</li>
<li><strong>min_samples</strong>: nombre minimum de points pour former un cluster dense</li>
</ul>
<div id="018f3b65" class="cell" data-execution_count="2">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> DBSCAN</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Clustering par densité</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>dbscan <span class="op">=</span> DBSCAN(eps<span class="op">=</span><span class="fl">1.5</span>, min_samples<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> dbscan.fit_predict(X)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Labels DBSCAN:"</span>, labels)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="co"># -1 = bruit (outliers)</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p><strong>Avantages</strong>:</p>
<ul>
<li>Pas besoin de spécifier le nombre de clusters</li>
<li>Détecte les clusters de forme arbitraire</li>
<li>Robuste aux outliers</li>
</ul>
<p><strong>Inconvénients</strong>:</p>
<ul>
<li>Sensible aux paramètres eps et min_samples</li>
<li>Difficulté avec des densités variées</li>
</ul>
</section>
<section id="autres-méthodes" class="level3">
<h3 class="anchored" data-anchor-id="autres-méthodes">Autres méthodes</h3>
<ul>
<li><strong>Agglomerative Clustering</strong>: approche hiérarchique</li>
<li><strong>Gaussian Mixture Models (GMM)</strong>: modèle probabiliste</li>
<li><strong>Mean Shift</strong>: basé sur la densité de noyau</li>
</ul>
</section>
</section>
<section id="mesures-de-qualité" class="level2">
<h2 class="anchored" data-anchor-id="mesures-de-qualité">Mesures de Qualité</h2>
<p>Comment évaluer la qualité d’un clustering sans labels vrais ?</p>
<section id="silhouette-score" class="level3">
<h3 class="anchored" data-anchor-id="silhouette-score">Silhouette Score</h3>
<p>Mesure de cohérence intra-cluster et séparation inter-cluster.</p>
<p><strong>Valeurs</strong>:</p>
<ul>
<li>Proche de 1: bonne séparation</li>
<li>Proche de 0: clusters se chevauchent</li>
<li>Négatif: mauvais clustering</li>
</ul>
<div id="08ab1926" class="cell" data-execution_count="3">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> silhouette_score</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> silhouette_score(X, labels)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Silhouette Score: </span><span class="sc">{</span>score<span class="sc">:.3f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="inertie-elbow-method" class="level3">
<h3 class="anchored" data-anchor-id="inertie-elbow-method">Inertie (Elbow Method)</h3>
<p>Somme des distances carrées des points à leur centroïde.</p>
<div id="81bc18f9" class="cell" data-execution_count="4">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>inertias <span class="op">=</span> []</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>K <span class="op">=</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">10</span>)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> K:</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span>k, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>    kmeans.fit(X)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>    inertias.append(kmeans.inertia_)</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>plt.plot(K, inertias, <span class="st">'bo-'</span>)</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Nombre de clusters (k)'</span>)</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Inertie'</span>)</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Méthode du coude (Elbow Method)'</span>)</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="davies-bouldin-index" class="level3">
<h3 class="anchored" data-anchor-id="davies-bouldin-index">Davies-Bouldin Index</h3>
<p>Mesure de similarité moyenne entre clusters.</p>
</section>
</section>
<section id="applications-réelles" class="level2">
<h2 class="anchored" data-anchor-id="applications-réelles">Applications Réelles</h2>
<section id="segmentation-client" class="level3">
<h3 class="anchored" data-anchor-id="segmentation-client">Segmentation Client</h3>
<div id="f351a707" class="cell" data-execution_count="5">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Exemple fictif de segmentation client</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> {</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">'age'</span>: [<span class="dv">25</span>, <span class="dv">30</span>, <span class="dv">35</span>, <span class="dv">40</span>, <span class="dv">45</span>, <span class="dv">50</span>, <span class="dv">55</span>, <span class="dv">60</span>],</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'revenu_annuel_k'</span>: [<span class="dv">40</span>, <span class="dv">45</span>, <span class="dv">50</span>, <span class="dv">80</span>, <span class="dv">90</span>, <span class="dv">30</span>, <span class="dv">35</span>, <span class="dv">25</span>],</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">'score_depense'</span>: [<span class="dv">8</span>, <span class="dv">7</span>, <span class="dv">6</span>, <span class="dv">9</span>, <span class="dv">8</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">2</span>]</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(data)</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Normalisation</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>X_scaled <span class="op">=</span> scaler.fit_transform(df)</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Clustering</span></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">3</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'cluster'</span>] <span class="op">=</span> kmeans.fit_predict(X_scaled)</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df.groupby(<span class="st">'cluster'</span>).mean())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="regroupement-de-documents" class="level3">
<h3 class="anchored" data-anchor-id="regroupement-de-documents">Regroupement de Documents</h3>
<ul>
<li>Groupement d’articles par thème</li>
<li>Organisation d’emails</li>
<li>Catégorisation de produits</li>
</ul>
</section>
<section id="analyse-dimages" class="level3">
<h3 class="anchored" data-anchor-id="analyse-dimages">Analyse d’Images</h3>
<ul>
<li>Segmentation d’image</li>
<li>Regroupement de pixels similaires</li>
<li>Compression d’image</li>
</ul>
</section>
</section>
<section id="réduction-de-dimension" class="level2">
<h2 class="anchored" data-anchor-id="réduction-de-dimension">Réduction de Dimension</h2>
<section id="pourquoi-réduire-la-dimension" class="level3">
<h3 class="anchored" data-anchor-id="pourquoi-réduire-la-dimension">Pourquoi réduire la dimension ?</h3>
<ul>
<li>Visualisation de données multidimensionnelles</li>
<li>Réduction du bruit</li>
<li>Accélération des algorithmes</li>
<li>Éviter le “fléau de la dimension”</li>
</ul>
</section>
<section id="pca-principal-component-analysis" class="level3">
<h3 class="anchored" data-anchor-id="pca-principal-component-analysis">PCA (Principal Component Analysis)</h3>
<p><strong>PCA</strong> transforme les données en composantes orthogonales capturant la variance maximale.</p>
<div id="5b9117b4" class="cell" data-execution_count="6">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Données de démonstration</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.random.randn(<span class="dv">100</span>, <span class="dv">5</span>)  <span class="co"># 100 échantillons, 5 features</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="co"># PCA</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>X_pca <span class="op">=</span> pca.fit_transform(X)</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Variance expliquée: </span><span class="sc">{</span>pca<span class="sc">.</span>explained_variance_ratio_<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Variance totale expliquée: </span><span class="sc">{</span><span class="bu">sum</span>(pca.explained_variance_ratio_)<span class="sc">:.2%}</span><span class="ss">"</span>)</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualisation</span></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>plt.scatter(X_pca[:, <span class="dv">0</span>], X_pca[:, <span class="dv">1</span>])</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Première composante principale'</span>)</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Deuxième composante principale'</span>)</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'PCA - Visualisation 2D'</span>)</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="t-sne-t-distributed-stochastic-neighbor-embedding" class="level3">
<h3 class="anchored" data-anchor-id="t-sne-t-distributed-stochastic-neighbor-embedding">t-SNE (t-Distributed Stochastic Neighbor Embedding)</h3>
<p>Méthode non linéaire particulièrement efficace pour la visualisation.</p>
<div id="630680c9" class="cell" data-execution_count="7">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.manifold <span class="im">import</span> TSNE</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>tsne <span class="op">=</span> TSNE(n_components<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>X_tsne <span class="op">=</span> tsne.fit_transform(X)</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>plt.scatter(X_tsne[:, <span class="dv">0</span>], X_tsne[:, <span class="dv">1</span>])</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'t-SNE 1'</span>)</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'t-SNE 2'</span>)</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'t-SNE - Visualisation 2D'</span>)</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
</section>
<section id="exercices-de-réflexion" class="level2">
<h2 class="anchored" data-anchor-id="exercices-de-réflexion">Exercices de Réflexion</h2>
<div class="callout callout-style-default callout-warning no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Warning</span>Question 1
</div>
</div>
<div class="callout-body-container callout-body">
<p>Pour chacun des scénarios suivants, proposez une méthode de clustering adaptée et justifiez votre choix :</p>
<ol type="a">
<li>Segmentation de clients avec des variables démographiques et comportementales</li>
<li>Détection de fraudes dans des transactions bancaires</li>
<li>Regroupement de documents textuels</li>
<li>Analyse de pixels d’une image satellite</li>
</ol>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Correction Question 1
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>a) Segmentation de clients:</strong></p>
<ul>
<li><strong>Méthode recommandée</strong>: <strong>k-means</strong></li>
<li><strong>Justification</strong>:
<ul>
<li>Variables démographiques et comportementales → données numériques</li>
<li>Nombre de segments généralement connu à l’avance (ex: 3-5 segments)</li>
<li>Besoin d’interprétabilité pour le marketing</li>
<li>Rapide et efficace sur grands volumes de clients</li>
</ul></li>
</ul>
<div id="8789c65a" class="cell" data-execution_count="8">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Exemple de segmentation client</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Préparation</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>X_scaled <span class="op">=</span> scaler.fit_transform(client_features)</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="co"># K-means avec 4 segments</span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">4</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>segments <span class="op">=</span> kmeans.fit_predict(X_scaled)</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Profilage des segments</span></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>profiles <span class="op">=</span> pd.DataFrame(X_scaled, columns<span class="op">=</span>feature_names)</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>profiles[<span class="st">'segment'</span>] <span class="op">=</span> segments</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(profiles.groupby(<span class="st">'segment'</span>).mean())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p><strong>b) Détection de fraudes:</strong></p>
<ul>
<li><p><strong>Méthode recommandée</strong>: <strong>DBSCAN</strong> ou <strong>Isolation Forest</strong></p></li>
<li><p><strong>Justification</strong>:</p>
<ul>
<li>Fraudes = anomalies (outliers)</li>
<li>DBSCAN identifie les points de bruit (label -1)</li>
<li>Pas besoin de connaître le nombre de types de fraude</li>
<li>Détecte des patterns de fraude de formes variées</li>
</ul></li>
</ul>
<div id="08aff0f6" class="cell" data-execution_count="9">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> DBSCAN</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="co"># DBSCAN pour détecter les anomalies</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>dbscan <span class="op">=</span> DBSCAN(eps<span class="op">=</span><span class="fl">0.5</span>, min_samples<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> dbscan.fit_predict(transactions_features)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Points anormaux (potentielles fraudes)</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>anomalies <span class="op">=</span> transactions_features[labels <span class="op">==</span> <span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Nombre de transactions suspectes: </span><span class="sc">{</span><span class="bu">len</span>(anomalies)<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p><strong>c) Regroupement de documents textuels:</strong></p>
<ul>
<li><p><strong>Méthode recommandée</strong>: <strong>k-means</strong> sur TF-IDF + <strong>Hierarchical Clustering</strong></p></li>
<li><p><strong>Justification</strong>:</p>
<ul>
<li>TF-IDF transforme texte en vecteurs numériques</li>
<li>K-means efficace en haute dimension (nombreux mots)</li>
<li>Hierarchical permet d’explorer la hiérarchie des thèmes</li>
<li>Peut combiner avec topic modeling (LDA)</li>
</ul></li>
</ul>
<div id="c8589599" class="cell" data-execution_count="10">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> TfidfVectorizer</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Vectorisation des textes</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>vectorizer <span class="op">=</span> TfidfVectorizer(max_features<span class="op">=</span><span class="dv">1000</span>, stop_words<span class="op">=</span><span class="st">'english'</span>)</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>X_tfidf <span class="op">=</span> vectorizer.fit_transform(documents)</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Clustering</span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">5</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>doc_clusters <span class="op">=</span> kmeans.fit_predict(X_tfidf)</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Top mots par cluster</span></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>terms <span class="op">=</span> vectorizer.get_feature_names_out()</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>    center <span class="op">=</span> kmeans.cluster_centers_[i]</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>    top_terms <span class="op">=</span> [terms[j] <span class="cf">for</span> j <span class="kw">in</span> center.argsort()[<span class="op">-</span><span class="dv">10</span>:]]</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Cluster </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span><span class="st">', '</span><span class="sc">.</span>join(top_terms)<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p><strong>d) Analyse de pixels d’image satellite:</strong></p>
<ul>
<li><p><strong>Méthode recommandée</strong>: <strong>k-means</strong> ou <strong>Mean Shift</strong></p></li>
<li><p><strong>Justification</strong>:</p>
<ul>
<li>Segmentation d’image = clustering de pixels (RGB ou multi-spectral)</li>
<li>K-means rapide pour millions de pixels</li>
<li>Mean Shift détecte automatiquement le nombre de segments</li>
<li>Peut identifier zones (forêt, eau, ville, etc.)</li>
</ul></li>
</ul>
<div id="b8f760d2" class="cell" data-execution_count="11">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Image satellite (exemple)</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a><span class="co"># image shape: (height, width, channels)</span></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>pixels <span class="op">=</span> image.reshape(<span class="op">-</span><span class="dv">1</span>, image.shape[<span class="dv">2</span>])  <span class="co"># Reshape en (n_pixels, channels)</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a><span class="co"># K-means sur pixels</span></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">5</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> kmeans.fit_predict(pixels)</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Reconstruction de l'image segmentée</span></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>segmented_image <span class="op">=</span> labels.reshape(image.shape[:<span class="dv">2</span>])</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>plt.imshow(segmented_image, cmap<span class="op">=</span><span class="st">'tab10'</span>)</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Segmentation de l</span><span class="ch">\'</span><span class="st">image satellite'</span>)</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-warning no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Warning</span>Question 2
</div>
</div>
<div class="callout-body-container callout-body">
<p>Pour un dataset avec 10 000 échantillons et 50 features :</p>
<ol type="a">
<li>Expliquez comment déterminer le nombre optimal de clusters pour k-means</li>
<li>Proposez une approche pour visualiser la structure des clusters</li>
<li>Quel avantage PCA peut-il apporter avant le clustering ?</li>
</ol>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Correction Question 2
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>a) Déterminer le nombre optimal de clusters:</strong></p>
<p><strong>Méthode 1: Elbow Method (Méthode du coude)</strong></p>
<div id="72e1b3f9" class="cell" data-execution_count="12">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Tester différentes valeurs de k</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>inertias <span class="op">=</span> []</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>silhouette_scores <span class="op">=</span> []</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>K_range <span class="op">=</span> <span class="bu">range</span>(<span class="dv">2</span>, <span class="dv">11</span>)</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> K_range:</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>    kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span>k, random_state<span class="op">=</span><span class="dv">42</span>, n_init<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>    kmeans.fit(X)</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>    inertias.append(kmeans.inertia_)</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>    silhouette_scores.append(silhouette_score(X, kmeans.labels_))</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualisation</span></span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>fig, (ax1, ax2) <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">5</span>))</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Courbe du coude</span></span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>ax1.plot(K_range, inertias, <span class="st">'bo-'</span>)</span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>ax1.set_xlabel(<span class="st">'Nombre de clusters (k)'</span>)</span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>ax1.set_ylabel(<span class="st">'Inertie'</span>)</span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>ax1.set_title(<span class="st">'Méthode du Coude'</span>)</span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a>ax1.grid(<span class="va">True</span>)</span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Silhouette score</span></span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a>ax2.plot(K_range, silhouette_scores, <span class="st">'go-'</span>)</span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a>ax2.set_xlabel(<span class="st">'Nombre de clusters (k)'</span>)</span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a>ax2.set_ylabel(<span class="st">'Silhouette Score'</span>)</span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a>ax2.set_title(<span class="st">'Score Silhouette'</span>)</span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a>ax2.grid(<span class="va">True</span>)</span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-33"><a href="#cb12-33" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb12-34"><a href="#cb12-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-35"><a href="#cb12-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Le k optimal est au "coude" de la courbe d'inertie</span></span>
<span id="cb12-36"><a href="#cb12-36" aria-hidden="true" tabindex="-1"></a><span class="co"># ET avec un bon silhouette score</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p><strong>Méthode 2: Gap Statistic</strong></p>
<div id="4151745c" class="cell" data-execution_count="13">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare l'inertie observée vs inertie sur données aléatoires</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> gap_statistic(X, k_max<span class="op">=</span><span class="dv">10</span>, n_refs<span class="op">=</span><span class="dv">10</span>):</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>    gaps <span class="op">=</span> []</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, k_max <span class="op">+</span> <span class="dv">1</span>):</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Inertie sur données réelles</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>        kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span>k, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>        kmeans.fit(X)</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>        real_inertia <span class="op">=</span> kmeans.inertia_</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Inertie moyenne sur données de référence</span></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>        ref_inertias <span class="op">=</span> []</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(n_refs):</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>            X_ref <span class="op">=</span> np.random.uniform(X.<span class="bu">min</span>(), X.<span class="bu">max</span>(), X.shape)</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>            kmeans_ref <span class="op">=</span> KMeans(n_clusters<span class="op">=</span>k, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>            kmeans_ref.fit(X_ref)</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>            ref_inertias.append(kmeans_ref.inertia_)</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>        gap <span class="op">=</span> np.log(np.mean(ref_inertias)) <span class="op">-</span> np.log(real_inertia)</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>        gaps.append(gap)</span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> gaps</span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a><span class="co"># K optimal = premier k où gap commence à décroître</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p><strong>Méthode 3: Silhouette Analysis détaillée</strong></p>
<div id="0aed15f6" class="cell" data-execution_count="14">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> silhouette_samples</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.cm <span class="im">as</span> cm</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> [<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>]:</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>    kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span>k, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>    labels <span class="op">=</span> kmeans.fit_predict(X)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>    silhouette_vals <span class="op">=</span> silhouette_samples(X, labels)</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>    y_lower <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(k):</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>        cluster_silhouette_vals <span class="op">=</span> silhouette_vals[labels <span class="op">==</span> i]</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>        cluster_silhouette_vals.sort()</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>        size <span class="op">=</span> cluster_silhouette_vals.shape[<span class="dv">0</span>]</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>        y_upper <span class="op">=</span> y_lower <span class="op">+</span> size</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>        plt.fill_betweenx(np.arange(y_lower, y_upper),</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>                         <span class="dv">0</span>, cluster_silhouette_vals,</span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>                         alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>        y_lower <span class="op">=</span> y_upper <span class="op">+</span> <span class="dv">10</span></span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="ss">f'Silhouette Plot (k=</span><span class="sc">{</span>k<span class="sc">}</span><span class="ss">)'</span>)</span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">'Coefficient Silhouette'</span>)</span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">'Cluster'</span>)</span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a>    plt.axvline(x<span class="op">=</span>silhouette_score(X, labels), color<span class="op">=</span><span class="st">"red"</span>, linestyle<span class="op">=</span><span class="st">"--"</span>)</span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p><strong>b) Visualiser la structure des clusters:</strong></p>
<p><strong>Approche 1: PCA pour réduction 2D/3D</strong></p>
<div id="a5843d06" class="cell" data-execution_count="15">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Réduction à 2D</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>X_pca <span class="op">=</span> pca.fit_transform(X)</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualisation</span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>scatter <span class="op">=</span> plt.scatter(X_pca[:, <span class="dv">0</span>], X_pca[:, <span class="dv">1</span>], </span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>                     c<span class="op">=</span>labels, cmap<span class="op">=</span><span class="st">'viridis'</span>, alpha<span class="op">=</span><span class="fl">0.6</span>)</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="ss">f'PC1 (</span><span class="sc">{</span>pca<span class="sc">.</span>explained_variance_ratio_[<span class="dv">0</span>]<span class="sc">:.1%}</span><span class="ss">)'</span>)</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="ss">f'PC2 (</span><span class="sc">{</span>pca<span class="sc">.</span>explained_variance_ratio_[<span class="dv">1</span>]<span class="sc">:.1%}</span><span class="ss">)'</span>)</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Clusters visualisés avec PCA'</span>)</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>plt.colorbar(scatter, label<span class="op">=</span><span class="st">'Cluster'</span>)</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Variance expliquée totale: </span><span class="sc">{</span><span class="bu">sum</span>(pca.explained_variance_ratio_)<span class="sc">:.2%}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p><strong>Approche 2: t-SNE pour visualisation non-linéaire</strong></p>
<div id="d47a438e" class="cell" data-execution_count="16">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.manifold <span class="im">import</span> TSNE</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="co"># t-SNE (plus lent mais meilleure visualisation)</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>tsne <span class="op">=</span> TSNE(n_components<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">42</span>, perplexity<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>X_tsne <span class="op">=</span> tsne.fit_transform(X)</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>plt.scatter(X_tsne[:, <span class="dv">0</span>], X_tsne[:, <span class="dv">1</span>], c<span class="op">=</span>labels, cmap<span class="op">=</span><span class="st">'tab10'</span>, alpha<span class="op">=</span><span class="fl">0.6</span>)</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Clusters visualisés avec t-SNE'</span>)</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>plt.colorbar(label<span class="op">=</span><span class="st">'Cluster'</span>)</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p><strong>Approche 3: Pairplot des features importantes</strong></p>
<div id="2d2440e1" class="cell" data-execution_count="17">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Sélectionner top features par variance</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_selection <span class="im">import</span> VarianceThreshold</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>selector <span class="op">=</span> VarianceThreshold(threshold<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>X_selected <span class="op">=</span> selector.fit_transform(X)</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Pairplot avec 4-5 features les plus variables</span></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>df_plot <span class="op">=</span> pd.DataFrame(X_selected[:, :<span class="dv">5</span>], columns<span class="op">=</span>[<span class="ss">f'F</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">'</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>)])</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>df_plot[<span class="st">'cluster'</span>] <span class="op">=</span> labels</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>sns.pairplot(df_plot, hue<span class="op">=</span><span class="st">'cluster'</span>, palette<span class="op">=</span><span class="st">'tab10'</span>)</span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p><strong>c) Avantages de PCA avant le clustering:</strong></p>
<p><strong>1. Réduction de dimension → Efficacité computationnelle</strong></p>
<div id="74f40095" class="cell" data-execution_count="18">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Sans PCA: 50 features</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>start <span class="op">=</span> time.time()</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>kmeans_full <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">5</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>kmeans_full.fit(X)  <span class="co"># X: (10000, 50)</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>time_full <span class="op">=</span> time.time() <span class="op">-</span> start</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Avec PCA: 10 features (gardant 95% de variance)</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="fl">0.95</span>)  <span class="co"># Garde 95% de variance</span></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>X_pca <span class="op">=</span> pca.fit_transform(X)  <span class="co"># X_pca: (10000, ~10)</span></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>start <span class="op">=</span> time.time()</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>kmeans_pca <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">5</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>kmeans_pca.fit(X_pca)</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>time_pca <span class="op">=</span> time.time() <span class="op">-</span> start</span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Temps sans PCA: </span><span class="sc">{</span>time_full<span class="sc">:.2f}</span><span class="ss">s"</span>)</span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Temps avec PCA: </span><span class="sc">{</span>time_pca<span class="sc">:.2f}</span><span class="ss">s"</span>)</span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accélération: </span><span class="sc">{</span>time_full<span class="op">/</span>time_pca<span class="sc">:.1f}</span><span class="ss">x"</span>)</span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Dimensions réduites: </span><span class="sc">{</span>X<span class="sc">.</span>shape[<span class="dv">1</span>]<span class="sc">}</span><span class="ss"> → </span><span class="sc">{</span>X_pca<span class="sc">.</span>shape[<span class="dv">1</span>]<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p><strong>2. Réduction du bruit</strong></p>
<div id="0dd9e0ec" class="cell" data-execution_count="19">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># PCA élimine les composantes de faible variance (souvent du bruit)</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>pca_full <span class="op">=</span> PCA()</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>pca_full.fit(X)</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Afficher la variance par composante</span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">5</span>))</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>plt.plot(<span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(pca_full.explained_variance_ratio_) <span class="op">+</span> <span class="dv">1</span>),</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>         pca_full.explained_variance_ratio_, <span class="st">'bo-'</span>)</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Composante'</span>)</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Variance expliquée'</span>)</span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Scree Plot'</span>)</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>plt.plot(<span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(pca_full.explained_variance_ratio_) <span class="op">+</span> <span class="dv">1</span>),</span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>         np.cumsum(pca_full.explained_variance_ratio_), <span class="st">'ro-'</span>)</span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Nombre de composantes'</span>)</span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Variance cumulée'</span>)</span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>plt.axhline(y<span class="op">=</span><span class="fl">0.95</span>, color<span class="op">=</span><span class="st">'g'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, label<span class="op">=</span><span class="st">'95%'</span>)</span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Variance Cumulée'</span>)</span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb19-27"><a href="#cb19-27" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb19-28"><a href="#cb19-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-29"><a href="#cb19-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Garder les composantes qui expliquent 95% de la variance</span></span>
<span id="cb19-30"><a href="#cb19-30" aria-hidden="true" tabindex="-1"></a><span class="co"># → élimine le bruit des dernières composantes</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p><strong>3. Évite la malédiction de la dimensionnalité</strong></p>
<div id="6c41d671" class="cell" data-execution_count="20">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># En haute dimension, les distances deviennent moins significatives</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.spatial.distance <span class="im">import</span> pdist, squareform</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Calcul des distances moyennes</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>distances_full <span class="op">=</span> pdist(X[:<span class="dv">100</span>])  <span class="co"># Sur 100 échantillons pour rapidité</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>distances_pca <span class="op">=</span> pdist(X_pca[:<span class="dv">100</span>])</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Distance moyenne (50D): </span><span class="sc">{</span>np<span class="sc">.</span>mean(distances_full)<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Distance moyenne (10D): </span><span class="sc">{</span>np<span class="sc">.</span>mean(distances_pca)<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Écart-type distances (50D): </span><span class="sc">{</span>np<span class="sc">.</span>std(distances_full)<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Écart-type distances (10D): </span><span class="sc">{</span>np<span class="sc">.</span>std(distances_pca)<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a><span class="co"># En dimension réduite, les distances sont plus discriminantes</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p><strong>4. Décorrélation des features</strong></p>
<div id="1a925b36" class="cell" data-execution_count="21">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># PCA produit des composantes non-corrélées</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="co"># → Améliore k-means qui suppose indépendance</span></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Corrélation avant PCA</span></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">5</span>))</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>sns.heatmap(np.corrcoef(X.T), cmap<span class="op">=</span><span class="st">'coolwarm'</span>, center<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>            cbar_kws<span class="op">=</span>{<span class="st">'label'</span>: <span class="st">'Corrélation'</span>})</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Corrélations avant PCA'</span>)</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Corrélation après PCA</span></span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>sns.heatmap(np.corrcoef(X_pca.T), cmap<span class="op">=</span><span class="st">'coolwarm'</span>, center<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>            cbar_kws<span class="op">=</span>{<span class="st">'label'</span>: <span class="st">'Corrélation'</span>})</span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Corrélations après PCA'</span>)</span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Après PCA: corrélations nulles entre composantes</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p><strong>Résumé des avantages:</strong></p>
<table class="caption-top table">
<colgroup>
<col style="width: 32%">
<col style="width: 41%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th>Avantage</th>
<th>Description</th>
<th>Impact</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Efficacité</strong></td>
<td>50 → 10 dimensions</td>
<td>5-10x plus rapide</td>
</tr>
<tr class="even">
<td><strong>Débruitage</strong></td>
<td>Élimine variance faible</td>
<td>Clusters plus nets</td>
</tr>
<tr class="odd">
<td><strong>Distances</strong></td>
<td>Plus discriminantes en faible dim</td>
<td>Meilleur clustering</td>
</tr>
<tr class="even">
<td><strong>Décorrélation</strong></td>
<td>Features indépendantes</td>
<td>K-means plus efficace</td>
</tr>
<tr class="odd">
<td><strong>Visualisation</strong></td>
<td>Réduction à 2-3D</td>
<td>Interprétation facile</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<div class="callout callout-style-default callout-warning no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Warning</span>Question 3
</div>
</div>
<div class="callout-body-container callout-body">
<p>Implémentez un pipeline complet de clustering sur le dataset Iris :</p>
<ol type="1">
<li>Chargez les données (ignorer les labels pour l’apprentissage non supervisé)</li>
<li>Appliquez PCA pour réduire à 2 dimensions</li>
<li>Testez k-means avec k=2,3,4 et comparez les résultats</li>
<li>Visualisez les clusters obtenus</li>
<li>Calculez le silhouette score pour chaque k</li>
</ol>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-8-contents" aria-controls="callout-8" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Correction Question 3
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-8" class="callout-8-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div id="fbc20fa4" class="cell" data-execution_count="22">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> datasets</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> silhouette_score, adjusted_rand_score</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Chargement des données (SANS utiliser les labels pour clustering)</span></span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"PIPELINE COMPLET DE CLUSTERING - DATASET IRIS"</span>)</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>iris <span class="op">=</span> datasets.load_iris()</span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> iris.data  <span class="co"># Features seulement (ignorer iris.target)</span></span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a>feature_names <span class="op">=</span> iris.feature_names</span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a>true_labels <span class="op">=</span> iris.target  <span class="co"># Gardé seulement pour évaluation finale</span></span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">1. Chargement des données:"</span>)</span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   Dimensions: </span><span class="sc">{</span>X<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb22-23"><a href="#cb22-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   Features: </span><span class="sc">{</span>feature_names<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb22-24"><a href="#cb22-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-25"><a href="#cb22-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Normalisation (important avant PCA)</span></span>
<span id="cb22-26"><a href="#cb22-26" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb22-27"><a href="#cb22-27" aria-hidden="true" tabindex="-1"></a>X_scaled <span class="op">=</span> scaler.fit_transform(X)</span>
<span id="cb22-28"><a href="#cb22-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   ✓ Données normalisées"</span>)</span>
<span id="cb22-29"><a href="#cb22-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-30"><a href="#cb22-30" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Application de PCA pour réduction à 2D</span></span>
<span id="cb22-31"><a href="#cb22-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">2. Réduction de dimension avec PCA:"</span>)</span>
<span id="cb22-32"><a href="#cb22-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-33"><a href="#cb22-33" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb22-34"><a href="#cb22-34" aria-hidden="true" tabindex="-1"></a>X_pca <span class="op">=</span> pca.fit_transform(X_scaled)</span>
<span id="cb22-35"><a href="#cb22-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-36"><a href="#cb22-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   Variance expliquée par composante: </span><span class="sc">{</span>pca<span class="sc">.</span>explained_variance_ratio_<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb22-37"><a href="#cb22-37" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   Variance totale expliquée: </span><span class="sc">{</span><span class="bu">sum</span>(pca.explained_variance_ratio_)<span class="sc">:.2%}</span><span class="ss">"</span>)</span>
<span id="cb22-38"><a href="#cb22-38" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   Dimensions: </span><span class="sc">{</span>X<span class="sc">.</span>shape[<span class="dv">1</span>]<span class="sc">}</span><span class="ss">D → </span><span class="sc">{</span>X_pca<span class="sc">.</span>shape[<span class="dv">1</span>]<span class="sc">}</span><span class="ss">D"</span>)</span>
<span id="cb22-39"><a href="#cb22-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-40"><a href="#cb22-40" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualisation des données après PCA (sans clustering)</span></span>
<span id="cb22-41"><a href="#cb22-41" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb22-42"><a href="#cb22-42" aria-hidden="true" tabindex="-1"></a>scatter <span class="op">=</span> plt.scatter(X_pca[:, <span class="dv">0</span>], X_pca[:, <span class="dv">1</span>], </span>
<span id="cb22-43"><a href="#cb22-43" aria-hidden="true" tabindex="-1"></a>                     c<span class="op">=</span>true_labels, cmap<span class="op">=</span><span class="st">'viridis'</span>, </span>
<span id="cb22-44"><a href="#cb22-44" aria-hidden="true" tabindex="-1"></a>                     alpha<span class="op">=</span><span class="fl">0.6</span>, edgecolors<span class="op">=</span><span class="st">'w'</span>)</span>
<span id="cb22-45"><a href="#cb22-45" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="ss">f'PC1 (</span><span class="sc">{</span>pca<span class="sc">.</span>explained_variance_ratio_[<span class="dv">0</span>]<span class="sc">:.1%}</span><span class="ss"> variance)'</span>)</span>
<span id="cb22-46"><a href="#cb22-46" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="ss">f'PC2 (</span><span class="sc">{</span>pca<span class="sc">.</span>explained_variance_ratio_[<span class="dv">1</span>]<span class="sc">:.1%}</span><span class="ss"> variance)'</span>)</span>
<span id="cb22-47"><a href="#cb22-47" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Dataset Iris après PCA (coloré par vraies classes)'</span>)</span>
<span id="cb22-48"><a href="#cb22-48" aria-hidden="true" tabindex="-1"></a>plt.colorbar(scatter, label<span class="op">=</span><span class="st">'Vraie classe'</span>)</span>
<span id="cb22-49"><a href="#cb22-49" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb22-50"><a href="#cb22-50" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb22-51"><a href="#cb22-51" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb22-52"><a href="#cb22-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-53"><a href="#cb22-53" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Test de k-means avec k=2,3,4</span></span>
<span id="cb22-54"><a href="#cb22-54" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">3. Clustering k-means avec différentes valeurs de k:"</span>)</span>
<span id="cb22-55"><a href="#cb22-55" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb22-56"><a href="#cb22-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-57"><a href="#cb22-57" aria-hidden="true" tabindex="-1"></a>K_values <span class="op">=</span> [<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>]</span>
<span id="cb22-58"><a href="#cb22-58" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> []</span>
<span id="cb22-59"><a href="#cb22-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-60"><a href="#cb22-60" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> K_values:</span>
<span id="cb22-61"><a href="#cb22-61" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Clustering</span></span>
<span id="cb22-62"><a href="#cb22-62" aria-hidden="true" tabindex="-1"></a>    kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span>k, random_state<span class="op">=</span><span class="dv">42</span>, n_init<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb22-63"><a href="#cb22-63" aria-hidden="true" tabindex="-1"></a>    labels <span class="op">=</span> kmeans.fit_predict(X_pca)</span>
<span id="cb22-64"><a href="#cb22-64" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-65"><a href="#cb22-65" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Métriques</span></span>
<span id="cb22-66"><a href="#cb22-66" aria-hidden="true" tabindex="-1"></a>    inertia <span class="op">=</span> kmeans.inertia_</span>
<span id="cb22-67"><a href="#cb22-67" aria-hidden="true" tabindex="-1"></a>    silhouette <span class="op">=</span> silhouette_score(X_pca, labels)</span>
<span id="cb22-68"><a href="#cb22-68" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-69"><a href="#cb22-69" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Comparaison avec vraies classes (juste pour curiosité)</span></span>
<span id="cb22-70"><a href="#cb22-70" aria-hidden="true" tabindex="-1"></a>    ari <span class="op">=</span> adjusted_rand_score(true_labels, labels)</span>
<span id="cb22-71"><a href="#cb22-71" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-72"><a href="#cb22-72" aria-hidden="true" tabindex="-1"></a>    results.append({</span>
<span id="cb22-73"><a href="#cb22-73" aria-hidden="true" tabindex="-1"></a>        <span class="st">'k'</span>: k,</span>
<span id="cb22-74"><a href="#cb22-74" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Inertie'</span>: inertia,</span>
<span id="cb22-75"><a href="#cb22-75" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Silhouette'</span>: silhouette,</span>
<span id="cb22-76"><a href="#cb22-76" aria-hidden="true" tabindex="-1"></a>        <span class="st">'ARI (vs vrai)'</span>: ari,</span>
<span id="cb22-77"><a href="#cb22-77" aria-hidden="true" tabindex="-1"></a>        <span class="st">'labels'</span>: labels,</span>
<span id="cb22-78"><a href="#cb22-78" aria-hidden="true" tabindex="-1"></a>        <span class="st">'centroids'</span>: kmeans.cluster_centers_</span>
<span id="cb22-79"><a href="#cb22-79" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb22-80"><a href="#cb22-80" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-81"><a href="#cb22-81" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">k = </span><span class="sc">{</span>k<span class="sc">}</span><span class="ss">:"</span>)</span>
<span id="cb22-82"><a href="#cb22-82" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   Inertie: </span><span class="sc">{</span>inertia<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb22-83"><a href="#cb22-83" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   Silhouette Score: </span><span class="sc">{</span>silhouette<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb22-84"><a href="#cb22-84" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   Taille des clusters: </span><span class="sc">{</span>np<span class="sc">.</span>bincount(labels)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb22-85"><a href="#cb22-85" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   ARI (comparaison avec vraies classes): </span><span class="sc">{</span>ari<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb22-86"><a href="#cb22-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-87"><a href="#cb22-87" aria-hidden="true" tabindex="-1"></a><span class="co"># DataFrame des résultats</span></span>
<span id="cb22-88"><a href="#cb22-88" aria-hidden="true" tabindex="-1"></a>df_results <span class="op">=</span> pd.DataFrame([{k: v <span class="cf">for</span> k, v <span class="kw">in</span> r.items() <span class="cf">if</span> k <span class="kw">not</span> <span class="kw">in</span> [<span class="st">'labels'</span>, <span class="st">'centroids'</span>]} </span>
<span id="cb22-89"><a href="#cb22-89" aria-hidden="true" tabindex="-1"></a>                          <span class="cf">for</span> r <span class="kw">in</span> results])</span>
<span id="cb22-90"><a href="#cb22-90" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">📊 Tableau récapitulatif:"</span>)</span>
<span id="cb22-91"><a href="#cb22-91" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df_results.to_string(index<span class="op">=</span><span class="va">False</span>))</span>
<span id="cb22-92"><a href="#cb22-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-93"><a href="#cb22-93" aria-hidden="true" tabindex="-1"></a><span class="co"># Meilleur k selon silhouette</span></span>
<span id="cb22-94"><a href="#cb22-94" aria-hidden="true" tabindex="-1"></a>best_k <span class="op">=</span> df_results.loc[df_results[<span class="st">'Silhouette'</span>].idxmax(), <span class="st">'k'</span>]</span>
<span id="cb22-95"><a href="#cb22-95" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">⭐ Meilleur k selon Silhouette Score: </span><span class="sc">{</span>best_k<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb22-96"><a href="#cb22-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-97"><a href="#cb22-97" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Visualisation des clusters pour chaque k</span></span>
<span id="cb22-98"><a href="#cb22-98" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">4. Visualisation des clusters:"</span>)</span>
<span id="cb22-99"><a href="#cb22-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-100"><a href="#cb22-100" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">18</span>, <span class="dv">5</span>))</span>
<span id="cb22-101"><a href="#cb22-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-102"><a href="#cb22-102" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx, result <span class="kw">in</span> <span class="bu">enumerate</span>(results):</span>
<span id="cb22-103"><a href="#cb22-103" aria-hidden="true" tabindex="-1"></a>    k <span class="op">=</span> result[<span class="st">'k'</span>]</span>
<span id="cb22-104"><a href="#cb22-104" aria-hidden="true" tabindex="-1"></a>    labels <span class="op">=</span> result[<span class="st">'labels'</span>]</span>
<span id="cb22-105"><a href="#cb22-105" aria-hidden="true" tabindex="-1"></a>    centroids <span class="op">=</span> result[<span class="st">'centroids'</span>]</span>
<span id="cb22-106"><a href="#cb22-106" aria-hidden="true" tabindex="-1"></a>    ax <span class="op">=</span> axes[idx]</span>
<span id="cb22-107"><a href="#cb22-107" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Scatter plot des points</span></span>
<span id="cb22-108"><a href="#cb22-108" aria-hidden="true" tabindex="-1"></a>    scatter <span class="op">=</span> ax.scatter(X_pca[:, <span class="dv">0</span>], X_pca[:, <span class="dv">1</span>], </span>
<span id="cb22-109"><a href="#cb22-109" aria-hidden="true" tabindex="-1"></a>                        c<span class="op">=</span>labels, cmap<span class="op">=</span><span class="st">'tab10'</span>, </span>
<span id="cb22-110"><a href="#cb22-110" aria-hidden="true" tabindex="-1"></a>                        alpha<span class="op">=</span><span class="fl">0.6</span>, edgecolors<span class="op">=</span><span class="st">'w'</span>, s<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb22-111"><a href="#cb22-111" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-112"><a href="#cb22-112" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Centroïdes</span></span>
<span id="cb22-113"><a href="#cb22-113" aria-hidden="true" tabindex="-1"></a>    ax.scatter(centroids[:, <span class="dv">0</span>], centroids[:, <span class="dv">1</span>], </span>
<span id="cb22-114"><a href="#cb22-114" aria-hidden="true" tabindex="-1"></a>              c<span class="op">=</span><span class="st">'red'</span>, marker<span class="op">=</span><span class="st">'X'</span>, s<span class="op">=</span><span class="dv">200</span>, </span>
<span id="cb22-115"><a href="#cb22-115" aria-hidden="true" tabindex="-1"></a>              edgecolors<span class="op">=</span><span class="st">'black'</span>, linewidths<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb22-116"><a href="#cb22-116" aria-hidden="true" tabindex="-1"></a>              label<span class="op">=</span><span class="st">'Centroïdes'</span>)</span>
<span id="cb22-117"><a href="#cb22-117" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-118"><a href="#cb22-118" aria-hidden="true" tabindex="-1"></a>    ax.set_xlabel(<span class="ss">f'PC1 (</span><span class="sc">{</span>pca<span class="sc">.</span>explained_variance_ratio_[<span class="dv">0</span>]<span class="sc">:.1%}</span><span class="ss">)'</span>)</span>
<span id="cb22-119"><a href="#cb22-119" aria-hidden="true" tabindex="-1"></a>    ax.set_ylabel(<span class="ss">f'PC2 (</span><span class="sc">{</span>pca<span class="sc">.</span>explained_variance_ratio_[<span class="dv">1</span>]<span class="sc">:.1%}</span><span class="ss">)'</span>)</span>
<span id="cb22-120"><a href="#cb22-120" aria-hidden="true" tabindex="-1"></a>    ax.set_title(<span class="ss">f'k=</span><span class="sc">{</span>k<span class="sc">}</span><span class="ss"> (Silhouette=</span><span class="sc">{</span>result[<span class="st">"Silhouette"</span>]<span class="sc">:.3f}</span><span class="ss">)'</span>)</span>
<span id="cb22-121"><a href="#cb22-121" aria-hidden="true" tabindex="-1"></a>    ax.legend()</span>
<span id="cb22-122"><a href="#cb22-122" aria-hidden="true" tabindex="-1"></a>    ax.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb22-123"><a href="#cb22-123" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-124"><a href="#cb22-124" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Colorbar</span></span>
<span id="cb22-125"><a href="#cb22-125" aria-hidden="true" tabindex="-1"></a>    plt.colorbar(scatter, ax<span class="op">=</span>ax, label<span class="op">=</span><span class="st">'Cluster'</span>)</span>
<span id="cb22-126"><a href="#cb22-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-127"><a href="#cb22-127" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb22-128"><a href="#cb22-128" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb22-129"><a href="#cb22-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-130"><a href="#cb22-130" aria-hidden="true" tabindex="-1"></a><span class="co"># 5. Analyse approfondie du meilleur k</span></span>
<span id="cb22-131"><a href="#cb22-131" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">5. Analyse détaillée pour k=</span><span class="sc">{</span>best_k<span class="sc">}</span><span class="ss">:"</span>)</span>
<span id="cb22-132"><a href="#cb22-132" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb22-133"><a href="#cb22-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-134"><a href="#cb22-134" aria-hidden="true" tabindex="-1"></a>best_result <span class="op">=</span> [r <span class="cf">for</span> r <span class="kw">in</span> results <span class="cf">if</span> r[<span class="st">'k'</span>] <span class="op">==</span> best_k][<span class="dv">0</span>]</span>
<span id="cb22-135"><a href="#cb22-135" aria-hidden="true" tabindex="-1"></a>best_labels <span class="op">=</span> best_result[<span class="st">'labels'</span>]</span>
<span id="cb22-136"><a href="#cb22-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-137"><a href="#cb22-137" aria-hidden="true" tabindex="-1"></a><span class="co"># Profilage des clusters</span></span>
<span id="cb22-138"><a href="#cb22-138" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Profilage des clusters (features originales):"</span>)</span>
<span id="cb22-139"><a href="#cb22-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-140"><a href="#cb22-140" aria-hidden="true" tabindex="-1"></a>df_analysis <span class="op">=</span> pd.DataFrame(X, columns<span class="op">=</span>feature_names)</span>
<span id="cb22-141"><a href="#cb22-141" aria-hidden="true" tabindex="-1"></a>df_analysis[<span class="st">'Cluster'</span>] <span class="op">=</span> best_labels</span>
<span id="cb22-142"><a href="#cb22-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-143"><a href="#cb22-143" aria-hidden="true" tabindex="-1"></a>cluster_profiles <span class="op">=</span> df_analysis.groupby(<span class="st">'Cluster'</span>).agg([<span class="st">'mean'</span>, <span class="st">'std'</span>])</span>
<span id="cb22-144"><a href="#cb22-144" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(cluster_profiles)</span>
<span id="cb22-145"><a href="#cb22-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-146"><a href="#cb22-146" aria-hidden="true" tabindex="-1"></a><span class="co"># Heatmap des caractéristiques par cluster</span></span>
<span id="cb22-147"><a href="#cb22-147" aria-hidden="true" tabindex="-1"></a>cluster_means <span class="op">=</span> df_analysis.groupby(<span class="st">'Cluster'</span>).mean()</span>
<span id="cb22-148"><a href="#cb22-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-149"><a href="#cb22-149" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb22-150"><a href="#cb22-150" aria-hidden="true" tabindex="-1"></a>sns.heatmap(cluster_means.T, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">'.2f'</span>, cmap<span class="op">=</span><span class="st">'YlOrRd'</span>,</span>
<span id="cb22-151"><a href="#cb22-151" aria-hidden="true" tabindex="-1"></a>            cbar_kws<span class="op">=</span>{<span class="st">'label'</span>: <span class="st">'Valeur moyenne'</span>})</span>
<span id="cb22-152"><a href="#cb22-152" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Cluster'</span>)</span>
<span id="cb22-153"><a href="#cb22-153" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Feature'</span>)</span>
<span id="cb22-154"><a href="#cb22-154" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="ss">f'Profil des </span><span class="sc">{</span>best_k<span class="sc">}</span><span class="ss"> clusters (valeurs moyennes)'</span>)</span>
<span id="cb22-155"><a href="#cb22-155" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb22-156"><a href="#cb22-156" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb22-157"><a href="#cb22-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-158"><a href="#cb22-158" aria-hidden="true" tabindex="-1"></a><span class="co"># Comparaison avec les vraies classes (curiosité académique)</span></span>
<span id="cb22-159"><a href="#cb22-159" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">📈 Comparaison avec les vraies espèces d'Iris:"</span>)</span>
<span id="cb22-160"><a href="#cb22-160" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"(Note: Le clustering est NON SUPERVISÉ, cette comparaison est"</span>)</span>
<span id="cb22-161"><a href="#cb22-161" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">" juste pour comprendre ce que l'algorithme a trouvé)"</span>)</span>
<span id="cb22-162"><a href="#cb22-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-163"><a href="#cb22-163" aria-hidden="true" tabindex="-1"></a>confusion_unsupervised <span class="op">=</span> pd.crosstab(</span>
<span id="cb22-164"><a href="#cb22-164" aria-hidden="true" tabindex="-1"></a>    pd.Series(true_labels, name<span class="op">=</span><span class="st">'Vraie espèce'</span>),</span>
<span id="cb22-165"><a href="#cb22-165" aria-hidden="true" tabindex="-1"></a>    pd.Series(best_labels, name<span class="op">=</span><span class="st">'Cluster trouvé'</span>)</span>
<span id="cb22-166"><a href="#cb22-166" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb22-167"><a href="#cb22-167" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(confusion_unsupervised)</span>
<span id="cb22-168"><a href="#cb22-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-169"><a href="#cb22-169" aria-hidden="true" tabindex="-1"></a><span class="co"># Conclusion</span></span>
<span id="cb22-170"><a href="#cb22-170" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb22-171"><a href="#cb22-171" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"CONCLUSION"</span>)</span>
<span id="cb22-172"><a href="#cb22-172" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb22-173"><a href="#cb22-173" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"✓ PCA a réduit les données de 4D à 2D"</span>)</span>
<span id="cb22-174"><a href="#cb22-174" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"✓ </span><span class="sc">{</span><span class="bu">sum</span>(pca.explained_variance_ratio_)<span class="sc">:.1%}</span><span class="ss"> de variance préservée"</span>)</span>
<span id="cb22-175"><a href="#cb22-175" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"✓ K optimal selon silhouette: </span><span class="sc">{</span>best_k<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb22-176"><a href="#cb22-176" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"✓ Silhouette score: </span><span class="sc">{</span>best_result[<span class="st">'Silhouette'</span>]<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb22-177"><a href="#cb22-177" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"✓ Les clusters correspondent </span><span class="sc">{</span><span class="st">'assez bien'</span> <span class="cf">if</span> best_result[<span class="st">'ARI (vs vrai)'</span>] <span class="op">&gt;</span> <span class="fl">0.7</span> <span class="cf">else</span> <span class="st">'partiellement'</span><span class="sc">}</span><span class="ss"> aux vraies espèces"</span>)</span>
<span id="cb22-178"><a href="#cb22-178" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  (ARI = </span><span class="sc">{</span>best_result[<span class="st">'ARI (vs vrai)'</span>]<span class="sc">:.3f}</span><span class="ss">)"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p><strong>Résultat attendu:</strong></p>
<p>Le pipeline devrait révéler que:</p>
<ul>
<li><strong>k=3</strong> est optimal (correspond aux 3 espèces d’Iris)</li>
<li>Le silhouette score sera autour de 0.5-0.6</li>
<li>PCA capture environ 95% de la variance en 2D</li>
<li>Les clusters trouvés correspondent assez bien aux vraies espèces</li>
<li>Une espèce (Setosa) sera bien séparée, les deux autres se chevaucheront un peu</li>
</ul>
</div>
</div>
</div>
</section>
<section id="résumé-de-la-séance" class="level2">
<h2 class="anchored" data-anchor-id="résumé-de-la-séance">Résumé de la Séance</h2>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Important</span>Points clés à retenir
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li><strong>Apprentissage non supervisé</strong> = découvrir des patterns dans des données non étiquetées</li>
<li><strong>Clustering</strong> = regrouper des données similaires (k-means, DBSCAN, hiérarchique)</li>
<li><strong>Mesures de qualité</strong> : silhouette score, inertie, Davies-Bouldin</li>
<li><strong>Réduction de dimension</strong> : PCA (linéaire), t-SNE (non-linéaire)</li>
<li><strong>Applications</strong> : segmentation client, analyse de documents, traitement d’image</li>
<li><strong>Défis</strong> : choix du nombre de clusters, qualité sans vérité terrain</li>
</ol>
</div>
</div>
</section>
<section id="lectures-complémentaires" class="level2">
<h2 class="anchored" data-anchor-id="lectures-complémentaires">Lectures Complémentaires</h2>
<ol type="1">
<li>Géron, A. (2019) - Chapitre 9: Unsupervised Learning Techniques</li>
<li><a href="https://scikit-learn.org/stable/modules/clustering.html">Scikit-learn Clustering Documentation</a></li>
<li><a href="https://jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf">Visualizing Data using t-SNE</a></li>
</ol>


<!-- -->

</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/nevermind78\.github\.io\/Ml_DL\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./seance8.html" class="pagination-link" aria-label="Séance 8: TP3 - Régression &amp; Optimisation">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-title">Séance 8: TP3 - Régression &amp; Optimisation</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./seance10.html" class="pagination-link" aria-label="Séance 10: TP4 - Clustering &amp; Réduction de Dimension">
        <span class="nav-page-text"><span class="chapter-title">Séance 10: TP4 - Clustering &amp; Réduction de Dimension</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb23" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># Séance 9: Apprentissage Non Supervisé</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>::: {.callout-note icon=false}</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="fu">## Informations de la séance</span></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Type**: Cours</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Durée**: 2h</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Objectifs**: Obj8, Obj9</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a><span class="fu">## Définitions et Principes</span></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>L'**apprentissage non supervisé** est un type d'apprentissage où le modèle apprend à partir de **données non étiquetées**, sans réponses connues.</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>**Objectif principal**: Découvrir des structures, des patterns ou des regroupements naturels dans les données.</span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip}</span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a><span class="fu">## Pourquoi l'apprentissage non supervisé ?</span></span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Les données étiquetées sont rares ou coûteuses à obtenir</span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Exploration de données inconnues</span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Réduction de dimension pour visualisation</span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Détection d'anomalies</span>
<span id="cb23-22"><a href="#cb23-22" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb23-23"><a href="#cb23-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-24"><a href="#cb23-24" aria-hidden="true" tabindex="-1"></a><span class="fu">## Clustering (Regroupement)</span></span>
<span id="cb23-25"><a href="#cb23-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-26"><a href="#cb23-26" aria-hidden="true" tabindex="-1"></a>Le **clustering** consiste à regrouper des données similaires dans des clusters (groupes).</span>
<span id="cb23-27"><a href="#cb23-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-28"><a href="#cb23-28" aria-hidden="true" tabindex="-1"></a><span class="fu">### k-means</span></span>
<span id="cb23-29"><a href="#cb23-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-30"><a href="#cb23-30" aria-hidden="true" tabindex="-1"></a>L'algorithme **k-means** est l'une des méthodes de clustering les plus populaires.</span>
<span id="cb23-31"><a href="#cb23-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-32"><a href="#cb23-32" aria-hidden="true" tabindex="-1"></a>**Principe**:</span>
<span id="cb23-33"><a href="#cb23-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-34"><a href="#cb23-34" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Choisir k points initiaux (centroïdes)</span>
<span id="cb23-35"><a href="#cb23-35" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Assigner chaque point au centroïde le plus proche</span>
<span id="cb23-36"><a href="#cb23-36" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Recalculer les centroïdes (moyenne des points du cluster)</span>
<span id="cb23-37"><a href="#cb23-37" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>Répéter jusqu'à convergence</span>
<span id="cb23-38"><a href="#cb23-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-41"><a href="#cb23-41" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-42"><a href="#cb23-42" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb23-43"><a href="#cb23-43" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb23-44"><a href="#cb23-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-45"><a href="#cb23-45" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb23-46"><a href="#cb23-46" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb23-47"><a href="#cb23-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-48"><a href="#cb23-48" aria-hidden="true" tabindex="-1"></a><span class="co"># Données non étiquetées</span></span>
<span id="cb23-49"><a href="#cb23-49" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.array([[<span class="dv">1</span>, <span class="dv">2</span>], [<span class="dv">1</span>, <span class="dv">4</span>], [<span class="dv">1</span>, <span class="dv">0</span>],</span>
<span id="cb23-50"><a href="#cb23-50" aria-hidden="true" tabindex="-1"></a>              [<span class="dv">10</span>, <span class="dv">2</span>], [<span class="dv">10</span>, <span class="dv">4</span>], [<span class="dv">10</span>, <span class="dv">0</span>]])</span>
<span id="cb23-51"><a href="#cb23-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-52"><a href="#cb23-52" aria-hidden="true" tabindex="-1"></a><span class="co"># Clustering avec k=2</span></span>
<span id="cb23-53"><a href="#cb23-53" aria-hidden="true" tabindex="-1"></a>kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb23-54"><a href="#cb23-54" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> kmeans.fit_predict(X)</span>
<span id="cb23-55"><a href="#cb23-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-56"><a href="#cb23-56" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Labels des clusters:"</span>, labels)</span>
<span id="cb23-57"><a href="#cb23-57" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Centroïdes:"</span>, kmeans.cluster_centers_)</span>
<span id="cb23-58"><a href="#cb23-58" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-59"><a href="#cb23-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-60"><a href="#cb23-60" aria-hidden="true" tabindex="-1"></a>**Avantages**:</span>
<span id="cb23-61"><a href="#cb23-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-62"><a href="#cb23-62" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Simple et rapide</span>
<span id="cb23-63"><a href="#cb23-63" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Évolutif pour grands datasets</span>
<span id="cb23-64"><a href="#cb23-64" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Résultats faciles à interpréter</span>
<span id="cb23-65"><a href="#cb23-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-66"><a href="#cb23-66" aria-hidden="true" tabindex="-1"></a>**Inconvénients**:</span>
<span id="cb23-67"><a href="#cb23-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-68"><a href="#cb23-68" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Nécessite de spécifier k</span>
<span id="cb23-69"><a href="#cb23-69" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Sensible aux valeurs aberrantes</span>
<span id="cb23-70"><a href="#cb23-70" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Suppose des clusters sphériques et de taille similaire</span>
<span id="cb23-71"><a href="#cb23-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-72"><a href="#cb23-72" aria-hidden="true" tabindex="-1"></a><span class="fu">### DBSCAN (Density-Based Spatial Clustering)</span></span>
<span id="cb23-73"><a href="#cb23-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-74"><a href="#cb23-74" aria-hidden="true" tabindex="-1"></a>**DBSCAN** regroupe les points basés sur la densité.</span>
<span id="cb23-75"><a href="#cb23-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-76"><a href="#cb23-76" aria-hidden="true" tabindex="-1"></a>**Paramètres clés**:</span>
<span id="cb23-77"><a href="#cb23-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-78"><a href="#cb23-78" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**eps**: distance maximale entre deux points pour être considérés voisins</span>
<span id="cb23-79"><a href="#cb23-79" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**min_samples**: nombre minimum de points pour former un cluster dense</span>
<span id="cb23-80"><a href="#cb23-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-83"><a href="#cb23-83" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-84"><a href="#cb23-84" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb23-85"><a href="#cb23-85" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb23-86"><a href="#cb23-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-87"><a href="#cb23-87" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> DBSCAN</span>
<span id="cb23-88"><a href="#cb23-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-89"><a href="#cb23-89" aria-hidden="true" tabindex="-1"></a><span class="co"># Clustering par densité</span></span>
<span id="cb23-90"><a href="#cb23-90" aria-hidden="true" tabindex="-1"></a>dbscan <span class="op">=</span> DBSCAN(eps<span class="op">=</span><span class="fl">1.5</span>, min_samples<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb23-91"><a href="#cb23-91" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> dbscan.fit_predict(X)</span>
<span id="cb23-92"><a href="#cb23-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-93"><a href="#cb23-93" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Labels DBSCAN:"</span>, labels)</span>
<span id="cb23-94"><a href="#cb23-94" aria-hidden="true" tabindex="-1"></a><span class="co"># -1 = bruit (outliers)</span></span>
<span id="cb23-95"><a href="#cb23-95" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-96"><a href="#cb23-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-97"><a href="#cb23-97" aria-hidden="true" tabindex="-1"></a>**Avantages**:</span>
<span id="cb23-98"><a href="#cb23-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-99"><a href="#cb23-99" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Pas besoin de spécifier le nombre de clusters</span>
<span id="cb23-100"><a href="#cb23-100" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Détecte les clusters de forme arbitraire</span>
<span id="cb23-101"><a href="#cb23-101" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Robuste aux outliers</span>
<span id="cb23-102"><a href="#cb23-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-103"><a href="#cb23-103" aria-hidden="true" tabindex="-1"></a>**Inconvénients**:</span>
<span id="cb23-104"><a href="#cb23-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-105"><a href="#cb23-105" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Sensible aux paramètres eps et min_samples</span>
<span id="cb23-106"><a href="#cb23-106" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Difficulté avec des densités variées</span>
<span id="cb23-107"><a href="#cb23-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-108"><a href="#cb23-108" aria-hidden="true" tabindex="-1"></a><span class="fu">### Autres méthodes</span></span>
<span id="cb23-109"><a href="#cb23-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-110"><a href="#cb23-110" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Agglomerative Clustering**: approche hiérarchique</span>
<span id="cb23-111"><a href="#cb23-111" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Gaussian Mixture Models (GMM)**: modèle probabiliste</span>
<span id="cb23-112"><a href="#cb23-112" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Mean Shift**: basé sur la densité de noyau</span>
<span id="cb23-113"><a href="#cb23-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-114"><a href="#cb23-114" aria-hidden="true" tabindex="-1"></a><span class="fu">## Mesures de Qualité</span></span>
<span id="cb23-115"><a href="#cb23-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-116"><a href="#cb23-116" aria-hidden="true" tabindex="-1"></a>Comment évaluer la qualité d'un clustering sans labels vrais ?</span>
<span id="cb23-117"><a href="#cb23-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-118"><a href="#cb23-118" aria-hidden="true" tabindex="-1"></a><span class="fu">### Silhouette Score</span></span>
<span id="cb23-119"><a href="#cb23-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-120"><a href="#cb23-120" aria-hidden="true" tabindex="-1"></a>Mesure de cohérence intra-cluster et séparation inter-cluster.</span>
<span id="cb23-121"><a href="#cb23-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-122"><a href="#cb23-122" aria-hidden="true" tabindex="-1"></a>**Valeurs**:</span>
<span id="cb23-123"><a href="#cb23-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-124"><a href="#cb23-124" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Proche de 1: bonne séparation</span>
<span id="cb23-125"><a href="#cb23-125" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Proche de 0: clusters se chevauchent</span>
<span id="cb23-126"><a href="#cb23-126" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Négatif: mauvais clustering</span>
<span id="cb23-127"><a href="#cb23-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-130"><a href="#cb23-130" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-131"><a href="#cb23-131" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb23-132"><a href="#cb23-132" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb23-133"><a href="#cb23-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-134"><a href="#cb23-134" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> silhouette_score</span>
<span id="cb23-135"><a href="#cb23-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-136"><a href="#cb23-136" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> silhouette_score(X, labels)</span>
<span id="cb23-137"><a href="#cb23-137" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Silhouette Score: </span><span class="sc">{</span>score<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb23-138"><a href="#cb23-138" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-139"><a href="#cb23-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-140"><a href="#cb23-140" aria-hidden="true" tabindex="-1"></a><span class="fu">### Inertie (Elbow Method)</span></span>
<span id="cb23-141"><a href="#cb23-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-142"><a href="#cb23-142" aria-hidden="true" tabindex="-1"></a>Somme des distances carrées des points à leur centroïde.</span>
<span id="cb23-143"><a href="#cb23-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-146"><a href="#cb23-146" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-147"><a href="#cb23-147" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb23-148"><a href="#cb23-148" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb23-149"><a href="#cb23-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-150"><a href="#cb23-150" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb23-151"><a href="#cb23-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-152"><a href="#cb23-152" aria-hidden="true" tabindex="-1"></a>inertias <span class="op">=</span> []</span>
<span id="cb23-153"><a href="#cb23-153" aria-hidden="true" tabindex="-1"></a>K <span class="op">=</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">10</span>)</span>
<span id="cb23-154"><a href="#cb23-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-155"><a href="#cb23-155" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> K:</span>
<span id="cb23-156"><a href="#cb23-156" aria-hidden="true" tabindex="-1"></a>    kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span>k, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb23-157"><a href="#cb23-157" aria-hidden="true" tabindex="-1"></a>    kmeans.fit(X)</span>
<span id="cb23-158"><a href="#cb23-158" aria-hidden="true" tabindex="-1"></a>    inertias.append(kmeans.inertia_)</span>
<span id="cb23-159"><a href="#cb23-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-160"><a href="#cb23-160" aria-hidden="true" tabindex="-1"></a>plt.plot(K, inertias, <span class="st">'bo-'</span>)</span>
<span id="cb23-161"><a href="#cb23-161" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Nombre de clusters (k)'</span>)</span>
<span id="cb23-162"><a href="#cb23-162" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Inertie'</span>)</span>
<span id="cb23-163"><a href="#cb23-163" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Méthode du coude (Elbow Method)'</span>)</span>
<span id="cb23-164"><a href="#cb23-164" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb23-165"><a href="#cb23-165" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb23-166"><a href="#cb23-166" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-167"><a href="#cb23-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-168"><a href="#cb23-168" aria-hidden="true" tabindex="-1"></a><span class="fu">### Davies-Bouldin Index</span></span>
<span id="cb23-169"><a href="#cb23-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-170"><a href="#cb23-170" aria-hidden="true" tabindex="-1"></a>Mesure de similarité moyenne entre clusters.</span>
<span id="cb23-171"><a href="#cb23-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-172"><a href="#cb23-172" aria-hidden="true" tabindex="-1"></a><span class="fu">## Applications Réelles</span></span>
<span id="cb23-173"><a href="#cb23-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-174"><a href="#cb23-174" aria-hidden="true" tabindex="-1"></a><span class="fu">### Segmentation Client</span></span>
<span id="cb23-175"><a href="#cb23-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-178"><a href="#cb23-178" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-179"><a href="#cb23-179" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb23-180"><a href="#cb23-180" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb23-181"><a href="#cb23-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-182"><a href="#cb23-182" aria-hidden="true" tabindex="-1"></a><span class="co"># Exemple fictif de segmentation client</span></span>
<span id="cb23-183"><a href="#cb23-183" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb23-184"><a href="#cb23-184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-185"><a href="#cb23-185" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> {</span>
<span id="cb23-186"><a href="#cb23-186" aria-hidden="true" tabindex="-1"></a>    <span class="st">'age'</span>: [<span class="dv">25</span>, <span class="dv">30</span>, <span class="dv">35</span>, <span class="dv">40</span>, <span class="dv">45</span>, <span class="dv">50</span>, <span class="dv">55</span>, <span class="dv">60</span>],</span>
<span id="cb23-187"><a href="#cb23-187" aria-hidden="true" tabindex="-1"></a>    <span class="st">'revenu_annuel_k'</span>: [<span class="dv">40</span>, <span class="dv">45</span>, <span class="dv">50</span>, <span class="dv">80</span>, <span class="dv">90</span>, <span class="dv">30</span>, <span class="dv">35</span>, <span class="dv">25</span>],</span>
<span id="cb23-188"><a href="#cb23-188" aria-hidden="true" tabindex="-1"></a>    <span class="st">'score_depense'</span>: [<span class="dv">8</span>, <span class="dv">7</span>, <span class="dv">6</span>, <span class="dv">9</span>, <span class="dv">8</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">2</span>]</span>
<span id="cb23-189"><a href="#cb23-189" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb23-190"><a href="#cb23-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-191"><a href="#cb23-191" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(data)</span>
<span id="cb23-192"><a href="#cb23-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-193"><a href="#cb23-193" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb23-194"><a href="#cb23-194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-195"><a href="#cb23-195" aria-hidden="true" tabindex="-1"></a><span class="co"># Normalisation</span></span>
<span id="cb23-196"><a href="#cb23-196" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb23-197"><a href="#cb23-197" aria-hidden="true" tabindex="-1"></a>X_scaled <span class="op">=</span> scaler.fit_transform(df)</span>
<span id="cb23-198"><a href="#cb23-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-199"><a href="#cb23-199" aria-hidden="true" tabindex="-1"></a><span class="co"># Clustering</span></span>
<span id="cb23-200"><a href="#cb23-200" aria-hidden="true" tabindex="-1"></a>kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">3</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb23-201"><a href="#cb23-201" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'cluster'</span>] <span class="op">=</span> kmeans.fit_predict(X_scaled)</span>
<span id="cb23-202"><a href="#cb23-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-203"><a href="#cb23-203" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df.groupby(<span class="st">'cluster'</span>).mean())</span>
<span id="cb23-204"><a href="#cb23-204" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-205"><a href="#cb23-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-206"><a href="#cb23-206" aria-hidden="true" tabindex="-1"></a><span class="fu">### Regroupement de Documents</span></span>
<span id="cb23-207"><a href="#cb23-207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-208"><a href="#cb23-208" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Groupement d'articles par thème</span>
<span id="cb23-209"><a href="#cb23-209" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Organisation d'emails</span>
<span id="cb23-210"><a href="#cb23-210" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Catégorisation de produits</span>
<span id="cb23-211"><a href="#cb23-211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-212"><a href="#cb23-212" aria-hidden="true" tabindex="-1"></a><span class="fu">### Analyse d'Images</span></span>
<span id="cb23-213"><a href="#cb23-213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-214"><a href="#cb23-214" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Segmentation d'image</span>
<span id="cb23-215"><a href="#cb23-215" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Regroupement de pixels similaires</span>
<span id="cb23-216"><a href="#cb23-216" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Compression d'image</span>
<span id="cb23-217"><a href="#cb23-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-218"><a href="#cb23-218" aria-hidden="true" tabindex="-1"></a><span class="fu">## Réduction de Dimension</span></span>
<span id="cb23-219"><a href="#cb23-219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-220"><a href="#cb23-220" aria-hidden="true" tabindex="-1"></a><span class="fu">### Pourquoi réduire la dimension ?</span></span>
<span id="cb23-221"><a href="#cb23-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-222"><a href="#cb23-222" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Visualisation de données multidimensionnelles</span>
<span id="cb23-223"><a href="#cb23-223" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Réduction du bruit</span>
<span id="cb23-224"><a href="#cb23-224" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Accélération des algorithmes</span>
<span id="cb23-225"><a href="#cb23-225" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Éviter le "fléau de la dimension"</span>
<span id="cb23-226"><a href="#cb23-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-227"><a href="#cb23-227" aria-hidden="true" tabindex="-1"></a><span class="fu">### PCA (Principal Component Analysis)</span></span>
<span id="cb23-228"><a href="#cb23-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-229"><a href="#cb23-229" aria-hidden="true" tabindex="-1"></a>**PCA** transforme les données en composantes orthogonales capturant la variance maximale.</span>
<span id="cb23-230"><a href="#cb23-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-233"><a href="#cb23-233" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-234"><a href="#cb23-234" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb23-235"><a href="#cb23-235" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb23-236"><a href="#cb23-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-237"><a href="#cb23-237" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb23-238"><a href="#cb23-238" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb23-239"><a href="#cb23-239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-240"><a href="#cb23-240" aria-hidden="true" tabindex="-1"></a><span class="co"># Données de démonstration</span></span>
<span id="cb23-241"><a href="#cb23-241" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb23-242"><a href="#cb23-242" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.random.randn(<span class="dv">100</span>, <span class="dv">5</span>)  <span class="co"># 100 échantillons, 5 features</span></span>
<span id="cb23-243"><a href="#cb23-243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-244"><a href="#cb23-244" aria-hidden="true" tabindex="-1"></a><span class="co"># PCA</span></span>
<span id="cb23-245"><a href="#cb23-245" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb23-246"><a href="#cb23-246" aria-hidden="true" tabindex="-1"></a>X_pca <span class="op">=</span> pca.fit_transform(X)</span>
<span id="cb23-247"><a href="#cb23-247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-248"><a href="#cb23-248" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Variance expliquée: </span><span class="sc">{</span>pca<span class="sc">.</span>explained_variance_ratio_<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-249"><a href="#cb23-249" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Variance totale expliquée: </span><span class="sc">{</span><span class="bu">sum</span>(pca.explained_variance_ratio_)<span class="sc">:.2%}</span><span class="ss">"</span>)</span>
<span id="cb23-250"><a href="#cb23-250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-251"><a href="#cb23-251" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualisation</span></span>
<span id="cb23-252"><a href="#cb23-252" aria-hidden="true" tabindex="-1"></a>plt.scatter(X_pca[:, <span class="dv">0</span>], X_pca[:, <span class="dv">1</span>])</span>
<span id="cb23-253"><a href="#cb23-253" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Première composante principale'</span>)</span>
<span id="cb23-254"><a href="#cb23-254" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Deuxième composante principale'</span>)</span>
<span id="cb23-255"><a href="#cb23-255" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'PCA - Visualisation 2D'</span>)</span>
<span id="cb23-256"><a href="#cb23-256" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb23-257"><a href="#cb23-257" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-258"><a href="#cb23-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-259"><a href="#cb23-259" aria-hidden="true" tabindex="-1"></a><span class="fu">### t-SNE (t-Distributed Stochastic Neighbor Embedding)</span></span>
<span id="cb23-260"><a href="#cb23-260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-261"><a href="#cb23-261" aria-hidden="true" tabindex="-1"></a>Méthode non linéaire particulièrement efficace pour la visualisation.</span>
<span id="cb23-262"><a href="#cb23-262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-265"><a href="#cb23-265" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-266"><a href="#cb23-266" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb23-267"><a href="#cb23-267" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb23-268"><a href="#cb23-268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-269"><a href="#cb23-269" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.manifold <span class="im">import</span> TSNE</span>
<span id="cb23-270"><a href="#cb23-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-271"><a href="#cb23-271" aria-hidden="true" tabindex="-1"></a>tsne <span class="op">=</span> TSNE(n_components<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb23-272"><a href="#cb23-272" aria-hidden="true" tabindex="-1"></a>X_tsne <span class="op">=</span> tsne.fit_transform(X)</span>
<span id="cb23-273"><a href="#cb23-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-274"><a href="#cb23-274" aria-hidden="true" tabindex="-1"></a>plt.scatter(X_tsne[:, <span class="dv">0</span>], X_tsne[:, <span class="dv">1</span>])</span>
<span id="cb23-275"><a href="#cb23-275" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'t-SNE 1'</span>)</span>
<span id="cb23-276"><a href="#cb23-276" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'t-SNE 2'</span>)</span>
<span id="cb23-277"><a href="#cb23-277" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'t-SNE - Visualisation 2D'</span>)</span>
<span id="cb23-278"><a href="#cb23-278" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb23-279"><a href="#cb23-279" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-280"><a href="#cb23-280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-281"><a href="#cb23-281" aria-hidden="true" tabindex="-1"></a><span class="fu">## Exercices de Réflexion</span></span>
<span id="cb23-282"><a href="#cb23-282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-283"><a href="#cb23-283" aria-hidden="true" tabindex="-1"></a>::: {.callout-warning icon=false}</span>
<span id="cb23-284"><a href="#cb23-284" aria-hidden="true" tabindex="-1"></a><span class="fu">## Question 1</span></span>
<span id="cb23-285"><a href="#cb23-285" aria-hidden="true" tabindex="-1"></a>Pour chacun des scénarios suivants, proposez une méthode de clustering adaptée et justifiez votre choix :</span>
<span id="cb23-286"><a href="#cb23-286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-287"><a href="#cb23-287" aria-hidden="true" tabindex="-1"></a>a) Segmentation de clients avec des variables démographiques et comportementales</span>
<span id="cb23-288"><a href="#cb23-288" aria-hidden="true" tabindex="-1"></a>b) Détection de fraudes dans des transactions bancaires</span>
<span id="cb23-289"><a href="#cb23-289" aria-hidden="true" tabindex="-1"></a>c) Regroupement de documents textuels</span>
<span id="cb23-290"><a href="#cb23-290" aria-hidden="true" tabindex="-1"></a>d) Analyse de pixels d'une image satellite</span>
<span id="cb23-291"><a href="#cb23-291" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb23-292"><a href="#cb23-292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-293"><a href="#cb23-293" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb23-294"><a href="#cb23-294" aria-hidden="true" tabindex="-1"></a><span class="fu">## Correction Question 1</span></span>
<span id="cb23-295"><a href="#cb23-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-296"><a href="#cb23-296" aria-hidden="true" tabindex="-1"></a>**a) Segmentation de clients:**</span>
<span id="cb23-297"><a href="#cb23-297" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-298"><a href="#cb23-298" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Méthode recommandée**: **k-means**</span>
<span id="cb23-299"><a href="#cb23-299" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Justification**:</span>
<span id="cb23-300"><a href="#cb23-300" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Variables démographiques et comportementales → données numériques</span>
<span id="cb23-301"><a href="#cb23-301" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Nombre de segments généralement connu à l'avance (ex: 3-5 segments)</span>
<span id="cb23-302"><a href="#cb23-302" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Besoin d'interprétabilité pour le marketing</span>
<span id="cb23-303"><a href="#cb23-303" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Rapide et efficace sur grands volumes de clients</span>
<span id="cb23-304"><a href="#cb23-304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-307"><a href="#cb23-307" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-308"><a href="#cb23-308" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb23-309"><a href="#cb23-309" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb23-310"><a href="#cb23-310" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-311"><a href="#cb23-311" aria-hidden="true" tabindex="-1"></a><span class="co"># Exemple de segmentation client</span></span>
<span id="cb23-312"><a href="#cb23-312" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb23-313"><a href="#cb23-313" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb23-314"><a href="#cb23-314" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-315"><a href="#cb23-315" aria-hidden="true" tabindex="-1"></a><span class="co"># Préparation</span></span>
<span id="cb23-316"><a href="#cb23-316" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb23-317"><a href="#cb23-317" aria-hidden="true" tabindex="-1"></a>X_scaled <span class="op">=</span> scaler.fit_transform(client_features)</span>
<span id="cb23-318"><a href="#cb23-318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-319"><a href="#cb23-319" aria-hidden="true" tabindex="-1"></a><span class="co"># K-means avec 4 segments</span></span>
<span id="cb23-320"><a href="#cb23-320" aria-hidden="true" tabindex="-1"></a>kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">4</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb23-321"><a href="#cb23-321" aria-hidden="true" tabindex="-1"></a>segments <span class="op">=</span> kmeans.fit_predict(X_scaled)</span>
<span id="cb23-322"><a href="#cb23-322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-323"><a href="#cb23-323" aria-hidden="true" tabindex="-1"></a><span class="co"># Profilage des segments</span></span>
<span id="cb23-324"><a href="#cb23-324" aria-hidden="true" tabindex="-1"></a>profiles <span class="op">=</span> pd.DataFrame(X_scaled, columns<span class="op">=</span>feature_names)</span>
<span id="cb23-325"><a href="#cb23-325" aria-hidden="true" tabindex="-1"></a>profiles[<span class="st">'segment'</span>] <span class="op">=</span> segments</span>
<span id="cb23-326"><a href="#cb23-326" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(profiles.groupby(<span class="st">'segment'</span>).mean())</span>
<span id="cb23-327"><a href="#cb23-327" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-328"><a href="#cb23-328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-329"><a href="#cb23-329" aria-hidden="true" tabindex="-1"></a>**b) Détection de fraudes:**</span>
<span id="cb23-330"><a href="#cb23-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-331"><a href="#cb23-331" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Méthode recommandée**: **DBSCAN** ou **Isolation Forest**</span>
<span id="cb23-332"><a href="#cb23-332" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Justification**:</span>
<span id="cb23-333"><a href="#cb23-333" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-334"><a href="#cb23-334" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Fraudes = anomalies (outliers)</span>
<span id="cb23-335"><a href="#cb23-335" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>DBSCAN identifie les points de bruit (label -1)</span>
<span id="cb23-336"><a href="#cb23-336" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Pas besoin de connaître le nombre de types de fraude</span>
<span id="cb23-337"><a href="#cb23-337" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Détecte des patterns de fraude de formes variées</span>
<span id="cb23-338"><a href="#cb23-338" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-341"><a href="#cb23-341" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-342"><a href="#cb23-342" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb23-343"><a href="#cb23-343" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb23-344"><a href="#cb23-344" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-345"><a href="#cb23-345" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> DBSCAN</span>
<span id="cb23-346"><a href="#cb23-346" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-347"><a href="#cb23-347" aria-hidden="true" tabindex="-1"></a><span class="co"># DBSCAN pour détecter les anomalies</span></span>
<span id="cb23-348"><a href="#cb23-348" aria-hidden="true" tabindex="-1"></a>dbscan <span class="op">=</span> DBSCAN(eps<span class="op">=</span><span class="fl">0.5</span>, min_samples<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb23-349"><a href="#cb23-349" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> dbscan.fit_predict(transactions_features)</span>
<span id="cb23-350"><a href="#cb23-350" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-351"><a href="#cb23-351" aria-hidden="true" tabindex="-1"></a><span class="co"># Points anormaux (potentielles fraudes)</span></span>
<span id="cb23-352"><a href="#cb23-352" aria-hidden="true" tabindex="-1"></a>anomalies <span class="op">=</span> transactions_features[labels <span class="op">==</span> <span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb23-353"><a href="#cb23-353" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Nombre de transactions suspectes: </span><span class="sc">{</span><span class="bu">len</span>(anomalies)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-354"><a href="#cb23-354" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-355"><a href="#cb23-355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-356"><a href="#cb23-356" aria-hidden="true" tabindex="-1"></a>**c) Regroupement de documents textuels:**</span>
<span id="cb23-357"><a href="#cb23-357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-358"><a href="#cb23-358" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Méthode recommandée**: **k-means** sur TF-IDF + **Hierarchical Clustering**</span>
<span id="cb23-359"><a href="#cb23-359" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Justification**:</span>
<span id="cb23-360"><a href="#cb23-360" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-361"><a href="#cb23-361" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>TF-IDF transforme texte en vecteurs numériques</span>
<span id="cb23-362"><a href="#cb23-362" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>K-means efficace en haute dimension (nombreux mots)</span>
<span id="cb23-363"><a href="#cb23-363" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Hierarchical permet d'explorer la hiérarchie des thèmes</span>
<span id="cb23-364"><a href="#cb23-364" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Peut combiner avec topic modeling (LDA)</span>
<span id="cb23-365"><a href="#cb23-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-368"><a href="#cb23-368" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-369"><a href="#cb23-369" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb23-370"><a href="#cb23-370" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb23-371"><a href="#cb23-371" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-372"><a href="#cb23-372" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> TfidfVectorizer</span>
<span id="cb23-373"><a href="#cb23-373" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb23-374"><a href="#cb23-374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-375"><a href="#cb23-375" aria-hidden="true" tabindex="-1"></a><span class="co"># Vectorisation des textes</span></span>
<span id="cb23-376"><a href="#cb23-376" aria-hidden="true" tabindex="-1"></a>vectorizer <span class="op">=</span> TfidfVectorizer(max_features<span class="op">=</span><span class="dv">1000</span>, stop_words<span class="op">=</span><span class="st">'english'</span>)</span>
<span id="cb23-377"><a href="#cb23-377" aria-hidden="true" tabindex="-1"></a>X_tfidf <span class="op">=</span> vectorizer.fit_transform(documents)</span>
<span id="cb23-378"><a href="#cb23-378" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-379"><a href="#cb23-379" aria-hidden="true" tabindex="-1"></a><span class="co"># Clustering</span></span>
<span id="cb23-380"><a href="#cb23-380" aria-hidden="true" tabindex="-1"></a>kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">5</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb23-381"><a href="#cb23-381" aria-hidden="true" tabindex="-1"></a>doc_clusters <span class="op">=</span> kmeans.fit_predict(X_tfidf)</span>
<span id="cb23-382"><a href="#cb23-382" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-383"><a href="#cb23-383" aria-hidden="true" tabindex="-1"></a><span class="co"># Top mots par cluster</span></span>
<span id="cb23-384"><a href="#cb23-384" aria-hidden="true" tabindex="-1"></a>terms <span class="op">=</span> vectorizer.get_feature_names_out()</span>
<span id="cb23-385"><a href="#cb23-385" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb23-386"><a href="#cb23-386" aria-hidden="true" tabindex="-1"></a>    center <span class="op">=</span> kmeans.cluster_centers_[i]</span>
<span id="cb23-387"><a href="#cb23-387" aria-hidden="true" tabindex="-1"></a>    top_terms <span class="op">=</span> [terms[j] <span class="cf">for</span> j <span class="kw">in</span> center.argsort()[<span class="op">-</span><span class="dv">10</span>:]]</span>
<span id="cb23-388"><a href="#cb23-388" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Cluster </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span><span class="st">', '</span><span class="sc">.</span>join(top_terms)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-389"><a href="#cb23-389" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-390"><a href="#cb23-390" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-391"><a href="#cb23-391" aria-hidden="true" tabindex="-1"></a>**d) Analyse de pixels d'image satellite:**</span>
<span id="cb23-392"><a href="#cb23-392" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-393"><a href="#cb23-393" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Méthode recommandée**: **k-means** ou **Mean Shift**</span>
<span id="cb23-394"><a href="#cb23-394" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Justification**:</span>
<span id="cb23-395"><a href="#cb23-395" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-396"><a href="#cb23-396" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Segmentation d'image = clustering de pixels (RGB ou multi-spectral)</span>
<span id="cb23-397"><a href="#cb23-397" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>K-means rapide pour millions de pixels</span>
<span id="cb23-398"><a href="#cb23-398" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Mean Shift détecte automatiquement le nombre de segments</span>
<span id="cb23-399"><a href="#cb23-399" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Peut identifier zones (forêt, eau, ville, etc.)</span>
<span id="cb23-400"><a href="#cb23-400" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-403"><a href="#cb23-403" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-404"><a href="#cb23-404" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb23-405"><a href="#cb23-405" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb23-406"><a href="#cb23-406" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-407"><a href="#cb23-407" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb23-408"><a href="#cb23-408" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb23-409"><a href="#cb23-409" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb23-410"><a href="#cb23-410" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-411"><a href="#cb23-411" aria-hidden="true" tabindex="-1"></a><span class="co"># Image satellite (exemple)</span></span>
<span id="cb23-412"><a href="#cb23-412" aria-hidden="true" tabindex="-1"></a><span class="co"># image shape: (height, width, channels)</span></span>
<span id="cb23-413"><a href="#cb23-413" aria-hidden="true" tabindex="-1"></a>pixels <span class="op">=</span> image.reshape(<span class="op">-</span><span class="dv">1</span>, image.shape[<span class="dv">2</span>])  <span class="co"># Reshape en (n_pixels, channels)</span></span>
<span id="cb23-414"><a href="#cb23-414" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-415"><a href="#cb23-415" aria-hidden="true" tabindex="-1"></a><span class="co"># K-means sur pixels</span></span>
<span id="cb23-416"><a href="#cb23-416" aria-hidden="true" tabindex="-1"></a>kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">5</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb23-417"><a href="#cb23-417" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> kmeans.fit_predict(pixels)</span>
<span id="cb23-418"><a href="#cb23-418" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-419"><a href="#cb23-419" aria-hidden="true" tabindex="-1"></a><span class="co"># Reconstruction de l'image segmentée</span></span>
<span id="cb23-420"><a href="#cb23-420" aria-hidden="true" tabindex="-1"></a>segmented_image <span class="op">=</span> labels.reshape(image.shape[:<span class="dv">2</span>])</span>
<span id="cb23-421"><a href="#cb23-421" aria-hidden="true" tabindex="-1"></a>plt.imshow(segmented_image, cmap<span class="op">=</span><span class="st">'tab10'</span>)</span>
<span id="cb23-422"><a href="#cb23-422" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Segmentation de l</span><span class="ch">\'</span><span class="st">image satellite'</span>)</span>
<span id="cb23-423"><a href="#cb23-423" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb23-424"><a href="#cb23-424" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-425"><a href="#cb23-425" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb23-426"><a href="#cb23-426" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-427"><a href="#cb23-427" aria-hidden="true" tabindex="-1"></a>::: {.callout-warning icon=false}</span>
<span id="cb23-428"><a href="#cb23-428" aria-hidden="true" tabindex="-1"></a><span class="fu">## Question 2</span></span>
<span id="cb23-429"><a href="#cb23-429" aria-hidden="true" tabindex="-1"></a>Pour un dataset avec 10 000 échantillons et 50 features :</span>
<span id="cb23-430"><a href="#cb23-430" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-431"><a href="#cb23-431" aria-hidden="true" tabindex="-1"></a>a) Expliquez comment déterminer le nombre optimal de clusters pour k-means</span>
<span id="cb23-432"><a href="#cb23-432" aria-hidden="true" tabindex="-1"></a>b) Proposez une approche pour visualiser la structure des clusters</span>
<span id="cb23-433"><a href="#cb23-433" aria-hidden="true" tabindex="-1"></a>c) Quel avantage PCA peut-il apporter avant le clustering ?</span>
<span id="cb23-434"><a href="#cb23-434" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb23-435"><a href="#cb23-435" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-436"><a href="#cb23-436" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb23-437"><a href="#cb23-437" aria-hidden="true" tabindex="-1"></a><span class="fu">## Correction Question 2</span></span>
<span id="cb23-438"><a href="#cb23-438" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-439"><a href="#cb23-439" aria-hidden="true" tabindex="-1"></a>**a) Déterminer le nombre optimal de clusters:**</span>
<span id="cb23-440"><a href="#cb23-440" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-441"><a href="#cb23-441" aria-hidden="true" tabindex="-1"></a>**Méthode 1: Elbow Method (Méthode du coude)**</span>
<span id="cb23-442"><a href="#cb23-442" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-445"><a href="#cb23-445" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-446"><a href="#cb23-446" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb23-447"><a href="#cb23-447" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb23-448"><a href="#cb23-448" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-449"><a href="#cb23-449" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb23-450"><a href="#cb23-450" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb23-451"><a href="#cb23-451" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-452"><a href="#cb23-452" aria-hidden="true" tabindex="-1"></a><span class="co"># Tester différentes valeurs de k</span></span>
<span id="cb23-453"><a href="#cb23-453" aria-hidden="true" tabindex="-1"></a>inertias <span class="op">=</span> []</span>
<span id="cb23-454"><a href="#cb23-454" aria-hidden="true" tabindex="-1"></a>silhouette_scores <span class="op">=</span> []</span>
<span id="cb23-455"><a href="#cb23-455" aria-hidden="true" tabindex="-1"></a>K_range <span class="op">=</span> <span class="bu">range</span>(<span class="dv">2</span>, <span class="dv">11</span>)</span>
<span id="cb23-456"><a href="#cb23-456" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-457"><a href="#cb23-457" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> K_range:</span>
<span id="cb23-458"><a href="#cb23-458" aria-hidden="true" tabindex="-1"></a>    kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span>k, random_state<span class="op">=</span><span class="dv">42</span>, n_init<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb23-459"><a href="#cb23-459" aria-hidden="true" tabindex="-1"></a>    kmeans.fit(X)</span>
<span id="cb23-460"><a href="#cb23-460" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-461"><a href="#cb23-461" aria-hidden="true" tabindex="-1"></a>    inertias.append(kmeans.inertia_)</span>
<span id="cb23-462"><a href="#cb23-462" aria-hidden="true" tabindex="-1"></a>    silhouette_scores.append(silhouette_score(X, kmeans.labels_))</span>
<span id="cb23-463"><a href="#cb23-463" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-464"><a href="#cb23-464" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualisation</span></span>
<span id="cb23-465"><a href="#cb23-465" aria-hidden="true" tabindex="-1"></a>fig, (ax1, ax2) <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">5</span>))</span>
<span id="cb23-466"><a href="#cb23-466" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-467"><a href="#cb23-467" aria-hidden="true" tabindex="-1"></a><span class="co"># Courbe du coude</span></span>
<span id="cb23-468"><a href="#cb23-468" aria-hidden="true" tabindex="-1"></a>ax1.plot(K_range, inertias, <span class="st">'bo-'</span>)</span>
<span id="cb23-469"><a href="#cb23-469" aria-hidden="true" tabindex="-1"></a>ax1.set_xlabel(<span class="st">'Nombre de clusters (k)'</span>)</span>
<span id="cb23-470"><a href="#cb23-470" aria-hidden="true" tabindex="-1"></a>ax1.set_ylabel(<span class="st">'Inertie'</span>)</span>
<span id="cb23-471"><a href="#cb23-471" aria-hidden="true" tabindex="-1"></a>ax1.set_title(<span class="st">'Méthode du Coude'</span>)</span>
<span id="cb23-472"><a href="#cb23-472" aria-hidden="true" tabindex="-1"></a>ax1.grid(<span class="va">True</span>)</span>
<span id="cb23-473"><a href="#cb23-473" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-474"><a href="#cb23-474" aria-hidden="true" tabindex="-1"></a><span class="co"># Silhouette score</span></span>
<span id="cb23-475"><a href="#cb23-475" aria-hidden="true" tabindex="-1"></a>ax2.plot(K_range, silhouette_scores, <span class="st">'go-'</span>)</span>
<span id="cb23-476"><a href="#cb23-476" aria-hidden="true" tabindex="-1"></a>ax2.set_xlabel(<span class="st">'Nombre de clusters (k)'</span>)</span>
<span id="cb23-477"><a href="#cb23-477" aria-hidden="true" tabindex="-1"></a>ax2.set_ylabel(<span class="st">'Silhouette Score'</span>)</span>
<span id="cb23-478"><a href="#cb23-478" aria-hidden="true" tabindex="-1"></a>ax2.set_title(<span class="st">'Score Silhouette'</span>)</span>
<span id="cb23-479"><a href="#cb23-479" aria-hidden="true" tabindex="-1"></a>ax2.grid(<span class="va">True</span>)</span>
<span id="cb23-480"><a href="#cb23-480" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-481"><a href="#cb23-481" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb23-482"><a href="#cb23-482" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-483"><a href="#cb23-483" aria-hidden="true" tabindex="-1"></a><span class="co"># Le k optimal est au "coude" de la courbe d'inertie</span></span>
<span id="cb23-484"><a href="#cb23-484" aria-hidden="true" tabindex="-1"></a><span class="co"># ET avec un bon silhouette score</span></span>
<span id="cb23-485"><a href="#cb23-485" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-486"><a href="#cb23-486" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-487"><a href="#cb23-487" aria-hidden="true" tabindex="-1"></a>**Méthode 2: Gap Statistic**</span>
<span id="cb23-488"><a href="#cb23-488" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-491"><a href="#cb23-491" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-492"><a href="#cb23-492" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb23-493"><a href="#cb23-493" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb23-494"><a href="#cb23-494" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-495"><a href="#cb23-495" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare l'inertie observée vs inertie sur données aléatoires</span></span>
<span id="cb23-496"><a href="#cb23-496" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> gap_statistic(X, k_max<span class="op">=</span><span class="dv">10</span>, n_refs<span class="op">=</span><span class="dv">10</span>):</span>
<span id="cb23-497"><a href="#cb23-497" aria-hidden="true" tabindex="-1"></a>    gaps <span class="op">=</span> []</span>
<span id="cb23-498"><a href="#cb23-498" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, k_max <span class="op">+</span> <span class="dv">1</span>):</span>
<span id="cb23-499"><a href="#cb23-499" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Inertie sur données réelles</span></span>
<span id="cb23-500"><a href="#cb23-500" aria-hidden="true" tabindex="-1"></a>        kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span>k, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb23-501"><a href="#cb23-501" aria-hidden="true" tabindex="-1"></a>        kmeans.fit(X)</span>
<span id="cb23-502"><a href="#cb23-502" aria-hidden="true" tabindex="-1"></a>        real_inertia <span class="op">=</span> kmeans.inertia_</span>
<span id="cb23-503"><a href="#cb23-503" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-504"><a href="#cb23-504" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Inertie moyenne sur données de référence</span></span>
<span id="cb23-505"><a href="#cb23-505" aria-hidden="true" tabindex="-1"></a>        ref_inertias <span class="op">=</span> []</span>
<span id="cb23-506"><a href="#cb23-506" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(n_refs):</span>
<span id="cb23-507"><a href="#cb23-507" aria-hidden="true" tabindex="-1"></a>            X_ref <span class="op">=</span> np.random.uniform(X.<span class="bu">min</span>(), X.<span class="bu">max</span>(), X.shape)</span>
<span id="cb23-508"><a href="#cb23-508" aria-hidden="true" tabindex="-1"></a>            kmeans_ref <span class="op">=</span> KMeans(n_clusters<span class="op">=</span>k, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb23-509"><a href="#cb23-509" aria-hidden="true" tabindex="-1"></a>            kmeans_ref.fit(X_ref)</span>
<span id="cb23-510"><a href="#cb23-510" aria-hidden="true" tabindex="-1"></a>            ref_inertias.append(kmeans_ref.inertia_)</span>
<span id="cb23-511"><a href="#cb23-511" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-512"><a href="#cb23-512" aria-hidden="true" tabindex="-1"></a>        gap <span class="op">=</span> np.log(np.mean(ref_inertias)) <span class="op">-</span> np.log(real_inertia)</span>
<span id="cb23-513"><a href="#cb23-513" aria-hidden="true" tabindex="-1"></a>        gaps.append(gap)</span>
<span id="cb23-514"><a href="#cb23-514" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-515"><a href="#cb23-515" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> gaps</span>
<span id="cb23-516"><a href="#cb23-516" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-517"><a href="#cb23-517" aria-hidden="true" tabindex="-1"></a><span class="co"># K optimal = premier k où gap commence à décroître</span></span>
<span id="cb23-518"><a href="#cb23-518" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-519"><a href="#cb23-519" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-520"><a href="#cb23-520" aria-hidden="true" tabindex="-1"></a>**Méthode 3: Silhouette Analysis détaillée**</span>
<span id="cb23-521"><a href="#cb23-521" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-524"><a href="#cb23-524" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-525"><a href="#cb23-525" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb23-526"><a href="#cb23-526" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb23-527"><a href="#cb23-527" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-528"><a href="#cb23-528" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> silhouette_samples</span>
<span id="cb23-529"><a href="#cb23-529" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.cm <span class="im">as</span> cm</span>
<span id="cb23-530"><a href="#cb23-530" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-531"><a href="#cb23-531" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> [<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>]:</span>
<span id="cb23-532"><a href="#cb23-532" aria-hidden="true" tabindex="-1"></a>    kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span>k, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb23-533"><a href="#cb23-533" aria-hidden="true" tabindex="-1"></a>    labels <span class="op">=</span> kmeans.fit_predict(X)</span>
<span id="cb23-534"><a href="#cb23-534" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-535"><a href="#cb23-535" aria-hidden="true" tabindex="-1"></a>    silhouette_vals <span class="op">=</span> silhouette_samples(X, labels)</span>
<span id="cb23-536"><a href="#cb23-536" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-537"><a href="#cb23-537" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb23-538"><a href="#cb23-538" aria-hidden="true" tabindex="-1"></a>    y_lower <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb23-539"><a href="#cb23-539" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-540"><a href="#cb23-540" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(k):</span>
<span id="cb23-541"><a href="#cb23-541" aria-hidden="true" tabindex="-1"></a>        cluster_silhouette_vals <span class="op">=</span> silhouette_vals[labels <span class="op">==</span> i]</span>
<span id="cb23-542"><a href="#cb23-542" aria-hidden="true" tabindex="-1"></a>        cluster_silhouette_vals.sort()</span>
<span id="cb23-543"><a href="#cb23-543" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-544"><a href="#cb23-544" aria-hidden="true" tabindex="-1"></a>        size <span class="op">=</span> cluster_silhouette_vals.shape[<span class="dv">0</span>]</span>
<span id="cb23-545"><a href="#cb23-545" aria-hidden="true" tabindex="-1"></a>        y_upper <span class="op">=</span> y_lower <span class="op">+</span> size</span>
<span id="cb23-546"><a href="#cb23-546" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-547"><a href="#cb23-547" aria-hidden="true" tabindex="-1"></a>        plt.fill_betweenx(np.arange(y_lower, y_upper),</span>
<span id="cb23-548"><a href="#cb23-548" aria-hidden="true" tabindex="-1"></a>                         <span class="dv">0</span>, cluster_silhouette_vals,</span>
<span id="cb23-549"><a href="#cb23-549" aria-hidden="true" tabindex="-1"></a>                         alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb23-550"><a href="#cb23-550" aria-hidden="true" tabindex="-1"></a>        y_lower <span class="op">=</span> y_upper <span class="op">+</span> <span class="dv">10</span></span>
<span id="cb23-551"><a href="#cb23-551" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-552"><a href="#cb23-552" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="ss">f'Silhouette Plot (k=</span><span class="sc">{</span>k<span class="sc">}</span><span class="ss">)'</span>)</span>
<span id="cb23-553"><a href="#cb23-553" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">'Coefficient Silhouette'</span>)</span>
<span id="cb23-554"><a href="#cb23-554" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">'Cluster'</span>)</span>
<span id="cb23-555"><a href="#cb23-555" aria-hidden="true" tabindex="-1"></a>    plt.axvline(x<span class="op">=</span>silhouette_score(X, labels), color<span class="op">=</span><span class="st">"red"</span>, linestyle<span class="op">=</span><span class="st">"--"</span>)</span>
<span id="cb23-556"><a href="#cb23-556" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb23-557"><a href="#cb23-557" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-558"><a href="#cb23-558" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-559"><a href="#cb23-559" aria-hidden="true" tabindex="-1"></a>**b) Visualiser la structure des clusters:**</span>
<span id="cb23-560"><a href="#cb23-560" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-561"><a href="#cb23-561" aria-hidden="true" tabindex="-1"></a>**Approche 1: PCA pour réduction 2D/3D**</span>
<span id="cb23-562"><a href="#cb23-562" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-565"><a href="#cb23-565" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-566"><a href="#cb23-566" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb23-567"><a href="#cb23-567" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb23-568"><a href="#cb23-568" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-569"><a href="#cb23-569" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb23-570"><a href="#cb23-570" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-571"><a href="#cb23-571" aria-hidden="true" tabindex="-1"></a><span class="co"># Réduction à 2D</span></span>
<span id="cb23-572"><a href="#cb23-572" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb23-573"><a href="#cb23-573" aria-hidden="true" tabindex="-1"></a>X_pca <span class="op">=</span> pca.fit_transform(X)</span>
<span id="cb23-574"><a href="#cb23-574" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-575"><a href="#cb23-575" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualisation</span></span>
<span id="cb23-576"><a href="#cb23-576" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb23-577"><a href="#cb23-577" aria-hidden="true" tabindex="-1"></a>scatter <span class="op">=</span> plt.scatter(X_pca[:, <span class="dv">0</span>], X_pca[:, <span class="dv">1</span>], </span>
<span id="cb23-578"><a href="#cb23-578" aria-hidden="true" tabindex="-1"></a>                     c<span class="op">=</span>labels, cmap<span class="op">=</span><span class="st">'viridis'</span>, alpha<span class="op">=</span><span class="fl">0.6</span>)</span>
<span id="cb23-579"><a href="#cb23-579" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="ss">f'PC1 (</span><span class="sc">{</span>pca<span class="sc">.</span>explained_variance_ratio_[<span class="dv">0</span>]<span class="sc">:.1%}</span><span class="ss">)'</span>)</span>
<span id="cb23-580"><a href="#cb23-580" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="ss">f'PC2 (</span><span class="sc">{</span>pca<span class="sc">.</span>explained_variance_ratio_[<span class="dv">1</span>]<span class="sc">:.1%}</span><span class="ss">)'</span>)</span>
<span id="cb23-581"><a href="#cb23-581" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Clusters visualisés avec PCA'</span>)</span>
<span id="cb23-582"><a href="#cb23-582" aria-hidden="true" tabindex="-1"></a>plt.colorbar(scatter, label<span class="op">=</span><span class="st">'Cluster'</span>)</span>
<span id="cb23-583"><a href="#cb23-583" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb23-584"><a href="#cb23-584" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-585"><a href="#cb23-585" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Variance expliquée totale: </span><span class="sc">{</span><span class="bu">sum</span>(pca.explained_variance_ratio_)<span class="sc">:.2%}</span><span class="ss">"</span>)</span>
<span id="cb23-586"><a href="#cb23-586" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-587"><a href="#cb23-587" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-588"><a href="#cb23-588" aria-hidden="true" tabindex="-1"></a>**Approche 2: t-SNE pour visualisation non-linéaire**</span>
<span id="cb23-589"><a href="#cb23-589" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-592"><a href="#cb23-592" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-593"><a href="#cb23-593" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb23-594"><a href="#cb23-594" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb23-595"><a href="#cb23-595" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-596"><a href="#cb23-596" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.manifold <span class="im">import</span> TSNE</span>
<span id="cb23-597"><a href="#cb23-597" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-598"><a href="#cb23-598" aria-hidden="true" tabindex="-1"></a><span class="co"># t-SNE (plus lent mais meilleure visualisation)</span></span>
<span id="cb23-599"><a href="#cb23-599" aria-hidden="true" tabindex="-1"></a>tsne <span class="op">=</span> TSNE(n_components<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">42</span>, perplexity<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb23-600"><a href="#cb23-600" aria-hidden="true" tabindex="-1"></a>X_tsne <span class="op">=</span> tsne.fit_transform(X)</span>
<span id="cb23-601"><a href="#cb23-601" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-602"><a href="#cb23-602" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb23-603"><a href="#cb23-603" aria-hidden="true" tabindex="-1"></a>plt.scatter(X_tsne[:, <span class="dv">0</span>], X_tsne[:, <span class="dv">1</span>], c<span class="op">=</span>labels, cmap<span class="op">=</span><span class="st">'tab10'</span>, alpha<span class="op">=</span><span class="fl">0.6</span>)</span>
<span id="cb23-604"><a href="#cb23-604" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Clusters visualisés avec t-SNE'</span>)</span>
<span id="cb23-605"><a href="#cb23-605" aria-hidden="true" tabindex="-1"></a>plt.colorbar(label<span class="op">=</span><span class="st">'Cluster'</span>)</span>
<span id="cb23-606"><a href="#cb23-606" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb23-607"><a href="#cb23-607" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-608"><a href="#cb23-608" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-609"><a href="#cb23-609" aria-hidden="true" tabindex="-1"></a>**Approche 3: Pairplot des features importantes**</span>
<span id="cb23-610"><a href="#cb23-610" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-613"><a href="#cb23-613" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-614"><a href="#cb23-614" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb23-615"><a href="#cb23-615" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb23-616"><a href="#cb23-616" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-617"><a href="#cb23-617" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb23-618"><a href="#cb23-618" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-619"><a href="#cb23-619" aria-hidden="true" tabindex="-1"></a><span class="co"># Sélectionner top features par variance</span></span>
<span id="cb23-620"><a href="#cb23-620" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_selection <span class="im">import</span> VarianceThreshold</span>
<span id="cb23-621"><a href="#cb23-621" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-622"><a href="#cb23-622" aria-hidden="true" tabindex="-1"></a>selector <span class="op">=</span> VarianceThreshold(threshold<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb23-623"><a href="#cb23-623" aria-hidden="true" tabindex="-1"></a>X_selected <span class="op">=</span> selector.fit_transform(X)</span>
<span id="cb23-624"><a href="#cb23-624" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-625"><a href="#cb23-625" aria-hidden="true" tabindex="-1"></a><span class="co"># Pairplot avec 4-5 features les plus variables</span></span>
<span id="cb23-626"><a href="#cb23-626" aria-hidden="true" tabindex="-1"></a>df_plot <span class="op">=</span> pd.DataFrame(X_selected[:, :<span class="dv">5</span>], columns<span class="op">=</span>[<span class="ss">f'F</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">'</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>)])</span>
<span id="cb23-627"><a href="#cb23-627" aria-hidden="true" tabindex="-1"></a>df_plot[<span class="st">'cluster'</span>] <span class="op">=</span> labels</span>
<span id="cb23-628"><a href="#cb23-628" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-629"><a href="#cb23-629" aria-hidden="true" tabindex="-1"></a>sns.pairplot(df_plot, hue<span class="op">=</span><span class="st">'cluster'</span>, palette<span class="op">=</span><span class="st">'tab10'</span>)</span>
<span id="cb23-630"><a href="#cb23-630" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb23-631"><a href="#cb23-631" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-632"><a href="#cb23-632" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-633"><a href="#cb23-633" aria-hidden="true" tabindex="-1"></a>**c) Avantages de PCA avant le clustering:**</span>
<span id="cb23-634"><a href="#cb23-634" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-635"><a href="#cb23-635" aria-hidden="true" tabindex="-1"></a>**1. Réduction de dimension → Efficacité computationnelle**</span>
<span id="cb23-636"><a href="#cb23-636" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-639"><a href="#cb23-639" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-640"><a href="#cb23-640" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb23-641"><a href="#cb23-641" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb23-642"><a href="#cb23-642" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-643"><a href="#cb23-643" aria-hidden="true" tabindex="-1"></a><span class="co"># Sans PCA: 50 features</span></span>
<span id="cb23-644"><a href="#cb23-644" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb23-645"><a href="#cb23-645" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-646"><a href="#cb23-646" aria-hidden="true" tabindex="-1"></a>start <span class="op">=</span> time.time()</span>
<span id="cb23-647"><a href="#cb23-647" aria-hidden="true" tabindex="-1"></a>kmeans_full <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">5</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb23-648"><a href="#cb23-648" aria-hidden="true" tabindex="-1"></a>kmeans_full.fit(X)  <span class="co"># X: (10000, 50)</span></span>
<span id="cb23-649"><a href="#cb23-649" aria-hidden="true" tabindex="-1"></a>time_full <span class="op">=</span> time.time() <span class="op">-</span> start</span>
<span id="cb23-650"><a href="#cb23-650" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-651"><a href="#cb23-651" aria-hidden="true" tabindex="-1"></a><span class="co"># Avec PCA: 10 features (gardant 95% de variance)</span></span>
<span id="cb23-652"><a href="#cb23-652" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="fl">0.95</span>)  <span class="co"># Garde 95% de variance</span></span>
<span id="cb23-653"><a href="#cb23-653" aria-hidden="true" tabindex="-1"></a>X_pca <span class="op">=</span> pca.fit_transform(X)  <span class="co"># X_pca: (10000, ~10)</span></span>
<span id="cb23-654"><a href="#cb23-654" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-655"><a href="#cb23-655" aria-hidden="true" tabindex="-1"></a>start <span class="op">=</span> time.time()</span>
<span id="cb23-656"><a href="#cb23-656" aria-hidden="true" tabindex="-1"></a>kmeans_pca <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">5</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb23-657"><a href="#cb23-657" aria-hidden="true" tabindex="-1"></a>kmeans_pca.fit(X_pca)</span>
<span id="cb23-658"><a href="#cb23-658" aria-hidden="true" tabindex="-1"></a>time_pca <span class="op">=</span> time.time() <span class="op">-</span> start</span>
<span id="cb23-659"><a href="#cb23-659" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-660"><a href="#cb23-660" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Temps sans PCA: </span><span class="sc">{</span>time_full<span class="sc">:.2f}</span><span class="ss">s"</span>)</span>
<span id="cb23-661"><a href="#cb23-661" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Temps avec PCA: </span><span class="sc">{</span>time_pca<span class="sc">:.2f}</span><span class="ss">s"</span>)</span>
<span id="cb23-662"><a href="#cb23-662" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accélération: </span><span class="sc">{</span>time_full<span class="op">/</span>time_pca<span class="sc">:.1f}</span><span class="ss">x"</span>)</span>
<span id="cb23-663"><a href="#cb23-663" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Dimensions réduites: </span><span class="sc">{</span>X<span class="sc">.</span>shape[<span class="dv">1</span>]<span class="sc">}</span><span class="ss"> → </span><span class="sc">{</span>X_pca<span class="sc">.</span>shape[<span class="dv">1</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-664"><a href="#cb23-664" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-665"><a href="#cb23-665" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-666"><a href="#cb23-666" aria-hidden="true" tabindex="-1"></a>**2. Réduction du bruit**</span>
<span id="cb23-667"><a href="#cb23-667" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-670"><a href="#cb23-670" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-671"><a href="#cb23-671" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb23-672"><a href="#cb23-672" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb23-673"><a href="#cb23-673" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-674"><a href="#cb23-674" aria-hidden="true" tabindex="-1"></a><span class="co"># PCA élimine les composantes de faible variance (souvent du bruit)</span></span>
<span id="cb23-675"><a href="#cb23-675" aria-hidden="true" tabindex="-1"></a>pca_full <span class="op">=</span> PCA()</span>
<span id="cb23-676"><a href="#cb23-676" aria-hidden="true" tabindex="-1"></a>pca_full.fit(X)</span>
<span id="cb23-677"><a href="#cb23-677" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-678"><a href="#cb23-678" aria-hidden="true" tabindex="-1"></a><span class="co"># Afficher la variance par composante</span></span>
<span id="cb23-679"><a href="#cb23-679" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">5</span>))</span>
<span id="cb23-680"><a href="#cb23-680" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-681"><a href="#cb23-681" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb23-682"><a href="#cb23-682" aria-hidden="true" tabindex="-1"></a>plt.plot(<span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(pca_full.explained_variance_ratio_) <span class="op">+</span> <span class="dv">1</span>),</span>
<span id="cb23-683"><a href="#cb23-683" aria-hidden="true" tabindex="-1"></a>         pca_full.explained_variance_ratio_, <span class="st">'bo-'</span>)</span>
<span id="cb23-684"><a href="#cb23-684" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Composante'</span>)</span>
<span id="cb23-685"><a href="#cb23-685" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Variance expliquée'</span>)</span>
<span id="cb23-686"><a href="#cb23-686" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Scree Plot'</span>)</span>
<span id="cb23-687"><a href="#cb23-687" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb23-688"><a href="#cb23-688" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-689"><a href="#cb23-689" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb23-690"><a href="#cb23-690" aria-hidden="true" tabindex="-1"></a>plt.plot(<span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(pca_full.explained_variance_ratio_) <span class="op">+</span> <span class="dv">1</span>),</span>
<span id="cb23-691"><a href="#cb23-691" aria-hidden="true" tabindex="-1"></a>         np.cumsum(pca_full.explained_variance_ratio_), <span class="st">'ro-'</span>)</span>
<span id="cb23-692"><a href="#cb23-692" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Nombre de composantes'</span>)</span>
<span id="cb23-693"><a href="#cb23-693" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Variance cumulée'</span>)</span>
<span id="cb23-694"><a href="#cb23-694" aria-hidden="true" tabindex="-1"></a>plt.axhline(y<span class="op">=</span><span class="fl">0.95</span>, color<span class="op">=</span><span class="st">'g'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, label<span class="op">=</span><span class="st">'95%'</span>)</span>
<span id="cb23-695"><a href="#cb23-695" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Variance Cumulée'</span>)</span>
<span id="cb23-696"><a href="#cb23-696" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb23-697"><a href="#cb23-697" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb23-698"><a href="#cb23-698" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-699"><a href="#cb23-699" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb23-700"><a href="#cb23-700" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb23-701"><a href="#cb23-701" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-702"><a href="#cb23-702" aria-hidden="true" tabindex="-1"></a><span class="co"># Garder les composantes qui expliquent 95% de la variance</span></span>
<span id="cb23-703"><a href="#cb23-703" aria-hidden="true" tabindex="-1"></a><span class="co"># → élimine le bruit des dernières composantes</span></span>
<span id="cb23-704"><a href="#cb23-704" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-705"><a href="#cb23-705" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-706"><a href="#cb23-706" aria-hidden="true" tabindex="-1"></a>**3. Évite la malédiction de la dimensionnalité**</span>
<span id="cb23-707"><a href="#cb23-707" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-710"><a href="#cb23-710" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-711"><a href="#cb23-711" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb23-712"><a href="#cb23-712" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb23-713"><a href="#cb23-713" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-714"><a href="#cb23-714" aria-hidden="true" tabindex="-1"></a><span class="co"># En haute dimension, les distances deviennent moins significatives</span></span>
<span id="cb23-715"><a href="#cb23-715" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.spatial.distance <span class="im">import</span> pdist, squareform</span>
<span id="cb23-716"><a href="#cb23-716" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-717"><a href="#cb23-717" aria-hidden="true" tabindex="-1"></a><span class="co"># Calcul des distances moyennes</span></span>
<span id="cb23-718"><a href="#cb23-718" aria-hidden="true" tabindex="-1"></a>distances_full <span class="op">=</span> pdist(X[:<span class="dv">100</span>])  <span class="co"># Sur 100 échantillons pour rapidité</span></span>
<span id="cb23-719"><a href="#cb23-719" aria-hidden="true" tabindex="-1"></a>distances_pca <span class="op">=</span> pdist(X_pca[:<span class="dv">100</span>])</span>
<span id="cb23-720"><a href="#cb23-720" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-721"><a href="#cb23-721" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Distance moyenne (50D): </span><span class="sc">{</span>np<span class="sc">.</span>mean(distances_full)<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb23-722"><a href="#cb23-722" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Distance moyenne (10D): </span><span class="sc">{</span>np<span class="sc">.</span>mean(distances_pca)<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb23-723"><a href="#cb23-723" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Écart-type distances (50D): </span><span class="sc">{</span>np<span class="sc">.</span>std(distances_full)<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb23-724"><a href="#cb23-724" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Écart-type distances (10D): </span><span class="sc">{</span>np<span class="sc">.</span>std(distances_pca)<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb23-725"><a href="#cb23-725" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-726"><a href="#cb23-726" aria-hidden="true" tabindex="-1"></a><span class="co"># En dimension réduite, les distances sont plus discriminantes</span></span>
<span id="cb23-727"><a href="#cb23-727" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-728"><a href="#cb23-728" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-729"><a href="#cb23-729" aria-hidden="true" tabindex="-1"></a>**4. Décorrélation des features**</span>
<span id="cb23-730"><a href="#cb23-730" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-733"><a href="#cb23-733" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-734"><a href="#cb23-734" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb23-735"><a href="#cb23-735" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb23-736"><a href="#cb23-736" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-737"><a href="#cb23-737" aria-hidden="true" tabindex="-1"></a><span class="co"># PCA produit des composantes non-corrélées</span></span>
<span id="cb23-738"><a href="#cb23-738" aria-hidden="true" tabindex="-1"></a><span class="co"># → Améliore k-means qui suppose indépendance</span></span>
<span id="cb23-739"><a href="#cb23-739" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-740"><a href="#cb23-740" aria-hidden="true" tabindex="-1"></a><span class="co"># Corrélation avant PCA</span></span>
<span id="cb23-741"><a href="#cb23-741" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">5</span>))</span>
<span id="cb23-742"><a href="#cb23-742" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-743"><a href="#cb23-743" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb23-744"><a href="#cb23-744" aria-hidden="true" tabindex="-1"></a>sns.heatmap(np.corrcoef(X.T), cmap<span class="op">=</span><span class="st">'coolwarm'</span>, center<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb23-745"><a href="#cb23-745" aria-hidden="true" tabindex="-1"></a>            cbar_kws<span class="op">=</span>{<span class="st">'label'</span>: <span class="st">'Corrélation'</span>})</span>
<span id="cb23-746"><a href="#cb23-746" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Corrélations avant PCA'</span>)</span>
<span id="cb23-747"><a href="#cb23-747" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-748"><a href="#cb23-748" aria-hidden="true" tabindex="-1"></a><span class="co"># Corrélation après PCA</span></span>
<span id="cb23-749"><a href="#cb23-749" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb23-750"><a href="#cb23-750" aria-hidden="true" tabindex="-1"></a>sns.heatmap(np.corrcoef(X_pca.T), cmap<span class="op">=</span><span class="st">'coolwarm'</span>, center<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb23-751"><a href="#cb23-751" aria-hidden="true" tabindex="-1"></a>            cbar_kws<span class="op">=</span>{<span class="st">'label'</span>: <span class="st">'Corrélation'</span>})</span>
<span id="cb23-752"><a href="#cb23-752" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Corrélations après PCA'</span>)</span>
<span id="cb23-753"><a href="#cb23-753" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-754"><a href="#cb23-754" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb23-755"><a href="#cb23-755" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb23-756"><a href="#cb23-756" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-757"><a href="#cb23-757" aria-hidden="true" tabindex="-1"></a><span class="co"># Après PCA: corrélations nulles entre composantes</span></span>
<span id="cb23-758"><a href="#cb23-758" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-759"><a href="#cb23-759" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-760"><a href="#cb23-760" aria-hidden="true" tabindex="-1"></a>**Résumé des avantages:**</span>
<span id="cb23-761"><a href="#cb23-761" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-762"><a href="#cb23-762" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Avantage <span class="pp">|</span> Description <span class="pp">|</span> Impact <span class="pp">|</span></span>
<span id="cb23-763"><a href="#cb23-763" aria-hidden="true" tabindex="-1"></a><span class="pp">|----------|-------------|--------|</span></span>
<span id="cb23-764"><a href="#cb23-764" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> **Efficacité** <span class="pp">|</span> 50 → 10 dimensions <span class="pp">|</span> 5-10x plus rapide <span class="pp">|</span></span>
<span id="cb23-765"><a href="#cb23-765" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> **Débruitage** <span class="pp">|</span> Élimine variance faible <span class="pp">|</span> Clusters plus nets <span class="pp">|</span></span>
<span id="cb23-766"><a href="#cb23-766" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> **Distances** <span class="pp">|</span> Plus discriminantes en faible dim <span class="pp">|</span> Meilleur clustering <span class="pp">|</span></span>
<span id="cb23-767"><a href="#cb23-767" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> **Décorrélation** <span class="pp">|</span> Features indépendantes <span class="pp">|</span> K-means plus efficace <span class="pp">|</span></span>
<span id="cb23-768"><a href="#cb23-768" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> **Visualisation** <span class="pp">|</span> Réduction à 2-3D <span class="pp">|</span> Interprétation facile <span class="pp">|</span></span>
<span id="cb23-769"><a href="#cb23-769" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb23-770"><a href="#cb23-770" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-771"><a href="#cb23-771" aria-hidden="true" tabindex="-1"></a>::: {.callout-warning icon=false}</span>
<span id="cb23-772"><a href="#cb23-772" aria-hidden="true" tabindex="-1"></a><span class="fu">## Question 3</span></span>
<span id="cb23-773"><a href="#cb23-773" aria-hidden="true" tabindex="-1"></a>Implémentez un pipeline complet de clustering sur le dataset Iris :</span>
<span id="cb23-774"><a href="#cb23-774" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-775"><a href="#cb23-775" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Chargez les données (ignorer les labels pour l'apprentissage non supervisé)</span>
<span id="cb23-776"><a href="#cb23-776" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Appliquez PCA pour réduire à 2 dimensions</span>
<span id="cb23-777"><a href="#cb23-777" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Testez k-means avec k=2,3,4 et comparez les résultats</span>
<span id="cb23-778"><a href="#cb23-778" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>Visualisez les clusters obtenus</span>
<span id="cb23-779"><a href="#cb23-779" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>Calculez le silhouette score pour chaque k</span>
<span id="cb23-780"><a href="#cb23-780" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb23-781"><a href="#cb23-781" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-782"><a href="#cb23-782" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb23-783"><a href="#cb23-783" aria-hidden="true" tabindex="-1"></a><span class="fu">## Correction Question 3</span></span>
<span id="cb23-784"><a href="#cb23-784" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-787"><a href="#cb23-787" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-788"><a href="#cb23-788" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb23-789"><a href="#cb23-789" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb23-790"><a href="#cb23-790" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-791"><a href="#cb23-791" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb23-792"><a href="#cb23-792" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb23-793"><a href="#cb23-793" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb23-794"><a href="#cb23-794" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb23-795"><a href="#cb23-795" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> datasets</span>
<span id="cb23-796"><a href="#cb23-796" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb23-797"><a href="#cb23-797" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb23-798"><a href="#cb23-798" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb23-799"><a href="#cb23-799" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> silhouette_score, adjusted_rand_score</span>
<span id="cb23-800"><a href="#cb23-800" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-801"><a href="#cb23-801" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Chargement des données (SANS utiliser les labels pour clustering)</span></span>
<span id="cb23-802"><a href="#cb23-802" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb23-803"><a href="#cb23-803" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"PIPELINE COMPLET DE CLUSTERING - DATASET IRIS"</span>)</span>
<span id="cb23-804"><a href="#cb23-804" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb23-805"><a href="#cb23-805" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-806"><a href="#cb23-806" aria-hidden="true" tabindex="-1"></a>iris <span class="op">=</span> datasets.load_iris()</span>
<span id="cb23-807"><a href="#cb23-807" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> iris.data  <span class="co"># Features seulement (ignorer iris.target)</span></span>
<span id="cb23-808"><a href="#cb23-808" aria-hidden="true" tabindex="-1"></a>feature_names <span class="op">=</span> iris.feature_names</span>
<span id="cb23-809"><a href="#cb23-809" aria-hidden="true" tabindex="-1"></a>true_labels <span class="op">=</span> iris.target  <span class="co"># Gardé seulement pour évaluation finale</span></span>
<span id="cb23-810"><a href="#cb23-810" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-811"><a href="#cb23-811" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">1. Chargement des données:"</span>)</span>
<span id="cb23-812"><a href="#cb23-812" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   Dimensions: </span><span class="sc">{</span>X<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-813"><a href="#cb23-813" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   Features: </span><span class="sc">{</span>feature_names<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-814"><a href="#cb23-814" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-815"><a href="#cb23-815" aria-hidden="true" tabindex="-1"></a><span class="co"># Normalisation (important avant PCA)</span></span>
<span id="cb23-816"><a href="#cb23-816" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb23-817"><a href="#cb23-817" aria-hidden="true" tabindex="-1"></a>X_scaled <span class="op">=</span> scaler.fit_transform(X)</span>
<span id="cb23-818"><a href="#cb23-818" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   ✓ Données normalisées"</span>)</span>
<span id="cb23-819"><a href="#cb23-819" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-820"><a href="#cb23-820" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Application de PCA pour réduction à 2D</span></span>
<span id="cb23-821"><a href="#cb23-821" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">2. Réduction de dimension avec PCA:"</span>)</span>
<span id="cb23-822"><a href="#cb23-822" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-823"><a href="#cb23-823" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb23-824"><a href="#cb23-824" aria-hidden="true" tabindex="-1"></a>X_pca <span class="op">=</span> pca.fit_transform(X_scaled)</span>
<span id="cb23-825"><a href="#cb23-825" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-826"><a href="#cb23-826" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   Variance expliquée par composante: </span><span class="sc">{</span>pca<span class="sc">.</span>explained_variance_ratio_<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-827"><a href="#cb23-827" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   Variance totale expliquée: </span><span class="sc">{</span><span class="bu">sum</span>(pca.explained_variance_ratio_)<span class="sc">:.2%}</span><span class="ss">"</span>)</span>
<span id="cb23-828"><a href="#cb23-828" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   Dimensions: </span><span class="sc">{</span>X<span class="sc">.</span>shape[<span class="dv">1</span>]<span class="sc">}</span><span class="ss">D → </span><span class="sc">{</span>X_pca<span class="sc">.</span>shape[<span class="dv">1</span>]<span class="sc">}</span><span class="ss">D"</span>)</span>
<span id="cb23-829"><a href="#cb23-829" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-830"><a href="#cb23-830" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualisation des données après PCA (sans clustering)</span></span>
<span id="cb23-831"><a href="#cb23-831" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb23-832"><a href="#cb23-832" aria-hidden="true" tabindex="-1"></a>scatter <span class="op">=</span> plt.scatter(X_pca[:, <span class="dv">0</span>], X_pca[:, <span class="dv">1</span>], </span>
<span id="cb23-833"><a href="#cb23-833" aria-hidden="true" tabindex="-1"></a>                     c<span class="op">=</span>true_labels, cmap<span class="op">=</span><span class="st">'viridis'</span>, </span>
<span id="cb23-834"><a href="#cb23-834" aria-hidden="true" tabindex="-1"></a>                     alpha<span class="op">=</span><span class="fl">0.6</span>, edgecolors<span class="op">=</span><span class="st">'w'</span>)</span>
<span id="cb23-835"><a href="#cb23-835" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="ss">f'PC1 (</span><span class="sc">{</span>pca<span class="sc">.</span>explained_variance_ratio_[<span class="dv">0</span>]<span class="sc">:.1%}</span><span class="ss"> variance)'</span>)</span>
<span id="cb23-836"><a href="#cb23-836" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="ss">f'PC2 (</span><span class="sc">{</span>pca<span class="sc">.</span>explained_variance_ratio_[<span class="dv">1</span>]<span class="sc">:.1%}</span><span class="ss"> variance)'</span>)</span>
<span id="cb23-837"><a href="#cb23-837" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Dataset Iris après PCA (coloré par vraies classes)'</span>)</span>
<span id="cb23-838"><a href="#cb23-838" aria-hidden="true" tabindex="-1"></a>plt.colorbar(scatter, label<span class="op">=</span><span class="st">'Vraie classe'</span>)</span>
<span id="cb23-839"><a href="#cb23-839" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb23-840"><a href="#cb23-840" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb23-841"><a href="#cb23-841" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb23-842"><a href="#cb23-842" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-843"><a href="#cb23-843" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Test de k-means avec k=2,3,4</span></span>
<span id="cb23-844"><a href="#cb23-844" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">3. Clustering k-means avec différentes valeurs de k:"</span>)</span>
<span id="cb23-845"><a href="#cb23-845" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb23-846"><a href="#cb23-846" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-847"><a href="#cb23-847" aria-hidden="true" tabindex="-1"></a>K_values <span class="op">=</span> [<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>]</span>
<span id="cb23-848"><a href="#cb23-848" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> []</span>
<span id="cb23-849"><a href="#cb23-849" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-850"><a href="#cb23-850" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> K_values:</span>
<span id="cb23-851"><a href="#cb23-851" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Clustering</span></span>
<span id="cb23-852"><a href="#cb23-852" aria-hidden="true" tabindex="-1"></a>    kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span>k, random_state<span class="op">=</span><span class="dv">42</span>, n_init<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb23-853"><a href="#cb23-853" aria-hidden="true" tabindex="-1"></a>    labels <span class="op">=</span> kmeans.fit_predict(X_pca)</span>
<span id="cb23-854"><a href="#cb23-854" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-855"><a href="#cb23-855" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Métriques</span></span>
<span id="cb23-856"><a href="#cb23-856" aria-hidden="true" tabindex="-1"></a>    inertia <span class="op">=</span> kmeans.inertia_</span>
<span id="cb23-857"><a href="#cb23-857" aria-hidden="true" tabindex="-1"></a>    silhouette <span class="op">=</span> silhouette_score(X_pca, labels)</span>
<span id="cb23-858"><a href="#cb23-858" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-859"><a href="#cb23-859" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Comparaison avec vraies classes (juste pour curiosité)</span></span>
<span id="cb23-860"><a href="#cb23-860" aria-hidden="true" tabindex="-1"></a>    ari <span class="op">=</span> adjusted_rand_score(true_labels, labels)</span>
<span id="cb23-861"><a href="#cb23-861" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-862"><a href="#cb23-862" aria-hidden="true" tabindex="-1"></a>    results.append({</span>
<span id="cb23-863"><a href="#cb23-863" aria-hidden="true" tabindex="-1"></a>        <span class="st">'k'</span>: k,</span>
<span id="cb23-864"><a href="#cb23-864" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Inertie'</span>: inertia,</span>
<span id="cb23-865"><a href="#cb23-865" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Silhouette'</span>: silhouette,</span>
<span id="cb23-866"><a href="#cb23-866" aria-hidden="true" tabindex="-1"></a>        <span class="st">'ARI (vs vrai)'</span>: ari,</span>
<span id="cb23-867"><a href="#cb23-867" aria-hidden="true" tabindex="-1"></a>        <span class="st">'labels'</span>: labels,</span>
<span id="cb23-868"><a href="#cb23-868" aria-hidden="true" tabindex="-1"></a>        <span class="st">'centroids'</span>: kmeans.cluster_centers_</span>
<span id="cb23-869"><a href="#cb23-869" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb23-870"><a href="#cb23-870" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-871"><a href="#cb23-871" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">k = </span><span class="sc">{</span>k<span class="sc">}</span><span class="ss">:"</span>)</span>
<span id="cb23-872"><a href="#cb23-872" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   Inertie: </span><span class="sc">{</span>inertia<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb23-873"><a href="#cb23-873" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   Silhouette Score: </span><span class="sc">{</span>silhouette<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb23-874"><a href="#cb23-874" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   Taille des clusters: </span><span class="sc">{</span>np<span class="sc">.</span>bincount(labels)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-875"><a href="#cb23-875" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   ARI (comparaison avec vraies classes): </span><span class="sc">{</span>ari<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb23-876"><a href="#cb23-876" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-877"><a href="#cb23-877" aria-hidden="true" tabindex="-1"></a><span class="co"># DataFrame des résultats</span></span>
<span id="cb23-878"><a href="#cb23-878" aria-hidden="true" tabindex="-1"></a>df_results <span class="op">=</span> pd.DataFrame([{k: v <span class="cf">for</span> k, v <span class="kw">in</span> r.items() <span class="cf">if</span> k <span class="kw">not</span> <span class="kw">in</span> [<span class="st">'labels'</span>, <span class="st">'centroids'</span>]} </span>
<span id="cb23-879"><a href="#cb23-879" aria-hidden="true" tabindex="-1"></a>                          <span class="cf">for</span> r <span class="kw">in</span> results])</span>
<span id="cb23-880"><a href="#cb23-880" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">📊 Tableau récapitulatif:"</span>)</span>
<span id="cb23-881"><a href="#cb23-881" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df_results.to_string(index<span class="op">=</span><span class="va">False</span>))</span>
<span id="cb23-882"><a href="#cb23-882" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-883"><a href="#cb23-883" aria-hidden="true" tabindex="-1"></a><span class="co"># Meilleur k selon silhouette</span></span>
<span id="cb23-884"><a href="#cb23-884" aria-hidden="true" tabindex="-1"></a>best_k <span class="op">=</span> df_results.loc[df_results[<span class="st">'Silhouette'</span>].idxmax(), <span class="st">'k'</span>]</span>
<span id="cb23-885"><a href="#cb23-885" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">⭐ Meilleur k selon Silhouette Score: </span><span class="sc">{</span>best_k<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-886"><a href="#cb23-886" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-887"><a href="#cb23-887" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Visualisation des clusters pour chaque k</span></span>
<span id="cb23-888"><a href="#cb23-888" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">4. Visualisation des clusters:"</span>)</span>
<span id="cb23-889"><a href="#cb23-889" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-890"><a href="#cb23-890" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">18</span>, <span class="dv">5</span>))</span>
<span id="cb23-891"><a href="#cb23-891" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-892"><a href="#cb23-892" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx, result <span class="kw">in</span> <span class="bu">enumerate</span>(results):</span>
<span id="cb23-893"><a href="#cb23-893" aria-hidden="true" tabindex="-1"></a>    k <span class="op">=</span> result[<span class="st">'k'</span>]</span>
<span id="cb23-894"><a href="#cb23-894" aria-hidden="true" tabindex="-1"></a>    labels <span class="op">=</span> result[<span class="st">'labels'</span>]</span>
<span id="cb23-895"><a href="#cb23-895" aria-hidden="true" tabindex="-1"></a>    centroids <span class="op">=</span> result[<span class="st">'centroids'</span>]</span>
<span id="cb23-896"><a href="#cb23-896" aria-hidden="true" tabindex="-1"></a>    ax <span class="op">=</span> axes[idx]</span>
<span id="cb23-897"><a href="#cb23-897" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Scatter plot des points</span></span>
<span id="cb23-898"><a href="#cb23-898" aria-hidden="true" tabindex="-1"></a>    scatter <span class="op">=</span> ax.scatter(X_pca[:, <span class="dv">0</span>], X_pca[:, <span class="dv">1</span>], </span>
<span id="cb23-899"><a href="#cb23-899" aria-hidden="true" tabindex="-1"></a>                        c<span class="op">=</span>labels, cmap<span class="op">=</span><span class="st">'tab10'</span>, </span>
<span id="cb23-900"><a href="#cb23-900" aria-hidden="true" tabindex="-1"></a>                        alpha<span class="op">=</span><span class="fl">0.6</span>, edgecolors<span class="op">=</span><span class="st">'w'</span>, s<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb23-901"><a href="#cb23-901" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-902"><a href="#cb23-902" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Centroïdes</span></span>
<span id="cb23-903"><a href="#cb23-903" aria-hidden="true" tabindex="-1"></a>    ax.scatter(centroids[:, <span class="dv">0</span>], centroids[:, <span class="dv">1</span>], </span>
<span id="cb23-904"><a href="#cb23-904" aria-hidden="true" tabindex="-1"></a>              c<span class="op">=</span><span class="st">'red'</span>, marker<span class="op">=</span><span class="st">'X'</span>, s<span class="op">=</span><span class="dv">200</span>, </span>
<span id="cb23-905"><a href="#cb23-905" aria-hidden="true" tabindex="-1"></a>              edgecolors<span class="op">=</span><span class="st">'black'</span>, linewidths<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb23-906"><a href="#cb23-906" aria-hidden="true" tabindex="-1"></a>              label<span class="op">=</span><span class="st">'Centroïdes'</span>)</span>
<span id="cb23-907"><a href="#cb23-907" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-908"><a href="#cb23-908" aria-hidden="true" tabindex="-1"></a>    ax.set_xlabel(<span class="ss">f'PC1 (</span><span class="sc">{</span>pca<span class="sc">.</span>explained_variance_ratio_[<span class="dv">0</span>]<span class="sc">:.1%}</span><span class="ss">)'</span>)</span>
<span id="cb23-909"><a href="#cb23-909" aria-hidden="true" tabindex="-1"></a>    ax.set_ylabel(<span class="ss">f'PC2 (</span><span class="sc">{</span>pca<span class="sc">.</span>explained_variance_ratio_[<span class="dv">1</span>]<span class="sc">:.1%}</span><span class="ss">)'</span>)</span>
<span id="cb23-910"><a href="#cb23-910" aria-hidden="true" tabindex="-1"></a>    ax.set_title(<span class="ss">f'k=</span><span class="sc">{</span>k<span class="sc">}</span><span class="ss"> (Silhouette=</span><span class="sc">{</span>result[<span class="st">"Silhouette"</span>]<span class="sc">:.3f}</span><span class="ss">)'</span>)</span>
<span id="cb23-911"><a href="#cb23-911" aria-hidden="true" tabindex="-1"></a>    ax.legend()</span>
<span id="cb23-912"><a href="#cb23-912" aria-hidden="true" tabindex="-1"></a>    ax.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb23-913"><a href="#cb23-913" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-914"><a href="#cb23-914" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Colorbar</span></span>
<span id="cb23-915"><a href="#cb23-915" aria-hidden="true" tabindex="-1"></a>    plt.colorbar(scatter, ax<span class="op">=</span>ax, label<span class="op">=</span><span class="st">'Cluster'</span>)</span>
<span id="cb23-916"><a href="#cb23-916" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-917"><a href="#cb23-917" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb23-918"><a href="#cb23-918" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb23-919"><a href="#cb23-919" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-920"><a href="#cb23-920" aria-hidden="true" tabindex="-1"></a><span class="co"># 5. Analyse approfondie du meilleur k</span></span>
<span id="cb23-921"><a href="#cb23-921" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">5. Analyse détaillée pour k=</span><span class="sc">{</span>best_k<span class="sc">}</span><span class="ss">:"</span>)</span>
<span id="cb23-922"><a href="#cb23-922" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb23-923"><a href="#cb23-923" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-924"><a href="#cb23-924" aria-hidden="true" tabindex="-1"></a>best_result <span class="op">=</span> [r <span class="cf">for</span> r <span class="kw">in</span> results <span class="cf">if</span> r[<span class="st">'k'</span>] <span class="op">==</span> best_k][<span class="dv">0</span>]</span>
<span id="cb23-925"><a href="#cb23-925" aria-hidden="true" tabindex="-1"></a>best_labels <span class="op">=</span> best_result[<span class="st">'labels'</span>]</span>
<span id="cb23-926"><a href="#cb23-926" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-927"><a href="#cb23-927" aria-hidden="true" tabindex="-1"></a><span class="co"># Profilage des clusters</span></span>
<span id="cb23-928"><a href="#cb23-928" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Profilage des clusters (features originales):"</span>)</span>
<span id="cb23-929"><a href="#cb23-929" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-930"><a href="#cb23-930" aria-hidden="true" tabindex="-1"></a>df_analysis <span class="op">=</span> pd.DataFrame(X, columns<span class="op">=</span>feature_names)</span>
<span id="cb23-931"><a href="#cb23-931" aria-hidden="true" tabindex="-1"></a>df_analysis[<span class="st">'Cluster'</span>] <span class="op">=</span> best_labels</span>
<span id="cb23-932"><a href="#cb23-932" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-933"><a href="#cb23-933" aria-hidden="true" tabindex="-1"></a>cluster_profiles <span class="op">=</span> df_analysis.groupby(<span class="st">'Cluster'</span>).agg([<span class="st">'mean'</span>, <span class="st">'std'</span>])</span>
<span id="cb23-934"><a href="#cb23-934" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(cluster_profiles)</span>
<span id="cb23-935"><a href="#cb23-935" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-936"><a href="#cb23-936" aria-hidden="true" tabindex="-1"></a><span class="co"># Heatmap des caractéristiques par cluster</span></span>
<span id="cb23-937"><a href="#cb23-937" aria-hidden="true" tabindex="-1"></a>cluster_means <span class="op">=</span> df_analysis.groupby(<span class="st">'Cluster'</span>).mean()</span>
<span id="cb23-938"><a href="#cb23-938" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-939"><a href="#cb23-939" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb23-940"><a href="#cb23-940" aria-hidden="true" tabindex="-1"></a>sns.heatmap(cluster_means.T, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">'.2f'</span>, cmap<span class="op">=</span><span class="st">'YlOrRd'</span>,</span>
<span id="cb23-941"><a href="#cb23-941" aria-hidden="true" tabindex="-1"></a>            cbar_kws<span class="op">=</span>{<span class="st">'label'</span>: <span class="st">'Valeur moyenne'</span>})</span>
<span id="cb23-942"><a href="#cb23-942" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Cluster'</span>)</span>
<span id="cb23-943"><a href="#cb23-943" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Feature'</span>)</span>
<span id="cb23-944"><a href="#cb23-944" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="ss">f'Profil des </span><span class="sc">{</span>best_k<span class="sc">}</span><span class="ss"> clusters (valeurs moyennes)'</span>)</span>
<span id="cb23-945"><a href="#cb23-945" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb23-946"><a href="#cb23-946" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb23-947"><a href="#cb23-947" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-948"><a href="#cb23-948" aria-hidden="true" tabindex="-1"></a><span class="co"># Comparaison avec les vraies classes (curiosité académique)</span></span>
<span id="cb23-949"><a href="#cb23-949" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">📈 Comparaison avec les vraies espèces d'Iris:"</span>)</span>
<span id="cb23-950"><a href="#cb23-950" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"(Note: Le clustering est NON SUPERVISÉ, cette comparaison est"</span>)</span>
<span id="cb23-951"><a href="#cb23-951" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">" juste pour comprendre ce que l'algorithme a trouvé)"</span>)</span>
<span id="cb23-952"><a href="#cb23-952" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-953"><a href="#cb23-953" aria-hidden="true" tabindex="-1"></a>confusion_unsupervised <span class="op">=</span> pd.crosstab(</span>
<span id="cb23-954"><a href="#cb23-954" aria-hidden="true" tabindex="-1"></a>    pd.Series(true_labels, name<span class="op">=</span><span class="st">'Vraie espèce'</span>),</span>
<span id="cb23-955"><a href="#cb23-955" aria-hidden="true" tabindex="-1"></a>    pd.Series(best_labels, name<span class="op">=</span><span class="st">'Cluster trouvé'</span>)</span>
<span id="cb23-956"><a href="#cb23-956" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb23-957"><a href="#cb23-957" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(confusion_unsupervised)</span>
<span id="cb23-958"><a href="#cb23-958" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-959"><a href="#cb23-959" aria-hidden="true" tabindex="-1"></a><span class="co"># Conclusion</span></span>
<span id="cb23-960"><a href="#cb23-960" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb23-961"><a href="#cb23-961" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"CONCLUSION"</span>)</span>
<span id="cb23-962"><a href="#cb23-962" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb23-963"><a href="#cb23-963" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"✓ PCA a réduit les données de 4D à 2D"</span>)</span>
<span id="cb23-964"><a href="#cb23-964" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"✓ </span><span class="sc">{</span><span class="bu">sum</span>(pca.explained_variance_ratio_)<span class="sc">:.1%}</span><span class="ss"> de variance préservée"</span>)</span>
<span id="cb23-965"><a href="#cb23-965" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"✓ K optimal selon silhouette: </span><span class="sc">{</span>best_k<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-966"><a href="#cb23-966" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"✓ Silhouette score: </span><span class="sc">{</span>best_result[<span class="st">'Silhouette'</span>]<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb23-967"><a href="#cb23-967" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"✓ Les clusters correspondent </span><span class="sc">{</span><span class="st">'assez bien'</span> <span class="cf">if</span> best_result[<span class="st">'ARI (vs vrai)'</span>] <span class="op">&gt;</span> <span class="fl">0.7</span> <span class="cf">else</span> <span class="st">'partiellement'</span><span class="sc">}</span><span class="ss"> aux vraies espèces"</span>)</span>
<span id="cb23-968"><a href="#cb23-968" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  (ARI = </span><span class="sc">{</span>best_result[<span class="st">'ARI (vs vrai)'</span>]<span class="sc">:.3f}</span><span class="ss">)"</span>)</span>
<span id="cb23-969"><a href="#cb23-969" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-970"><a href="#cb23-970" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-971"><a href="#cb23-971" aria-hidden="true" tabindex="-1"></a>**Résultat attendu:**</span>
<span id="cb23-972"><a href="#cb23-972" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-973"><a href="#cb23-973" aria-hidden="true" tabindex="-1"></a>Le pipeline devrait révéler que:</span>
<span id="cb23-974"><a href="#cb23-974" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-975"><a href="#cb23-975" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**k=3** est optimal (correspond aux 3 espèces d'Iris)</span>
<span id="cb23-976"><a href="#cb23-976" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Le silhouette score sera autour de 0.5-0.6</span>
<span id="cb23-977"><a href="#cb23-977" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>PCA capture environ 95% de la variance en 2D</span>
<span id="cb23-978"><a href="#cb23-978" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Les clusters trouvés correspondent assez bien aux vraies espèces</span>
<span id="cb23-979"><a href="#cb23-979" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Une espèce (Setosa) sera bien séparée, les deux autres se chevaucheront un peu</span>
<span id="cb23-980"><a href="#cb23-980" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb23-981"><a href="#cb23-981" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-982"><a href="#cb23-982" aria-hidden="true" tabindex="-1"></a><span class="fu">## Résumé de la Séance</span></span>
<span id="cb23-983"><a href="#cb23-983" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-984"><a href="#cb23-984" aria-hidden="true" tabindex="-1"></a>::: {.callout-important icon=false}</span>
<span id="cb23-985"><a href="#cb23-985" aria-hidden="true" tabindex="-1"></a><span class="fu">## Points clés à retenir</span></span>
<span id="cb23-986"><a href="#cb23-986" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-987"><a href="#cb23-987" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Apprentissage non supervisé** = découvrir des patterns dans des données non étiquetées</span>
<span id="cb23-988"><a href="#cb23-988" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Clustering** = regrouper des données similaires (k-means, DBSCAN, hiérarchique)</span>
<span id="cb23-989"><a href="#cb23-989" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**Mesures de qualité** : silhouette score, inertie, Davies-Bouldin</span>
<span id="cb23-990"><a href="#cb23-990" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>**Réduction de dimension** : PCA (linéaire), t-SNE (non-linéaire)</span>
<span id="cb23-991"><a href="#cb23-991" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>**Applications** : segmentation client, analyse de documents, traitement d'image</span>
<span id="cb23-992"><a href="#cb23-992" aria-hidden="true" tabindex="-1"></a><span class="ss">6. </span>**Défis** : choix du nombre de clusters, qualité sans vérité terrain</span>
<span id="cb23-993"><a href="#cb23-993" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb23-994"><a href="#cb23-994" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-995"><a href="#cb23-995" aria-hidden="true" tabindex="-1"></a><span class="fu">## Lectures Complémentaires</span></span>
<span id="cb23-996"><a href="#cb23-996" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-997"><a href="#cb23-997" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Géron, A. (2019) - Chapitre 9: Unsupervised Learning Techniques</span>
<span id="cb23-998"><a href="#cb23-998" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span><span class="co">[</span><span class="ot">Scikit-learn Clustering Documentation</span><span class="co">](https://scikit-learn.org/stable/modules/clustering.html)</span></span>
<span id="cb23-999"><a href="#cb23-999" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span><span class="co">[</span><span class="ot">Visualizing Data using t-SNE</span><span class="co">](https://jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf)</span><span class="dt">&lt;/</span><span class="kw">parameter</span><span class="dt">&gt;</span></span>
</code></pre></div><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></div>
</div></div></div></div></div>
</div> <!-- /content -->




</body></html>