{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Séance 8: TP3 - Régression & Optimisation\n",
        "\n",
        "::: {.callout-note icon=false}\n",
        "## Informations de la séance\n",
        "- **Type**: Travaux Pratiques\n",
        "- **Durée**: 2h\n",
        "- **Objectifs**: Obj6, Obj7\n",
        ":::\n",
        "\n",
        "## Introduction\n",
        "Dans ce TP, nous allons mettre en pratique les concepts de régression vus en cours. Nous travaillerons sur un dataset réel pour prédire les prix de maisons, en comparant différents modèles de régression et en optimisant leurs hyperparamètres.\n",
        "\n",
        "**Objectifs du TP:**\n",
        "\n",
        "1. Prétraiter des données pour la régression\n",
        "2. Implémenter et comparer Linear, Ridge, Lasso, ElasticNet, SVR\n",
        "3. Optimiser les hyperparamètres avec CV\n",
        "4. Évaluer avec métriques multiples (MAE, RMSE, R²)\n",
        "5. Interpréter et visualiser les résultats\n",
        "\n",
        "## 1. Chargement et Exploration du Dataset\n",
        "\n",
        "Nous utilisons le **Boston Housing Dataset** (ou California Housing si Boston non disponible)."
      ],
      "id": "dde72c72"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "#| eval: true\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Chargement\n",
        "california = fetch_california_housing()\n",
        "X, y = california.data, california.target\n",
        "\n",
        "# DataFrame pour exploration\n",
        "df = pd.DataFrame(X, columns=california.feature_names)\n",
        "df['MedHouseVal'] = y\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"DATASET: CALIFORNIA HOUSING\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\\nShape: {X.shape}\")\n",
        "print(f\"Features: {california.feature_names}\")\n",
        "print(f\"\\nDescription du target (prix médian en 100k$):\")\n",
        "print(df['MedHouseVal'].describe())\n",
        "\n",
        "# Statistiques descriptives\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"STATISTIQUES DESCRIPTIVES\")\n",
        "print(\"=\" * 70)\n",
        "print(df.describe().T)\n",
        "\n",
        "# Vérifier les valeurs manquantes\n",
        "print(f\"\\nValeurs manquantes par feature:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Visualisations\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "\n",
        "# Distribution du target\n",
        "axes[0, 0].hist(y, bins=50, edgecolor='black', alpha=0.7)\n",
        "axes[0, 0].set_xlabel('Prix Médian (100k$)')\n",
        "axes[0, 0].set_ylabel('Fréquence')\n",
        "axes[0, 0].set_title('Distribution des Prix')\n",
        "axes[0, 0].axvline(y.mean(), color='red', linestyle='--', label=f'Moyenne: {y.mean():.2f}')\n",
        "axes[0, 0].legend()\n",
        "\n",
        "# Boxplot des features (normalisées pour comparaison)\n",
        "df_normalized = (df - df.mean()) / df.std()\n",
        "axes[0, 1].boxplot([df_normalized[col] for col in california.feature_names],\n",
        "                    labels=california.feature_names, vert=True)\n",
        "axes[0, 1].set_xticklabels(california.feature_names, rotation=45, ha='right')\n",
        "axes[0, 1].set_ylabel('Valeurs normalisées')\n",
        "axes[0, 1].set_title('Distribution des Features (normalisées)')\n",
        "axes[0, 1].grid(alpha=0.3)\n",
        "\n",
        "# Matrice de corrélation\n",
        "corr_matrix = df.corr()\n",
        "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
        "sns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.2f', cmap='coolwarm',\n",
        "            center=0, ax=axes[1, 0], cbar_kws={'label': 'Corrélation'})\n",
        "axes[1, 0].set_title('Matrice de Corrélation')\n",
        "\n",
        "# Scatter: Feature la plus corrélée avec target\n",
        "corr_with_target = corr_matrix['MedHouseVal'].drop('MedHouseVal').abs().sort_values(ascending=False)\n",
        "best_feature = corr_with_target.index[0]\n",
        "axes[1, 1].scatter(df[best_feature], df['MedHouseVal'], alpha=0.3)\n",
        "axes[1, 1].set_xlabel(best_feature)\n",
        "axes[1, 1].set_ylabel('Prix Médian')\n",
        "axes[1, 1].set_title(f'Prix vs {best_feature} (corr={corr_matrix.loc[best_feature, \"MedHouseVal\"]:.2f})')\n",
        "axes[1, 1].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"CORRÉLATIONS AVEC LE TARGET\")\n",
        "print(\"=\" * 70)\n",
        "print(corr_with_target)"
      ],
      "id": "4a068f55",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercice 1.1: Analyse Exploratoire\n",
        "\n",
        "**Questions:**\n",
        "\n",
        "1. Quelle feature est la plus corrélée avec le prix?\n",
        "2. Y a-t-il des features fortement corrélées entre elles? (Multicolinéarité potentielle?)\n",
        "3. La distribution du target est-elle gaussienne? Quel traitement pourrait être appliqué si non?\n",
        "4. Identifiez des outliers potentiels\n",
        "\n",
        "::: {.callout-note collapse=\"true\"}\n",
        "## Solution Exercice 1.1"
      ],
      "id": "bef51d78"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "#| eval: true\n",
        "print(\"=\" * 70)\n",
        "print(\"ANALYSE EXPLORATOIRE - RÉPONSES\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# 1. Feature la plus corrélée\n",
        "print(f\"\\n1. Feature la plus corrélée avec le prix:\")\n",
        "print(f\"   → {best_feature} (corrélation = {corr_matrix.loc[best_feature, 'MedHouseVal']:.3f})\")\n",
        "\n",
        "# 2. Multicolinéarité\n",
        "print(f\"\\n2. Paires de features fortement corrélées (|corr| > 0.7):\")\n",
        "corr_pairs = []\n",
        "for i in range(len(corr_matrix.columns)):\n",
        "    for j in range(i+1, len(corr_matrix.columns)):\n",
        "        if i != j:\n",
        "            corr_val = corr_matrix.iloc[i, j]\n",
        "            if abs(corr_val) > 0.7:\n",
        "                corr_pairs.append((corr_matrix.columns[i], corr_matrix.columns[j], corr_val))\n",
        "\n",
        "if corr_pairs:\n",
        "    for feat1, feat2, corr_val in corr_pairs:\n",
        "        print(f\"   • {feat1} <-> {feat2}: {corr_val:.3f}\")\n",
        "else:\n",
        "    print(\"   → Aucune multicolinéarité forte détectée\")\n",
        "\n",
        "# 3. Distribution du target\n",
        "from scipy import stats\n",
        "shapiro_stat, shapiro_p = stats.shapiro(y[:1000])  # Test sur échantillon\n",
        "print(f\"\\n3. Test de normalité (Shapiro-Wilk):\")\n",
        "print(f\"   Statistique: {shapiro_stat:.4f}, p-value: {shapiro_p:.4e}\")\n",
        "if shapiro_p < 0.05:\n",
        "    print(\"   → Distribution NON gaussienne (p < 0.05)\")\n",
        "    print(\"   Traitements possibles:\")\n",
        "    print(\"   • Transformation log(y)\")\n",
        "    print(\"   • Transformation Box-Cox\")\n",
        "    print(\"   • Utiliser des modèles robustes aux distributions non-gaussiennes\")\n",
        "else:\n",
        "    print(\"   → Distribution gaussienne (p >= 0.05)\")\n",
        "\n",
        "# Skewness et Kurtosis\n",
        "skewness = stats.skew(y)\n",
        "kurtosis = stats.kurtosis(y)\n",
        "print(f\"   Asymétrie (Skewness): {skewness:.3f}\")\n",
        "print(f\"   Aplatissement (Kurtosis): {kurtosis:.3f}\")\n",
        "\n",
        "# 4. Outliers\n",
        "print(f\"\\n4. Détection d'outliers:\")\n",
        "Q1 = df['MedHouseVal'].quantile(0.25)\n",
        "Q3 = df['MedHouseVal'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "outliers = df[(df['MedHouseVal'] < lower_bound) | (df['MedHouseVal'] > upper_bound)]\n",
        "print(f\"   Intervalle IQR: [{Q1:.2f}, {Q3:.2f}]\")\n",
        "print(f\"   Bornes: [{lower_bound:.2f}, {upper_bound:.2f}]\")\n",
        "print(f\"   Nombre d'outliers: {len(outliers)} ({len(outliers)/len(df)*100:.1f}%)\")\n",
        "\n",
        "# Visualisation des outliers\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "ax.scatter(range(len(y)), np.sort(y), alpha=0.5, s=10)\n",
        "ax.axhline(lower_bound, color='red', linestyle='--', label='Lower bound')\n",
        "ax.axhline(upper_bound, color='red', linestyle='--', label='Upper bound')\n",
        "ax.set_xlabel('Index (trié)')\n",
        "ax.set_ylabel('Prix')\n",
        "ax.set_title('Détection d\\'Outliers par IQR')\n",
        "ax.legend()\n",
        "ax.grid(alpha=0.3)\n",
        "plt.show()"
      ],
      "id": "841d85df",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Conclusions typiques:**\n",
        "\n",
        "1. **MedInc** (revenu médian) généralement le plus corrélé (~0.68)\n",
        "2. Multicolinéarité possible → considérer Ridge/ElasticNet\n",
        "3. Distribution souvent légèrement asymétrique → transformation log possible\n",
        "4. Quelques outliers mais acceptable (<5%)\n",
        ":::\n",
        "\n",
        "## 2. Prétraitement et Split"
      ],
      "id": "1a148654"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "#| eval: true\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Split train/test (80/20)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"SPLIT DES DONNÉES\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Train set: {X_train.shape}\")\n",
        "print(f\"Test set: {X_test.shape}\")\n",
        "\n",
        "# Standardisation (importante pour Ridge, Lasso, SVR)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"\\nStandardisation:\")\n",
        "print(f\"Mean (train): {X_train_scaled.mean(axis=0)}\")  # Devrait être ~0\n",
        "print(f\"Std (train): {X_train_scaled.std(axis=0)}\")    # Devrait être ~1\n",
        "\n",
        "# Vérification\n",
        "print(f\"\\nVérification après scaling:\")\n",
        "print(f\"  Mean proche de 0: {np.allclose(X_train_scaled.mean(axis=0), 0, atol=1e-10)}\")\n",
        "print(f\"  Std proche de 1: {np.allclose(X_train_scaled.std(axis=0), 1, atol=1e-2)}\")"
      ],
      "id": "95602d4a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.callout-warning}\n",
        "## Importance de la Standardisation\n",
        "\n",
        "**Pourquoi standardiser?**\n",
        "- Ridge/Lasso: Pénalisation équitable des coefficients\n",
        "- SVR: Sensible à l'échelle des features\n",
        "- Convergence plus rapide des algorithmes itératifs\n",
        "\n",
        "**Quand ne PAS standardiser?**\n",
        "- Arbres de décision / Random Forest (invariants aux transformations monotones)\n",
        "- Régression linéaire simple (si pas de régularisation)\n",
        "\n",
        "**Règle:** Toujours fit sur train, transform sur test (éviter data leakage)\n",
        ":::\n",
        "\n",
        "## 3. Modèles de Base\n",
        "\n",
        "### Exercice 3.1: Régression Linéaire Simple\n",
        "\n",
        "Entraînez une régression linéaire et évaluez-la.\n",
        "\n",
        "**Instructions:**\n",
        "1. Créez et entraînez le modèle\n",
        "2. Prédisez sur train et test\n",
        "3. Calculez MAE, RMSE, R² pour les deux ensembles\n",
        "4. Affichez les 5 coefficients les plus importants\n",
        "5. Visualisez prédictions vs vraies valeurs\n",
        "\n",
        "::: {.callout-note collapse=\"true\"}\n",
        "## Solution Exercice 3.1"
      ],
      "id": "5c69fbfa"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "#| eval: true\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"RÉGRESSION LINÉAIRE SIMPLE\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# 1. Entraînement\n",
        "model_lr = LinearRegression()\n",
        "model_lr.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 2. Prédictions\n",
        "y_train_pred = model_lr.predict(X_train_scaled)\n",
        "y_test_pred = model_lr.predict(X_test_scaled)\n",
        "\n",
        "# 3. Métriques\n",
        "def evaluate_model(y_true, y_pred, dataset_name=\"\"):\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    \n",
        "    print(f\"\\n{dataset_name}:\")\n",
        "    print(f\"  MAE:  {mae:.4f}\")\n",
        "    print(f\"  RMSE: {rmse:.4f}\")\n",
        "    print(f\"  R²:   {r2:.4f}\")\n",
        "    \n",
        "    return {'MAE': mae, 'RMSE': rmse, 'R2': r2}\n",
        "\n",
        "train_metrics = evaluate_model(y_train, y_train_pred, \"Train Set\")\n",
        "test_metrics = evaluate_model(y_test, y_test_pred, \"Test Set\")\n",
        "\n",
        "# 4. Coefficients importants\n",
        "coef_df = pd.DataFrame({\n",
        "    'Feature': california.feature_names,\n",
        "    'Coefficient': model_lr.coef_\n",
        "})\n",
        "coef_df['Abs_Coef'] = np.abs(coef_df['Coefficient'])\n",
        "coef_df = coef_df.sort_values('Abs_Coef', ascending=False)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"COEFFICIENTS (TOP 5)\")\n",
        "print(\"=\" * 70)\n",
        "print(coef_df[['Feature', 'Coefficient']].head().to_string(index=False))\n",
        "\n",
        "# 5. Visualisation\n",
        "fig, axes = plt.subplots(1, 3, figsize=(12, 5))\n",
        "\n",
        "# Prédictions vs Vraies valeurs (Test)\n",
        "axes[0].scatter(y_test, y_test_pred, alpha=0.3, s=10)\n",
        "axes[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \n",
        "             'r--', lw=2, label='Prédiction parfaite')\n",
        "axes[0].set_xlabel('Vraie valeur')\n",
        "axes[0].set_ylabel('Prédiction')\n",
        "axes[0].set_title(f'Régression Linéaire (Test R²={test_metrics[\"R2\"]:.3f})')\n",
        "axes[0].legend()\n",
        "axes[0].grid(alpha=0.3)\n",
        "\n",
        "# Résidus\n",
        "residuals = y_test - y_test_pred\n",
        "axes[1].scatter(y_test_pred, residuals, alpha=0.3, s=10)\n",
        "axes[1].axhline(0, color='red', linestyle='--', lw=2)\n",
        "axes[1].set_xlabel('Prédictions')\n",
        "axes[1].set_ylabel('Résidus')\n",
        "axes[1].set_title('Graphique des Résidus')\n",
        "axes[1].grid(alpha=0.3)\n",
        "\n",
        "# Distribution des résidus\n",
        "axes[2].hist(residuals, bins=50, edgecolor='black', alpha=0.7)\n",
        "axes[2].axvline(residuals.mean(), color='red', linestyle='--', \n",
        "               label=f'Moyenne: {residuals.mean():.4f}')\n",
        "axes[2].set_xlabel('Résidus')\n",
        "axes[2].set_ylabel('Fréquence')\n",
        "axes[2].set_title('Distribution des Résidus')\n",
        "axes[2].legend()\n",
        "axes[2].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Analyse des résidus\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"ANALYSE DES RÉSIDUS\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Moyenne: {residuals.mean():.6f} (devrait être $\\approx$ 0)\")\n",
        "print(f\"Std: {residuals.std():.4f}\")\n",
        "print(f\"Min: {residuals.min():.4f}\")\n",
        "print(f\"Max: {residuals.max():.4f}\")"
      ],
      "id": "79cdf242",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Interprétation:**\n",
        "- R² train > R² test → léger surapprentissage (normal)\n",
        "- Résidus centrés sur 0 → modèle non biaisé\n",
        "- Distribution des résidus approximativement gaussienne → hypothèses vérifiées\n",
        ":::\n",
        "\n",
        "## 4. Modèles Régularisés\n",
        "\n",
        "### Exercice 4.1: Comparaison Ridge, Lasso, ElasticNet\n",
        "\n",
        "Comparez les 3 modèles régularisés avec différentes valeurs de alpha.\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "1. Testez alpha dans [0.001, 0.01, 0.1, 1, 10, 100]\n",
        "2. Pour chaque modèle et chaque alpha:\n",
        "   - Entraînez sur train\n",
        "   - Calculez R² sur test\n",
        "3. Tracez R² vs alpha pour les 3 modèles\n",
        "4. Identifiez le meilleur modèle et le meilleur alpha\n",
        "\n",
        "::: {.callout-note collapse=\"true\"}\n",
        "## Solution Exercice 4.1"
      ],
      "id": "f4b0c51d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "#| eval: true\n",
        "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"COMPARAISON RIDGE, LASSO, ELASTICNET\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# 1. Grille d'alphas\n",
        "alphas = [0.001, 0.01, 0.1, 1, 10, 100]\n",
        "\n",
        "# Stocker les résultats\n",
        "results = {'Ridge': [], 'Lasso': [], 'ElasticNet': []}\n",
        "\n",
        "# 2. Entraînement\n",
        "for alpha in alphas:\n",
        "    # Ridge\n",
        "    ridge = Ridge(alpha=alpha)\n",
        "    ridge.fit(X_train_scaled, y_train)\n",
        "    r2_ridge = r2_score(y_test, ridge.predict(X_test_scaled))\n",
        "    results['Ridge'].append(r2_ridge)\n",
        "    \n",
        "    # Lasso\n",
        "    lasso = Lasso(alpha=alpha, max_iter=10000)\n",
        "    lasso.fit(X_train_scaled, y_train)\n",
        "    r2_lasso = r2_score(y_test, lasso.predict(X_test_scaled))\n",
        "    results['Lasso'].append(r2_lasso)\n",
        "    \n",
        "    # ElasticNet\n",
        "    elastic = ElasticNet(alpha=alpha, l1_ratio=0.5, max_iter=10000)\n",
        "    elastic.fit(X_train_scaled, y_train)\n",
        "    r2_elastic = r2_score(y_test, elastic.predict(X_test_scaled))\n",
        "    results['ElasticNet'].append(r2_elastic)\n",
        "\n",
        "# 3. Visualisation\n",
        "plt.figure(figsize=(12, 6))\n",
        "for model_name, r2_scores in results.items():\n",
        "    plt.plot(alphas, r2_scores, marker='o', label=model_name, linewidth=2)\n",
        "\n",
        "plt.xscale('log')\n",
        "plt.xlabel('alpha (log scale)')\n",
        "plt.ylabel('R² Score (Test)')\n",
        "plt.title('Comparaison Ridge, Lasso, ElasticNet')\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "plt.axhline(test_metrics['R2'], color='red', linestyle='--', \n",
        "           label=f'Linear (alpha=0): {test_metrics[\"R2\"]:.4f}', alpha=0.5)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 4. Meilleur modèle\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"MEILLEURS HYPERPARAMÈTRES\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "for model_name, r2_scores in results.items():\n",
        "    best_idx = np.argmax(r2_scores)\n",
        "    best_alpha = alphas[best_idx]\n",
        "    best_r2 = r2_scores[best_idx]\n",
        "    print(f\"\\n{model_name}:\")\n",
        "    print(f\"  Meilleur alpha: {best_alpha}\")\n",
        "    print(f\"  R² Test: {best_r2:.4f}\")\n",
        "\n",
        "# Tableau comparatif\n",
        "df_comparison = pd.DataFrame(results, index=[f'alpha={a}' for a in alphas])\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"TABLEAU COMPARATIF (R² Test)\")\n",
        "print(\"=\" * 70)\n",
        "print(df_comparison.to_string())"
      ],
      "id": "17f04417",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observations attendues:**\n",
        "- Ridge: R² stable, peu sensible à alpha\n",
        "- Lasso: R² peut chuter si alpha trop élevé (trop de coefficients à 0)\n",
        "- ElasticNet: Compromis entre Ridge et Lasso\n",
        ":::\n",
        "\n",
        "### Exercice 4.2: Sélection de Features avec Lasso\n",
        "\n",
        "Utilisez Lasso pour identifier les features importantes.\n",
        "\n",
        "**Instructions:**\n",
        "1. Entraînez Lasso avec alpha=0.1\n",
        "2. Affichez le nombre de coefficients non-nuls\n",
        "3. Identifiez les features sélectionnées\n",
        "4. Comparez les coefficients Lasso vs Linear\n",
        "\n",
        "::: {.callout-note collapse=\"true\"}\n",
        "## Solution Exercice 4.2\n",
        "\n",
        "```python\n",
        "print(\"=\" * 70)\n",
        "print(\"SÉLECTION DE FEATURES AVEC LASSO\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# 1. Entraînement\n",
        "lasso = Lasso(alpha=0.1, max_iter=10000)\n",
        "lasso.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 2. Coefficients non-nuls\n",
        "non_zero_mask = np.abs(lasso.coef_) > 1e-5\n",
        "n_selected = np.sum(non_zero_mask)\n",
        "n_total = len(lasso.coef_)\n",
        "\n",
        "print(f\"\\nNombre de features sélectionnées: {n_selected}/{n_total}\")\n",
        "\n",
        "# 3. Features sélectionnées\n",
        "selected_features = pd.DataFrame({\n",
        "    'Feature': california.feature_names,\n",
        "    'Lasso_Coef': lasso.coef_,\n",
        "    'Linear_Coef': model_lr.coef_,\n",
        "    'Selected': non_zero_mask\n",
        "})\n",
        "selected_features['Abs_Lasso'] = np.abs(selected_features['Lasso_Coef'])\n",
        "selected_features = selected_features.sort_values('Abs_Lasso', ascending=False)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"COMPARAISON COEFFICIENTS\")\n",
        "print(\"=\" * 70)\n",
        "print(selected_features[['Feature', 'Lasso_Coef', 'Linear_Coef', 'Selected']].to_string(index=False))\n",
        "\n",
        "# 4. Visualisation\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "# Barplot comparatif\n",
        "x_pos = np.arange(len(california.feature_names))\n",
        "width = 0.35\n",
        "\n",
        "axes[0].bar(x_pos - width/2, model_lr.coef_, width, label='Linear', alpha=0.7)\n",
        "axes[0].bar(x_pos + width/2, lasso.coef_, width, label='Lasso (alpha=0.1)', alpha=0.7)\n",
        "axes[0].set_xticks(x_pos)\n",
        "axes[0].set_xticklabels(california.feature_names, rotation=45, ha='right')\n",
        "axes[0].set_ylabel('Coefficient')\n",
        "axes[0].set_title('Comparaison Coefficients: Linear vs Lasso')\n",
        "axes[0].legend()\n",
        "axes[0].axhline(0, color='black', linewidth=0.8)\n",
        "axes[0].grid(alpha=0.3, axis='y')\n",
        "\n",
        "# Scatter: Linear vs Lasso\n",
        "axes[1].scatter(model_lr.coef_, lasso.coef_, s=100, alpha=0.6)\n",
        "for i, feature in enumerate(california.feature_names):\n",
        "    axes[1].annotate(feature, (model_lr.coef_[i], lasso.coef_[i]),\n",
        "                     fontsize=8, alpha=0.7)\n",
        "axes[1].plot([model_lr.coef_.min(), model_lr.coef_.max()],\n",
        "             [model_lr.coef_.min(), model_lr.coef_.max()],\n",
        "             'r--', label='y=x')\n",
        "axes[1].set_xlabel('Coefficient Linear')\n",
        "axes[1].set_ylabel('Coefficient Lasso')\n",
        "axes[1].set_title('Linear vs Lasso Coefficients')\n",
        "axes[1].legend()\n",
        "axes[1].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"FEATURES ÉLIMINÉES PAR LASSO\")\n",
        "print(\"=\" * 70)\n",
        "eliminated = selected_features[~selected_features['Selected']]['Feature'].tolist()\n",
        "if eliminated:\n",
        "    print(\"Features mises à 0:\")\n",
        "    for feat in eliminated:\n",
        "        print(f\"  • {feat}\")\n",
        "else:\n",
        "    print(\"Aucune feature éliminée (alpha peut-être trop faible)\")\n",
        "```\n",
        "\n",
        "**Interprétation:**\n",
        "- Lasso réduit certains coefficients exactement à 0\n",
        "- Features éliminées = probablement redondantes ou peu informatives\n",
        "- Peut améliorer l'interprétabilité du modèle\n",
        ":::\n",
        "\n",
        "## 5. Optimisation avec Cross-Validation\n",
        "\n",
        "### Exercice 5.1: RidgeCV et LassoCV\n",
        "\n",
        "Utilisez les versions CV pour trouver automatiquement le meilleur alpha.\n",
        "\n",
        "::: {.callout-note collapse=\"true\"}\n",
        "## Solution Exercice 5.1\n",
        "\n",
        "```python\n",
        "from sklearn.linear_model import RidgeCV, LassoCV\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"OPTIMISATION AUTOMATIQUE AVEC CV\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Grille d'alphas\n",
        "alphas_cv = np.logspace(-3, 3, 50)\n",
        "\n",
        "# RidgeCV\n",
        "print(\"\\n1. RidgeCV...\")\n",
        "ridge_cv = RidgeCV(alphas=alphas_cv, cv=5, scoring='r2')\n",
        "ridge_cv.fit(X_train_scaled, y_train)\n",
        "print(f\"   Meilleur alpha: {ridge_cv.alpha_:.4f}\")\n",
        "\n",
        "y_pred_ridge = ridge_cv.predict(X_test_scaled)\n",
        "ridge_metrics = evaluate_model(y_test, y_pred_ridge, \"Ridge (CV)\")\n",
        "\n",
        "# LassoCV\n",
        "print(\"\\n2. LassoCV...\")\n",
        "lasso_cv = LassoCV(alphas=alphas_cv, cv=5, max_iter=10000, random_state=42)\n",
        "lasso_cv.fit(X_train_scaled, y_train)\n",
        "print(f\"   Meilleur alpha: {lasso_cv.alpha_:.4f}\")\n",
        "\n",
        "y_pred_lasso = lasso_cv.predict(X_test_scaled)\n",
        "lasso_metrics = evaluate_model(y_test, y_pred_lasso, \"Lasso (CV)\")\n",
        "\n",
        "# ElasticNetCV\n",
        "from sklearn.linear_model import ElasticNetCV\n",
        "\n",
        "print(\"\\n3. ElasticNetCV...\")\n",
        "elastic_cv = ElasticNetCV(alphas=alphas_cv, l1_ratio=[0.1, 0.5, 0.7, 0.9, 0.95, 0.99],\n",
        "                          cv=5, max_iter=10000, random_state=42)\n",
        "elastic_cv.fit(X_train_scaled, y_train)\n",
        "print(f\"   Meilleur alpha: {elastic_cv.alpha_:.4f}\")\n",
        "print(f\"   Meilleur l1_ratio: {elastic_cv.l1_ratio_:.2f}\")\n",
        "\n",
        "y_pred_elastic = elastic_cv.predict(X_test_scaled)\n",
        "elastic_metrics = evaluate_model(y_test, y_pred_elastic, \"ElasticNet (CV)\")\n",
        "\n",
        "# Comparaison finale\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"COMPARAISON FINALE\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "final_comparison = pd.DataFrame({\n",
        "    'Modèle': ['Linear', 'Ridge (CV)', 'Lasso (CV)', 'ElasticNet (CV)'],\n",
        "    'MAE': [test_metrics['MAE'], ridge_metrics['MAE'], \n",
        "            lasso_metrics['MAE'], elastic_metrics['MAE']],\n",
        "    'RMSE': [test_metrics['RMSE'], ridge_metrics['RMSE'], \n",
        "             lasso_metrics['RMSE'], elastic_metrics['RMSE']],\n",
        "    'R²': [test_metrics['R2'], ridge_metrics['R2'], \n",
        "           lasso_metrics['R2'], elastic_metrics['R2']]\n",
        "})\n",
        "\n",
        "print(final_comparison.to_string(index=False))\n",
        "\n",
        "# Meilleur modèle\n",
        "best_idx = final_comparison['R²'].idxmax()\n",
        "best_model_name = final_comparison.loc[best_idx, 'Modèle']\n",
        "print(f\"\\n→ Meilleur modèle: {best_model_name}\")\n",
        "```\n",
        ":::\n",
        "\n",
        "## 6. SVR (Support Vector Regression)\n",
        "\n",
        "### Exercice 6.1: SVR avec différents kernels\n",
        "\n",
        "Comparez SVR linéaire et RBF.\n",
        "\n",
        "::: {.callout-note collapse=\"true\"}\n",
        "## Solution Exercice 6.1\n",
        "\n",
        "```python\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"SUPPORT VECTOR REGRESSION\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Note: SVR est lent, on réduit le dataset pour démo\n",
        "X_train_small = X_train_scaled[:5000]\n",
        "y_train_small = y_train[:5000]\n",
        "\n",
        "# 1. SVR Linéaire\n",
        "print(\"\\n1. SVR Linéaire...\")\n",
        "svr_lin = SVR(kernel='linear', C=1.0)\n",
        "svr_lin.fit(X_train_small, y_train_small)\n",
        "y_pred_svr_lin = svr_lin.predict(X_test_scaled)\n",
        "svr_lin_metrics = evaluate_model(y_test, y_pred_svr_lin, \"SVR Linear\")\n",
        "\n",
        "# 2. SVR RBF\n",
        "print(\"\\n2. SVR RBF...\")\n",
        "svr_rbf = SVR(kernel='rbf', C=1.0, gamma='scale')\n",
        "svr_rbf.fit(X_train_small, y_train_small)\n",
        "y_pred_svr_rbf = svr_rbf.predict(X_test_scaled)\n",
        "svr_rbf_metrics = evaluate_model(y_test, y_pred_svr_rbf, \"SVR RBF\")\n",
        "\n",
        "# 3. Comparaison\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"COMPARAISON SVR\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "svr_comparison = pd.DataFrame({\n",
        "    'Kernel': ['linear', 'rbf'],\n",
        "    'MAE': [svr_lin_metrics['MAE'], svr_rbf_metrics['MAE']],\n",
        "    'RMSE': [svr_lin_metrics['RMSE'], svr_rbf_metrics['RMSE']],\n",
        "    'R²': [svr_lin_metrics['R2'], svr_rbf_metrics['R2']]\n",
        "})\n",
        "print(svr_comparison.to_string(index=False))\n",
        "\n",
        "# 4. Optimisation SVR RBF\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"OPTIMISATION SVR RBF AVEC GRIDSEARCH\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Réduction supplémentaire pour vitesse\n",
        "X_val = X_train_scaled[5000:6000]\n",
        "y_val = y_train[5000:6000]\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'gamma': ['scale', 'auto', 0.01, 0.1],\n",
        "    'epsilon': [0.01, 0.1, 0.5]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    SVR(kernel='rbf'),\n",
        "    param_grid,\n",
        "    cv=3,\n",
        "    scoring='r2',\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"Entraînement GridSearch (peut être long)...\")\n",
        "grid_search.fit(X_train_small, y_train_small)\n",
        "\n",
        "print(f\"\\nMeilleurs paramètres: {grid_search.best_params_}\")\n",
        "best_svr = grid_search.best_estimator_\n",
        "y_pred_best_svr = best_svr.predict(X_val)\n",
        "best_svr_metrics = evaluate_model(y_val, y_pred_best_svr, \"SVR optimisé (val)\")\n",
        "\n",
        "# Visualisation SVR\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Prédictions vs Vraies valeurs\n",
        "axes[0].scatter(y_val, y_pred_best_svr, alpha=0.3, s=10)\n",
        "axes[0].plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], \n",
        "             'r--', lw=2, label='Prédiction parfaite')\n",
        "axes[0].set_xlabel('Vraie valeur')\n",
        "axes[0].set_ylabel('Prédiction')\n",
        "axes[0].set_title(f'SVR Optimisé (R²={best_svr_metrics[\"R2\"]:.3f})')\n",
        "axes[0].legend()\n",
        "axes[0].grid(alpha=0.3)\n",
        "\n",
        "# Comparaison modèles\n",
        "models_comparison = pd.DataFrame({\n",
        "    'Modèle': ['Linear', 'Ridge', 'Lasso', 'SVR Linear', 'SVR RBF'],\n",
        "    'RMSE': [test_metrics['RMSE'], ridge_metrics['RMSE'], \n",
        "             lasso_metrics['RMSE'], svr_lin_metrics['RMSE'], svr_rbf_metrics['RMSE']],\n",
        "    'R²': [test_metrics['R2'], ridge_metrics['R2'], \n",
        "           lasso_metrics['R2'], svr_lin_metrics['R2'], svr_rbf_metrics['R2']]\n",
        "})\n",
        "\n",
        "x_pos = np.arange(len(models_comparison))\n",
        "width = 0.35\n",
        "\n",
        "bars1 = axes[1].bar(x_pos - width/2, models_comparison['RMSE'], width, label='RMSE')\n",
        "bars2 = axes[1].bar(x_pos + width/2, models_comparison['R²'], width, label='R²')\n",
        "\n",
        "axes[1].set_xticks(x_pos)\n",
        "axes[1].set_xticklabels(models_comparison['Modèle'], rotation=45, ha='right')\n",
        "axes[1].set_ylabel('Score')\n",
        "axes[1].set_title('Comparaison Modèles de Régression')\n",
        "axes[1].legend()\n",
        "\n",
        "# Annoter les barres\n",
        "for bars in [bars1, bars2]:\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        axes[1].annotate(f'{height:.3f}',\n",
        "                        xy=(bar.get_x() + bar.get_width() / 2, height),\n",
        "                        xytext=(0, 3),\n",
        "                        textcoords=\"offset points\",\n",
        "                        ha='center', va='bottom', fontsize=8)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"CONSÉILS POUR SVR\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\"\"\n",
        "• SVR est puissant mais COMPUTATIONNELLEMENT COÛTEUX\n",
        "• Scaling des features OBLIGATOIRE\n",
        "• GridSearch peut être très long\n",
        "• Pour grands datasets, considérez:\n",
        "  - LinearSVR (plus rapide que SVR kernel='linear')\n",
        "  - Réduction de features (PCA) avant SVR\n",
        "  - Échantillonnage pour hyperparamètres\n",
        "\"\"\")\n",
        "```\n",
        ":::\n",
        "\n",
        "## 7. Comparaison Finale de Tous les Modèles\n",
        "\n",
        "### Exercice 7.1: Tableau de Bord Complet\n",
        "\n",
        "Créez un tableau de bord comparatif de tous les modèles.\n",
        "\n",
        "::: {.callout-note collapse=\"true\"}\n",
        "```python\n",
        "print(\"=\" * 70)\n",
        "print(\"TABLEAU DE BORD COMPARATIF\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Collecte de tous les résultats\n",
        "all_results = []\n",
        "\n",
        "# Fonction pour ajouter un modèle\n",
        "def add_result(name, y_pred, metrics_func=evaluate_model):\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    return {'Modèle': name, 'MAE': mae, 'RMSE': rmse, 'R²': r2}\n",
        "\n",
        "# Ajout de tous les modèles\n",
        "all_results.append(add_result('Linear', y_test_pred))\n",
        "all_results.append(add_result('Ridge (CV)', y_pred_ridge))\n",
        "all_results.append(add_result('Lasso (CV)', y_pred_lasso))\n",
        "all_results.append(add_result('ElasticNet (CV)', y_pred_elastic))\n",
        "all_results.append(add_result('SVR Linear', y_pred_svr_lin))\n",
        "all_results.append(add_result('SVR RBF', y_pred_svr_rbf))\n",
        "\n",
        "df_all_results = pd.DataFrame(all_results)\n",
        "\n",
        "# Tri par R²\n",
        "df_all_results = df_all_results.sort_values('R²', ascending=False).reset_index(drop=True)\n",
        "\n",
        "print(\"\\nClassement par R²:\")\n",
        "print(df_all_results.to_string(index=False))\n",
        "\n",
        "# Visualisation\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
        "\n",
        "# 1. Barplot R²\n",
        "x_pos = np.arange(len(df_all_results))\n",
        "axes[0, 0].barh(x_pos, df_all_results['R²'], color='skyblue')\n",
        "axes[0, 0].set_yticks(x_pos)\n",
        "axes[0, 0].set_yticklabels(df_all_results['Modèle'])\n",
        "axes[0, 0].set_xlabel('R² Score')\n",
        "axes[0, 0].set_title('Comparaison R² des Modèles')\n",
        "axes[0, 0].invert_yaxis()  # Meilleur en haut\n",
        "\n",
        "# Annoter les valeurs\n",
        "for i, v in enumerate(df_all_results['R²']):\n",
        "    axes[0, 0].text(v + 0.001, i, f'{v:.4f}', va='center')\n",
        "\n",
        "# 2. Comparaison MAE vs RMSE\n",
        "scatter = axes[0, 1].scatter(df_all_results['MAE'], df_all_results['RMSE'], \n",
        "                             s=200, alpha=0.6, c=df_all_results['R²'], cmap='viridis')\n",
        "for i, row in df_all_results.iterrows():\n",
        "    axes[0, 1].annotate(row['Modèle'], (row['MAE'], row['RMSE']), fontsize=8)\n",
        "axes[0, 1].set_xlabel('MAE')\n",
        "axes[0, 1].set_ylabel('RMSE')\n",
        "axes[0, 1].set_title('MAE vs RMSE (couleur = R²)')\n",
        "plt.colorbar(scatter, ax=axes[0, 1], label='R² Score')\n",
        "\n",
        "# 3. Temps d'entraînement (exemple)\n",
        "# Dans un cas réel, on mesurerait le temps\n",
        "training_times = [0.1, 0.2, 0.3, 0.4, 2.0, 5.0]  # valeurs d'exemple\n",
        "df_all_results['Temps(s)'] = training_times\n",
        "\n",
        "axes[1, 0].scatter(df_all_results['Temps(s)'], df_all_results['R²'], s=100)\n",
        "for i, row in df_all_results.iterrows():\n",
        "    axes[1, 0].annotate(row['Modèle'], (row['Temps(s)'], row['R²']), fontsize=8)\n",
        "axes[1, 0].set_xlabel('Temps d\\'entraînement (s)')\n",
        "axes[1, 0].set_ylabel('R² Score')\n",
        "axes[1, 0].set_title('Performance vs Temps d\\'entraînement')\n",
        "axes[1, 0].grid(alpha=0.3)\n",
        "\n",
        "# 4. Heatmap des métriques\n",
        "metrics_df = df_all_results.set_index('Modèle')[['MAE', 'RMSE', 'R²']]\n",
        "sns.heatmap(metrics_df, annot=True, fmt='.4f', cmap='YlOrRd', \n",
        "            center=0, ax=axes[1, 1], cbar_kws={'label': 'Valeur'})\n",
        "axes[1, 1].set_title('Heatmap des Métriques par Modèle')\n",
        "axes[1, 1].tick_params(axis='x', rotation=45)\n",
        "axes[1, 1].tick_params(axis='y', rotation=0)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"RECOMMANDATIONS FINALES\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Recommandation basée sur différents critères\n",
        "print(\"\"\"\n",
        "1. Pour PERFORMANCE MAX (R²):\n",
        "   → {} (R²={:.4f})\n",
        "   \n",
        "2. Pour INTERPRÉTABILITÉ (coefficients):\n",
        "   → Lasso (CV) (sélection de features)\n",
        "   \n",
        "3. Pour RAPIDITÉ:\n",
        "   → Linear ou Ridge (CV)\n",
        "   \n",
        "4. Pour COMPLEXITÉ NON-LINÉAIRE:\n",
        "   → SVR RBF (mais plus lent)\n",
        "   \n",
        "5. COMPROMIS PERFORMANCE/TEMPS:\n",
        "   → ElasticNet (CV)\n",
        "\"\"\".format(df_all_results.iloc[0]['Modèle'], df_all_results.iloc[0]['R²']))\n",
        "\n",
        "# Sauvegarde des résultats\n",
        "df_all_results.to_csv('resultats_regression_comparaison.csv', index=False)\n",
        "print(\"\\nRésultats sauvegardés dans 'resultats_regression_comparaison.csv'\")\n",
        "```\n",
        ":::\n",
        "\n",
        "## 8. Projet Bonus: Regression Avancée\n",
        "\n",
        "### Exercice 8.1: Ensemble Methods\n",
        "\n",
        "Testez Random Forest et Gradient Boosting pour la régression.\n",
        "\n",
        "```python\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# TODO: Implémentez Random Forest et Gradient Boosting\n",
        "# Optimisez avec RandomizedSearchCV\n",
        "# Comparez avec les modèles linéaires\n",
        "```\n",
        "\n",
        "**Indices:**\n",
        "- Pas besoin de standardisation pour les arbres\n",
        "- Optimisez: n_estimators, max_depth, min_samples_split\n",
        "- Métrique: RMSE ou MAE\n",
        "- Visualisez l'importance des features\n",
        "\n",
        "::: {.callout-note collapse=\"true\"}\n",
        "## Solution Exercice 8.1\n",
        "\n",
        "```python\n",
        "print(\"=\" * 70)\n",
        "print(\"ENSEMBLE METHODS: RANDOM FOREST & GRADIENT BOOSTING\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Pas besoin de scaling pour les arbres\n",
        "X_train_trees = X_train\n",
        "X_test_trees = X_test\n",
        "\n",
        "# 1. Random Forest\n",
        "print(\"\\n1. Random Forest Regressor...\")\n",
        "rf = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
        "\n",
        "# Hyperparamètres\n",
        "param_dist_rf = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "rf_random = RandomizedSearchCV(\n",
        "    rf, param_dist_rf, n_iter=20, cv=3, \n",
        "    scoring='neg_mean_squared_error', n_jobs=-1, random_state=42\n",
        ")\n",
        "\n",
        "rf_random.fit(X_train_trees, y_train)\n",
        "best_rf = rf_random.best_estimator_\n",
        "y_pred_rf = best_rf.predict(X_test_trees)\n",
        "\n",
        "print(f\"Meilleurs paramètres RF: {rf_random.best_params_}\")\n",
        "rf_metrics = evaluate_model(y_test, y_pred_rf, \"Random Forest\")\n",
        "\n",
        "# 2. Gradient Boosting\n",
        "print(\"\\n2. Gradient Boosting Regressor...\")\n",
        "gbr = GradientBoostingRegressor(random_state=42)\n",
        "\n",
        "param_dist_gbr = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'max_depth': [3, 4, 5],\n",
        "    'subsample': [0.8, 0.9, 1.0]\n",
        "}\n",
        "\n",
        "gbr_random = RandomizedSearchCV(\n",
        "    gbr, param_dist_gbr, n_iter=15, cv=3,\n",
        "    scoring='neg_mean_squared_error', n_jobs=-1, random_state=42\n",
        ")\n",
        "\n",
        "gbr_random.fit(X_train_trees, y_train)\n",
        "best_gbr = gbr_random.best_estimator_\n",
        "y_pred_gbr = best_gbr.predict(X_test_trees)\n",
        "\n",
        "print(f\"Meilleurs paramètres GBR: {gbr_random.best_params_}\")\n",
        "gbr_metrics = evaluate_model(y_test, y_pred_gbr, \"Gradient Boosting\")\n",
        "\n",
        "# 3. Comparaison\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"COMPARAISON MODÈLES AVANCÉS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "ensemble_results = pd.DataFrame([\n",
        "    {'Modèle': 'Random Forest', 'MAE': rf_metrics['MAE'], \n",
        "     'RMSE': rf_metrics['RMSE'], 'R²': rf_metrics['R2']},\n",
        "    {'Modèle': 'Gradient Boosting', 'MAE': gbr_metrics['MAE'], \n",
        "     'RMSE': gbr_metrics['RMSE'], 'R²': gbr_metrics['R2']},\n",
        "    {'Modèle': 'Meilleur Linéaire', 'MAE': df_all_results.iloc[0]['MAE'],\n",
        "     'RMSE': df_all_results.iloc[0]['RMSE'], 'R²': df_all_results.iloc[0]['R²']}\n",
        "])\n",
        "\n",
        "print(ensemble_results.to_string(index=False))\n",
        "\n",
        "# 4. Importance des features\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "# Random Forest\n",
        "rf_importances = pd.DataFrame({\n",
        "    'Feature': california.feature_names,\n",
        "    'Importance': best_rf.feature_importances_\n",
        "}).sort_values('Importance', ascending=True)\n",
        "\n",
        "axes[0].barh(rf_importances['Feature'], rf_importances['Importance'])\n",
        "axes[0].set_xlabel('Importance')\n",
        "axes[0].set_title('Importance des Features - Random Forest')\n",
        "\n",
        "# Gradient Boosting\n",
        "gbr_importances = pd.DataFrame({\n",
        "    'Feature': california.feature_names,\n",
        "    'Importance': best_gbr.feature_importances_\n",
        "}).sort_values('Importance', ascending=True)\n",
        "\n",
        "axes[1].barh(gbr_importances['Feature'], gbr_importances['Importance'])\n",
        "axes[1].set_xlabel('Importance')\n",
        "axes[1].set_title('Importance des Features - Gradient Boosting')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 5. Visualisation prédictions\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "axes[0].scatter(y_test, y_pred_rf, alpha=0.3, s=10)\n",
        "axes[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
        "axes[0].set_xlabel('Vraie valeur')\n",
        "axes[0].set_ylabel('Prédiction')\n",
        "axes[0].set_title(f'Random Forest (R²={rf_metrics[\"R2\"]:.3f})')\n",
        "axes[0].grid(alpha=0.3)\n",
        "\n",
        "axes[1].scatter(y_test, y_pred_gbr, alpha=0.3, s=10)\n",
        "axes[1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
        "axes[1].set_xlabel('Vraie valeur')\n",
        "axes[1].set_ylabel('Prédiction')\n",
        "axes[1].set_title(f'Gradient Boosting (R²={gbr_metrics[\"R2\"]:.3f})')\n",
        "axes[1].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"CONCLUSION ENSEMBLE METHODS\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\"\"\n",
        "• Random Forest et Gradient Boosting PERFORMENT TRÈS BIEN\n",
        "• Pas besoin de feature scaling\n",
        "• Capturent relations non-linéaires complexes\n",
        "• MOINS INTERPRÉTABLES que les modèles linéaires\n",
        "• PLUS LENTS à entraîner\n",
        "• Risque de surapprentissage si pas bien régularisés\n",
        "\n",
        "→ Recommandation: Utiliser pour compétitions Kaggle\n",
        "→ Pour production: Privilégier modèles plus simples si performance similaire\n",
        "\"\"\")\n",
        "```\n",
        ":::\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "### Résumé des Points Clés\n",
        "\n",
        "1. **Prétraitement**:\n",
        "   - Standardisation cruciale pour modèles régularisés et SVR\n",
        "   - Split stratifié (si target stratifiable)\n",
        "   - Pas de data leakage\n",
        "\n",
        "2. **Modèles Linéaires**:\n",
        "   - **Linear**: Simple, rapide, interprétable\n",
        "   - **Ridge**: Régularisation L2, réduit overfitting\n",
        "   - **Lasso**: Régularisation L1, sélection features\n",
        "   - **ElasticNet**: Compromis L1+L2\n",
        "\n",
        "3. **Modèles Non-Linéaires**:\n",
        "   - **SVR**: Puissant mais lent, sensible aux hyperparamètres\n",
        "   - **Random Forest**: Robuste, capture non-linéarités\n",
        "   - **Gradient Boosting**: Souvent meilleure performance\n",
        "\n",
        "4. **Optimisation**:\n",
        "   - Utiliser *CV (RidgeCV, LassoCV) pour alpha automatique\n",
        "   - GridSearch pour petit espace\n",
        "   - RandomizedSearch pour grand espace\n",
        "\n",
        "5. **Évaluation**:\n",
        "   - Multiples métriques: MAE, RMSE, R²\n",
        "   - Visualisations: résidus, prédictions vs vraies valeurs\n",
        "   - Importance des features pour interprétation\n",
        "\n",
        "### Checklist de Validation\n",
        "\n",
        "Avant de soumettre votre travail:\n",
        "\n",
        "- [ ] Exploratory Data Analysis complète\n",
        "- [ ] Prétraitement correct (train/test séparés)\n",
        "- [ ] Au moins 4 modèles comparés\n",
        "- [ ] Optimisation hyperparamètres avec CV\n",
        "- [ ] Évaluation sur test set (une seule fois)\n",
        "- [ ] Visualisations claires et annotées\n",
        "- [ ] Interprétation des résultats\n",
        "- [ ] Code commenté et organisé\n",
        "\n",
        "### Pour Aller Plus Loin\n",
        "\n",
        "**Extensions possibles:**\n",
        "\n",
        "1. **Feature Engineering**:\n",
        "   - Créer interactions entre features\n",
        "   - Transformations polynomiales\n",
        "   - Variables dummy pour catégorielles\n",
        "\n",
        "2. **Pipeline Scikit-learn**:\n",
        "   ```python\n",
        "   from sklearn.pipeline import Pipeline\n",
        "   from sklearn.compose import ColumnTransformer\n",
        "   \n",
        "   pipeline = Pipeline([\n",
        "       ('scaler', StandardScaler()),\n",
        "       ('regressor', RidgeCV())\n",
        "   ])\n",
        "   ```\n",
        "\n",
        "3. **Validation Croisée Temporelle**:\n",
        "   - Pour données chronologiques\n",
        "   - TimeSeriesSplit au lieu de KFold\n",
        "\n",
        "4. **Prédiction d'Intervalles**:\n",
        "   - Quantile Regression\n",
        "   - Bootstrap pour incertitude\n",
        "\n",
        "5. **Déploiement**:\n",
        "   - Sauvegarde modèle (joblib)\n",
        "   - API avec FastAPI/Flask\n",
        "   - Monitoring des performances\n",
        "\n",
        "**Exercices supplémentaires:**\n",
        "\n",
        "1. Testez PolynomialFeatures + Regression\n",
        "2. Implémentez une validation croisée imbriquée\n",
        "3. Ajoutez XGBoost ou LightGBM à la comparaison\n",
        "4. Créez un dashboard interactif avec Plotly\n",
        "\n",
        "**Prochain TP:** Séries Temporelles ou Deep Learning\n",
        "\n",
        ":::{.callout-tip}\n",
        "## Astuce Finale\n",
        "\n",
        "**La meilleure pratique:** Commencez toujours par un modèle simple (régression linéaire), puis complexifiez si nécessaire. Souvent, les modèles simples suffisent et sont plus faciles à maintenir en production!\n",
        ":::"
      ],
      "id": "3ee57357"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "test_env",
      "language": "python",
      "display_name": "Python (test_env)",
      "path": "C:\\Users\\abdal\\AppData\\Roaming\\jupyter\\kernels\\test_env"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}