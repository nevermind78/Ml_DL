#| echo: true
#| eval: true
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
# Chargement
california = fetch_california_housing()
X, y = california.data, california.target
# DataFrame pour exploration
df = pd.DataFrame(X, columns=california.feature_names)
df['MedHouseVal'] = y
print("=" * 70)
print("DATASET: CALIFORNIA HOUSING")
print("=" * 70)
print(f"\nShape: {X.shape}")
print(f"Features: {california.feature_names}")
print(f"\nDescription du target (prix médian en 100k$):")
print(df['MedHouseVal'].describe())
# Statistiques descriptives
print("\n" + "=" * 70)
print("STATISTIQUES DESCRIPTIVES")
print("=" * 70)
print(df.describe().T)
# Vérifier les valeurs manquantes
print(f"\nValeurs manquantes par feature:")
print(df.isnull().sum())
# Visualisations
fig, axes = plt.subplots(2, 2, figsize=(14, 10))
# Distribution du target
axes[0, 0].hist(y, bins=50, edgecolor='black', alpha=0.7)
axes[0, 0].set_xlabel('Prix Médian (100k$)')
axes[0, 0].set_ylabel('Fréquence')
axes[0, 0].set_title('Distribution des Prix')
axes[0, 0].axvline(y.mean(), color='red', linestyle='--', label=f'Moyenne: {y.mean():.2f}')
axes[0, 0].legend()
# Boxplot des features (normalisées pour comparaison)
df_normalized = (df - df.mean()) / df.std()
axes[0, 1].boxplot([df_normalized[col] for col in california.feature_names],
labels=california.feature_names, vert=True)
axes[0, 1].set_xticklabels(california.feature_names, rotation=45, ha='right')
axes[0, 1].set_ylabel('Valeurs normalisées')
axes[0, 1].set_title('Distribution des Features (normalisées)')
axes[0, 1].grid(alpha=0.3)
# Matrice de corrélation
corr_matrix = df.corr()
mask = np.triu(np.ones_like(corr_matrix, dtype=bool))
sns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.2f', cmap='coolwarm',
center=0, ax=axes[1, 0], cbar_kws={'label': 'Corrélation'})
axes[1, 0].set_title('Matrice de Corrélation')
# Scatter: Feature la plus corrélée avec target
corr_with_target = corr_matrix['MedHouseVal'].drop('MedHouseVal').abs().sort_values(ascending=False)
best_feature = corr_with_target.index[0]
axes[1, 1].scatter(df[best_feature], df['MedHouseVal'], alpha=0.3)
axes[1, 1].set_xlabel(best_feature)
axes[1, 1].set_ylabel('Prix Médian')
axes[1, 1].set_title(f'Prix vs {best_feature} (corr={corr_matrix.loc[best_feature, "MedHouseVal"]:.2f})')
axes[1, 1].grid(alpha=0.3)
plt.tight_layout()
plt.show()
print("\n" + "=" * 70)
print("CORRÉLATIONS AVEC LE TARGET")
print("=" * 70)
print(corr_with_target)
#| echo: true
#| eval: true
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
# Chargement
california = fetch_california_housing()
X, y = california.data, california.target
# DataFrame pour exploration
df = pd.DataFrame(X, columns=california.feature_names)
df['MedHouseVal'] = y
print("=" * 70)
print("DATASET: CALIFORNIA HOUSING")
print("=" * 70)
print(f"\nShape: {X.shape}")
print(f"Features: {california.feature_names}")
print(f"\nDescription du target (prix médian en 100k$):")
print(df['MedHouseVal'].describe())
# Statistiques descriptives
print("\n" + "=" * 70)
print("STATISTIQUES DESCRIPTIVES")
print("=" * 70)
print(df.describe().T)
# Vérifier les valeurs manquantes
print(f"\nValeurs manquantes par feature:")
print(df.isnull().sum())
# Visualisations
fig, axes = plt.subplots(2, 2, figsize=(12, 10))
# Distribution du target
axes[0, 0].hist(y, bins=50, edgecolor='black', alpha=0.7)
axes[0, 0].set_xlabel('Prix Médian (100k$)')
axes[0, 0].set_ylabel('Fréquence')
axes[0, 0].set_title('Distribution des Prix')
axes[0, 0].axvline(y.mean(), color='red', linestyle='--', label=f'Moyenne: {y.mean():.2f}')
axes[0, 0].legend()
# Boxplot des features (normalisées pour comparaison)
df_normalized = (df - df.mean()) / df.std()
axes[0, 1].boxplot([df_normalized[col] for col in california.feature_names],
labels=california.feature_names, vert=True)
axes[0, 1].set_xticklabels(california.feature_names, rotation=45, ha='right')
axes[0, 1].set_ylabel('Valeurs normalisées')
axes[0, 1].set_title('Distribution des Features (normalisées)')
axes[0, 1].grid(alpha=0.3)
# Matrice de corrélation
corr_matrix = df.corr()
mask = np.triu(np.ones_like(corr_matrix, dtype=bool))
sns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.2f', cmap='coolwarm',
center=0, ax=axes[1, 0], cbar_kws={'label': 'Corrélation'})
axes[1, 0].set_title('Matrice de Corrélation')
# Scatter: Feature la plus corrélée avec target
corr_with_target = corr_matrix['MedHouseVal'].drop('MedHouseVal').abs().sort_values(ascending=False)
best_feature = corr_with_target.index[0]
axes[1, 1].scatter(df[best_feature], df['MedHouseVal'], alpha=0.3)
axes[1, 1].set_xlabel(best_feature)
axes[1, 1].set_ylabel('Prix Médian')
axes[1, 1].set_title(f'Prix vs {best_feature} (corr={corr_matrix.loc[best_feature, "MedHouseVal"]:.2f})')
axes[1, 1].grid(alpha=0.3)
plt.tight_layout()
plt.show()
print("\n" + "=" * 70)
print("CORRÉLATIONS AVEC LE TARGET")
print("=" * 70)
print(corr_with_target)
