# S√©ance 1: Introduction IA et Machine Learning

::: {.callout-note icon=false}
## Informations de la s√©ance
- **Type**: Cours
- **Dur√©e**: 2h
- **Objectifs**: Obj1, Obj2, Obj3
:::

## 1. D√©finitions et Concepts de Base

### 1.1 Intelligence Artificielle (IA)

L'**Intelligence Artificielle** est un domaine de l'informatique qui vise √† cr√©er des syst√®mes capables d'effectuer des t√¢ches n√©cessitant normalement l'intelligence humaine.

::: {.callout-tip}
## Exemples d'IA au quotidien
- Assistants vocaux (Siri, Alexa, Google Assistant)
- Recommandations Netflix/Spotify
- Filtres anti-spam des emails
- Reconnaissance faciale sur smartphones
- Traduction automatique
:::

### 1.2 Machine Learning (Apprentissage Automatique)

Le **Machine Learning** est une sous-discipline de l'IA qui permet aux ordinateurs d'apprendre √† partir de donn√©es sans √™tre explicitement programm√©s.

**Diff√©rence cl√©**:

- **Programmation traditionnelle**: Humain √©crit les r√®gles ‚Üí Ordinateur applique
- **Machine Learning**: Ordinateur apprend les r√®gles √† partir des donn√©es

```python
# Approche traditionnelle
def classifier_email(email):
    if "viagra" in email or "lottery" in email:
        return "spam"
    else:
        return "not spam"

# Approche Machine Learning
from sklearn.linear_model import LogisticRegression
model = LogisticRegression()
model.fit(X_train, y_train)  # Apprend des exemples
prediction = model.predict(new_email)
```

### 1.3 Deep Learning

Le **Deep Learning** est une sous-cat√©gorie du ML utilisant des r√©seaux de neurones artificiels profonds (plusieurs couches).

**Diagramme mermaid:**
```{mermaid}
graph TD
    A[Intelligence Artificielle] --> B[Machine Learning]
    B --> C[Deep Learning]
    A --> D[Syst√®mes experts]
    A --> E[Robotique]
    B --> F[Apprentissage supervis√©]
    B --> G[Apprentissage non supervis√©]
    B --> H[Apprentissage par renforcement]
```

## 2. Applications et Cas d'Utilisation

### 2.1 Vision par Ordinateur
- D√©tection d'objets
- Reconnaissance faciale
- Diagnostic m√©dical (imagerie)
- Voitures autonomes

### 2.2 Traitement du Langage Naturel (NLP)
- Chatbots et assistants virtuels
- Traduction automatique
- Analyse de sentiments
- R√©sum√© automatique de textes

### 2.3 Syst√®mes de Recommandation
- E-commerce (Amazon, Alibaba)
- Streaming (Netflix, YouTube)
- R√©seaux sociaux (Facebook, Instagram)

### 2.4 Finance
- D√©tection de fraude
- Trading algorithmique
- √âvaluation de risque de cr√©dit

### 2.5 Sant√©
- Diagnostic de maladies
- D√©couverte de m√©dicaments
- Analyse d'imagerie m√©dicale

## 3. Types d'Apprentissage

### 3.1 Apprentissage Supervis√©

Le mod√®le apprend √† partir de **donn√©es √©tiquet√©es** (avec r√©ponses connues).

::: {.callout-note}
## Exemple
**Donn√©es d'entra√Ænement**: emails avec labels "spam" ou "non spam"
**Objectif**: Pr√©dire si un nouveau email est spam
:::

**T√¢ches principales**:
- **Classification**: pr√©dire une cat√©gorie (spam/non spam, chat/chien)
- **R√©gression**: pr√©dire une valeur continue (prix maison, temp√©rature)

```python
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestRegressor

# Classification
clf = LogisticRegression()
clf.fit(X_train, y_train)  # y_train contient les cat√©gories
pred_class = clf.predict(X_test)

# R√©gression
reg = RandomForestRegressor()
reg.fit(X_train, y_train)  # y_train contient les valeurs continues
pred_value = reg.predict(X_test)
```

### 3.2 Apprentissage Non Supervis√©

Le mod√®le apprend √† partir de **donn√©es non √©tiquet√©es** (sans r√©ponses).

::: {.callout-note}
## Exemple
**Donn√©es**: comportements d'achat de clients
**Objectif**: Identifier des groupes de clients similaires (segmentation)
:::

**T√¢ches principales**:
- **Clustering**: regrouper des donn√©es similaires
- **R√©duction de dimension**: simplifier les donn√©es
- **D√©tection d'anomalies**: identifier des points inhabituels

```python
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA

# Clustering
kmeans = KMeans(n_clusters=3)
clusters = kmeans.fit_predict(X)

# R√©duction de dimension
pca = PCA(n_components=2)
X_reduced = pca.fit_transform(X)
```

### 3.3 Apprentissage Semi-Supervis√©

Combine donn√©es √©tiquet√©es (peu) et non √©tiquet√©es (beaucoup).

**Cas d'usage**: Lorsque l'√©tiquetage est co√ªteux (imagerie m√©dicale, reconnaissance vocale)

### 3.4 Apprentissage par Renforcement

L'agent apprend par **essai-erreur** en interagissant avec un environnement.

::: {.callout-note}
## Exemple
- Jeux vid√©o (AlphaGo, Chess AI)
- Robotique
- Contr√¥le de syst√®mes complexes
:::

**Composants**:
- **Agent**: celui qui apprend
- **Environnement**: le monde dans lequel l'agent √©volue
- **Actions**: ce que l'agent peut faire
- **R√©compenses**: feedback positif/n√©gatif

## 4. √âtapes de Conception d'un Mod√®le IA

### 4.1 Pipeline ML Standard

**Diagramme mermaid:**
```{mermaid}
graph TB
    A[1 D√©finir le probl√®me] --> B[2 Collecter les donn√©es]
    B --> C[3 Explorer les donn√©es]
    C --> D[4 Pr√©parer les donn√©es]
    D --> E[5 Choisir un mod√®le]
    E --> F[6 Entra√Æner le mod√®le]
    F --> G[7 √âvaluer le mod√®le]
    G --> H{Performance OK?}
    H -->|Non| E
    H -->|Oui| I[8 D√©ployer]
    I --> J[9 Monitorer]
```

### 4.2 D√©tails des √âtapes

#### √âtape 1: D√©finir le Probl√®me
- Quel type de probl√®me? (classification, r√©gression, clustering)
- Quelles sont les m√©triques de succ√®s?
- Quelles sont les contraintes?

#### √âtape 2: Collecter les Donn√©es
- Sources de donn√©es
- Quantit√© n√©cessaire
- Qualit√© des donn√©es

#### √âtape 3: Explorer les Donn√©es (EDA)
- Statistiques descriptives
- Visualisations
- Identifier les patterns, outliers, donn√©es manquantes

```python
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Exemple EDA simple
df = pd.read_csv('data.csv')
print(df.info())
print(df.describe())

# Visualisation
sns.pairplot(df)
plt.show()
```

#### √âtape 4: Pr√©parer les Donn√©es
- Nettoyage (valeurs manquantes, doublons)
- Transformation (normalisation, encodage)
- Feature engineering
- Split train/test

```python
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer

# Split des donn√©es
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Normalisation
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Gestion des valeurs manquantes
imputer = SimpleImputer(strategy='mean')
X_train_imputed = imputer.fit_transform(X_train)
X_test_imputed = imputer.transform(X_test)
```

#### √âtape 5: Choisir un Mod√®le
- Bas√© sur le type de probl√®me
- Complexit√© vs interpr√©tabilit√©
- Ressources disponibles

#### √âtape 6: Entra√Æner le Mod√®le
- Ajuster les param√®tres
- Optimisation

#### √âtape 7: √âvaluer le Mod√®le
- M√©triques appropri√©es
- Validation crois√©e
- Analyse des erreurs

#### √âtape 8: D√©ployer
- Mise en production
- API, application web, etc.

#### √âtape 9: Monitorer
- Performances en production
- D√©rive des donn√©es (data drift)
- Mise √† jour du mod√®le

## 5. Concepts Cl√©s

### 5.1 Overfitting vs Underfitting

::: {.panel-tabset}

## Underfitting
- Mod√®le **trop simple**
- Ne capture pas les patterns dans les donn√©es
- **Biais √©lev√©**, variance faible
- Mauvaise performance train ET test

## Overfitting
- Mod√®le **trop complexe**
- M√©morise les donn√©es d'entra√Ænement (bruit inclus)
- Biais faible, **variance √©lev√©e**
- Bonne performance train, **mauvaise** performance test

## Juste bien (Good fit)
- Mod√®le √©quilibr√©
- Capture les vrais patterns
- Biais et variance faibles
- Bonne g√©n√©ralisation

:::

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression

# G√©n√©ration de donn√©es
np.random.seed(42)
X = np.linspace(0, 10, 50)
y = 2*X + 1 + np.random.randn(50)*2

# Sous-ajustement (linear)
underfit_model = LinearRegression()
underfit_model.fit(X.reshape(-1, 1), y)
y_underfit = underfit_model.predict(X.reshape(-1, 1))

# Bon ajustement (polynomial degree 2)
goodfit_model = Pipeline([
    ('poly', PolynomialFeatures(degree=2)),
    ('linear', LinearRegression())
])
goodfit_model.fit(X.reshape(-1, 1), y)
y_goodfit = goodfit_model.predict(X.reshape(-1, 1))

# Surajustement (polynomial degree 15)
overfit_model = Pipeline([
    ('poly', PolynomialFeatures(degree=15)),
    ('linear', LinearRegression())
])
overfit_model.fit(X.reshape(-1, 1), y)
y_overfit = overfit_model.predict(X.reshape(-1, 1))

# Visualisation
fig, axes = plt.subplots(1, 3, figsize=(15, 4))

axes[0].scatter(X, y, alpha=0.5)
axes[0].plot(X, y_underfit, 'r-', linewidth=2)
axes[0].set_title('Underfitting (lin√©aire)')

axes[1].scatter(X, y, alpha=0.5)
axes[1].plot(X, y_goodfit, 'g-', linewidth=2)
axes[1].set_title('Good Fit (polynomial deg 2)')

axes[2].scatter(X, y, alpha=0.5)
axes[2].plot(X, y_overfit, 'b-', linewidth=2)
axes[2].set_title('Overfitting (polynomial deg 15)')

plt.tight_layout()
plt.show()
```

### 5.2 Compromis Biais-Variance


## **L'√©quilibre fondamental du Machine Learning**

Le **compromis biais-variance** est un concept essentiel qui explique pourquoi certains mod√®les ne g√©n√©ralisent pas bien. Imaginez apprendre pour un examen :
- **Biais √©lev√©** = Vous survolez trop le cours (sous-apprentissage)
- **Variance √©lev√©e** = Vous m√©morisez par c≈ìur sans comprendre (sur-apprentissage)

## **Formules Math√©matiques Cl√©s**

**Erreur totale du mod√®le :**
$$E_{\text{total}} = \underbrace{\text{Biais}^2}_{\text{simplicit√©}} + \underbrace{\text{Variance}}_{\text{complexit√©}} + \epsilon$$

**O√π :**
- $\text{Biais} = E[\hat{f}(x)] - f(x)$ (diff√©rence entre pr√©diction moyenne et v√©rit√©)
- $\text{Variance} = E[(\hat{f}(x) - E[\hat{f}(x)])^2]$ (variabilit√© des pr√©dictions)
- $\epsilon$ = Bruit irr√©ductible des donn√©es

## **Exemple Illustratif avec Python**

```{python}
import numpy as np
import matplotlib.pyplot as plt
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split

# 1. Cr√©ation de donn√©es
np.random.seed(42)
X = np.linspace(0, 10, 50)
y = 2*np.sin(X) + np.random.randn(50)  # Relation sinuso√Ødale + bruit

# 2. Split des donn√©es
X_train, X_test, y_train, y_test = train_test_split(
    X.reshape(-1, 1), y, test_size=0.3, random_state=42
)

# 3. Test de diff√©rents degr√©s de complexit√©
fig, axes = plt.subplots(2, 3, figsize=(15, 8))

degrees = [1, 3, 9]  # Degr√©s test√©s
train_errors, test_errors = [], []

for idx, degree in enumerate(degrees):
    # Cr√©ation du mod√®le polynomial
    model = Pipeline([
        ('poly', PolynomialFeatures(degree=degree)),
        ('linear', LinearRegression())
    ])
    
    # Entra√Ænement
    model.fit(X_train, y_train)
    
    # Pr√©dictions
    X_plot = np.linspace(0, 10, 100).reshape(-1, 1)
    y_plot = model.predict(X_plot)
    
    # Calcul des erreurs
    train_pred = model.predict(X_train)
    test_pred = model.predict(X_test)
    train_error = np.mean((train_pred - y_train) ** 2)
    test_error = np.mean((test_pred - y_test) ** 2)
    
    train_errors.append(train_error)
    test_errors.append(test_error)
    
    # Graphiques sup√©rieurs : Mod√®les
    ax = axes[0, idx]
    ax.scatter(X_train, y_train, alpha=0.5, s=20, label='Train')
    ax.scatter(X_test, y_test, alpha=0.5, s=20, color='red', label='Test')
    ax.plot(X_plot, y_plot, 'g-', linewidth=2)
    ax.set_title(f'Degr√© {degree}\nTrain MSE: {train_error:.2f}, Test MSE: {test_error:.2f}')
    ax.legend()
    ax.grid(True, alpha=0.3)

# 4. Courbe du compromis
ax_comp = axes[1, 1]
degrees_range = range(1, 15)
train_errs, test_errs = [], []

for d in degrees_range:
    model = Pipeline([
        ('poly', PolynomialFeatures(degree=d)),
        ('linear', LinearRegression())
    ])
    model.fit(X_train, y_train)
    train_errs.append(np.mean((model.predict(X_train) - y_train) ** 2))
    test_errs.append(np.mean((model.predict(X_test) - y_test) ** 2))

ax_comp.plot(degrees_range, train_errs, 'b-', label='Erreur Train', linewidth=2)
ax_comp.plot(degrees_range, test_errs, 'r-', label='Erreur Test', linewidth=2)
ax_comp.fill_between([1, 3], 0, 25, color='green', alpha=0.2, label='Zone optimale')
ax_comp.set_xlabel('Degr√© du polyn√¥me (Complexit√©)')
ax_comp.set_ylabel('Erreur Quadratique Moyenne')
ax_comp.set_title('Courbe du Compromis Biais-Variance')
ax_comp.legend()
ax_comp.grid(True, alpha=0.3)

# 5. Zones du compromis
ax_zone = axes[1, 0]
zones = ['Underfitting', 'Good Fit', 'Overfitting']
colors = ['red', 'green', 'blue']

for i, (zone, color) in enumerate(zip(zones, colors)):
    ax_zone.bar(i, [1], color=color, alpha=0.6, label=zone)
    ax_zone.text(i, 0.5, zone, ha='center', va='center', fontweight='bold')

ax_zone.set_ylim([0, 1.5])
ax_zone.set_title('Zones du Compromis')
ax_zone.set_xticks([])
ax_zone.legend()
ax_zone.set_yticks([])

# 6. Tableau synth√®se
ax_table = axes[1, 2]
ax_table.axis('tight')
ax_table.axis('off')

data = [
    ['Biais', 'Variance', 'Zone'],
    ['‚Üë Haut', '‚Üì Bas', 'Underfitting'],
    ['‚Üï Mod√©r√©', '‚Üï Mod√©r√©', 'Good Fit'],
    ['‚Üì Bas', '‚Üë Haut', 'Overfitting']
]

table = ax_table.table(cellText=data, cellLoc='center', loc='center')
table.auto_set_font_size(False)
table.set_fontsize(10)
table.scale(1, 2)
ax_table.set_title('Synth√®se')

plt.tight_layout()
plt.show()

print("üîç ANALYSE DU COMPROMIS BIAS-VARIANCE")
print("=" * 40)
print("Degr√© 1 (Underfitting) :")
print(f"  ‚Üí Biais¬≤ √©lev√© ({train_errors[0]:.2f}) - Mod√®le trop simple")
print(f"  ‚Üí Variance faible - Stable mais impr√©cis")
print()
print("Degr√© 3 (Good Fit) :")
print(f"  ‚Üí Biais¬≤ mod√©r√© ({train_errors[1]:.2f}) - Capture bien les patterns")
print(f"  ‚Üí Variance mod√©r√©e - G√©n√©ralise correctement")
print()
print("Degr√© 9 (Overfitting) :")
print(f"  ‚Üí Biais¬≤ faible ({train_errors[2]:.2f}) - Pr√©cision sur l'entra√Ænement")
print(f"  ‚Üí Variance √©lev√©e - M√©morise le bruit")
print(f"  ‚Üí √âcart Train/Test: {test_errors[2] - train_errors[2]:.2f}")
```

## **Diagramme du Compromis**

```{mermaid}
graph TD
    A[Erreur Totale] --> B[Biais¬≤<br>Erreur due √† la simplicit√©]
    A --> C[Variance<br>Erreur due √† la complexit√©]
    A --> D[Bruit irr√©ductible<br>Non contr√¥lable]
    
    E[Complexit√© ‚Üë] --> F{Biais}
    E --> G{Variance}
    
    F -->|‚Üì| H[üìâ Baisse du Biais]
    F -->|‚Üë| I[üìà Augmentation du Biais]
    
    G -->|‚Üë| J[üìà Hausse de la Variance]
    G -->|‚Üì| K[üìâ Baisse de la Variance]
    
    L[üîç Recherche de l'√©quilibre] --> M[Zone optimale<br>Biais¬≤ ‚âà Variance]
    M --> N[‚úÖ Mod√®le g√©n√©ralise bien]
```

## **Tableau Synth√®se Visuel**

| Zone | Biais | Variance | Sympt√¥mes | Solution |
|------|-------|----------|-----------|----------|
| **Underfitting** | üìà Haut | üìâ Bas | Erreurs train/test √©lev√©es | ‚Üë Complexit√© du mod√®le |
| **Good Fit** | ‚Üï Mod√©r√© | ‚Üï Mod√©r√© | G√©n√©ralisation bonne | ‚úÖ Maintenir |
| **Overfitting** | üìâ Bas | üìà Haut | Train parfait, test m√©diocre | ‚Üì Complexit√©, r√©gularisation |

## **Comment Trouver l'√âquilibre ?**

1. **Commencez simple** (r√©gression lin√©aire comme baseline)
2. **Augmentez progressivement** la complexit√©
3. **Surveillez l'√©cart** entre performance d'entra√Ænement et de test
4. **Arr√™tez quand** l'erreur de test commence √† augmenter

**Formule √† retenir** :
$$E_{\text{test}} = \text{Biais}^2 + \text{Variance} + \epsilon$$

**Le succ√®s** = trouver le point o√π cette somme est minimale !

> **R√®gle d'or** : Visez l'√©quilibre o√π votre mod√®le est assez complexe pour apprendre les patterns importants, mais assez simple pour ignorer le bruit al√©atoire.

Cette compr√©hension est cruciale pour choisir et ajuster vos mod√®les. L'objectif n'est pas d'√©liminer le biais ou la variance, mais de trouver l'√©quilibre optimal pour votre probl√®me sp√©cifique !

#### Exercice Pratique : Diagnostic et Correction

```python
from sklearn.datasets import make_moons
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split

# Donn√©es non-lin√©aires
X, y = make_moons(n_samples=1000, noise=0.3, random_state=42)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)

# Test de diff√©rents mod√®les
models = {
    'Arbre Profond (Variance)': DecisionTreeClassifier(max_depth=20),
    'Arbre Simple (Biais)': DecisionTreeClassifier(max_depth=2),
    'Arbre Optimis√©': DecisionTreeClassifier(max_depth=5, min_samples_split=10),
    'Random Forest': RandomForestClassifier(n_estimators=100, max_depth=5),
    'SVM Lin√©aire (Biais)': SVC(kernel='linear', C=1),
    'SVM RBF (Variance)': SVC(kernel='rbf', C=10, gamma=10)
}

print("üß™ TEST DU COMPROMIS BIAS-VARIANCE")
print("=" * 50)

for name, model in models.items():
    diagnose_bias_variance(model, X_train, X_test, y_train, y_test)
    print("-" * 40)
```

#### Conclusion et Bonnes Pratiques

**Checklist de Validation**
- [ ] **Biais √©lev√© suspect√©** ‚Üí Essayer mod√®les plus complexes
- [ ] **Variance √©lev√©e suspect√©e** ‚Üí Ajouter r√©gularisation
- [ ] **Donn√©es limit√©es** ‚Üí Privil√©gier mod√®les simples
- [ ] **Donn√©es abondantes** ‚Üí Mod√®les complexes possibles
- [ ] **Toujours** utiliser validation crois√©e

**R√®gles Empiriques**
1. **Commencez simple** : Lin√©aire/logistique comme baseline
2. **Augmentez progressivement** la complexit√©
3. **Surveillez l'√©cart** entre train et validation
4. **Utilisez l'ensemble de test** UNE SEULE FOIS √† la fin
5. **Documentez** vos choix d'hyperparam√®tres

**Formule √† Retenir**
> **Mod√®le Id√©al = Biais¬≤ + Variance + Bruit**  
> ‚Üí Minimiser la somme, pas individuellement

Le compromis biais-variance n'est pas un probl√®me √† √©liminer mais un √©quilibre √† ma√Ætriser. La cl√© r√©side dans la compr√©hension des besoins de votre probl√®me sp√©cifique et l'ajustement continu de votre approche.

## 6. Exercices de R√©flexion

::: {.callout-warning icon=false}
## Question 1
Pour chacun des probl√®mes suivants, identifiez le type d'apprentissage appropri√© (supervis√©, non supervis√©, renforcement):

a) Pr√©dire si un patient a une maladie cardiaque
b) Regrouper des articles de presse par th√®me
c) Apprendre √† un robot √† marcher
d) Pr√©dire le prix d'une maison
e) D√©tecter des transactions frauduleuses inhabituelles
:::
::: {.callout-note collapse="true"}
## R√©ponse 1
a) **Apprentissage supervis√©** (Classification) : On pr√©dit une √©tiquette binaire (malade ou non).
b) **Apprentissage non supervis√©** (Clustering) : On regroupe des donn√©es sans √©tiquettes pr√©alables.
c) **Apprentissage par renforcement** : Le robot apprend par essais et erreurs avec un syst√®me de r√©compenses.
d) **Apprentissage supervis√©** (R√©gression) : On pr√©dit une valeur num√©rique continue.
e) **Apprentissage non supervis√©** (D√©tection d'anomalies) : On cherche des comportements qui s'√©cartent de la norme.
:::

::: {.callout-warning icon=false}
## Question 2
Expliquez pourquoi un mod√®le avec 100% de pr√©cision sur les donn√©es d'entra√Ænement peut √™tre probl√©matique.
:::
::: {.callout-note collapse="true"}
## R√©ponse 2
Une pr√©cision de 100 % sur les donn√©es d'entra√Ænement est souvent le signe d'un **surapprentissage (overfitting)**. Le mod√®le a "m√©moris√©" le bruit et les particularit√©s des donn√©es d'entra√Ænement au lieu d'apprendre les tendances g√©n√©rales. Par cons√©quent, il risque d'avoir de tr√®s mauvaises performances sur de nouvelles donn√©es (faible capacit√© de g√©n√©ralisation).
:::

::: {.callout-warning icon=false}
## Question 3
Donnez 3 exemples d'applications ML dans votre domaine d'int√©r√™t et identifiez le type de probl√®me (classification, r√©gression, clustering).
:::
::: {.callout-note collapse="true"}
## R√©ponse 3
*Exemples dans le domaine du commerce √©lectronique :*

1. **Syst√®me de recommandation de produits** : Identifier des groupes de clients aux comportements similaires (**Clustering**).
2. **Pr√©vision de la demande (stocks)** : Pr√©dire le nombre d'unit√©s qui seront vendues le mois prochain (**R√©gression**).
3. **Filtrage de commentaires abusifs** : Identifier si un avis client est conforme ou non aux r√®gles de la plateforme (**Classification**).
:::

## R√©sum√© de la S√©ance

::: {.callout-important icon=false}
## Points cl√©s √† retenir

1. **ML** = apprentissage √† partir de donn√©es sans programmation explicite
2. **Trois types principaux**: supervis√©, non supervis√©, renforcement
3. **Pipeline ML**: Probl√®me ‚Üí Donn√©es ‚Üí Exploration ‚Üí Pr√©paration ‚Üí Mod√®le ‚Üí √âvaluation ‚Üí D√©ploiement
4. **Overfitting vs Underfitting**: √©quilibre crucial pour la g√©n√©ralisation
5. **Applications diverses**: vision, NLP, recommandations, finance, sant√©

:::

## Lectures Compl√©mentaires

1. G√©ron, A. (2019) - Chapitre 1: The Machine Learning Landscape
2. [Google's Machine Learning Crash Course](https://developers.google.com/machine-learning/crash-course)
3. [Andrew Ng - What is Machine Learning?](https://www.coursera.org/learn/machine-learning)
