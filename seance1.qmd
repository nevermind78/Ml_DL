# S√©ance 1: Introduction IA et Machine Learning

::: {.callout-note icon=false}
## Informations de la s√©ance
- **Type**: Cours
- **Dur√©e**: 2h
- **Objectifs**: Obj1, Obj2, Obj3
:::

## 1. D√©finitions et Concepts de Base

### 1.1 Intelligence Artificielle (IA)

L'**Intelligence Artificielle** est un domaine de l'informatique qui vise √† cr√©er des syst√®mes capables d'effectuer des t√¢ches n√©cessitant normalement l'intelligence humaine.

::: {.callout-tip}
## Exemples d'IA au quotidien
- Assistants vocaux (Siri, Alexa, Google Assistant)
- Recommandations Netflix/Spotify
- Filtres anti-spam des emails
- Reconnaissance faciale sur smartphones
- Traduction automatique
:::

### 1.2 Machine Learning (Apprentissage Automatique)

Le **Machine Learning** est une sous-discipline de l'IA qui permet aux ordinateurs d'apprendre √† partir de donn√©es sans √™tre explicitement programm√©s.

**Diff√©rence cl√©**:

- **Programmation traditionnelle**: Humain √©crit les r√®gles ‚Üí Ordinateur applique
- **Machine Learning**: Ordinateur apprend les r√®gles √† partir des donn√©es

```python
# Approche traditionnelle
def classifier_email(email):
    if "viagra" in email or "lottery" in email:
        return "spam"
    else:
        return "not spam"

# Approche Machine Learning
from sklearn.linear_model import LogisticRegression
model = LogisticRegression()
model.fit(X_train, y_train)  # Apprend des exemples
prediction = model.predict(new_email)
```

### 1.3 Deep Learning

Le **Deep Learning** est une sous-cat√©gorie du ML utilisant des r√©seaux de neurones artificiels profonds (plusieurs couches).

**Diagramme mermaid:**
```{mermaid}
graph TD
    A[Intelligence Artificielle] --> B[Machine Learning]
    B --> C[Deep Learning]
    A --> D[Syst√®mes experts]
    A --> E[Robotique]
    B --> F[Apprentissage supervis√©]
    B --> G[Apprentissage non supervis√©]
    B --> H[Apprentissage par renforcement]
```

## 2. Applications et Cas d'Utilisation

### 2.1 Vision par Ordinateur
- D√©tection d'objets
- Reconnaissance faciale
- Diagnostic m√©dical (imagerie)
- Voitures autonomes

### 2.2 Traitement du Langage Naturel (NLP)
- Chatbots et assistants virtuels
- Traduction automatique
- Analyse de sentiments
- R√©sum√© automatique de textes

### 2.3 Syst√®mes de Recommandation
- E-commerce (Amazon, Alibaba)
- Streaming (Netflix, YouTube)
- R√©seaux sociaux (Facebook, Instagram)

### 2.4 Finance
- D√©tection de fraude
- Trading algorithmique
- √âvaluation de risque de cr√©dit

### 2.5 Sant√©
- Diagnostic de maladies
- D√©couverte de m√©dicaments
- Analyse d'imagerie m√©dicale

## 3. Types d'Apprentissage

### 3.1 Apprentissage Supervis√©

Le mod√®le apprend √† partir de **donn√©es √©tiquet√©es** (avec r√©ponses connues).

::: {.callout-note}
## Exemple
**Donn√©es d'entra√Ænement**: emails avec labels "spam" ou "non spam"
**Objectif**: Pr√©dire si un nouveau email est spam
:::

**T√¢ches principales**:

- **Classification**: pr√©dire une cat√©gorie (spam/non spam, chat/chien)
- **R√©gression**: pr√©dire une valeur continue (prix maison, temp√©rature)

```python
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestRegressor

# Classification
clf = LogisticRegression()
clf.fit(X_train, y_train)  # y_train contient les cat√©gories
pred_class = clf.predict(X_test)

# R√©gression
reg = RandomForestRegressor()
reg.fit(X_train, y_train)  # y_train contient les valeurs continues
pred_value = reg.predict(X_test)
```

### 3.2 Apprentissage Non Supervis√©

Le mod√®le apprend √† partir de **donn√©es non √©tiquet√©es** (sans r√©ponses).

::: {.callout-note}
## Exemple
**Donn√©es**: comportements d'achat de clients
**Objectif**: Identifier des groupes de clients similaires (segmentation)
:::

**T√¢ches principales**:

- **Clustering**: regrouper des donn√©es similaires
- **R√©duction de dimension**: simplifier les donn√©es
- **D√©tection d'anomalies**: identifier des points inhabituels

```python
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA

# Clustering
kmeans = KMeans(n_clusters=3)
clusters = kmeans.fit_predict(X)

# R√©duction de dimension
pca = PCA(n_components=2)
X_reduced = pca.fit_transform(X)
```

### 3.3 Apprentissage Semi-Supervis√©

Combine donn√©es √©tiquet√©es (peu) et non √©tiquet√©es (beaucoup).

**Cas d'usage**: Lorsque l'√©tiquetage est co√ªteux (imagerie m√©dicale, reconnaissance vocale)

### 3.4 Apprentissage par Renforcement

L'agent apprend par **essai-erreur** en interagissant avec un environnement.

::: {.callout-note}
## Exemple
- Jeux vid√©o (AlphaGo, Chess AI)
- Robotique
- Contr√¥le de syst√®mes complexes
:::

**Composants**:

- **Agent**: celui qui apprend
- **Environnement**: le monde dans lequel l'agent √©volue
- **Actions**: ce que l'agent peut faire
- **R√©compenses**: feedback positif/n√©gatif

## 4. √âtapes de Conception d'un Mod√®le IA

### 4.1 Pipeline ML Standard

**Diagramme mermaid:**
```{mermaid}
graph TB
    A[1 D√©finir le probl√®me] --> B[2 Collecter les donn√©es]
    B --> C[3 Explorer les donn√©es]
    C --> D[4 Pr√©parer les donn√©es]
    D --> E[5 Choisir un mod√®le]
    E --> F[6 Entra√Æner le mod√®le]
    F --> G[7 √âvaluer le mod√®le]
    G --> H{Performance OK?}
    H -->|Non| E
    H -->|Oui| I[8 D√©ployer]
    I --> J[9 Monitorer]
```

### 4.2 D√©tails des √âtapes

#### √âtape 1: D√©finir le Probl√®me
- Quel type de probl√®me? (classification, r√©gression, clustering)
- Quelles sont les m√©triques de succ√®s?
- Quelles sont les contraintes?

#### √âtape 2: Collecter les Donn√©es
- Sources de donn√©es
- Quantit√© n√©cessaire
- Qualit√© des donn√©es

#### √âtape 3: Explorer les Donn√©es (EDA)
- Statistiques descriptives
- Visualisations
- Identifier les patterns, outliers, donn√©es manquantes

```python
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Exemple EDA simple
df = pd.read_csv('data.csv')
print(df.info())
print(df.describe())

# Visualisation
sns.pairplot(df)
plt.show()
```

#### √âtape 4: Pr√©parer les Donn√©es
- Nettoyage (valeurs manquantes, doublons)
- Transformation (normalisation, encodage)
- Feature engineering
- Split train/test

```python
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer

# Split des donn√©es
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Normalisation
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Gestion des valeurs manquantes
imputer = SimpleImputer(strategy='mean')
X_train_imputed = imputer.fit_transform(X_train)
X_test_imputed = imputer.transform(X_test)
```

#### √âtape 5: Choisir un Mod√®le
- Bas√© sur le type de probl√®me
- Complexit√© vs interpr√©tabilit√©
- Ressources disponibles

#### √âtape 6: Entra√Æner le Mod√®le
- Ajuster les param√®tres
- Optimisation

#### √âtape 7: √âvaluer le Mod√®le
- M√©triques appropri√©es
- Validation crois√©e
- Analyse des erreurs

#### √âtape 8: D√©ployer
- Mise en production
- API, application web, etc.

#### √âtape 9: Monitorer
- Performances en production
- D√©rive des donn√©es (data drift)
- Mise √† jour du mod√®le

## 5. Concepts Cl√©s

### 5.1 Overfitting vs Underfitting

::: {.panel-tabset}

## Underfitting
- Mod√®le **trop simple**
- Ne capture pas les patterns dans les donn√©es
- **Biais √©lev√©**, variance faible
- Mauvaise performance train ET test

## Overfitting
- Mod√®le **trop complexe**
- M√©morise les donn√©es d'entra√Ænement (bruit inclus)
- Biais faible, **variance √©lev√©e**
- Bonne performance train, **mauvaise** performance test

## Juste bien (Good fit)
- Mod√®le √©quilibr√©
- Capture les vrais patterns
- Biais et variance faibles
- Bonne g√©n√©ralisation

:::

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression

# G√©n√©ration de donn√©es
np.random.seed(42)
X = np.linspace(0, 10, 50)
y = 2*X + 1 + np.random.randn(50)*2

# Sous-ajustement (linear)
underfit_model = LinearRegression()
underfit_model.fit(X.reshape(-1, 1), y)
y_underfit = underfit_model.predict(X.reshape(-1, 1))

# Bon ajustement (polynomial degree 2)
goodfit_model = Pipeline([
    ('poly', PolynomialFeatures(degree=2)),
    ('linear', LinearRegression())
])
goodfit_model.fit(X.reshape(-1, 1), y)
y_goodfit = goodfit_model.predict(X.reshape(-1, 1))

# Surajustement (polynomial degree 15)
overfit_model = Pipeline([
    ('poly', PolynomialFeatures(degree=15)),
    ('linear', LinearRegression())
])
overfit_model.fit(X.reshape(-1, 1), y)
y_overfit = overfit_model.predict(X.reshape(-1, 1))

# Visualisation
fig, axes = plt.subplots(1, 3, figsize=(15, 4))

axes[0].scatter(X, y, alpha=0.5)
axes[0].plot(X, y_underfit, 'r-', linewidth=2)
axes[0].set_title('Underfitting (lin√©aire)')

axes[1].scatter(X, y, alpha=0.5)
axes[1].plot(X, y_goodfit, 'g-', linewidth=2)
axes[1].set_title('Good Fit (polynomial deg 2)')

axes[2].scatter(X, y, alpha=0.5)
axes[2].plot(X, y_overfit, 'b-', linewidth=2)
axes[2].set_title('Overfitting (polynomial deg 15)')

plt.tight_layout()
plt.show()
```

### 5.2 Compromis Biais-Variance


#### **L'√©quilibre fondamental du Machine Learning**

Le **compromis biais-variance** est un concept essentiel qui explique pourquoi certains mod√®les ne g√©n√©ralisent pas bien. Imaginez apprendre pour un examen :

- **Biais √©lev√©** = Vous survolez trop le cours (sous-apprentissage)
- **Variance √©lev√©e** = Vous m√©morisez par c≈ìur sans comprendre (sur-apprentissage)

#### **Formules Math√©matiques Cl√©s**

**Erreur totale du mod√®le :**
$$E_{\text{total}} = \underbrace{\text{Biais}^2}_{\text{simplicit√©}} + \underbrace{\text{Variance}}_{\text{complexit√©}} + \epsilon$$

**O√π :**

- $\text{Biais} = E[\hat{f}(x)] - f(x)$ (diff√©rence entre pr√©diction moyenne et v√©rit√©)
- $\text{Variance} = E[(\hat{f}(x) - E[\hat{f}(x)])^2]$ (variabilit√© des pr√©dictions)
- $\epsilon$ = Bruit irr√©ductible des donn√©es

#### **Exemple Illustratif avec Python**
Dans cet exemple ,nous allons explorer le **compromis biais-variance** √† travers un cas concret :

##### **Le Sc√©nario**
Imaginons que nous voulons pr√©dire une variable `y` √† partir d'une variable `X`. Nos donn√©es suivent une **tendance sinuso√Ødale** (comme une vague) avec du **bruit al√©atoire** ajout√© pour simuler des mesures r√©elles imparfaites.

##### **Les Trois Types de Mod√®les Test√©s**

Nous allons ajuster trois mod√®les polynomiaux de complexit√© croissante :

1. **Degr√© 1 (Lin√©aire)** : 
   - Mod√®le le plus simple : une ligne droite
   - **Probl√®me attendu** : Trop simple pour capturer la forme sinuso√Ødale ‚Üí **Biais √©lev√©** (sous-ajustement)
   - La ligne droite ne peut pas suivre les courbes des donn√©es

2. **Degr√© 3 (Cubique)** :
   - Complexit√© mod√©r√©e : peut faire des courbes douces
   - **R√©sultat attendu** : Bon √©quilibre entre simplicit√© et flexibilit√©
   - Capture la tendance g√©n√©rale sans trop coller au bruit

3. **Degr√© 9 (Polyn√¥me de haut degr√©)** :
   - Mod√®le tr√®s complexe : peut faire des courbes tr√®s compliqu√©es
   - **Probl√®me attendu** : Trop flexible, suit le bruit ‚Üí **Variance √©lev√©e** (sur-ajustement)
   - Passe par presque tous les points d'entra√Ænement mais pr√©dit mal sur de nouvelles donn√©es


#### **Ce que Vous Allez Observer**

Dans les onglets suivants, vous verrez :

- **Points bleus** = Donn√©es d'entra√Ænement (le mod√®le "voit" ces points)
- **Points rouges** = Donn√©es de test (le mod√®le ne "voit" PAS ces points)
- **Ligne verte** = Pr√©dictions du mod√®le

**Question cl√© √† observer** : Quel mod√®le pr√©dit le mieux les points rouges (test) qu'il n'a jamais vus ?

---

```{python}
#| echo: false
#| eval: true
#| warning: false

# ============================================================================
# IMPORTATION DES BIBLIOTH√àQUES
# ============================================================================
import numpy as np
import matplotlib.pyplot as plt
import ipywidgets as widgets
from IPython.display import display
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split

# ============================================================================
# G√âN√âRATION DES DONN√âES SYNTH√âTIQUES
# ============================================================================
# Fixation de la graine al√©atoire pour la reproductibilit√© des r√©sultats
np.random.seed(42)

# Cr√©ation de 50 points √©quidistants entre 0 et 10
X = np.linspace(0, 10, 50)

# G√©n√©ration de la variable cible : fonction sinuso√Ødale avec bruit gaussien
# y = 2*sin(X) + bruit al√©atoire
# Cela simule des donn√©es r√©elles avec une tendance non-lin√©aire et du bruit
y = 2*np.sin(X) + np.random.randn(50)

# S√©paration des donn√©es en ensembles d'entra√Ænement (70%) et de test (30%)
# - X_train, y_train : pour entra√Æner les mod√®les
# - X_test, y_test : pour √©valuer la performance et la g√©n√©ralisation
X_train, X_test, y_train, y_test = train_test_split(
    X.reshape(-1, 1),  # reshape n√©cessaire pour sklearn (format 2D)
    y, 
    test_size=0.3,      # 30% des donn√©es pour le test
    random_state=42     # pour des r√©sultats reproductibles
)

# ============================================================================
# FONCTION : CR√âATION D'UN GRAPHIQUE POUR UN DEGR√â POLYNOMIAL SP√âCIFIQUE
# ============================================================================
def create_model_plot(degree):
    """
    Cr√©e un graphique montrant l'ajustement d'un mod√®le polynomial.
    
    Param√®tres:
    -----------
    degree : int
        Degr√© du polyn√¥me (1=lin√©aire, 3=cubique, 9=tr√®s complexe)
    
    Retourne:
    ---------
    fig : matplotlib.figure.Figure
        La figure contenant le graphique
    
    Concepts illustr√©s:
    -------------------
    - Degr√© faible (1) : sous-ajustement (underfitting), biais √©lev√©
    - Degr√© moyen (3) : bon √©quilibre
    - Degr√© √©lev√© (9) : sur-ajustement (overfitting), variance √©lev√©e
    """
    fig, ax = plt.subplots(figsize=(7, 5))
    
    # Cr√©ation d'un pipeline sklearn :
    # 1. PolynomialFeatures : transforme X en [X, X^2, X^3, ..., X^degree]
    # 2. LinearRegression : ajuste un mod√®le lin√©aire sur ces features polynomiales
    model = Pipeline([
        ('poly', PolynomialFeatures(degree=degree)),
        ('linear', LinearRegression())
    ])
    
    # Entra√Ænement du mod√®le sur les donn√©es d'entra√Ænement
    model.fit(X_train, y_train)
    
    # Cr√©ation de points pour tracer une courbe lisse de pr√©diction
    X_plot = np.linspace(0, 10, 100).reshape(-1, 1)
    y_plot = model.predict(X_plot)
    
    # Visualisation :
    # - Points bleus : donn√©es d'entra√Ænement
    # - Points rouges : donn√©es de test
    # - Ligne verte : pr√©dictions du mod√®le
    ax.scatter(X_train, y_train, alpha=0.5, s=30, label='Train')
    ax.scatter(X_test, y_test, alpha=0.5, s=30, color='red', label='Test')
    ax.plot(X_plot, y_plot, 'g-', linewidth=2, label='Pr√©diction')
    
    ax.set_title(f'Mod√®le polynomial de degr√© {degree}')
    ax.set_xlabel('X')
    ax.set_ylabel('y')
    ax.legend()
    ax.grid(True, alpha=0.3)
    plt.tight_layout()
    
    return fig

# ============================================================================
# FONCTION : COURBE DU COMPROMIS BIAIS-VARIANCE
# ============================================================================
def create_bias_variance_curve():
    """
    Cr√©e un graphique montrant l'√©volution des erreurs en fonction de la complexit√©.
    
    Concepts illustr√©s:
    -------------------
    - Erreur d'entra√Ænement (bleue) : diminue toujours avec la complexit√©
    - Erreur de test (rouge) : forme en U caract√©ristique
      * D√©but √©lev√© : sous-ajustement (biais √©lev√©)
      * Minimum : zone optimale (bon √©quilibre)
      * Fin √©lev√© : sur-ajustement (variance √©lev√©e)
    """
    fig, ax = plt.subplots(figsize=(7, 5))
    
    # Test de mod√®les avec des degr√©s polynomiaux de 1 √† 14
    degrees_range = range(1, 15)
    train_errs, test_errs = [], []
    
    # Pour chaque degr√©, on calcule l'erreur quadratique moyenne (MSE)
    for d in degrees_range:
        model = Pipeline([
            ('poly', PolynomialFeatures(degree=d)),
            ('linear', LinearRegression())
        ])
        model.fit(X_train, y_train)
        
        # Erreur sur l'entra√Ænement : mesure le biais
        # Une erreur √©lev√©e indique un mod√®le trop simple
        train_errs.append(np.mean((model.predict(X_train) - y_train) ** 2))
        
        # Erreur sur le test : mesure la capacit√© de g√©n√©ralisation
        # Une erreur √©lev√©e indique soit du biais soit de la variance
        test_errs.append(np.mean((model.predict(X_test) - y_test) ** 2))
    
    # Tra√ßage des courbes
    ax.plot(degrees_range, train_errs, 'b-', label='Erreur Train', linewidth=2)
    ax.plot(degrees_range, test_errs, 'r-', label='Erreur Test', linewidth=2)
    
    ax.set_xlabel('Degr√© du polyn√¥me (Complexit√©)')
    ax.set_ylabel('Erreur Quadratique Moyenne')
    ax.set_title('Courbe du compromis Biais-Variance')
    ax.legend()
    ax.grid(True, alpha=0.3)
    plt.tight_layout()
    
    return fig

# ============================================================================
# FONCTION : AFFICHAGE DES FORMULES MATH√âMATIQUES
# ============================================================================
def create_formulas():
    """
    Affiche les formules math√©matiques du compromis biais-variance.
    
    Formules:
    ---------
    1. Erreur totale = Biais¬≤ + Variance + Bruit irr√©ductible
    2. Biais = Diff√©rence entre pr√©diction moyenne et vraie valeur
    3. Variance = Variabilit√© des pr√©dictions pour diff√©rents ensembles
    """
    fig, ax = plt.subplots(figsize=(7, 5))
    ax.axis('off')  # Pas d'axes pour ce graphique
    
    # Formules en LaTeX (notation math√©matique)
    formules = r"""$E_{\mathrm{total}} = \mathrm{Biais}^2 + \mathrm{Variance} + \epsilon$

$\mathrm{Biais} = E[\hat{f}(x)] - f(x)$

$\mathrm{Variance} = E[(\hat{f}(x) - E[\hat{f}(x)])^2]$"""
    
    ax.text(0.5, 0.5, formules, fontsize=16, ha='center', va='center')
    plt.tight_layout()
    
    return fig

# ============================================================================
# CR√âATION DES WIDGETS INTERACTIFS (ONGLETS)
# ============================================================================
# Cr√©ation de conteneurs pour chaque graphique
# widgets.Output() permet de capturer et afficher les sorties matplotlib
out_degree1 = widgets.Output()
out_degree3 = widgets.Output()
out_degree9 = widgets.Output()
out_curve = widgets.Output()
out_formulas = widgets.Output()

# G√©n√©ration et affichage de chaque graphique dans son conteneur
# Degr√© 1 : Mod√®le lin√©aire simple (sous-ajustement probable)
with out_degree1:
    fig1 = create_model_plot(1)
    plt.show()

# Degr√© 3 : Mod√®le cubique (souvent un bon √©quilibre)
with out_degree3:
    fig3 = create_model_plot(3)
    plt.show()

# Degr√© 9 : Mod√®le tr√®s complexe (sur-ajustement probable)
with out_degree9:
    fig9 = create_model_plot(9)
    plt.show()

# Courbe montrant l'√©volution des erreurs
with out_curve:
    fig_curve = create_bias_variance_curve()
    plt.show()

# Formules math√©matiques
with out_formulas:
    fig_formulas = create_formulas()
    plt.show()

# ============================================================================
# ASSEMBLAGE DES ONGLETS ET AFFICHAGE FINAL
# ============================================================================
# Cr√©ation d'une interface √† onglets contenant tous les graphiques
tabs = widgets.Tab(children=[out_degree1, out_degree3, out_degree9, out_curve])

# Attribution des titres pour chaque onglet
tabs.set_title(0, 'Degr√© 1')          # Mod√®le simple
tabs.set_title(1, 'Degr√© 3')          # Mod√®le √©quilibr√©
tabs.set_title(2, 'Degr√© 9')          # Mod√®le complexe
tabs.set_title(3, 'Courbe Biais-Variance')  # Vue d'ensemble
#tabs.set_title(4, 'Formules')         # Th√©orie math√©matique

# Affichage de l'interface interactive
display(tabs)
```

---


#### **Composition de l'Erreur Totale**

**Explication :** L'erreur totale d'un mod√®le se d√©compose en trois parties :

- **Biais¬≤** : Erreur syst√©matique due √† la simplicit√© du mod√®le
- **Variance** : Sensibilit√© du mod√®le aux variations dans les donn√©es
- **Bruit irr√©ductible** : Erreur al√©atoire inh√©rente aux donn√©es

```{mermaid}
graph TD
    A["Erreur Totale"] --> B["Biais au carre<br/>Erreur due a la simplicite"]
    A --> C["Variance<br/>Erreur due a la complexite"]
    A --> D["Bruit irreductible<br/>Non controlable"]
    
    style A fill:#e1f5ff
    style B fill:#ffe1e1
    style C fill:#fff4e1
    style D fill:#f0f0f0
```

---

##### Impact de la Complexit√© sur le Mod√®le

**Explication :** Lorsqu'on augmente la complexit√© d'un mod√®le :

- Le **biais diminue** : le mod√®le peut mieux capturer les patterns complexes
- La **variance augmente** : le mod√®le devient plus sensible au bruit dans les donn√©es

C'est le c≈ìur du compromis biais-variance !

```{mermaid}
graph TD
    E1["Complexite croissante"] --> F1["Impact sur Biais"]
    E1 --> G1["Impact sur Variance"]
    
    F1 --> H1["Modele simple: Biais eleve"]
    F1 --> I1["Modele complexe: Biais faible"]
    
    G1 --> J1["Modele simple: Variance faible"]
    G1 --> K1["Modele complexe: Variance elevee"]
    
    style E1 fill:#e1f5ff
    style F1 fill:#fff4e1
    style G1 fill:#fff4e1
    style H1 fill:#f8d7da
    style I1 fill:#d4edda
    style J1 fill:#d4edda
    style K1 fill:#f8d7da
```

---

##### Recherche de la Zone Optimale

**Explication :** L'objectif est de trouver le point d'√©quilibre o√π :

- Le biais n'est pas trop √©lev√© (mod√®le pas trop simple)
- La variance n'est pas trop √©lev√©e (mod√®le pas trop complexe)
- Le mod√®le **g√©n√©ralise bien** sur de nouvelles donn√©es

```{mermaid}
graph TD
    L2["Recherche de l equilibre"] --> M2["Zone optimale<br/>Biais carre proche Variance"]
    M2 --> N2["Modele generalise bien"]
    
    style L2 fill:#fff3cd
    style M2 fill:#d1ecf1
    style N2 fill:#d4edda
```

---


#### A Retenir
1. **Biais √©lev√©** = Mod√®le trop simple = Sous-ajustement (underfitting)
2. **Variance √©lev√©e** = Mod√®le trop complexe = Sur-ajustement (overfitting)
3. **Objectif** = Trouver le juste milieu pour une bonne g√©n√©ralisation
4. **Erreur de test** = Indicateur principal de la performance r√©elle du mod√®le

#### **Comment Trouver l'√âquilibre ?**
1. **Commencez simple** (r√©gression lin√©aire comme baseline)
2. **Augmentez progressivement** la complexit√©
3. **Surveillez l'√©cart** entre performance d'entra√Ænement et de test
4. **Arr√™tez quand** l'erreur de test commence √† augmenter

**Formule √† retenir** :
$$E_{\text{test}} = \text{Biais}^2 + \text{Variance} + \epsilon$$

**Le succ√®s** = trouver le point o√π cette somme est minimale !

> **R√®gle d'or** : Visez l'√©quilibre o√π votre mod√®le est assez complexe pour apprendre les patterns importants, mais assez simple pour ignorer le bruit al√©atoire.

Cette compr√©hension est cruciale pour choisir et ajuster vos mod√®les. L'objectif n'est pas d'√©liminer le biais ou la variance, mais de trouver l'√©quilibre optimal pour votre probl√®me sp√©cifique !

#### Exercice Pratique : Diagnostic et Correction

```python
from sklearn.datasets import make_moons
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split

# Donn√©es non-lin√©aires
X, y = make_moons(n_samples=1000, noise=0.3, random_state=42)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)

# Test de diff√©rents mod√®les
models = {
    'Arbre Profond (Variance)': DecisionTreeClassifier(max_depth=20),
    'Arbre Simple (Biais)': DecisionTreeClassifier(max_depth=2),
    'Arbre Optimis√©': DecisionTreeClassifier(max_depth=5, min_samples_split=10),
    'Random Forest': RandomForestClassifier(n_estimators=100, max_depth=5),
    'SVM Lin√©aire (Biais)': SVC(kernel='linear', C=1),
    'SVM RBF (Variance)': SVC(kernel='rbf', C=10, gamma=10)
}

print("üß™ TEST DU COMPROMIS BIAS-VARIANCE")
print("=" * 50)

for name, model in models.items():
    diagnose_bias_variance(model, X_train, X_test, y_train, y_test)
    print("-" * 40)
```

#### Conclusion et Bonnes Pratiques

**Checklist de Validation**

- [ ] **Biais √©lev√© suspect√©** ‚Üí Essayer mod√®les plus complexes
- [ ] **Variance √©lev√©e suspect√©e** ‚Üí Ajouter r√©gularisation
- [ ] **Donn√©es limit√©es** ‚Üí Privil√©gier mod√®les simples
- [ ] **Donn√©es abondantes** ‚Üí Mod√®les complexes possibles
- [ ] **Toujours** utiliser validation crois√©e

**R√®gles Empiriques**

1. **Commencez simple** : Lin√©aire/logistique comme baseline
2. **Augmentez progressivement** la complexit√©
3. **Surveillez l'√©cart** entre train et validation
4. **Utilisez l'ensemble de test** UNE SEULE FOIS √† la fin
5. **Documentez** vos choix d'hyperparam√®tres

**Formule √† Retenir**

> **Mod√®le Id√©al = Biais¬≤ + Variance + Bruit**  
> ‚Üí Minimiser la somme, pas individuellement

Le compromis biais-variance n'est pas un probl√®me √† √©liminer mais un √©quilibre √† ma√Ætriser. La cl√© r√©side dans la compr√©hension des besoins de votre probl√®me sp√©cifique et l'ajustement continu de votre approche.

## 6. Exercices de R√©flexion

::: {.callout-warning icon=false}
## Question 1
Pour chacun des probl√®mes suivants, identifiez le type d'apprentissage appropri√© (supervis√©, non supervis√©, renforcement):

a) Pr√©dire si un patient a une maladie cardiaque
b) Regrouper des articles de presse par th√®me
c) Apprendre √† un robot √† marcher
d) Pr√©dire le prix d'une maison
e) D√©tecter des transactions frauduleuses inhabituelles
:::
::: {.callout-note collapse="true"}
## R√©ponse 1
a) **Apprentissage supervis√©** (Classification) : On pr√©dit une √©tiquette binaire (malade ou non).
b) **Apprentissage non supervis√©** (Clustering) : On regroupe des donn√©es sans √©tiquettes pr√©alables.
c) **Apprentissage par renforcement** : Le robot apprend par essais et erreurs avec un syst√®me de r√©compenses.
d) **Apprentissage supervis√©** (R√©gression) : On pr√©dit une valeur num√©rique continue.
e) **Apprentissage non supervis√©** (D√©tection d'anomalies) : On cherche des comportements qui s'√©cartent de la norme.
:::

::: {.callout-warning icon=false}
## Question 2
Expliquez pourquoi un mod√®le avec 100% de pr√©cision sur les donn√©es d'entra√Ænement peut √™tre probl√©matique.
:::
::: {.callout-note collapse="true"}
## R√©ponse 2
Une pr√©cision de 100 % sur les donn√©es d'entra√Ænement est souvent le signe d'un **surapprentissage (overfitting)**. Le mod√®le a "m√©moris√©" le bruit et les particularit√©s des donn√©es d'entra√Ænement au lieu d'apprendre les tendances g√©n√©rales. Par cons√©quent, il risque d'avoir de tr√®s mauvaises performances sur de nouvelles donn√©es (faible capacit√© de g√©n√©ralisation).
:::

::: {.callout-warning icon=false}
## Question 3
Donnez 3 exemples d'applications ML dans votre domaine d'int√©r√™t et identifiez le type de probl√®me (classification, r√©gression, clustering).
:::
::: {.callout-note collapse="true"}
## R√©ponse 3
*Exemples dans le domaine du commerce √©lectronique :*

1. **Syst√®me de recommandation de produits** : Identifier des groupes de clients aux comportements similaires (**Clustering**).
2. **Pr√©vision de la demande (stocks)** : Pr√©dire le nombre d'unit√©s qui seront vendues le mois prochain (**R√©gression**).
3. **Filtrage de commentaires abusifs** : Identifier si un avis client est conforme ou non aux r√®gles de la plateforme (**Classification**).
:::

## R√©sum√© de la S√©ance

::: {.callout-important icon=false}
## Points cl√©s √† retenir

1. **ML** = apprentissage √† partir de donn√©es sans programmation explicite
2. **Trois types principaux**: supervis√©, non supervis√©, renforcement
3. **Pipeline ML**: Probl√®me ‚Üí Donn√©es ‚Üí Exploration ‚Üí Pr√©paration ‚Üí Mod√®le ‚Üí √âvaluation ‚Üí D√©ploiement
4. **Overfitting vs Underfitting**: √©quilibre crucial pour la g√©n√©ralisation
5. **Applications diverses**: vision, NLP, recommandations, finance, sant√©

:::

## Lectures Compl√©mentaires

1. G√©ron, A. (2019) - Chapitre 1: The Machine Learning Landscape
2. [Google's Machine Learning Crash Course](https://developers.google.com/machine-learning/crash-course)
3. [Andrew Ng - What is Machine Learning?](https://www.coursera.org/learn/machine-learning)
