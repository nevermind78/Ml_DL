<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.27">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Séance 4: TD1 - Modèles de Classification de Base – Machine Learning et Deep Learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./seance5.html" rel="next">
<link href="./seance3.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-8b4baf804e461d9b72633f0de59a0cac.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark-f1aadacce99040138bbb613f9330654f.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-8b4baf804e461d9b72633f0de59a0cac.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-670c757105cc8b81a53606a71844536c.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark-b7200e4a2f6cd71dc52354e94e906ccc.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="site_libs/bootstrap/bootstrap-670c757105cc8b81a53606a71844536c.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="site_libs/quarto-diagram/mermaid.min.js"></script>
<script src="site_libs/quarto-diagram/mermaid-init.js"></script>
<link href="site_libs/quarto-diagram/mermaid.css" rel="stylesheet">
<!-- Google Translate Widget -->
</head><body class="nav-sidebar floating quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script><div id="google_translate_element"></div>

<script type="text/javascript">
function googleTranslateElementInit() {
  new google.translate.TranslateElement({
    pageLanguage: 'fr',
    includedLanguages: 'fr,en', // Seulement FR et EN
    layout: google.translate.TranslateElement.InlineLayout.SIMPLE,
    autoDisplay: false
  }, 'google_translate_element');
}
</script>

<script type="text/javascript" src="https://translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script>

<style>
/* Style pour le widget Google Translate - MODIFIÉ */
#google_translate_element {
  position: fixed;
  top: 10px;
  right: 10px;
  z-index: 9999;
  background: white;
  padding: 2px;
  border-radius: 20px; /* Forme arrondie */
  box-shadow: 0 1px 3px rgba(0,0,0,0.1);
  border: 1px solid #ddd;
}

/* Cacher le branding Google */
.goog-te-gadget {
  font-size: 0 !important;
}

.goog-te-gadget-simple {
  background-color: transparent !important;
  border: none !important;
  padding: 0 !important;
}

.goog-te-menu-value span {
  color: #333 !important;
  font-size: 13px !important;
}

.goog-te-menu-value {
  color: #333 !important;
  border: none !important;
  background: transparent !important;
  padding: 4px 10px !important;
  border-radius: 15px !important;
}

/* Style personnalisé - Afficher seulement FR/EN */
.goog-te-gadget .goog-te-menu-value span:first-child {
  display: none !important;
}

/* Remplacer le texte par FR/EN seulement */
.goog-te-gadget .goog-te-menu-value span:last-child {
  display: inline-block;
  min-width: 30px;
  text-align: center;
}

/* Cacher la flèche */
.goog-te-gadget .goog-te-menu-value span:last-child:after {
  content: '';
  display: none;
}

/* Correction pour l'affichage */
.goog-te-banner-frame.skiptranslate {
  display: none !important;
}

body {
  top: 0px !important;
}

/* Style pour le menu déroulant */
.goog-te-menu2 {
  border-radius: 10px !important;
  box-shadow: 0 2px 8px rgba(0,0,0,0.15) !important;
  border: 1px solid #eee !important;
  min-width: 60px !important;
}

.goog-te-menu2-item {
  padding: 8px 12px !important;
  font-size: 13px !important;
  text-align: center;
}

/* Garder seulement FR et EN dans le menu */
.goog-te-menu2-item div:first-child {
  font-weight: 500;
}
</style>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>





<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./seance1.html">Partie 1: Machine Learning Fondamental</a></li><li class="breadcrumb-item"><a href="./seance4.html"><span class="chapter-title">Séance 4: TD1 - Modèles de Classification de Base</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Machine Learning et Deep Learning</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/nevermind78/Ml_DL" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Présentation du Cours</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Partie 1: Machine Learning Fondamental</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./seance1.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Séance 1: Introduction IA et Machine Learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./seance2.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Séance 2: Apprentissage Supervisé - Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./seance3.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Séance 3: TP1 - Pipeline de Classification Binaire</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./seance4.html" class="sidebar-item-text sidebar-link active"><span class="chapter-title">Séance 4: TD1 - Modèles de Classification de Base</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./seance5.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Séance 5: TD2 - Critères d’Évaluation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./seance6.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Séance 6: TP2 - Classification Multi-classes &amp; Optimisation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./seance7.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Séance 7: Cours - Apprentissage Supervisé : Régression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./seance8.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Séance 8: TP3 - Régression &amp; Optimisation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./seance9.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Séance 9: Apprentissage Non Supervisé</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./seance10.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Séance 10: TP4 - Clustering &amp; Réduction de Dimension</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#partie-1-arbres-de-décision" id="toc-partie-1-arbres-de-décision" class="nav-link" data-scroll-target="#partie-1-arbres-de-décision">Partie 1: Arbres de Décision</a>
  <ul class="collapse">
  <li><a href="#exercice-1.1-construction-dun-arbre" id="toc-exercice-1.1-construction-dun-arbre" class="nav-link" data-scroll-target="#exercice-1.1-construction-dun-arbre">Exercice 1.1: Construction d’un Arbre</a></li>
  <li><a href="#exercice-1.2-overfitting-dans-les-arbres" id="toc-exercice-1.2-overfitting-dans-les-arbres" class="nav-link" data-scroll-target="#exercice-1.2-overfitting-dans-les-arbres">Exercice 1.2: Overfitting dans les Arbres</a></li>
  </ul></li>
  <li><a href="#partie-2-régression-logistique" id="toc-partie-2-régression-logistique" class="nav-link" data-scroll-target="#partie-2-régression-logistique">Partie 2: Régression Logistique</a>
  <ul class="collapse">
  <li><a href="#exercice-2.1-intuition-probabiliste" id="toc-exercice-2.1-intuition-probabiliste" class="nav-link" data-scroll-target="#exercice-2.1-intuition-probabiliste">Exercice 2.1: Intuition Probabiliste</a></li>
  <li><a href="#exercice-2.2-régression-logistique-multiclasse" id="toc-exercice-2.2-régression-logistique-multiclasse" class="nav-link" data-scroll-target="#exercice-2.2-régression-logistique-multiclasse">Exercice 2.2: Régression Logistique Multiclasse</a></li>
  </ul></li>
  <li><a href="#partie-3-k-nearest-neighbors" id="toc-partie-3-k-nearest-neighbors" class="nav-link" data-scroll-target="#partie-3-k-nearest-neighbors">Partie 3: k-Nearest Neighbors</a>
  <ul class="collapse">
  <li><a href="#exercice-3.1-distance-et-voisinage" id="toc-exercice-3.1-distance-et-voisinage" class="nav-link" data-scroll-target="#exercice-3.1-distance-et-voisinage">Exercice 3.1: Distance et Voisinage</a></li>
  </ul></li>
  <li><a href="#partie-4-naive-bayes" id="toc-partie-4-naive-bayes" class="nav-link" data-scroll-target="#partie-4-naive-bayes">Partie 4: Naive Bayes</a>
  <ul class="collapse">
  <li><a href="#exercice-4.1-application-du-théorème-de-bayes" id="toc-exercice-4.1-application-du-théorème-de-bayes" class="nav-link" data-scroll-target="#exercice-4.1-application-du-théorème-de-bayes">Exercice 4.1: Application du Théorème de Bayes</a></li>
  </ul></li>
  <li><a href="#partie-5-gradient-boosting-xgboostlightgbm" id="toc-partie-5-gradient-boosting-xgboostlightgbm" class="nav-link" data-scroll-target="#partie-5-gradient-boosting-xgboostlightgbm">Partie 5: Gradient Boosting (XGBoost/LightGBM)</a>
  <ul class="collapse">
  <li><a href="#exercice-5.1-comprendre-le-boosting" id="toc-exercice-5.1-comprendre-le-boosting" class="nav-link" data-scroll-target="#exercice-5.1-comprendre-le-boosting">Exercice 5.1: Comprendre le Boosting</a></li>
  </ul></li>
  <li><a href="#exercices-récapitulatifs" id="toc-exercices-récapitulatifs" class="nav-link" data-scroll-target="#exercices-récapitulatifs">Exercices Récapitulatifs</a></li>
  <li><a href="#résumé-du-td" id="toc-résumé-du-td" class="nav-link" data-scroll-target="#résumé-du-td">Résumé du TD</a></li>
  <li><a href="#pour-le-prochain-cours" id="toc-pour-le-prochain-cours" class="nav-link" data-scroll-target="#pour-le-prochain-cours">Pour le Prochain Cours</a></li>
  <li><a href="#ressources-complémentaires" id="toc-ressources-complémentaires" class="nav-link" data-scroll-target="#ressources-complémentaires">Ressources Complémentaires</a></li>
  <li><a href="#correction" id="toc-correction" class="nav-link" data-scroll-target="#correction">Correction</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./seance1.html">Partie 1: Machine Learning Fondamental</a></li><li class="breadcrumb-item"><a href="./seance4.html"><span class="chapter-title">Séance 4: TD1 - Modèles de Classification de Base</span></a></li></ol></nav>
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span class="chapter-title">Séance 4: TD1 - Modèles de Classification de Base</span></h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Informations de la séance
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>Type</strong>: Travaux Dirigés</li>
<li><strong>Durée</strong>: 2h</li>
<li><strong>Objectifs</strong>: Obj4, Obj6</li>
</ul>
</div>
</div>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Ce TD vous permet d’approfondir votre compréhension théorique et pratique des principaux algorithmes de classification. Vous allez travailler sur des exercices conceptuels et des problèmes appliqués.</p>
</section>
<section id="partie-1-arbres-de-décision" class="level2">
<h2 class="anchored" data-anchor-id="partie-1-arbres-de-décision">Partie 1: Arbres de Décision</h2>
<section id="exercice-1.1-construction-dun-arbre" class="level3">
<h3 class="anchored" data-anchor-id="exercice-1.1-construction-dun-arbre">Exercice 1.1: Construction d’un Arbre</h3>
<p>Considérez le dataset suivant pour prédire si un client va acheter un ordinateur:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Age</th>
<th>Revenu</th>
<th>Étudiant</th>
<th>Crédit</th>
<th>Achète</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Jeune</td>
<td>Élevé</td>
<td>Non</td>
<td>Excellent</td>
<td>Non</td>
</tr>
<tr class="even">
<td>Jeune</td>
<td>Élevé</td>
<td>Non</td>
<td>Excellent</td>
<td>Non</td>
</tr>
<tr class="odd">
<td>Moyen</td>
<td>Élevé</td>
<td>Non</td>
<td>Excellent</td>
<td>Oui</td>
</tr>
<tr class="even">
<td>Senior</td>
<td>Moyen</td>
<td>Non</td>
<td>Excellent</td>
<td>Oui</td>
</tr>
<tr class="odd">
<td>Senior</td>
<td>Faible</td>
<td>Oui</td>
<td>Excellent</td>
<td>Oui</td>
</tr>
<tr class="even">
<td>Senior</td>
<td>Faible</td>
<td>Oui</td>
<td>Bon</td>
<td>Non</td>
</tr>
<tr class="odd">
<td>Moyen</td>
<td>Faible</td>
<td>Oui</td>
<td>Bon</td>
<td>Oui</td>
</tr>
<tr class="even">
<td>Jeune</td>
<td>Moyen</td>
<td>Non</td>
<td>Excellent</td>
<td>Non</td>
</tr>
<tr class="odd">
<td>Jeune</td>
<td>Faible</td>
<td>Oui</td>
<td>Excellent</td>
<td>Oui</td>
</tr>
<tr class="even">
<td>Senior</td>
<td>Moyen</td>
<td>Oui</td>
<td>Excellent</td>
<td>Oui</td>
</tr>
<tr class="odd">
<td>Jeune</td>
<td>Moyen</td>
<td>Oui</td>
<td>Bon</td>
<td>Oui</td>
</tr>
<tr class="even">
<td>Moyen</td>
<td>Moyen</td>
<td>Non</td>
<td>Bon</td>
<td>Oui</td>
</tr>
<tr class="odd">
<td>Moyen</td>
<td>Élevé</td>
<td>Oui</td>
<td>Excellent</td>
<td>Oui</td>
</tr>
<tr class="even">
<td>Senior</td>
<td>Moyen</td>
<td>Non</td>
<td>Bon</td>
<td>Non</td>
</tr>
</tbody>
</table>
<p><strong>Questions:</strong></p>
<ol type="1">
<li>Calculez l’entropie initiale du dataset</li>
<li>Calculez le gain d’information pour chaque attribut (Age, Revenu, Étudiant, Crédit)</li>
<li>Quel attribut sera choisi comme racine de l’arbre ?</li>
<li>Dessinez l’arbre de décision complet</li>
</ol>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Rappels - Formules et Algorithme
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>Entropie:</strong> <span class="math display">\[H(S) = -\sum_{i=1}^{c} p_i \log_2(p_i)\]</span></p>
<p><strong>Gain d’Information:</strong> <span class="math display">\[IG(S, A) = H(S) - \sum_{v \in Values(A)} \frac{|S_v|}{|S|} H(S_v)\]</span></p>
<p>où:</p>
<ul>
<li><span class="math inline">\(S\)</span> = ensemble de données</li>
<li><span class="math inline">\(A\)</span> = attribut</li>
<li><span class="math inline">\(c\)</span> = nombre de classes</li>
<li><span class="math inline">\(p_i\)</span> = proportion de la classe <span class="math inline">\(i\)</span></li>
<li><span class="math inline">\(S_v\)</span> = sous-ensemble où <span class="math inline">\(A = v\)</span></li>
</ul>
<p><strong>Algorithme ID3 (construction de l’arbre) :</strong></p>
<ol type="1">
<li>Si tous les exemples appartiennent à la même classe → créer une <strong>feuille</strong> avec cette classe</li>
<li>Si plus aucun attribut à tester → créer une <strong>feuille</strong> avec la classe majoritaire</li>
<li>Sinon :
<ul>
<li>Calculer <span class="math inline">\(IG(S, A)\)</span> pour chaque attribut <span class="math inline">\(A\)</span></li>
<li>Choisir l’attribut <span class="math inline">\(A^*\)</span> avec le <strong>gain d’information maximal</strong></li>
<li>Créer un <strong>nœud</strong> de décision sur <span class="math inline">\(A^*\)</span></li>
<li>Pour chaque valeur <span class="math inline">\(v\)</span> de <span class="math inline">\(A^*\)</span> :
<ul>
<li>Créer une branche pour <span class="math inline">\(S_v = \{x \in S \mid A^*(x) = v\}\)</span></li>
<li><strong>Appliquer récursivement</strong> l’algorithme sur <span class="math inline">\(S_v\)</span> sans l’attribut <span class="math inline">\(A^*\)</span></li>
</ul></li>
</ul></li>
</ol>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Solution Exercice 1.1
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div id="cc2bbc65" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Données</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> [</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'Jeune'</span>, <span class="st">'Élevé'</span>, <span class="st">'Non'</span>, <span class="st">'Excellent'</span>, <span class="st">'Non'</span>),</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'Jeune'</span>, <span class="st">'Élevé'</span>, <span class="st">'Non'</span>, <span class="st">'Excellent'</span>, <span class="st">'Non'</span>),</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'Moyen'</span>, <span class="st">'Élevé'</span>, <span class="st">'Non'</span>, <span class="st">'Excellent'</span>, <span class="st">'Oui'</span>),</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'Senior'</span>, <span class="st">'Moyen'</span>, <span class="st">'Non'</span>, <span class="st">'Excellent'</span>, <span class="st">'Oui'</span>),</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'Senior'</span>, <span class="st">'Faible'</span>, <span class="st">'Oui'</span>, <span class="st">'Excellent'</span>, <span class="st">'Oui'</span>),</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'Senior'</span>, <span class="st">'Faible'</span>, <span class="st">'Oui'</span>, <span class="st">'Bon'</span>, <span class="st">'Non'</span>),</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'Moyen'</span>, <span class="st">'Faible'</span>, <span class="st">'Oui'</span>, <span class="st">'Bon'</span>, <span class="st">'Oui'</span>),</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'Jeune'</span>, <span class="st">'Moyen'</span>, <span class="st">'Non'</span>, <span class="st">'Excellent'</span>, <span class="st">'Non'</span>),</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'Jeune'</span>, <span class="st">'Faible'</span>, <span class="st">'Oui'</span>, <span class="st">'Excellent'</span>, <span class="st">'Oui'</span>),</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'Senior'</span>, <span class="st">'Moyen'</span>, <span class="st">'Oui'</span>, <span class="st">'Excellent'</span>, <span class="st">'Oui'</span>),</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'Jeune'</span>, <span class="st">'Moyen'</span>, <span class="st">'Oui'</span>, <span class="st">'Bon'</span>, <span class="st">'Oui'</span>),</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'Moyen'</span>, <span class="st">'Moyen'</span>, <span class="st">'Non'</span>, <span class="st">'Bon'</span>, <span class="st">'Oui'</span>),</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'Moyen'</span>, <span class="st">'Élevé'</span>, <span class="st">'Oui'</span>, <span class="st">'Excellent'</span>, <span class="st">'Oui'</span>),</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'Senior'</span>, <span class="st">'Moyen'</span>, <span class="st">'Non'</span>, <span class="st">'Bon'</span>, <span class="st">'Non'</span>)</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> entropy(labels):</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Calcule l'entropie"""</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>    counter <span class="op">=</span> Counter(labels)</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>    total <span class="op">=</span> <span class="bu">len</span>(labels)</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>    ent <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> count <span class="kw">in</span> counter.values():</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>        p <span class="op">=</span> count <span class="op">/</span> total</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> p <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>            ent <span class="op">-=</span> p <span class="op">*</span> np.log2(p)</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> ent</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> information_gain(data, attr_idx):</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Calcule le gain d'information"""</span></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Entropie initiale</span></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>    labels <span class="op">=</span> [row[<span class="op">-</span><span class="dv">1</span>] <span class="cf">for</span> row <span class="kw">in</span> data]</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>    h_s <span class="op">=</span> entropy(labels)</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Partition par attribut</span></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>    partitions <span class="op">=</span> {}</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> row <span class="kw">in</span> data:</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>        attr_value <span class="op">=</span> row[attr_idx]</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> attr_value <span class="kw">not</span> <span class="kw">in</span> partitions:</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>            partitions[attr_value] <span class="op">=</span> []</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>        partitions[attr_value].append(row[<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Entropie pondérée</span></span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a>    h_s_a <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>    total <span class="op">=</span> <span class="bu">len</span>(data)</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> partition_labels <span class="kw">in</span> partitions.values():</span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>        p <span class="op">=</span> <span class="bu">len</span>(partition_labels) <span class="op">/</span> total</span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>        h_s_a <span class="op">+=</span> p <span class="op">*</span> entropy(partition_labels)</span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> h_s <span class="op">-</span> h_s_a</span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Entropie initiale</span></span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> [row[<span class="op">-</span><span class="dv">1</span>] <span class="cf">for</span> row <span class="kw">in</span> data]</span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"1. Entropie initiale: </span><span class="sc">{</span>entropy(labels)<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Gain d'information pour chaque attribut</span></span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a>attributes <span class="op">=</span> [<span class="st">'Age'</span>, <span class="st">'Revenu'</span>, <span class="st">'Étudiant'</span>, <span class="st">'Crédit'</span>]</span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">2. Gain d'information:"</span>)</span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a>gains <span class="op">=</span> {}</span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx, attr <span class="kw">in</span> <span class="bu">enumerate</span>(attributes):</span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a>    ig <span class="op">=</span> information_gain(data, idx)</span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a>    gains[attr] <span class="op">=</span> ig</span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   </span><span class="sc">{</span>attr<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>ig<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Meilleur attribut</span></span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a>best_attr <span class="op">=</span> <span class="bu">max</span>(gains, key<span class="op">=</span>gains.get)</span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">3. Attribut racine: </span><span class="sc">{</span>best_attr<span class="sc">}</span><span class="ss"> (IG = </span><span class="sc">{</span>gains[best_attr]<span class="sc">:.4f}</span><span class="ss">)"</span>)</span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. L'arbre complet nécessiterait une implémentation récursive</span></span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">4. Arbre de décision (structure simplifiée):"</span>)</span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"""</span></span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a><span class="st">         Age?</span></span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a><span class="st">        /    |    </span><span class="ch">\\</span></span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a><span class="st">    Jeune  Moyen  Senior</span></span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a><span class="st">      |      |      |</span></span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a><span class="st">    [Classes selon données]</span></span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<p><strong>Réponses:</strong></p>
<ol type="1">
<li>Entropie initiale <span class="math inline">\(\approx\)</span> 0.940</li>
<li>Gains d’information:
<ul>
<li>Age: ~0.246</li>
<li>Revenu: ~0.029</li>
<li>Étudiant: ~0.151</li>
<li>Crédit: ~0.048</li>
</ul></li>
<li><strong>Age</strong> sera choisi comme racine (gain le plus élevé)</li>
</ol>
</div>
</div>
</div>
</section>
<section id="exercice-1.2-overfitting-dans-les-arbres" class="level3">
<h3 class="anchored" data-anchor-id="exercice-1.2-overfitting-dans-les-arbres">Exercice 1.2: Overfitting dans les Arbres</h3>
<p><strong>Question:</strong> Expliquez pourquoi un arbre de décision sans contraintes (profondeur illimitée) tend à faire de l’overfitting.</p>
<p><strong>Proposez 3 méthodes pour limiter l’overfitting dans les arbres de décision.</strong></p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Solution Exercice 1.2
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>Pourquoi l’overfitting ?</strong></p>
<p>Un arbre sans contraintes va créer des branches jusqu’à ce que chaque feuille soit “pure” (contient une seule classe). Cela signifie: - L’arbre mémorise les données d’entraînement, y compris le bruit - Il crée des règles très spécifiques qui ne généralisent pas - La complexité du modèle est trop élevée par rapport aux données</p>
<p><strong>3 méthodes pour limiter l’overfitting:</strong></p>
<ol type="1">
<li><strong>Pré-élagage (Pre-pruning)</strong>:
<ul>
<li><code>max_depth</code>: Limiter la profondeur maximale</li>
<li><code>min_samples_split</code>: Nombre minimum d’échantillons pour diviser un nœud</li>
<li><code>min_samples_leaf</code>: Nombre minimum d’échantillons dans une feuille</li>
<li><code>max_leaf_nodes</code>: Nombre maximum de feuilles</li>
</ul></li>
<li><strong>Post-élagage (Post-pruning)</strong>:
<ul>
<li>Construire l’arbre complet</li>
<li>Élaguer les branches qui n’apportent pas assez d’amélioration</li>
<li>Utiliser un ensemble de validation pour guider l’élagage</li>
</ul></li>
<li><strong>Ensemble Methods</strong>:
<ul>
<li>Random Forest: moyenne de plusieurs arbres</li>
<li>Gradient Boosting: construction itérative d’arbres</li>
<li>Bagging: bootstrap + agrégation</li>
</ul></li>
</ol>
<div id="23e1f71d" class="cell" data-execution_count="2">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Exemple pratique</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Arbre avec overfitting</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>tree_overfit <span class="op">=</span> DecisionTreeClassifier()  <span class="co"># Pas de contraintes</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Arbre régularisé</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>tree_regularized <span class="op">=</span> DecisionTreeClassifier(</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>    max_depth<span class="op">=</span><span class="dv">5</span>,              <span class="co"># Profondeur max</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>    min_samples_split<span class="op">=</span><span class="dv">10</span>,     <span class="co"># Min échantillons pour split</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>    min_samples_leaf<span class="op">=</span><span class="dv">5</span>,       <span class="co"># Min échantillons par feuille</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>    max_leaf_nodes<span class="op">=</span><span class="dv">20</span>         <span class="co"># Max feuilles</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</div>
</div>
</section>
</section>
<section id="partie-2-régression-logistique" class="level2">
<h2 class="anchored" data-anchor-id="partie-2-régression-logistique">Partie 2: Régression Logistique</h2>
<section id="exercice-2.1-intuition-probabiliste" class="level3">
<h3 class="anchored" data-anchor-id="exercice-2.1-intuition-probabiliste">Exercice 2.1: Intuition Probabiliste</h3>
<p>Considérez le modèle de régression logistique suivant pour prédire l’admission à l’université:</p>
<p><span class="math display">\[P(admission=1|score) = \frac{1}{1 + e^{-(0.05 \times score - 3)}}\]</span></p>
<p><strong>Questions:</strong></p>
<ol type="1">
<li>Quelle est la probabilité d’admission pour un score de 60?</li>
<li>Quelle est la probabilité d’admission pour un score de 80?</li>
<li>Quel score donne une probabilité d’admission de 50%?</li>
<li>Interprétez le coefficient 0.05</li>
</ol>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Solution Exercice 2.1
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div id="1e0e9dcb" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sigmoid(z):</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Fonction sigmoïde"""</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">1</span> <span class="op">/</span> (<span class="dv">1</span> <span class="op">+</span> np.exp(<span class="op">-</span>z))</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> prob_admission(score):</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Probabilité d'admission"""</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    z <span class="op">=</span> <span class="fl">0.05</span> <span class="op">*</span> score <span class="op">-</span> <span class="dv">3</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> sigmoid(z)</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Probabilité pour score = 60</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>p_60 <span class="op">=</span> prob_admission(<span class="dv">60</span>)</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"1. P(admission|score=60) = </span><span class="sc">{</span>p_60<span class="sc">:.4f}</span><span class="ss"> = </span><span class="sc">{</span>p_60<span class="op">*</span><span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">%"</span>)</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Probabilité pour score = 80</span></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>p_80 <span class="op">=</span> prob_admission(<span class="dv">80</span>)</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"2. P(admission|score=80) = </span><span class="sc">{</span>p_80<span class="sc">:.4f}</span><span class="ss"> = </span><span class="sc">{</span>p_80<span class="op">*</span><span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">%"</span>)</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Score pour P = 0.5</span></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a><span class="co"># 0.5 = 1/(1 + e^(-(0.05*score - 3)))</span></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a><span class="co"># =&gt; 0.05*score - 3 = 0</span></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a><span class="co"># =&gt; score = 60</span></span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>score_50 <span class="op">=</span> <span class="dv">3</span> <span class="op">/</span> <span class="fl">0.05</span></span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"3. Score pour P=50%: </span><span class="sc">{</span>score_50<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Interprétation du coefficient</span></span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">4. Coefficient 0.05:"</span>)</span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   - Augmenter le score de 1 point augmente z de 0.05"</span>)</span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   - Cela augmente les log-odds de 0.05"</span>)</span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   - Odds ratio = e^0.05 = </span><span class="sc">{</span>np<span class="sc">.</span>exp(<span class="fl">0.05</span>)<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualisation</span></span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a>scores <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">100</span>, <span class="dv">1000</span>)</span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>probs <span class="op">=</span> [prob_admission(s) <span class="cf">for</span> s <span class="kw">in</span> scores]</span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a>plt.plot(scores, probs, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a>plt.axhline(y<span class="op">=</span><span class="fl">0.5</span>, color<span class="op">=</span><span class="st">'r'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, label<span class="op">=</span><span class="st">'P = 0.5'</span>)</span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a>plt.axvline(x<span class="op">=</span><span class="dv">60</span>, color<span class="op">=</span><span class="st">'r'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, label<span class="op">=</span><span class="st">'Score = 60'</span>)</span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a>plt.scatter([<span class="dv">60</span>, <span class="dv">80</span>], [p_60, p_80], color<span class="op">=</span><span class="st">'red'</span>, s<span class="op">=</span><span class="dv">100</span>, zorder<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Score'</span>)</span>
<span id="cb3-44"><a href="#cb3-44" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Probabilité d</span><span class="ch">\'</span><span class="st">admission'</span>)</span>
<span id="cb3-45"><a href="#cb3-45" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Régression Logistique - Admission à l</span><span class="ch">\'</span><span class="st">université'</span>)</span>
<span id="cb3-46"><a href="#cb3-46" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb3-47"><a href="#cb3-47" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb3-48"><a href="#cb3-48" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb3-49"><a href="#cb3-49" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<p><strong>Réponses:</strong></p>
<ol type="1">
<li>P(admission|score=60) = 0.50 = 50%</li>
<li>P(admission|score=80) = 0.73 = 73%</li>
<li>Score pour P=50%: <strong>60</strong></li>
<li>Le coefficient 0.05 indique qu’augmenter le score de 1 point multiplie les odds d’admission par e^0.05 <span class="math inline">\(\approx\)</span> 1.051 (5.1% d’augmentation)</li>
</ol>
</div>
</div>
</div>
</section>
<section id="exercice-2.2-régression-logistique-multiclasse" class="level3">
<h3 class="anchored" data-anchor-id="exercice-2.2-régression-logistique-multiclasse">Exercice 2.2: Régression Logistique Multiclasse</h3>
<p>Expliquez comment adapter la régression logistique pour un problème multiclasse (ex: 3 classes). Quelles sont les deux approches principales?</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Solution Exercice 2.2
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>Deux approches pour la classification multiclasse:</strong></p>
<section id="one-vs-rest-ovr-ou-one-vs-all-ova" class="level3">
<h3 class="anchored" data-anchor-id="one-vs-rest-ovr-ou-one-vs-all-ova">1. One-vs-Rest (OvR) ou One-vs-All (OvA)</h3>
<p><strong>Principe:</strong></p>
<ul>
<li>Entraîner K modèles binaires (K = nombre de classes)</li>
<li>Chaque modèle sépare une classe vs toutes les autres</li>
<li>Prédiction: choisir la classe avec la probabilité la plus élevée</li>
</ul>
<p><strong>Exemple avec 3 classes:</strong></p>
<ul>
<li>Modèle 1: Classe A vs (B, C)</li>
<li>Modèle 2: Classe B vs (A, C)</li>
<li>Modèle 3: Classe C vs (A, B)</li>
</ul>
<div id="7b5aee77" class="cell" data-execution_count="4">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="co"># One-vs-Rest (par défaut dans scikit-learn)</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>ovr_model <span class="op">=</span> LogisticRegression(multi_class<span class="op">=</span><span class="st">'ovr'</span>)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>ovr_model.fit(X_train, y_train)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="softmax-ou-multinomial" class="level3">
<h3 class="anchored" data-anchor-id="softmax-ou-multinomial">2. Softmax (ou Multinomial)</h3>
<p><strong>Principe:</strong></p>
<ul>
<li>Un seul modèle qui produit K probabilités (une par classe)</li>
<li>Utilise la fonction softmax au lieu de sigmoid</li>
<li>Les probabilités somment à 1</li>
</ul>
<p><strong>Fonction Softmax:</strong> <span class="math display">\[P(y=k|X) = \frac{e^{z_k}}{\sum_{j=1}^{K} e^{z_j}}\]</span></p>
<p>où <span class="math inline">\(z_k = w_k^T X + b_k\)</span></p>
<div id="60fb30d1" class="cell" data-execution_count="5">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Softmax / Multinomial</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>softmax_model <span class="op">=</span> LogisticRegression(multi_class<span class="op">=</span><span class="st">'multinomial'</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>softmax_model.fit(X_train, y_train)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p><strong>Comparaison:</strong></p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Critère</th>
<th>One-vs-Rest</th>
<th>Softmax</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Nombre de modèles</td>
<td>K modèles</td>
<td>1 modèle</td>
</tr>
<tr class="even">
<td>Probabilités</td>
<td>Peuvent dépasser 1 (total)</td>
<td>Somment à 1</td>
</tr>
<tr class="odd">
<td>Entraînement</td>
<td>Plus rapide</td>
<td>Plus lent</td>
</tr>
<tr class="even">
<td>Performance</td>
<td>Généralement similaire</td>
<td>Légèrement meilleur</td>
</tr>
<tr class="odd">
<td>Calibration</td>
<td>Moins bonne</td>
<td>Meilleure</td>
</tr>
</tbody>
</table>
</section>
</div>
</div>
</div>
</section>
</section>
<section id="partie-3-k-nearest-neighbors" class="level2">
<h2 class="anchored" data-anchor-id="partie-3-k-nearest-neighbors">Partie 3: k-Nearest Neighbors</h2>
<section id="exercice-3.1-distance-et-voisinage" class="level3">
<h3 class="anchored" data-anchor-id="exercice-3.1-distance-et-voisinage">Exercice 3.1: Distance et Voisinage</h3>
<p>Considérez les points suivants dans un espace 2D:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Point</th>
<th>x1</th>
<th>x2</th>
<th>Classe</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>A</td>
<td>2</td>
<td>3</td>
<td>Rouge</td>
</tr>
<tr class="even">
<td>B</td>
<td>3</td>
<td>4</td>
<td>Rouge</td>
</tr>
<tr class="odd">
<td>C</td>
<td>5</td>
<td>6</td>
<td>Bleu</td>
</tr>
<tr class="even">
<td>D</td>
<td>5</td>
<td>4</td>
<td>Bleu</td>
</tr>
<tr class="odd">
<td>E</td>
<td>7</td>
<td>8</td>
<td>Bleu</td>
</tr>
</tbody>
</table>
<p>Nouveau point: <strong>P (4, 5)</strong></p>
<p><strong>Questions:</strong></p>
<ol type="1">
<li>Calculez la distance euclidienne entre P et chaque point</li>
<li>Avec k=3, quelle classe sera prédite pour P?</li>
<li>Que se passerait-il avec k=5?</li>
<li>Pourquoi est-il important de normaliser les données avant d’utiliser k-NN?</li>
</ol>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-7-contents" aria-controls="callout-7" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Solution Exercice 3.1
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-7" class="callout-7-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div id="f96f4070" class="cell" data-execution_count="6">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Points</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>points <span class="op">=</span> {</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'A'</span>: ([<span class="dv">2</span>, <span class="dv">3</span>], <span class="st">'Rouge'</span>),</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">'B'</span>: ([<span class="dv">3</span>, <span class="dv">4</span>], <span class="st">'Rouge'</span>),</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">'C'</span>: ([<span class="dv">5</span>, <span class="dv">6</span>], <span class="st">'Bleu'</span>),</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">'D'</span>: ([<span class="dv">5</span>, <span class="dv">4</span>], <span class="st">'Bleu'</span>),</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">'E'</span>: ([<span class="dv">7</span>, <span class="dv">8</span>], <span class="st">'Bleu'</span>)</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Nouveau point</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>P <span class="op">=</span> np.array([<span class="dv">4</span>, <span class="dv">5</span>])</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Distances euclidiennes</span></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"1. Distances euclidiennes:"</span>)</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>distances <span class="op">=</span> {}</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> name, (coords, classe) <span class="kw">in</span> points.items():</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>    dist <span class="op">=</span> np.sqrt(np.<span class="bu">sum</span>((np.array(coords) <span class="op">-</span> P)<span class="op">**</span><span class="dv">2</span>))</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>    distances[name] <span class="op">=</span> (dist, classe)</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   P → </span><span class="sc">{</span>name<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>dist<span class="sc">:.4f}</span><span class="ss"> (classe: </span><span class="sc">{</span>classe<span class="sc">}</span><span class="ss">)"</span>)</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. k=3</span></span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">2. k=3:"</span>)</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>sorted_distances <span class="op">=</span> <span class="bu">sorted</span>(distances.items(), key<span class="op">=</span><span class="kw">lambda</span> x: x[<span class="dv">1</span>][<span class="dv">0</span>])</span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>k3_neighbors <span class="op">=</span> sorted_distances[:<span class="dv">3</span>]</span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>k3_classes <span class="op">=</span> [classe <span class="cf">for</span> _, (_, classe) <span class="kw">in</span> k3_neighbors]</span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a>k3_prediction <span class="op">=</span> Counter(k3_classes).most_common(<span class="dv">1</span>)[<span class="dv">0</span>][<span class="dv">0</span>]</span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   3 voisins les plus proches: </span><span class="sc">{</span>[n[<span class="dv">0</span>] <span class="cf">for</span> n <span class="kw">in</span> k3_neighbors]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   Classes: </span><span class="sc">{</span>k3_classes<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   Prédiction: </span><span class="sc">{</span>k3_prediction<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. k=5</span></span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">3. k=5:"</span>)</span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a>k5_neighbors <span class="op">=</span> sorted_distances[:<span class="dv">5</span>]</span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a>k5_classes <span class="op">=</span> [classe <span class="cf">for</span> _, (_, classe) <span class="kw">in</span> k5_neighbors]</span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a>k5_prediction <span class="op">=</span> Counter(k5_classes).most_common(<span class="dv">1</span>)[<span class="dv">0</span>][<span class="dv">0</span>]</span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   5 voisins les plus proches: </span><span class="sc">{</span>[n[<span class="dv">0</span>] <span class="cf">for</span> n <span class="kw">in</span> k5_neighbors]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   Classes: </span><span class="sc">{</span>k5_classes<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-41"><a href="#cb6-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   Prédiction: </span><span class="sc">{</span>k5_prediction<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-42"><a href="#cb6-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-43"><a href="#cb6-43" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Importance de la normalisation</span></span>
<span id="cb6-44"><a href="#cb6-44" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">4. Importance de la normalisation:"</span>)</span>
<span id="cb6-45"><a href="#cb6-45" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   Sans normalisation, une feature avec une grande échelle"</span>)</span>
<span id="cb6-46"><a href="#cb6-46" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   dominera le calcul de distance."</span>)</span>
<span id="cb6-47"><a href="#cb6-47" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">   Exemple:"</span>)</span>
<span id="cb6-48"><a href="#cb6-48" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   - Feature 1 (âge): 20-80 → échelle ~60"</span>)</span>
<span id="cb6-49"><a href="#cb6-49" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   - Feature 2 (revenu): 20000-100000 → échelle ~80000"</span>)</span>
<span id="cb6-50"><a href="#cb6-50" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   → La distance sera dominée par le revenu!"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<p><strong>Réponses:</strong></p>
<ol type="1">
<li>Distances:
<ul>
<li>P → A: 2.828</li>
<li>P → B: 1.414 (plus proche)</li>
<li>P → C: 1.414 (plus proche)</li>
<li>P → D: 1.414 (plus proche)</li>
<li>P → E: 4.243</li>
</ul></li>
<li>Avec k=3: Les 3 voisins sont B (Rouge), C (Bleu), D (Bleu)
<ul>
<li>Vote: 1 Rouge, 2 Bleus</li>
<li><strong>Prédiction: Bleu</strong></li>
</ul></li>
<li>Avec k=5: Tous les points
<ul>
<li>Vote: 2 Rouges, 3 Bleus</li>
<li><strong>Prédiction: Bleu</strong> (même résultat)</li>
</ul></li>
<li><strong>Normalisation importante</strong> car:
<ul>
<li>Les features avec de grandes valeurs dominent le calcul de distance</li>
<li>Exemple: Si une feature est en milliers et l’autre en dizaines, la première écrasera la seconde</li>
<li>Solution: StandardScaler ou MinMaxScaler</li>
</ul></li>
</ol>
</div>
</div>
</div>
</section>
</section>
<section id="partie-4-naive-bayes" class="level2">
<h2 class="anchored" data-anchor-id="partie-4-naive-bayes">Partie 4: Naive Bayes</h2>
<section id="exercice-4.1-application-du-théorème-de-bayes" class="level3">
<h3 class="anchored" data-anchor-id="exercice-4.1-application-du-théorème-de-bayes">Exercice 4.1: Application du Théorème de Bayes</h3>
<p>Dataset pour classification de courriels:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Courriel</th>
<th>“gratuit”</th>
<th>“argent”</th>
<th>“viagra”</th>
<th>Classe</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>Oui</td>
<td>Non</td>
<td>Non</td>
<td>Spam</td>
</tr>
<tr class="even">
<td>2</td>
<td>Oui</td>
<td>Oui</td>
<td>Oui</td>
<td>Spam</td>
</tr>
<tr class="odd">
<td>3</td>
<td>Non</td>
<td>Non</td>
<td>Non</td>
<td>Ham</td>
</tr>
<tr class="even">
<td>4</td>
<td>Non</td>
<td>Non</td>
<td>Non</td>
<td>Ham</td>
</tr>
<tr class="odd">
<td>5</td>
<td>Oui</td>
<td>Oui</td>
<td>Non</td>
<td>Spam</td>
</tr>
</tbody>
</table>
<p>Nouveau courriel contient: <strong>“gratuit”</strong> et <strong>“argent”</strong></p>
<p><strong>Calculez P(Spam | gratuit, argent) et P(Ham | gratuit, argent)</strong></p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-8-contents" aria-controls="callout-8" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Solution Exercice 4.1
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-8" class="callout-8-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div id="26d8826e" class="cell" data-execution_count="7">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Données</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>emails <span class="op">=</span> [</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>    {<span class="st">'gratuit'</span>: <span class="dv">1</span>, <span class="st">'argent'</span>: <span class="dv">0</span>, <span class="st">'viagra'</span>: <span class="dv">0</span>, <span class="st">'classe'</span>: <span class="st">'Spam'</span>},</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    {<span class="st">'gratuit'</span>: <span class="dv">1</span>, <span class="st">'argent'</span>: <span class="dv">1</span>, <span class="st">'viagra'</span>: <span class="dv">1</span>, <span class="st">'classe'</span>: <span class="st">'Spam'</span>},</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    {<span class="st">'gratuit'</span>: <span class="dv">0</span>, <span class="st">'argent'</span>: <span class="dv">0</span>, <span class="st">'viagra'</span>: <span class="dv">0</span>, <span class="st">'classe'</span>: <span class="st">'Ham'</span>},</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    {<span class="st">'gratuit'</span>: <span class="dv">0</span>, <span class="st">'argent'</span>: <span class="dv">0</span>, <span class="st">'viagra'</span>: <span class="dv">0</span>, <span class="st">'classe'</span>: <span class="st">'Ham'</span>},</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    {<span class="st">'gratuit'</span>: <span class="dv">1</span>, <span class="st">'argent'</span>: <span class="dv">1</span>, <span class="st">'viagra'</span>: <span class="dv">0</span>, <span class="st">'classe'</span>: <span class="st">'Spam'</span>},</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Probabilités a priori</span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>n_spam <span class="op">=</span> <span class="bu">sum</span>(<span class="dv">1</span> <span class="cf">for</span> e <span class="kw">in</span> emails <span class="cf">if</span> e[<span class="st">'classe'</span>] <span class="op">==</span> <span class="st">'Spam'</span>)</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>n_ham <span class="op">=</span> <span class="bu">sum</span>(<span class="dv">1</span> <span class="cf">for</span> e <span class="kw">in</span> emails <span class="cf">if</span> e[<span class="st">'classe'</span>] <span class="op">==</span> <span class="st">'Ham'</span>)</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>total <span class="op">=</span> <span class="bu">len</span>(emails)</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>p_spam <span class="op">=</span> n_spam <span class="op">/</span> total</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>p_ham <span class="op">=</span> n_ham <span class="op">/</span> total</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Probabilités a priori:"</span>)</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"P(Spam) = </span><span class="sc">{</span>n_spam<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>total<span class="sc">}</span><span class="ss"> = </span><span class="sc">{</span>p_spam<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"P(Ham) = </span><span class="sc">{</span>n_ham<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>total<span class="sc">}</span><span class="ss"> = </span><span class="sc">{</span>p_ham<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Probabilités conditionnelles pour Spam</span></span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>spam_emails <span class="op">=</span> [e <span class="cf">for</span> e <span class="kw">in</span> emails <span class="cf">if</span> e[<span class="st">'classe'</span>] <span class="op">==</span> <span class="st">'Spam'</span>]</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>p_gratuit_spam <span class="op">=</span> <span class="bu">sum</span>(e[<span class="st">'gratuit'</span>] <span class="cf">for</span> e <span class="kw">in</span> spam_emails) <span class="op">/</span> n_spam</span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>p_argent_spam <span class="op">=</span> <span class="bu">sum</span>(e[<span class="st">'argent'</span>] <span class="cf">for</span> e <span class="kw">in</span> spam_emails) <span class="op">/</span> n_spam</span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">P(gratuit|Spam) = </span><span class="sc">{</span>p_gratuit_spam<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"P(argent|Spam) = </span><span class="sc">{</span>p_argent_spam<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Probabilités conditionnelles pour Ham</span></span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a>ham_emails <span class="op">=</span> [e <span class="cf">for</span> e <span class="kw">in</span> emails <span class="cf">if</span> e[<span class="st">'classe'</span>] <span class="op">==</span> <span class="st">'Ham'</span>]</span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a>p_gratuit_ham <span class="op">=</span> <span class="bu">sum</span>(e[<span class="st">'gratuit'</span>] <span class="cf">for</span> e <span class="kw">in</span> ham_emails) <span class="op">/</span> n_ham</span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a>p_argent_ham <span class="op">=</span> <span class="bu">sum</span>(e[<span class="st">'argent'</span>] <span class="cf">for</span> e <span class="kw">in</span> ham_emails) <span class="op">/</span> n_ham</span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">P(gratuit|Ham) = </span><span class="sc">{</span>p_gratuit_ham<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"P(argent|Ham) = </span><span class="sc">{</span>p_argent_ham<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Calcul Naive Bayes (hypothèse d'indépendance)</span></span>
<span id="cb7-39"><a href="#cb7-39" aria-hidden="true" tabindex="-1"></a><span class="co"># P(Spam | gratuit, argent) $\propto$ P(gratuit|Spam) * P(argent|Spam) * P(Spam)</span></span>
<span id="cb7-40"><a href="#cb7-40" aria-hidden="true" tabindex="-1"></a>numerator_spam <span class="op">=</span> p_gratuit_spam <span class="op">*</span> p_argent_spam <span class="op">*</span> p_spam</span>
<span id="cb7-41"><a href="#cb7-41" aria-hidden="true" tabindex="-1"></a>numerator_ham <span class="op">=</span> p_gratuit_ham <span class="op">*</span> p_argent_ham <span class="op">*</span> p_ham</span>
<span id="cb7-42"><a href="#cb7-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-43"><a href="#cb7-43" aria-hidden="true" tabindex="-1"></a><span class="co"># Normalisation</span></span>
<span id="cb7-44"><a href="#cb7-44" aria-hidden="true" tabindex="-1"></a>p_spam_given_words <span class="op">=</span> numerator_spam <span class="op">/</span> (numerator_spam <span class="op">+</span> numerator_ham)</span>
<span id="cb7-45"><a href="#cb7-45" aria-hidden="true" tabindex="-1"></a>p_ham_given_words <span class="op">=</span> numerator_ham <span class="op">/</span> (numerator_spam <span class="op">+</span> numerator_ham)</span>
<span id="cb7-46"><a href="#cb7-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-47"><a href="#cb7-47" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Résultats:"</span>)</span>
<span id="cb7-48"><a href="#cb7-48" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"P(Spam | gratuit, argent) = </span><span class="sc">{</span>p_spam_given_words<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb7-49"><a href="#cb7-49" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"P(Ham | gratuit, argent) = </span><span class="sc">{</span>p_ham_given_words<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb7-50"><a href="#cb7-50" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Prédiction: </span><span class="sc">{</span><span class="st">'Spam'</span> <span class="cf">if</span> p_spam_given_words <span class="op">&gt;</span> p_ham_given_words <span class="cf">else</span> <span class="st">'Ham'</span><span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<p><strong>Résolution manuelle:</strong></p>
<p><strong>Étape 1: Probabilités a priori</strong></p>
<ul>
<li>P(Spam) = 3/5 = 0.6</li>
<li>P(Ham) = 2/5 = 0.4</li>
</ul>
<p><strong>Étape 2: Probabilités conditionnelles</strong></p>
<p>Pour Spam:</p>
<ul>
<li>P(gratuit|Spam) = 3/3 = 1.0</li>
<li>P(argent|Spam) = 2/3 <span class="math inline">\(\approx\)</span> 0.67</li>
</ul>
<p>Pour Ham:</p>
<ul>
<li>P(gratuit|Ham) = 0/2 = 0</li>
<li>P(argent|Ham) = 0/2 = 0</li>
</ul>
<p><strong>Étape 3: Application de Bayes</strong></p>
<p>P(Spam | gratuit, argent) <span class="math inline">\(\propto\)</span> 1.0 × 0.67 × 0.6 = 0.4</p>
<p>P(Ham | gratuit, argent) <span class="math inline">\(\propto\)</span> 0 × 0 × 0.4 = 0</p>
<p><strong>Prédiction: Spam</strong> (avec 100% de confiance)</p>
</div>
</div>
</div>
</section>
</section>
<section id="partie-5-gradient-boosting-xgboostlightgbm" class="level2">
<h2 class="anchored" data-anchor-id="partie-5-gradient-boosting-xgboostlightgbm">Partie 5: Gradient Boosting (XGBoost/LightGBM)</h2>
<section id="exercice-5.1-comprendre-le-boosting" class="level3">
<h3 class="anchored" data-anchor-id="exercice-5.1-comprendre-le-boosting">Exercice 5.1: Comprendre le Boosting</h3>
<p><strong>Questions conceptuelles:</strong></p>
<ol type="1">
<li>Quelle est la différence fondamentale entre Random Forest (Bagging) et Gradient Boosting?</li>
<li>Pourquoi le Gradient Boosting est-il plus sensible à l’overfitting que Random Forest?</li>
<li>Quels sont les 3 hyperparamètres les plus importants à ajuster pour XGBoost/LightGBM?</li>
</ol>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-9-contents" aria-controls="callout-9" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Solution Exercice 5.1
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-9" class="callout-9-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>📎 <strong>Lien du Slide :</strong> <a href="https://nevermind78.github.io/AN_slides/GB_C.html#/title-slide">Gradient Boosting — Classification</a></p>
<p><strong>1. Différence Bagging vs Boosting:</strong></p>
<table class="caption-top table">
<colgroup>
<col style="width: 15%">
<col style="width: 47%">
<col style="width: 37%">
</colgroup>
<thead>
<tr class="header">
<th>Aspect</th>
<th>Random Forest (Bagging)</th>
<th>Gradient Boosting</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Construction</strong></td>
<td>Parallèle (arbres indépendants)</td>
<td>Séquentielle (arbres dépendants)</td>
</tr>
<tr class="even">
<td><strong>Objectif</strong></td>
<td>Réduire la variance</td>
<td>Réduire le biais</td>
</tr>
<tr class="odd">
<td><strong>Données</strong></td>
<td>Bootstrap (échantillonnage)</td>
<td>Totalité des données</td>
</tr>
<tr class="even">
<td><strong>Poids</strong></td>
<td>Tous arbres égaux</td>
<td>Arbres pondérés</td>
</tr>
<tr class="odd">
<td><strong>Prédiction</strong></td>
<td>Moyenne simple</td>
<td>Somme pondérée</td>
</tr>
<tr class="even">
<td><strong>Focus</strong></td>
<td>Erreurs aléatoires</td>
<td>Erreurs résiduelles</td>
</tr>
</tbody>
</table>
<p><strong>Diagramme :</strong></p>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">graph LR
    A[Random Forest] --&gt; B[Arbre 1]
    A --&gt; C[Arbre 2]
    A --&gt; D[Arbre N]
    B --&gt; E[Vote]
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p><strong>2. Sensibilité à l’overfitting:</strong></p>
<p>Gradient Boosting est plus sensible car: - Chaque arbre se concentre sur les erreurs précédentes - Risque d’apprendre le bruit si trop d’itérations - Peut “mémoriser” les cas difficiles du train set - Pas de randomisation par défaut (contrairement à RF)</p>
<p><strong>Solutions:</strong> - Limiter le nombre d’arbres (<code>n_estimators</code>) - Réduire le taux d’apprentissage (<code>learning_rate</code>) - Limiter la profondeur (<code>max_depth</code>) - Early stopping avec validation set</p>
<p><strong>3. Hyperparamètres clés:</strong></p>
<div id="d4c9fead" class="cell" data-execution_count="8">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> xgboost <span class="im">import</span> XGBClassifier</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> XGBClassifier(</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 1. Nombre d'arbres</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>    n_estimators<span class="op">=</span><span class="dv">100</span>,  <span class="co"># Plus = meilleur mais risque overfitting</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 2. Taux d'apprentissage</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>    learning_rate<span class="op">=</span><span class="fl">0.1</span>,  <span class="co"># Plus faible = besoin de plus d'arbres</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>                        <span class="co"># Typage: 0.01-0.3</span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 3. Profondeur maximale</span></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>    max_depth<span class="op">=</span><span class="dv">6</span>,  <span class="co"># Plus profond = plus complexe</span></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>                  <span class="co"># Typique: 3-10</span></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Bonus importants:</span></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>    subsample<span class="op">=</span><span class="fl">0.8</span>,      <span class="co"># Échantillonnage des données (0.5-1.0)</span></span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>    colsample_bytree<span class="op">=</span><span class="fl">0.8</span>,  <span class="co"># Échantillonnage des features</span></span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>    min_child_weight<span class="op">=</span><span class="dv">1</span>,    <span class="co"># Régularisation</span></span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p><strong>Recommandations de tuning:</strong></p>
<ol type="1">
<li><p><strong>Commencer avec:</strong></p>
<ul>
<li><code>learning_rate=0.1</code></li>
<li><code>max_depth=6</code></li>
<li><code>n_estimators=100</code></li>
</ul></li>
<li><p><strong>Puis optimiser:</strong></p>
<ul>
<li>Augmenter <code>n_estimators</code> + réduire <code>learning_rate</code></li>
<li>Ajuster <code>max_depth</code> (3-10)</li>
<li>Ajouter régularisation (<code>subsample</code>, <code>colsample_bytree</code>)</li>
</ul></li>
<li><p><strong>Utiliser early stopping:</strong></p></li>
</ol>
<div id="85921b05" class="cell" data-execution_count="9">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>model.fit(</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>    X_train, y_train,</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>    eval_set<span class="op">=</span>[(X_val, y_val)],</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    early_stopping_rounds<span class="op">=</span><span class="dv">10</span>,  <span class="co"># Stop si pas d'amélioration</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="va">False</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</div>
</div>
</section>
</section>
<section id="exercices-récapitulatifs" class="level2">
<h2 class="anchored" data-anchor-id="exercices-récapitulatifs">Exercices Récapitulatifs</h2>
<div class="callout callout-style-default callout-warning no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Warning</span>Exercice Final: Choix d’Algorithme
</div>
</div>
<div class="callout-body-container callout-body">
<p>Pour chacun des scénarios suivants, recommandez un algorithme et justifiez:</p>
<ol type="1">
<li><strong>Diagnostic médical</strong> (interprétabilité cruciale, 1000 patients, 20 features)</li>
<li><strong>Détection de fraude</strong> (millions de transactions, temps réel, déséquilibre 99/1)</li>
<li><strong>Classification d’images</strong> (50000 images, haute dimension, GPU disponible)</li>
<li><strong>Prédiction de churn</strong> (10000 clients, features mixtes, besoin de probabilités calibrées)</li>
<li><strong>Classification de textes</strong> (emails spam, 100000 emails, features = mots)</li>
</ol>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-11-contents" aria-controls="callout-11" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Solution Exercice Final
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-11" class="callout-11-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>1. Diagnostic médical:</strong></p>
<ul>
<li><p><strong>Recommandation</strong>: Decision Tree ou Régression Logistique</p></li>
<li><p><strong>Justification</strong>:</p>
<ul>
<li>Interprétabilité essentielle pour les médecins</li>
<li>Dataset de taille modérée</li>
<li>Besoin de comprendre les règles de décision</li>
<li>Alternative: Random Forest + feature importance</li>
</ul></li>
</ul>
<p><strong>2. Détection de fraude:</strong></p>
<ul>
<li><p><strong>Recommandation</strong>: XGBoost/LightGBM</p></li>
<li><p><strong>Justification</strong>:</p>
<ul>
<li>Excellent avec classes déséquilibrées (paramètre <code>scale_pos_weight</code>)</li>
<li>Très rapide en prédiction (important pour temps réel)</li>
<li>Gère bien les grandes données</li>
<li>Robuste et performant</li>
<li>Peut utiliser early stopping</li>
</ul></li>
</ul>
<p><strong>3. Classification d’images:</strong></p>
<ul>
<li><p><strong>Recommandation</strong>: CNN (Deep Learning) - hors scope pour l’instant</p></li>
<li><p><strong>Justification actuelle avec ML classique</strong>:</p>
<ul>
<li>Random Forest avec features extraites (HOG, SIFT)</li>
<li>SVM avec kernel RBF</li>
<li>Mais performances limitées vs Deep Learning</li>
</ul></li>
</ul>
<p><strong>4. Prédiction de churn:</strong></p>
<ul>
<li><p><strong>Recommandation</strong>: Régression Logistique ou Gradient Boosting</p></li>
<li><p><strong>Justification</strong>:</p>
<ul>
<li>Logistic Regression: probabilités bien calibrées, interprétable</li>
<li>Gradient Boosting: meilleures performances, feature importance</li>
<li>Dataset de taille moyenne</li>
<li>Features mixtes gérées par les deux</li>
</ul></li>
</ul>
<p><strong>5. Classification de textes:</strong></p>
<ul>
<li><p><strong>Recommandation</strong>: Naive Bayes (Multinomial)</p></li>
<li><p><strong>Justification</strong>:</p>
<ul>
<li>Très performant pour la classification de texte</li>
<li>Rapide à entraîner et prédire</li>
<li>Gère bien les grandes dimensions (nombreux mots)</li>
<li>Probabilités natives</li>
<li>Alternative: Régression Logistique</li>
</ul></li>
</ul>
</div>
</div>
</div>
</section>
<section id="résumé-du-td" class="level2">
<h2 class="anchored" data-anchor-id="résumé-du-td">Résumé du TD</h2>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Important</span>Points clés à retenir
</div>
</div>
<section id="algorithmes-et-leurs-forces" class="level3 callout-body-container callout-body">
<h3 class="anchored" data-anchor-id="algorithmes-et-leurs-forces">Algorithmes et leurs forces</h3>
<ol type="1">
<li><strong>Decision Tree</strong>
<ul>
<li><span class="math inline">\(\checkmark\)</span> Interprétable, visuel</li>
<li>X Overfitting, instable</li>
</ul></li>
<li><strong>Random Forest</strong>
<ul>
<li><span class="math inline">\(\checkmark\)</span> Robuste, performant</li>
<li>X Moins interprétable, mémoire</li>
</ul></li>
<li><strong>SVM</strong>
<ul>
<li><span class="math inline">\(\checkmark\)</span> Excellent en haute dimension</li>
<li>X Lent, difficile à interpréter</li>
</ul></li>
<li><strong>Naive Bayes</strong>
<ul>
<li><span class="math inline">\(\checkmark\)</span> Rapide, bon pour texte</li>
<li>X Hypothèse d’indépendance forte</li>
</ul></li>
<li><strong>Régression Logistique</strong>
<ul>
<li><span class="math inline">\(\checkmark\)</span> Probabilités calibrées, interprétable</li>
<li>X Assume linéarité</li>
</ul></li>
<li><strong>k-NN</strong>
<ul>
<li><span class="math inline">\(\checkmark\)</span> Simple, pas de training</li>
<li>X Lent en prédiction, besoin normalisation</li>
</ul></li>
<li><strong>Gradient Boosting</strong>
<ul>
<li><span class="math inline">\(\checkmark\)</span> Très performant, gère déséquilibre</li>
<li>X Sensible overfitting, plus complexe</li>
</ul></li>
</ol>
</section>
</div>
</section>
<section id="pour-le-prochain-cours" class="level2">
<h2 class="anchored" data-anchor-id="pour-le-prochain-cours">Pour le Prochain Cours</h2>
<p>Préparez-vous pour le <strong>TD2 sur les Critères d’Évaluation</strong> où nous approfondirons: - Matrice de confusion - Precision, Recall, F1-score - Courbe ROC et AUC - Choix de métriques selon le contexte</p>
</section>
<section id="ressources-complémentaires" class="level2">
<h2 class="anchored" data-anchor-id="ressources-complémentaires">Ressources Complémentaires</h2>
<ol type="1">
<li><a href="https://scikit-learn.org/stable/tutorial/machine_learning_map/">Scikit-learn: Choosing the right estimator</a></li>
<li><a href="https://www.youtube.com/watch?v=7VeUPuFGJHk">StatQuest: Decision Trees</a></li>
<li><a href="https://xgboost.readthedocs.io/">XGBoost Documentation</a></li>
</ol>
</section>
<section id="correction" class="level2">
<h2 class="anchored" data-anchor-id="correction">Correction</h2>
<p>📎 <strong>Lien de la correction :</strong> <a href="https://nevermind78.github.io/AN_slides/td1_corr_eng.html#/title-slide">TD1 — Modèles de Classification de Base</a></p>


<!-- -->

</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/nevermind78\.github\.io\/Ml_DL\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./seance3.html" class="pagination-link" aria-label="Séance 3: TP1 - Pipeline de Classification Binaire">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-title">Séance 3: TP1 - Pipeline de Classification Binaire</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./seance5.html" class="pagination-link" aria-label="Séance 5: TD2 - Critères d'Évaluation">
        <span class="nav-page-text"><span class="chapter-title">Séance 5: TD2 - Critères d’Évaluation</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb10" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># Séance 4: TD1 - Modèles de Classification de Base</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>::: {.callout-note icon=false}</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="fu">## Informations de la séance</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Type**: Travaux Dirigés</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Durée**: 2h</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Objectifs**: Obj4, Obj6</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a><span class="fu">## Introduction</span></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>Ce TD vous permet d'approfondir votre compréhension théorique et pratique des principaux algorithmes de classification. Vous allez travailler sur des exercices conceptuels et des problèmes appliqués.</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a><span class="fu">## Partie 1: Arbres de Décision</span></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a><span class="fu">### Exercice 1.1: Construction d'un Arbre</span></span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>Considérez le dataset suivant pour prédire si un client va acheter un ordinateur:</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Age <span class="pp">|</span> Revenu <span class="pp">|</span> Étudiant <span class="pp">|</span> Crédit <span class="pp">|</span> Achète <span class="pp">|</span></span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a><span class="pp">|-----|--------|----------|--------|--------|</span></span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Jeune <span class="pp">|</span> Élevé <span class="pp">|</span> Non <span class="pp">|</span> Excellent <span class="pp">|</span> Non <span class="pp">|</span></span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Jeune <span class="pp">|</span> Élevé <span class="pp">|</span> Non <span class="pp">|</span> Excellent <span class="pp">|</span> Non <span class="pp">|</span></span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Moyen <span class="pp">|</span> Élevé <span class="pp">|</span> Non <span class="pp">|</span> Excellent <span class="pp">|</span> Oui <span class="pp">|</span></span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Senior <span class="pp">|</span> Moyen <span class="pp">|</span> Non <span class="pp">|</span> Excellent <span class="pp">|</span> Oui <span class="pp">|</span></span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Senior <span class="pp">|</span> Faible <span class="pp">|</span> Oui <span class="pp">|</span> Excellent <span class="pp">|</span> Oui <span class="pp">|</span></span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Senior <span class="pp">|</span> Faible <span class="pp">|</span> Oui <span class="pp">|</span> Bon <span class="pp">|</span> Non <span class="pp">|</span></span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Moyen <span class="pp">|</span> Faible <span class="pp">|</span> Oui <span class="pp">|</span> Bon <span class="pp">|</span> Oui <span class="pp">|</span></span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Jeune <span class="pp">|</span> Moyen <span class="pp">|</span> Non <span class="pp">|</span> Excellent <span class="pp">|</span> Non <span class="pp">|</span></span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Jeune <span class="pp">|</span> Faible <span class="pp">|</span> Oui <span class="pp">|</span> Excellent <span class="pp">|</span> Oui <span class="pp">|</span></span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Senior <span class="pp">|</span> Moyen <span class="pp">|</span> Oui <span class="pp">|</span> Excellent <span class="pp">|</span> Oui <span class="pp">|</span></span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Jeune <span class="pp">|</span> Moyen <span class="pp">|</span> Oui <span class="pp">|</span> Bon <span class="pp">|</span> Oui <span class="pp">|</span></span>
<span id="cb10-33"><a href="#cb10-33" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Moyen <span class="pp">|</span> Moyen <span class="pp">|</span> Non <span class="pp">|</span> Bon <span class="pp">|</span> Oui <span class="pp">|</span></span>
<span id="cb10-34"><a href="#cb10-34" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Moyen <span class="pp">|</span> Élevé <span class="pp">|</span> Oui <span class="pp">|</span> Excellent <span class="pp">|</span> Oui <span class="pp">|</span></span>
<span id="cb10-35"><a href="#cb10-35" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Senior <span class="pp">|</span> Moyen <span class="pp">|</span> Non <span class="pp">|</span> Bon <span class="pp">|</span> Non <span class="pp">|</span></span>
<span id="cb10-36"><a href="#cb10-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-37"><a href="#cb10-37" aria-hidden="true" tabindex="-1"></a>**Questions:**</span>
<span id="cb10-38"><a href="#cb10-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-39"><a href="#cb10-39" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Calculez l'entropie initiale du dataset</span>
<span id="cb10-40"><a href="#cb10-40" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Calculez le gain d'information pour chaque attribut (Age, Revenu, Étudiant, Crédit)</span>
<span id="cb10-41"><a href="#cb10-41" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Quel attribut sera choisi comme racine de l'arbre ?</span>
<span id="cb10-42"><a href="#cb10-42" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>Dessinez l'arbre de décision complet</span>
<span id="cb10-43"><a href="#cb10-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-44"><a href="#cb10-44" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip collapse="true"}</span>
<span id="cb10-45"><a href="#cb10-45" aria-hidden="true" tabindex="-1"></a><span class="fu">## Rappels - Formules et Algorithme</span></span>
<span id="cb10-46"><a href="#cb10-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-47"><a href="#cb10-47" aria-hidden="true" tabindex="-1"></a>**Entropie:**</span>
<span id="cb10-48"><a href="#cb10-48" aria-hidden="true" tabindex="-1"></a>$$H(S) = -\sum_{i=1}^{c} p_i \log_2(p_i)$$</span>
<span id="cb10-49"><a href="#cb10-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-50"><a href="#cb10-50" aria-hidden="true" tabindex="-1"></a>**Gain d'Information:**</span>
<span id="cb10-51"><a href="#cb10-51" aria-hidden="true" tabindex="-1"></a>$$IG(S, A) = H(S) - \sum_{v \in Values(A)} \frac{|S_v|}{|S|} H(S_v)$$</span>
<span id="cb10-52"><a href="#cb10-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-53"><a href="#cb10-53" aria-hidden="true" tabindex="-1"></a>où:</span>
<span id="cb10-54"><a href="#cb10-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-55"><a href="#cb10-55" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$S$ = ensemble de données</span>
<span id="cb10-56"><a href="#cb10-56" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$A$ = attribut</span>
<span id="cb10-57"><a href="#cb10-57" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$c$ = nombre de classes</span>
<span id="cb10-58"><a href="#cb10-58" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$p_i$ = proportion de la classe $i$</span>
<span id="cb10-59"><a href="#cb10-59" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$S_v$ = sous-ensemble où $A = v$</span>
<span id="cb10-60"><a href="#cb10-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-61"><a href="#cb10-61" aria-hidden="true" tabindex="-1"></a>**Algorithme ID3 (construction de l'arbre) :**</span>
<span id="cb10-62"><a href="#cb10-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-63"><a href="#cb10-63" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Si tous les exemples appartiennent à la même classe → créer une **feuille** avec cette classe</span>
<span id="cb10-64"><a href="#cb10-64" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Si plus aucun attribut à tester → créer une **feuille** avec la classe majoritaire</span>
<span id="cb10-65"><a href="#cb10-65" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Sinon :</span>
<span id="cb10-66"><a href="#cb10-66" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Calculer $IG(S, A)$ pour chaque attribut $A$</span>
<span id="cb10-67"><a href="#cb10-67" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Choisir l'attribut $A^*$ avec le **gain d'information maximal**</span>
<span id="cb10-68"><a href="#cb10-68" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Créer un **nœud** de décision sur $A^*$</span>
<span id="cb10-69"><a href="#cb10-69" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Pour chaque valeur $v$ de $A^*$ :</span>
<span id="cb10-70"><a href="#cb10-70" aria-hidden="true" tabindex="-1"></a><span class="ss">     - </span>Créer une branche pour $S_v = <span class="sc">\{</span>x \in S \mid A^*(x) = v<span class="sc">\}</span>$</span>
<span id="cb10-71"><a href="#cb10-71" aria-hidden="true" tabindex="-1"></a><span class="ss">     - </span>**Appliquer récursivement** l'algorithme sur $S_v$ sans l'attribut $A^*$</span>
<span id="cb10-72"><a href="#cb10-72" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb10-73"><a href="#cb10-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-74"><a href="#cb10-74" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb10-75"><a href="#cb10-75" aria-hidden="true" tabindex="-1"></a><span class="fu">## Solution Exercice 1.1</span></span>
<span id="cb10-76"><a href="#cb10-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-79"><a href="#cb10-79" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb10-80"><a href="#cb10-80" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb10-81"><a href="#cb10-81" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb10-82"><a href="#cb10-82" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb10-83"><a href="#cb10-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-84"><a href="#cb10-84" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb10-85"><a href="#cb10-85" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb10-86"><a href="#cb10-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-87"><a href="#cb10-87" aria-hidden="true" tabindex="-1"></a><span class="co"># Données</span></span>
<span id="cb10-88"><a href="#cb10-88" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> [</span>
<span id="cb10-89"><a href="#cb10-89" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'Jeune'</span>, <span class="st">'Élevé'</span>, <span class="st">'Non'</span>, <span class="st">'Excellent'</span>, <span class="st">'Non'</span>),</span>
<span id="cb10-90"><a href="#cb10-90" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'Jeune'</span>, <span class="st">'Élevé'</span>, <span class="st">'Non'</span>, <span class="st">'Excellent'</span>, <span class="st">'Non'</span>),</span>
<span id="cb10-91"><a href="#cb10-91" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'Moyen'</span>, <span class="st">'Élevé'</span>, <span class="st">'Non'</span>, <span class="st">'Excellent'</span>, <span class="st">'Oui'</span>),</span>
<span id="cb10-92"><a href="#cb10-92" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'Senior'</span>, <span class="st">'Moyen'</span>, <span class="st">'Non'</span>, <span class="st">'Excellent'</span>, <span class="st">'Oui'</span>),</span>
<span id="cb10-93"><a href="#cb10-93" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'Senior'</span>, <span class="st">'Faible'</span>, <span class="st">'Oui'</span>, <span class="st">'Excellent'</span>, <span class="st">'Oui'</span>),</span>
<span id="cb10-94"><a href="#cb10-94" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'Senior'</span>, <span class="st">'Faible'</span>, <span class="st">'Oui'</span>, <span class="st">'Bon'</span>, <span class="st">'Non'</span>),</span>
<span id="cb10-95"><a href="#cb10-95" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'Moyen'</span>, <span class="st">'Faible'</span>, <span class="st">'Oui'</span>, <span class="st">'Bon'</span>, <span class="st">'Oui'</span>),</span>
<span id="cb10-96"><a href="#cb10-96" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'Jeune'</span>, <span class="st">'Moyen'</span>, <span class="st">'Non'</span>, <span class="st">'Excellent'</span>, <span class="st">'Non'</span>),</span>
<span id="cb10-97"><a href="#cb10-97" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'Jeune'</span>, <span class="st">'Faible'</span>, <span class="st">'Oui'</span>, <span class="st">'Excellent'</span>, <span class="st">'Oui'</span>),</span>
<span id="cb10-98"><a href="#cb10-98" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'Senior'</span>, <span class="st">'Moyen'</span>, <span class="st">'Oui'</span>, <span class="st">'Excellent'</span>, <span class="st">'Oui'</span>),</span>
<span id="cb10-99"><a href="#cb10-99" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'Jeune'</span>, <span class="st">'Moyen'</span>, <span class="st">'Oui'</span>, <span class="st">'Bon'</span>, <span class="st">'Oui'</span>),</span>
<span id="cb10-100"><a href="#cb10-100" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'Moyen'</span>, <span class="st">'Moyen'</span>, <span class="st">'Non'</span>, <span class="st">'Bon'</span>, <span class="st">'Oui'</span>),</span>
<span id="cb10-101"><a href="#cb10-101" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'Moyen'</span>, <span class="st">'Élevé'</span>, <span class="st">'Oui'</span>, <span class="st">'Excellent'</span>, <span class="st">'Oui'</span>),</span>
<span id="cb10-102"><a href="#cb10-102" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'Senior'</span>, <span class="st">'Moyen'</span>, <span class="st">'Non'</span>, <span class="st">'Bon'</span>, <span class="st">'Non'</span>)</span>
<span id="cb10-103"><a href="#cb10-103" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb10-104"><a href="#cb10-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-105"><a href="#cb10-105" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> entropy(labels):</span>
<span id="cb10-106"><a href="#cb10-106" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Calcule l'entropie"""</span></span>
<span id="cb10-107"><a href="#cb10-107" aria-hidden="true" tabindex="-1"></a>    counter <span class="op">=</span> Counter(labels)</span>
<span id="cb10-108"><a href="#cb10-108" aria-hidden="true" tabindex="-1"></a>    total <span class="op">=</span> <span class="bu">len</span>(labels)</span>
<span id="cb10-109"><a href="#cb10-109" aria-hidden="true" tabindex="-1"></a>    ent <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb10-110"><a href="#cb10-110" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> count <span class="kw">in</span> counter.values():</span>
<span id="cb10-111"><a href="#cb10-111" aria-hidden="true" tabindex="-1"></a>        p <span class="op">=</span> count <span class="op">/</span> total</span>
<span id="cb10-112"><a href="#cb10-112" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> p <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb10-113"><a href="#cb10-113" aria-hidden="true" tabindex="-1"></a>            ent <span class="op">-=</span> p <span class="op">*</span> np.log2(p)</span>
<span id="cb10-114"><a href="#cb10-114" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> ent</span>
<span id="cb10-115"><a href="#cb10-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-116"><a href="#cb10-116" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> information_gain(data, attr_idx):</span>
<span id="cb10-117"><a href="#cb10-117" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Calcule le gain d'information"""</span></span>
<span id="cb10-118"><a href="#cb10-118" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Entropie initiale</span></span>
<span id="cb10-119"><a href="#cb10-119" aria-hidden="true" tabindex="-1"></a>    labels <span class="op">=</span> [row[<span class="op">-</span><span class="dv">1</span>] <span class="cf">for</span> row <span class="kw">in</span> data]</span>
<span id="cb10-120"><a href="#cb10-120" aria-hidden="true" tabindex="-1"></a>    h_s <span class="op">=</span> entropy(labels)</span>
<span id="cb10-121"><a href="#cb10-121" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-122"><a href="#cb10-122" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Partition par attribut</span></span>
<span id="cb10-123"><a href="#cb10-123" aria-hidden="true" tabindex="-1"></a>    partitions <span class="op">=</span> {}</span>
<span id="cb10-124"><a href="#cb10-124" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> row <span class="kw">in</span> data:</span>
<span id="cb10-125"><a href="#cb10-125" aria-hidden="true" tabindex="-1"></a>        attr_value <span class="op">=</span> row[attr_idx]</span>
<span id="cb10-126"><a href="#cb10-126" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> attr_value <span class="kw">not</span> <span class="kw">in</span> partitions:</span>
<span id="cb10-127"><a href="#cb10-127" aria-hidden="true" tabindex="-1"></a>            partitions[attr_value] <span class="op">=</span> []</span>
<span id="cb10-128"><a href="#cb10-128" aria-hidden="true" tabindex="-1"></a>        partitions[attr_value].append(row[<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb10-129"><a href="#cb10-129" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-130"><a href="#cb10-130" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Entropie pondérée</span></span>
<span id="cb10-131"><a href="#cb10-131" aria-hidden="true" tabindex="-1"></a>    h_s_a <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb10-132"><a href="#cb10-132" aria-hidden="true" tabindex="-1"></a>    total <span class="op">=</span> <span class="bu">len</span>(data)</span>
<span id="cb10-133"><a href="#cb10-133" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> partition_labels <span class="kw">in</span> partitions.values():</span>
<span id="cb10-134"><a href="#cb10-134" aria-hidden="true" tabindex="-1"></a>        p <span class="op">=</span> <span class="bu">len</span>(partition_labels) <span class="op">/</span> total</span>
<span id="cb10-135"><a href="#cb10-135" aria-hidden="true" tabindex="-1"></a>        h_s_a <span class="op">+=</span> p <span class="op">*</span> entropy(partition_labels)</span>
<span id="cb10-136"><a href="#cb10-136" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-137"><a href="#cb10-137" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> h_s <span class="op">-</span> h_s_a</span>
<span id="cb10-138"><a href="#cb10-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-139"><a href="#cb10-139" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Entropie initiale</span></span>
<span id="cb10-140"><a href="#cb10-140" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> [row[<span class="op">-</span><span class="dv">1</span>] <span class="cf">for</span> row <span class="kw">in</span> data]</span>
<span id="cb10-141"><a href="#cb10-141" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"1. Entropie initiale: </span><span class="sc">{</span>entropy(labels)<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb10-142"><a href="#cb10-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-143"><a href="#cb10-143" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Gain d'information pour chaque attribut</span></span>
<span id="cb10-144"><a href="#cb10-144" aria-hidden="true" tabindex="-1"></a>attributes <span class="op">=</span> [<span class="st">'Age'</span>, <span class="st">'Revenu'</span>, <span class="st">'Étudiant'</span>, <span class="st">'Crédit'</span>]</span>
<span id="cb10-145"><a href="#cb10-145" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">2. Gain d'information:"</span>)</span>
<span id="cb10-146"><a href="#cb10-146" aria-hidden="true" tabindex="-1"></a>gains <span class="op">=</span> {}</span>
<span id="cb10-147"><a href="#cb10-147" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx, attr <span class="kw">in</span> <span class="bu">enumerate</span>(attributes):</span>
<span id="cb10-148"><a href="#cb10-148" aria-hidden="true" tabindex="-1"></a>    ig <span class="op">=</span> information_gain(data, idx)</span>
<span id="cb10-149"><a href="#cb10-149" aria-hidden="true" tabindex="-1"></a>    gains[attr] <span class="op">=</span> ig</span>
<span id="cb10-150"><a href="#cb10-150" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   </span><span class="sc">{</span>attr<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>ig<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb10-151"><a href="#cb10-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-152"><a href="#cb10-152" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Meilleur attribut</span></span>
<span id="cb10-153"><a href="#cb10-153" aria-hidden="true" tabindex="-1"></a>best_attr <span class="op">=</span> <span class="bu">max</span>(gains, key<span class="op">=</span>gains.get)</span>
<span id="cb10-154"><a href="#cb10-154" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">3. Attribut racine: </span><span class="sc">{</span>best_attr<span class="sc">}</span><span class="ss"> (IG = </span><span class="sc">{</span>gains[best_attr]<span class="sc">:.4f}</span><span class="ss">)"</span>)</span>
<span id="cb10-155"><a href="#cb10-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-156"><a href="#cb10-156" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. L'arbre complet nécessiterait une implémentation récursive</span></span>
<span id="cb10-157"><a href="#cb10-157" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">4. Arbre de décision (structure simplifiée):"</span>)</span>
<span id="cb10-158"><a href="#cb10-158" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"""</span></span>
<span id="cb10-159"><a href="#cb10-159" aria-hidden="true" tabindex="-1"></a><span class="st">         Age?</span></span>
<span id="cb10-160"><a href="#cb10-160" aria-hidden="true" tabindex="-1"></a><span class="st">        /    |    </span><span class="ch">\\</span></span>
<span id="cb10-161"><a href="#cb10-161" aria-hidden="true" tabindex="-1"></a><span class="st">    Jeune  Moyen  Senior</span></span>
<span id="cb10-162"><a href="#cb10-162" aria-hidden="true" tabindex="-1"></a><span class="st">      |      |      |</span></span>
<span id="cb10-163"><a href="#cb10-163" aria-hidden="true" tabindex="-1"></a><span class="st">    [Classes selon données]</span></span>
<span id="cb10-164"><a href="#cb10-164" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span>)</span>
<span id="cb10-165"><a href="#cb10-165" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb10-166"><a href="#cb10-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-167"><a href="#cb10-167" aria-hidden="true" tabindex="-1"></a>**Réponses:**</span>
<span id="cb10-168"><a href="#cb10-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-169"><a href="#cb10-169" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Entropie initiale $\approx$ 0.940</span>
<span id="cb10-170"><a href="#cb10-170" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Gains d'information:</span>
<span id="cb10-171"><a href="#cb10-171" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Age: ~0.246</span>
<span id="cb10-172"><a href="#cb10-172" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Revenu: ~0.029</span>
<span id="cb10-173"><a href="#cb10-173" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Étudiant: ~0.151</span>
<span id="cb10-174"><a href="#cb10-174" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Crédit: ~0.048</span>
<span id="cb10-175"><a href="#cb10-175" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**Age** sera choisi comme racine (gain le plus élevé)</span>
<span id="cb10-176"><a href="#cb10-176" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb10-177"><a href="#cb10-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-178"><a href="#cb10-178" aria-hidden="true" tabindex="-1"></a><span class="fu">### Exercice 1.2: Overfitting dans les Arbres</span></span>
<span id="cb10-179"><a href="#cb10-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-180"><a href="#cb10-180" aria-hidden="true" tabindex="-1"></a>**Question:** Expliquez pourquoi un arbre de décision sans contraintes (profondeur illimitée) tend à faire de l'overfitting.</span>
<span id="cb10-181"><a href="#cb10-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-182"><a href="#cb10-182" aria-hidden="true" tabindex="-1"></a>**Proposez 3 méthodes pour limiter l'overfitting dans les arbres de décision.**</span>
<span id="cb10-183"><a href="#cb10-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-184"><a href="#cb10-184" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb10-185"><a href="#cb10-185" aria-hidden="true" tabindex="-1"></a><span class="fu">## Solution Exercice 1.2</span></span>
<span id="cb10-186"><a href="#cb10-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-187"><a href="#cb10-187" aria-hidden="true" tabindex="-1"></a>**Pourquoi l'overfitting ?**</span>
<span id="cb10-188"><a href="#cb10-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-189"><a href="#cb10-189" aria-hidden="true" tabindex="-1"></a>Un arbre sans contraintes va créer des branches jusqu'à ce que chaque feuille soit "pure" (contient une seule classe). Cela signifie:</span>
<span id="cb10-190"><a href="#cb10-190" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>L'arbre mémorise les données d'entraînement, y compris le bruit</span>
<span id="cb10-191"><a href="#cb10-191" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Il crée des règles très spécifiques qui ne généralisent pas</span>
<span id="cb10-192"><a href="#cb10-192" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>La complexité du modèle est trop élevée par rapport aux données</span>
<span id="cb10-193"><a href="#cb10-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-194"><a href="#cb10-194" aria-hidden="true" tabindex="-1"></a>**3 méthodes pour limiter l'overfitting:**</span>
<span id="cb10-195"><a href="#cb10-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-196"><a href="#cb10-196" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Pré-élagage (Pre-pruning)**:</span>
<span id="cb10-197"><a href="#cb10-197" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span><span class="in">`max_depth`</span>: Limiter la profondeur maximale</span>
<span id="cb10-198"><a href="#cb10-198" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span><span class="in">`min_samples_split`</span>: Nombre minimum d'échantillons pour diviser un nœud</span>
<span id="cb10-199"><a href="#cb10-199" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span><span class="in">`min_samples_leaf`</span>: Nombre minimum d'échantillons dans une feuille</span>
<span id="cb10-200"><a href="#cb10-200" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span><span class="in">`max_leaf_nodes`</span>: Nombre maximum de feuilles</span>
<span id="cb10-201"><a href="#cb10-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-202"><a href="#cb10-202" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Post-élagage (Post-pruning)**:</span>
<span id="cb10-203"><a href="#cb10-203" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Construire l'arbre complet</span>
<span id="cb10-204"><a href="#cb10-204" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Élaguer les branches qui n'apportent pas assez d'amélioration</span>
<span id="cb10-205"><a href="#cb10-205" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Utiliser un ensemble de validation pour guider l'élagage</span>
<span id="cb10-206"><a href="#cb10-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-207"><a href="#cb10-207" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**Ensemble Methods**:</span>
<span id="cb10-208"><a href="#cb10-208" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Random Forest: moyenne de plusieurs arbres</span>
<span id="cb10-209"><a href="#cb10-209" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Gradient Boosting: construction itérative d'arbres</span>
<span id="cb10-210"><a href="#cb10-210" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Bagging: bootstrap + agrégation</span>
<span id="cb10-211"><a href="#cb10-211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-214"><a href="#cb10-214" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb10-215"><a href="#cb10-215" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb10-216"><a href="#cb10-216" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb10-217"><a href="#cb10-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-218"><a href="#cb10-218" aria-hidden="true" tabindex="-1"></a><span class="co"># Exemple pratique</span></span>
<span id="cb10-219"><a href="#cb10-219" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier</span>
<span id="cb10-220"><a href="#cb10-220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-221"><a href="#cb10-221" aria-hidden="true" tabindex="-1"></a><span class="co"># Arbre avec overfitting</span></span>
<span id="cb10-222"><a href="#cb10-222" aria-hidden="true" tabindex="-1"></a>tree_overfit <span class="op">=</span> DecisionTreeClassifier()  <span class="co"># Pas de contraintes</span></span>
<span id="cb10-223"><a href="#cb10-223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-224"><a href="#cb10-224" aria-hidden="true" tabindex="-1"></a><span class="co"># Arbre régularisé</span></span>
<span id="cb10-225"><a href="#cb10-225" aria-hidden="true" tabindex="-1"></a>tree_regularized <span class="op">=</span> DecisionTreeClassifier(</span>
<span id="cb10-226"><a href="#cb10-226" aria-hidden="true" tabindex="-1"></a>    max_depth<span class="op">=</span><span class="dv">5</span>,              <span class="co"># Profondeur max</span></span>
<span id="cb10-227"><a href="#cb10-227" aria-hidden="true" tabindex="-1"></a>    min_samples_split<span class="op">=</span><span class="dv">10</span>,     <span class="co"># Min échantillons pour split</span></span>
<span id="cb10-228"><a href="#cb10-228" aria-hidden="true" tabindex="-1"></a>    min_samples_leaf<span class="op">=</span><span class="dv">5</span>,       <span class="co"># Min échantillons par feuille</span></span>
<span id="cb10-229"><a href="#cb10-229" aria-hidden="true" tabindex="-1"></a>    max_leaf_nodes<span class="op">=</span><span class="dv">20</span>         <span class="co"># Max feuilles</span></span>
<span id="cb10-230"><a href="#cb10-230" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb10-231"><a href="#cb10-231" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb10-232"><a href="#cb10-232" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb10-233"><a href="#cb10-233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-234"><a href="#cb10-234" aria-hidden="true" tabindex="-1"></a><span class="fu">## Partie 2: Régression Logistique</span></span>
<span id="cb10-235"><a href="#cb10-235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-236"><a href="#cb10-236" aria-hidden="true" tabindex="-1"></a><span class="fu">### Exercice 2.1: Intuition Probabiliste</span></span>
<span id="cb10-237"><a href="#cb10-237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-238"><a href="#cb10-238" aria-hidden="true" tabindex="-1"></a>Considérez le modèle de régression logistique suivant pour prédire l'admission à l'université:</span>
<span id="cb10-239"><a href="#cb10-239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-240"><a href="#cb10-240" aria-hidden="true" tabindex="-1"></a>$$P(admission=1|score) = \frac{1}{1 + e^{-(0.05 \times score - 3)}}$$</span>
<span id="cb10-241"><a href="#cb10-241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-242"><a href="#cb10-242" aria-hidden="true" tabindex="-1"></a>**Questions:**</span>
<span id="cb10-243"><a href="#cb10-243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-244"><a href="#cb10-244" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Quelle est la probabilité d'admission pour un score de 60?</span>
<span id="cb10-245"><a href="#cb10-245" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Quelle est la probabilité d'admission pour un score de 80?</span>
<span id="cb10-246"><a href="#cb10-246" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Quel score donne une probabilité d'admission de 50%?</span>
<span id="cb10-247"><a href="#cb10-247" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>Interprétez le coefficient 0.05</span>
<span id="cb10-248"><a href="#cb10-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-249"><a href="#cb10-249" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb10-250"><a href="#cb10-250" aria-hidden="true" tabindex="-1"></a><span class="fu">## Solution Exercice 2.1</span></span>
<span id="cb10-251"><a href="#cb10-251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-254"><a href="#cb10-254" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb10-255"><a href="#cb10-255" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb10-256"><a href="#cb10-256" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb10-257"><a href="#cb10-257" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb10-258"><a href="#cb10-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-259"><a href="#cb10-259" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb10-260"><a href="#cb10-260" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb10-261"><a href="#cb10-261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-262"><a href="#cb10-262" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sigmoid(z):</span>
<span id="cb10-263"><a href="#cb10-263" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Fonction sigmoïde"""</span></span>
<span id="cb10-264"><a href="#cb10-264" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">1</span> <span class="op">/</span> (<span class="dv">1</span> <span class="op">+</span> np.exp(<span class="op">-</span>z))</span>
<span id="cb10-265"><a href="#cb10-265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-266"><a href="#cb10-266" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> prob_admission(score):</span>
<span id="cb10-267"><a href="#cb10-267" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Probabilité d'admission"""</span></span>
<span id="cb10-268"><a href="#cb10-268" aria-hidden="true" tabindex="-1"></a>    z <span class="op">=</span> <span class="fl">0.05</span> <span class="op">*</span> score <span class="op">-</span> <span class="dv">3</span></span>
<span id="cb10-269"><a href="#cb10-269" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> sigmoid(z)</span>
<span id="cb10-270"><a href="#cb10-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-271"><a href="#cb10-271" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Probabilité pour score = 60</span></span>
<span id="cb10-272"><a href="#cb10-272" aria-hidden="true" tabindex="-1"></a>p_60 <span class="op">=</span> prob_admission(<span class="dv">60</span>)</span>
<span id="cb10-273"><a href="#cb10-273" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"1. P(admission|score=60) = </span><span class="sc">{</span>p_60<span class="sc">:.4f}</span><span class="ss"> = </span><span class="sc">{</span>p_60<span class="op">*</span><span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">%"</span>)</span>
<span id="cb10-274"><a href="#cb10-274" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-275"><a href="#cb10-275" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Probabilité pour score = 80</span></span>
<span id="cb10-276"><a href="#cb10-276" aria-hidden="true" tabindex="-1"></a>p_80 <span class="op">=</span> prob_admission(<span class="dv">80</span>)</span>
<span id="cb10-277"><a href="#cb10-277" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"2. P(admission|score=80) = </span><span class="sc">{</span>p_80<span class="sc">:.4f}</span><span class="ss"> = </span><span class="sc">{</span>p_80<span class="op">*</span><span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">%"</span>)</span>
<span id="cb10-278"><a href="#cb10-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-279"><a href="#cb10-279" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Score pour P = 0.5</span></span>
<span id="cb10-280"><a href="#cb10-280" aria-hidden="true" tabindex="-1"></a><span class="co"># 0.5 = 1/(1 + e^(-(0.05*score - 3)))</span></span>
<span id="cb10-281"><a href="#cb10-281" aria-hidden="true" tabindex="-1"></a><span class="co"># =&gt; 0.05*score - 3 = 0</span></span>
<span id="cb10-282"><a href="#cb10-282" aria-hidden="true" tabindex="-1"></a><span class="co"># =&gt; score = 60</span></span>
<span id="cb10-283"><a href="#cb10-283" aria-hidden="true" tabindex="-1"></a>score_50 <span class="op">=</span> <span class="dv">3</span> <span class="op">/</span> <span class="fl">0.05</span></span>
<span id="cb10-284"><a href="#cb10-284" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"3. Score pour P=50%: </span><span class="sc">{</span>score_50<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb10-285"><a href="#cb10-285" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-286"><a href="#cb10-286" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Interprétation du coefficient</span></span>
<span id="cb10-287"><a href="#cb10-287" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">4. Coefficient 0.05:"</span>)</span>
<span id="cb10-288"><a href="#cb10-288" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   - Augmenter le score de 1 point augmente z de 0.05"</span>)</span>
<span id="cb10-289"><a href="#cb10-289" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   - Cela augmente les log-odds de 0.05"</span>)</span>
<span id="cb10-290"><a href="#cb10-290" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   - Odds ratio = e^0.05 = </span><span class="sc">{</span>np<span class="sc">.</span>exp(<span class="fl">0.05</span>)<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb10-291"><a href="#cb10-291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-292"><a href="#cb10-292" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualisation</span></span>
<span id="cb10-293"><a href="#cb10-293" aria-hidden="true" tabindex="-1"></a>scores <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">100</span>, <span class="dv">1000</span>)</span>
<span id="cb10-294"><a href="#cb10-294" aria-hidden="true" tabindex="-1"></a>probs <span class="op">=</span> [prob_admission(s) <span class="cf">for</span> s <span class="kw">in</span> scores]</span>
<span id="cb10-295"><a href="#cb10-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-296"><a href="#cb10-296" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb10-297"><a href="#cb10-297" aria-hidden="true" tabindex="-1"></a>plt.plot(scores, probs, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb10-298"><a href="#cb10-298" aria-hidden="true" tabindex="-1"></a>plt.axhline(y<span class="op">=</span><span class="fl">0.5</span>, color<span class="op">=</span><span class="st">'r'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, label<span class="op">=</span><span class="st">'P = 0.5'</span>)</span>
<span id="cb10-299"><a href="#cb10-299" aria-hidden="true" tabindex="-1"></a>plt.axvline(x<span class="op">=</span><span class="dv">60</span>, color<span class="op">=</span><span class="st">'r'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, label<span class="op">=</span><span class="st">'Score = 60'</span>)</span>
<span id="cb10-300"><a href="#cb10-300" aria-hidden="true" tabindex="-1"></a>plt.scatter([<span class="dv">60</span>, <span class="dv">80</span>], [p_60, p_80], color<span class="op">=</span><span class="st">'red'</span>, s<span class="op">=</span><span class="dv">100</span>, zorder<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb10-301"><a href="#cb10-301" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Score'</span>)</span>
<span id="cb10-302"><a href="#cb10-302" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Probabilité d</span><span class="ch">\'</span><span class="st">admission'</span>)</span>
<span id="cb10-303"><a href="#cb10-303" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Régression Logistique - Admission à l</span><span class="ch">\'</span><span class="st">université'</span>)</span>
<span id="cb10-304"><a href="#cb10-304" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb10-305"><a href="#cb10-305" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb10-306"><a href="#cb10-306" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb10-307"><a href="#cb10-307" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb10-308"><a href="#cb10-308" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb10-309"><a href="#cb10-309" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-310"><a href="#cb10-310" aria-hidden="true" tabindex="-1"></a>**Réponses:**</span>
<span id="cb10-311"><a href="#cb10-311" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-312"><a href="#cb10-312" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>P(admission|score=60) = 0.50 = 50%</span>
<span id="cb10-313"><a href="#cb10-313" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>P(admission|score=80) = 0.73 = 73%</span>
<span id="cb10-314"><a href="#cb10-314" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Score pour P=50%: **60**</span>
<span id="cb10-315"><a href="#cb10-315" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>Le coefficient 0.05 indique qu'augmenter le score de 1 point multiplie les odds d'admission par e^0.05 $\approx$ 1.051 (5.1% d'augmentation)</span>
<span id="cb10-316"><a href="#cb10-316" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb10-317"><a href="#cb10-317" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-318"><a href="#cb10-318" aria-hidden="true" tabindex="-1"></a><span class="fu">### Exercice 2.2: Régression Logistique Multiclasse</span></span>
<span id="cb10-319"><a href="#cb10-319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-320"><a href="#cb10-320" aria-hidden="true" tabindex="-1"></a>Expliquez comment adapter la régression logistique pour un problème multiclasse (ex: 3 classes). Quelles sont les deux approches principales?</span>
<span id="cb10-321"><a href="#cb10-321" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-322"><a href="#cb10-322" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb10-323"><a href="#cb10-323" aria-hidden="true" tabindex="-1"></a><span class="fu">## Solution Exercice 2.2</span></span>
<span id="cb10-324"><a href="#cb10-324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-325"><a href="#cb10-325" aria-hidden="true" tabindex="-1"></a>**Deux approches pour la classification multiclasse:**</span>
<span id="cb10-326"><a href="#cb10-326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-327"><a href="#cb10-327" aria-hidden="true" tabindex="-1"></a><span class="fu">### 1. One-vs-Rest (OvR) ou One-vs-All (OvA)</span></span>
<span id="cb10-328"><a href="#cb10-328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-329"><a href="#cb10-329" aria-hidden="true" tabindex="-1"></a>**Principe:**</span>
<span id="cb10-330"><a href="#cb10-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-331"><a href="#cb10-331" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Entraîner K modèles binaires (K = nombre de classes)</span>
<span id="cb10-332"><a href="#cb10-332" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Chaque modèle sépare une classe vs toutes les autres</span>
<span id="cb10-333"><a href="#cb10-333" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Prédiction: choisir la classe avec la probabilité la plus élevée</span>
<span id="cb10-334"><a href="#cb10-334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-335"><a href="#cb10-335" aria-hidden="true" tabindex="-1"></a>**Exemple avec 3 classes:**</span>
<span id="cb10-336"><a href="#cb10-336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-337"><a href="#cb10-337" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Modèle 1: Classe A vs (B, C)</span>
<span id="cb10-338"><a href="#cb10-338" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Modèle 2: Classe B vs (A, C)</span>
<span id="cb10-339"><a href="#cb10-339" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Modèle 3: Classe C vs (A, B)</span>
<span id="cb10-340"><a href="#cb10-340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-343"><a href="#cb10-343" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb10-344"><a href="#cb10-344" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb10-345"><a href="#cb10-345" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb10-346"><a href="#cb10-346" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-347"><a href="#cb10-347" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb10-348"><a href="#cb10-348" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-349"><a href="#cb10-349" aria-hidden="true" tabindex="-1"></a><span class="co"># One-vs-Rest (par défaut dans scikit-learn)</span></span>
<span id="cb10-350"><a href="#cb10-350" aria-hidden="true" tabindex="-1"></a>ovr_model <span class="op">=</span> LogisticRegression(multi_class<span class="op">=</span><span class="st">'ovr'</span>)</span>
<span id="cb10-351"><a href="#cb10-351" aria-hidden="true" tabindex="-1"></a>ovr_model.fit(X_train, y_train)</span>
<span id="cb10-352"><a href="#cb10-352" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb10-353"><a href="#cb10-353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-354"><a href="#cb10-354" aria-hidden="true" tabindex="-1"></a><span class="fu">### 2. Softmax (ou Multinomial)</span></span>
<span id="cb10-355"><a href="#cb10-355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-356"><a href="#cb10-356" aria-hidden="true" tabindex="-1"></a>**Principe:**</span>
<span id="cb10-357"><a href="#cb10-357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-358"><a href="#cb10-358" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Un seul modèle qui produit K probabilités (une par classe)</span>
<span id="cb10-359"><a href="#cb10-359" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Utilise la fonction softmax au lieu de sigmoid</span>
<span id="cb10-360"><a href="#cb10-360" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Les probabilités somment à 1</span>
<span id="cb10-361"><a href="#cb10-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-362"><a href="#cb10-362" aria-hidden="true" tabindex="-1"></a>**Fonction Softmax:**</span>
<span id="cb10-363"><a href="#cb10-363" aria-hidden="true" tabindex="-1"></a>$$P(y=k|X) = \frac{e^{z_k}}{\sum_{j=1}^{K} e^{z_j}}$$</span>
<span id="cb10-364"><a href="#cb10-364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-365"><a href="#cb10-365" aria-hidden="true" tabindex="-1"></a>où $z_k = w_k^T X + b_k$</span>
<span id="cb10-366"><a href="#cb10-366" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-369"><a href="#cb10-369" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb10-370"><a href="#cb10-370" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb10-371"><a href="#cb10-371" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb10-372"><a href="#cb10-372" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-373"><a href="#cb10-373" aria-hidden="true" tabindex="-1"></a><span class="co"># Softmax / Multinomial</span></span>
<span id="cb10-374"><a href="#cb10-374" aria-hidden="true" tabindex="-1"></a>softmax_model <span class="op">=</span> LogisticRegression(multi_class<span class="op">=</span><span class="st">'multinomial'</span>)</span>
<span id="cb10-375"><a href="#cb10-375" aria-hidden="true" tabindex="-1"></a>softmax_model.fit(X_train, y_train)</span>
<span id="cb10-376"><a href="#cb10-376" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb10-377"><a href="#cb10-377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-378"><a href="#cb10-378" aria-hidden="true" tabindex="-1"></a>**Comparaison:**</span>
<span id="cb10-379"><a href="#cb10-379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-380"><a href="#cb10-380" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Critère <span class="pp">|</span> One-vs-Rest <span class="pp">|</span> Softmax <span class="pp">|</span></span>
<span id="cb10-381"><a href="#cb10-381" aria-hidden="true" tabindex="-1"></a><span class="pp">|---------|-------------|---------|</span></span>
<span id="cb10-382"><a href="#cb10-382" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Nombre de modèles <span class="pp">|</span> K modèles <span class="pp">|</span> 1 modèle <span class="pp">|</span></span>
<span id="cb10-383"><a href="#cb10-383" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Probabilités <span class="pp">|</span> Peuvent dépasser 1 (total) <span class="pp">|</span> Somment à 1 <span class="pp">|</span></span>
<span id="cb10-384"><a href="#cb10-384" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Entraînement <span class="pp">|</span> Plus rapide <span class="pp">|</span> Plus lent <span class="pp">|</span></span>
<span id="cb10-385"><a href="#cb10-385" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Performance <span class="pp">|</span> Généralement similaire <span class="pp">|</span> Légèrement meilleur <span class="pp">|</span></span>
<span id="cb10-386"><a href="#cb10-386" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Calibration <span class="pp">|</span> Moins bonne <span class="pp">|</span> Meilleure <span class="pp">|</span></span>
<span id="cb10-387"><a href="#cb10-387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-388"><a href="#cb10-388" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb10-389"><a href="#cb10-389" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-390"><a href="#cb10-390" aria-hidden="true" tabindex="-1"></a><span class="fu">## Partie 3: k-Nearest Neighbors</span></span>
<span id="cb10-391"><a href="#cb10-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-392"><a href="#cb10-392" aria-hidden="true" tabindex="-1"></a><span class="fu">### Exercice 3.1: Distance et Voisinage</span></span>
<span id="cb10-393"><a href="#cb10-393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-394"><a href="#cb10-394" aria-hidden="true" tabindex="-1"></a>Considérez les points suivants dans un espace 2D:</span>
<span id="cb10-395"><a href="#cb10-395" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-396"><a href="#cb10-396" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Point <span class="pp">|</span> x1 <span class="pp">|</span> x2 <span class="pp">|</span> Classe <span class="pp">|</span></span>
<span id="cb10-397"><a href="#cb10-397" aria-hidden="true" tabindex="-1"></a><span class="pp">|-------|----|----|--------|</span></span>
<span id="cb10-398"><a href="#cb10-398" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> A <span class="pp">|</span> 2 <span class="pp">|</span> 3 <span class="pp">|</span> Rouge <span class="pp">|</span></span>
<span id="cb10-399"><a href="#cb10-399" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> B <span class="pp">|</span> 3 <span class="pp">|</span> 4 <span class="pp">|</span> Rouge <span class="pp">|</span></span>
<span id="cb10-400"><a href="#cb10-400" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> C <span class="pp">|</span> 5 <span class="pp">|</span> 6 <span class="pp">|</span> Bleu <span class="pp">|</span></span>
<span id="cb10-401"><a href="#cb10-401" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> D <span class="pp">|</span> 5 <span class="pp">|</span> 4 <span class="pp">|</span> Bleu <span class="pp">|</span></span>
<span id="cb10-402"><a href="#cb10-402" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> E <span class="pp">|</span> 7 <span class="pp">|</span> 8 <span class="pp">|</span> Bleu <span class="pp">|</span></span>
<span id="cb10-403"><a href="#cb10-403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-404"><a href="#cb10-404" aria-hidden="true" tabindex="-1"></a>Nouveau point: **P (4, 5)**</span>
<span id="cb10-405"><a href="#cb10-405" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-406"><a href="#cb10-406" aria-hidden="true" tabindex="-1"></a>**Questions:**</span>
<span id="cb10-407"><a href="#cb10-407" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-408"><a href="#cb10-408" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Calculez la distance euclidienne entre P et chaque point</span>
<span id="cb10-409"><a href="#cb10-409" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Avec k=3, quelle classe sera prédite pour P?</span>
<span id="cb10-410"><a href="#cb10-410" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Que se passerait-il avec k=5?</span>
<span id="cb10-411"><a href="#cb10-411" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>Pourquoi est-il important de normaliser les données avant d'utiliser k-NN?</span>
<span id="cb10-412"><a href="#cb10-412" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-413"><a href="#cb10-413" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb10-414"><a href="#cb10-414" aria-hidden="true" tabindex="-1"></a><span class="fu">## Solution Exercice 3.1</span></span>
<span id="cb10-415"><a href="#cb10-415" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-418"><a href="#cb10-418" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb10-419"><a href="#cb10-419" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb10-420"><a href="#cb10-420" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb10-421"><a href="#cb10-421" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb10-422"><a href="#cb10-422" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-423"><a href="#cb10-423" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb10-424"><a href="#cb10-424" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb10-425"><a href="#cb10-425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-426"><a href="#cb10-426" aria-hidden="true" tabindex="-1"></a><span class="co"># Points</span></span>
<span id="cb10-427"><a href="#cb10-427" aria-hidden="true" tabindex="-1"></a>points <span class="op">=</span> {</span>
<span id="cb10-428"><a href="#cb10-428" aria-hidden="true" tabindex="-1"></a>    <span class="st">'A'</span>: ([<span class="dv">2</span>, <span class="dv">3</span>], <span class="st">'Rouge'</span>),</span>
<span id="cb10-429"><a href="#cb10-429" aria-hidden="true" tabindex="-1"></a>    <span class="st">'B'</span>: ([<span class="dv">3</span>, <span class="dv">4</span>], <span class="st">'Rouge'</span>),</span>
<span id="cb10-430"><a href="#cb10-430" aria-hidden="true" tabindex="-1"></a>    <span class="st">'C'</span>: ([<span class="dv">5</span>, <span class="dv">6</span>], <span class="st">'Bleu'</span>),</span>
<span id="cb10-431"><a href="#cb10-431" aria-hidden="true" tabindex="-1"></a>    <span class="st">'D'</span>: ([<span class="dv">5</span>, <span class="dv">4</span>], <span class="st">'Bleu'</span>),</span>
<span id="cb10-432"><a href="#cb10-432" aria-hidden="true" tabindex="-1"></a>    <span class="st">'E'</span>: ([<span class="dv">7</span>, <span class="dv">8</span>], <span class="st">'Bleu'</span>)</span>
<span id="cb10-433"><a href="#cb10-433" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb10-434"><a href="#cb10-434" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-435"><a href="#cb10-435" aria-hidden="true" tabindex="-1"></a><span class="co"># Nouveau point</span></span>
<span id="cb10-436"><a href="#cb10-436" aria-hidden="true" tabindex="-1"></a>P <span class="op">=</span> np.array([<span class="dv">4</span>, <span class="dv">5</span>])</span>
<span id="cb10-437"><a href="#cb10-437" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-438"><a href="#cb10-438" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Distances euclidiennes</span></span>
<span id="cb10-439"><a href="#cb10-439" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"1. Distances euclidiennes:"</span>)</span>
<span id="cb10-440"><a href="#cb10-440" aria-hidden="true" tabindex="-1"></a>distances <span class="op">=</span> {}</span>
<span id="cb10-441"><a href="#cb10-441" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> name, (coords, classe) <span class="kw">in</span> points.items():</span>
<span id="cb10-442"><a href="#cb10-442" aria-hidden="true" tabindex="-1"></a>    dist <span class="op">=</span> np.sqrt(np.<span class="bu">sum</span>((np.array(coords) <span class="op">-</span> P)<span class="op">**</span><span class="dv">2</span>))</span>
<span id="cb10-443"><a href="#cb10-443" aria-hidden="true" tabindex="-1"></a>    distances[name] <span class="op">=</span> (dist, classe)</span>
<span id="cb10-444"><a href="#cb10-444" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"   P → </span><span class="sc">{</span>name<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>dist<span class="sc">:.4f}</span><span class="ss"> (classe: </span><span class="sc">{</span>classe<span class="sc">}</span><span class="ss">)"</span>)</span>
<span id="cb10-445"><a href="#cb10-445" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-446"><a href="#cb10-446" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. k=3</span></span>
<span id="cb10-447"><a href="#cb10-447" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">2. k=3:"</span>)</span>
<span id="cb10-448"><a href="#cb10-448" aria-hidden="true" tabindex="-1"></a>sorted_distances <span class="op">=</span> <span class="bu">sorted</span>(distances.items(), key<span class="op">=</span><span class="kw">lambda</span> x: x[<span class="dv">1</span>][<span class="dv">0</span>])</span>
<span id="cb10-449"><a href="#cb10-449" aria-hidden="true" tabindex="-1"></a>k3_neighbors <span class="op">=</span> sorted_distances[:<span class="dv">3</span>]</span>
<span id="cb10-450"><a href="#cb10-450" aria-hidden="true" tabindex="-1"></a>k3_classes <span class="op">=</span> [classe <span class="cf">for</span> _, (_, classe) <span class="kw">in</span> k3_neighbors]</span>
<span id="cb10-451"><a href="#cb10-451" aria-hidden="true" tabindex="-1"></a>k3_prediction <span class="op">=</span> Counter(k3_classes).most_common(<span class="dv">1</span>)[<span class="dv">0</span>][<span class="dv">0</span>]</span>
<span id="cb10-452"><a href="#cb10-452" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   3 voisins les plus proches: </span><span class="sc">{</span>[n[<span class="dv">0</span>] <span class="cf">for</span> n <span class="kw">in</span> k3_neighbors]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb10-453"><a href="#cb10-453" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   Classes: </span><span class="sc">{</span>k3_classes<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb10-454"><a href="#cb10-454" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   Prédiction: </span><span class="sc">{</span>k3_prediction<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb10-455"><a href="#cb10-455" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-456"><a href="#cb10-456" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. k=5</span></span>
<span id="cb10-457"><a href="#cb10-457" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">3. k=5:"</span>)</span>
<span id="cb10-458"><a href="#cb10-458" aria-hidden="true" tabindex="-1"></a>k5_neighbors <span class="op">=</span> sorted_distances[:<span class="dv">5</span>]</span>
<span id="cb10-459"><a href="#cb10-459" aria-hidden="true" tabindex="-1"></a>k5_classes <span class="op">=</span> [classe <span class="cf">for</span> _, (_, classe) <span class="kw">in</span> k5_neighbors]</span>
<span id="cb10-460"><a href="#cb10-460" aria-hidden="true" tabindex="-1"></a>k5_prediction <span class="op">=</span> Counter(k5_classes).most_common(<span class="dv">1</span>)[<span class="dv">0</span>][<span class="dv">0</span>]</span>
<span id="cb10-461"><a href="#cb10-461" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   5 voisins les plus proches: </span><span class="sc">{</span>[n[<span class="dv">0</span>] <span class="cf">for</span> n <span class="kw">in</span> k5_neighbors]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb10-462"><a href="#cb10-462" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   Classes: </span><span class="sc">{</span>k5_classes<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb10-463"><a href="#cb10-463" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   Prédiction: </span><span class="sc">{</span>k5_prediction<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb10-464"><a href="#cb10-464" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-465"><a href="#cb10-465" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Importance de la normalisation</span></span>
<span id="cb10-466"><a href="#cb10-466" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">4. Importance de la normalisation:"</span>)</span>
<span id="cb10-467"><a href="#cb10-467" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   Sans normalisation, une feature avec une grande échelle"</span>)</span>
<span id="cb10-468"><a href="#cb10-468" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   dominera le calcul de distance."</span>)</span>
<span id="cb10-469"><a href="#cb10-469" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">   Exemple:"</span>)</span>
<span id="cb10-470"><a href="#cb10-470" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   - Feature 1 (âge): 20-80 → échelle ~60"</span>)</span>
<span id="cb10-471"><a href="#cb10-471" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   - Feature 2 (revenu): 20000-100000 → échelle ~80000"</span>)</span>
<span id="cb10-472"><a href="#cb10-472" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   → La distance sera dominée par le revenu!"</span>)</span>
<span id="cb10-473"><a href="#cb10-473" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb10-474"><a href="#cb10-474" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-475"><a href="#cb10-475" aria-hidden="true" tabindex="-1"></a>**Réponses:**</span>
<span id="cb10-476"><a href="#cb10-476" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-477"><a href="#cb10-477" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Distances:</span>
<span id="cb10-478"><a href="#cb10-478" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>P → A: 2.828</span>
<span id="cb10-479"><a href="#cb10-479" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>P → B: 1.414 (plus proche)</span>
<span id="cb10-480"><a href="#cb10-480" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>P → C: 1.414 (plus proche)</span>
<span id="cb10-481"><a href="#cb10-481" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>P → D: 1.414 (plus proche)</span>
<span id="cb10-482"><a href="#cb10-482" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>P → E: 4.243</span>
<span id="cb10-483"><a href="#cb10-483" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-484"><a href="#cb10-484" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Avec k=3: Les 3 voisins sont B (Rouge), C (Bleu), D (Bleu)</span>
<span id="cb10-485"><a href="#cb10-485" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Vote: 1 Rouge, 2 Bleus</span>
<span id="cb10-486"><a href="#cb10-486" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>**Prédiction: Bleu**</span>
<span id="cb10-487"><a href="#cb10-487" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-488"><a href="#cb10-488" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Avec k=5: Tous les points</span>
<span id="cb10-489"><a href="#cb10-489" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Vote: 2 Rouges, 3 Bleus</span>
<span id="cb10-490"><a href="#cb10-490" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>**Prédiction: Bleu** (même résultat)</span>
<span id="cb10-491"><a href="#cb10-491" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-492"><a href="#cb10-492" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>**Normalisation importante** car:</span>
<span id="cb10-493"><a href="#cb10-493" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Les features avec de grandes valeurs dominent le calcul de distance</span>
<span id="cb10-494"><a href="#cb10-494" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Exemple: Si une feature est en milliers et l'autre en dizaines, la première écrasera la seconde</span>
<span id="cb10-495"><a href="#cb10-495" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Solution: StandardScaler ou MinMaxScaler</span>
<span id="cb10-496"><a href="#cb10-496" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb10-497"><a href="#cb10-497" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-498"><a href="#cb10-498" aria-hidden="true" tabindex="-1"></a><span class="fu">## Partie 4: Naive Bayes</span></span>
<span id="cb10-499"><a href="#cb10-499" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-500"><a href="#cb10-500" aria-hidden="true" tabindex="-1"></a><span class="fu">### Exercice 4.1: Application du Théorème de Bayes</span></span>
<span id="cb10-501"><a href="#cb10-501" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-502"><a href="#cb10-502" aria-hidden="true" tabindex="-1"></a>Dataset pour classification de courriels:</span>
<span id="cb10-503"><a href="#cb10-503" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-504"><a href="#cb10-504" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Courriel <span class="pp">|</span> "gratuit" <span class="pp">|</span> "argent" <span class="pp">|</span> "viagra" <span class="pp">|</span> Classe <span class="pp">|</span></span>
<span id="cb10-505"><a href="#cb10-505" aria-hidden="true" tabindex="-1"></a><span class="pp">|----------|-----------|----------|----------|--------|</span></span>
<span id="cb10-506"><a href="#cb10-506" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> 1 <span class="pp">|</span> Oui <span class="pp">|</span> Non <span class="pp">|</span> Non <span class="pp">|</span> Spam <span class="pp">|</span></span>
<span id="cb10-507"><a href="#cb10-507" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> 2 <span class="pp">|</span> Oui <span class="pp">|</span> Oui <span class="pp">|</span> Oui <span class="pp">|</span> Spam <span class="pp">|</span></span>
<span id="cb10-508"><a href="#cb10-508" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> 3 <span class="pp">|</span> Non <span class="pp">|</span> Non <span class="pp">|</span> Non <span class="pp">|</span> Ham <span class="pp">|</span></span>
<span id="cb10-509"><a href="#cb10-509" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> 4 <span class="pp">|</span> Non <span class="pp">|</span> Non <span class="pp">|</span> Non <span class="pp">|</span> Ham <span class="pp">|</span></span>
<span id="cb10-510"><a href="#cb10-510" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> 5 <span class="pp">|</span> Oui <span class="pp">|</span> Oui <span class="pp">|</span> Non <span class="pp">|</span> Spam <span class="pp">|</span></span>
<span id="cb10-511"><a href="#cb10-511" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-512"><a href="#cb10-512" aria-hidden="true" tabindex="-1"></a>Nouveau courriel contient: **"gratuit"** et **"argent"**</span>
<span id="cb10-513"><a href="#cb10-513" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-514"><a href="#cb10-514" aria-hidden="true" tabindex="-1"></a>**Calculez P(Spam | gratuit, argent) et P(Ham | gratuit, argent)**</span>
<span id="cb10-515"><a href="#cb10-515" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-516"><a href="#cb10-516" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb10-517"><a href="#cb10-517" aria-hidden="true" tabindex="-1"></a><span class="fu">## Solution Exercice 4.1</span></span>
<span id="cb10-518"><a href="#cb10-518" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-521"><a href="#cb10-521" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb10-522"><a href="#cb10-522" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb10-523"><a href="#cb10-523" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb10-524"><a href="#cb10-524" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb10-525"><a href="#cb10-525" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-526"><a href="#cb10-526" aria-hidden="true" tabindex="-1"></a><span class="co"># Données</span></span>
<span id="cb10-527"><a href="#cb10-527" aria-hidden="true" tabindex="-1"></a>emails <span class="op">=</span> [</span>
<span id="cb10-528"><a href="#cb10-528" aria-hidden="true" tabindex="-1"></a>    {<span class="st">'gratuit'</span>: <span class="dv">1</span>, <span class="st">'argent'</span>: <span class="dv">0</span>, <span class="st">'viagra'</span>: <span class="dv">0</span>, <span class="st">'classe'</span>: <span class="st">'Spam'</span>},</span>
<span id="cb10-529"><a href="#cb10-529" aria-hidden="true" tabindex="-1"></a>    {<span class="st">'gratuit'</span>: <span class="dv">1</span>, <span class="st">'argent'</span>: <span class="dv">1</span>, <span class="st">'viagra'</span>: <span class="dv">1</span>, <span class="st">'classe'</span>: <span class="st">'Spam'</span>},</span>
<span id="cb10-530"><a href="#cb10-530" aria-hidden="true" tabindex="-1"></a>    {<span class="st">'gratuit'</span>: <span class="dv">0</span>, <span class="st">'argent'</span>: <span class="dv">0</span>, <span class="st">'viagra'</span>: <span class="dv">0</span>, <span class="st">'classe'</span>: <span class="st">'Ham'</span>},</span>
<span id="cb10-531"><a href="#cb10-531" aria-hidden="true" tabindex="-1"></a>    {<span class="st">'gratuit'</span>: <span class="dv">0</span>, <span class="st">'argent'</span>: <span class="dv">0</span>, <span class="st">'viagra'</span>: <span class="dv">0</span>, <span class="st">'classe'</span>: <span class="st">'Ham'</span>},</span>
<span id="cb10-532"><a href="#cb10-532" aria-hidden="true" tabindex="-1"></a>    {<span class="st">'gratuit'</span>: <span class="dv">1</span>, <span class="st">'argent'</span>: <span class="dv">1</span>, <span class="st">'viagra'</span>: <span class="dv">0</span>, <span class="st">'classe'</span>: <span class="st">'Spam'</span>},</span>
<span id="cb10-533"><a href="#cb10-533" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb10-534"><a href="#cb10-534" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-535"><a href="#cb10-535" aria-hidden="true" tabindex="-1"></a><span class="co"># Probabilités a priori</span></span>
<span id="cb10-536"><a href="#cb10-536" aria-hidden="true" tabindex="-1"></a>n_spam <span class="op">=</span> <span class="bu">sum</span>(<span class="dv">1</span> <span class="cf">for</span> e <span class="kw">in</span> emails <span class="cf">if</span> e[<span class="st">'classe'</span>] <span class="op">==</span> <span class="st">'Spam'</span>)</span>
<span id="cb10-537"><a href="#cb10-537" aria-hidden="true" tabindex="-1"></a>n_ham <span class="op">=</span> <span class="bu">sum</span>(<span class="dv">1</span> <span class="cf">for</span> e <span class="kw">in</span> emails <span class="cf">if</span> e[<span class="st">'classe'</span>] <span class="op">==</span> <span class="st">'Ham'</span>)</span>
<span id="cb10-538"><a href="#cb10-538" aria-hidden="true" tabindex="-1"></a>total <span class="op">=</span> <span class="bu">len</span>(emails)</span>
<span id="cb10-539"><a href="#cb10-539" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-540"><a href="#cb10-540" aria-hidden="true" tabindex="-1"></a>p_spam <span class="op">=</span> n_spam <span class="op">/</span> total</span>
<span id="cb10-541"><a href="#cb10-541" aria-hidden="true" tabindex="-1"></a>p_ham <span class="op">=</span> n_ham <span class="op">/</span> total</span>
<span id="cb10-542"><a href="#cb10-542" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-543"><a href="#cb10-543" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Probabilités a priori:"</span>)</span>
<span id="cb10-544"><a href="#cb10-544" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"P(Spam) = </span><span class="sc">{</span>n_spam<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>total<span class="sc">}</span><span class="ss"> = </span><span class="sc">{</span>p_spam<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb10-545"><a href="#cb10-545" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"P(Ham) = </span><span class="sc">{</span>n_ham<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>total<span class="sc">}</span><span class="ss"> = </span><span class="sc">{</span>p_ham<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb10-546"><a href="#cb10-546" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-547"><a href="#cb10-547" aria-hidden="true" tabindex="-1"></a><span class="co"># Probabilités conditionnelles pour Spam</span></span>
<span id="cb10-548"><a href="#cb10-548" aria-hidden="true" tabindex="-1"></a>spam_emails <span class="op">=</span> [e <span class="cf">for</span> e <span class="kw">in</span> emails <span class="cf">if</span> e[<span class="st">'classe'</span>] <span class="op">==</span> <span class="st">'Spam'</span>]</span>
<span id="cb10-549"><a href="#cb10-549" aria-hidden="true" tabindex="-1"></a>p_gratuit_spam <span class="op">=</span> <span class="bu">sum</span>(e[<span class="st">'gratuit'</span>] <span class="cf">for</span> e <span class="kw">in</span> spam_emails) <span class="op">/</span> n_spam</span>
<span id="cb10-550"><a href="#cb10-550" aria-hidden="true" tabindex="-1"></a>p_argent_spam <span class="op">=</span> <span class="bu">sum</span>(e[<span class="st">'argent'</span>] <span class="cf">for</span> e <span class="kw">in</span> spam_emails) <span class="op">/</span> n_spam</span>
<span id="cb10-551"><a href="#cb10-551" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-552"><a href="#cb10-552" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">P(gratuit|Spam) = </span><span class="sc">{</span>p_gratuit_spam<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb10-553"><a href="#cb10-553" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"P(argent|Spam) = </span><span class="sc">{</span>p_argent_spam<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb10-554"><a href="#cb10-554" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-555"><a href="#cb10-555" aria-hidden="true" tabindex="-1"></a><span class="co"># Probabilités conditionnelles pour Ham</span></span>
<span id="cb10-556"><a href="#cb10-556" aria-hidden="true" tabindex="-1"></a>ham_emails <span class="op">=</span> [e <span class="cf">for</span> e <span class="kw">in</span> emails <span class="cf">if</span> e[<span class="st">'classe'</span>] <span class="op">==</span> <span class="st">'Ham'</span>]</span>
<span id="cb10-557"><a href="#cb10-557" aria-hidden="true" tabindex="-1"></a>p_gratuit_ham <span class="op">=</span> <span class="bu">sum</span>(e[<span class="st">'gratuit'</span>] <span class="cf">for</span> e <span class="kw">in</span> ham_emails) <span class="op">/</span> n_ham</span>
<span id="cb10-558"><a href="#cb10-558" aria-hidden="true" tabindex="-1"></a>p_argent_ham <span class="op">=</span> <span class="bu">sum</span>(e[<span class="st">'argent'</span>] <span class="cf">for</span> e <span class="kw">in</span> ham_emails) <span class="op">/</span> n_ham</span>
<span id="cb10-559"><a href="#cb10-559" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-560"><a href="#cb10-560" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">P(gratuit|Ham) = </span><span class="sc">{</span>p_gratuit_ham<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb10-561"><a href="#cb10-561" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"P(argent|Ham) = </span><span class="sc">{</span>p_argent_ham<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb10-562"><a href="#cb10-562" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-563"><a href="#cb10-563" aria-hidden="true" tabindex="-1"></a><span class="co"># Calcul Naive Bayes (hypothèse d'indépendance)</span></span>
<span id="cb10-564"><a href="#cb10-564" aria-hidden="true" tabindex="-1"></a><span class="co"># P(Spam | gratuit, argent) $\propto$ P(gratuit|Spam) * P(argent|Spam) * P(Spam)</span></span>
<span id="cb10-565"><a href="#cb10-565" aria-hidden="true" tabindex="-1"></a>numerator_spam <span class="op">=</span> p_gratuit_spam <span class="op">*</span> p_argent_spam <span class="op">*</span> p_spam</span>
<span id="cb10-566"><a href="#cb10-566" aria-hidden="true" tabindex="-1"></a>numerator_ham <span class="op">=</span> p_gratuit_ham <span class="op">*</span> p_argent_ham <span class="op">*</span> p_ham</span>
<span id="cb10-567"><a href="#cb10-567" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-568"><a href="#cb10-568" aria-hidden="true" tabindex="-1"></a><span class="co"># Normalisation</span></span>
<span id="cb10-569"><a href="#cb10-569" aria-hidden="true" tabindex="-1"></a>p_spam_given_words <span class="op">=</span> numerator_spam <span class="op">/</span> (numerator_spam <span class="op">+</span> numerator_ham)</span>
<span id="cb10-570"><a href="#cb10-570" aria-hidden="true" tabindex="-1"></a>p_ham_given_words <span class="op">=</span> numerator_ham <span class="op">/</span> (numerator_spam <span class="op">+</span> numerator_ham)</span>
<span id="cb10-571"><a href="#cb10-571" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-572"><a href="#cb10-572" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Résultats:"</span>)</span>
<span id="cb10-573"><a href="#cb10-573" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"P(Spam | gratuit, argent) = </span><span class="sc">{</span>p_spam_given_words<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb10-574"><a href="#cb10-574" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"P(Ham | gratuit, argent) = </span><span class="sc">{</span>p_ham_given_words<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb10-575"><a href="#cb10-575" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Prédiction: </span><span class="sc">{</span><span class="st">'Spam'</span> <span class="cf">if</span> p_spam_given_words <span class="op">&gt;</span> p_ham_given_words <span class="cf">else</span> <span class="st">'Ham'</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb10-576"><a href="#cb10-576" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb10-577"><a href="#cb10-577" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-578"><a href="#cb10-578" aria-hidden="true" tabindex="-1"></a>**Résolution manuelle:**</span>
<span id="cb10-579"><a href="#cb10-579" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-580"><a href="#cb10-580" aria-hidden="true" tabindex="-1"></a>**Étape 1: Probabilités a priori**</span>
<span id="cb10-581"><a href="#cb10-581" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-582"><a href="#cb10-582" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>P(Spam) = 3/5 = 0.6</span>
<span id="cb10-583"><a href="#cb10-583" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>P(Ham) = 2/5 = 0.4</span>
<span id="cb10-584"><a href="#cb10-584" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-585"><a href="#cb10-585" aria-hidden="true" tabindex="-1"></a>**Étape 2: Probabilités conditionnelles**</span>
<span id="cb10-586"><a href="#cb10-586" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-587"><a href="#cb10-587" aria-hidden="true" tabindex="-1"></a>Pour Spam:</span>
<span id="cb10-588"><a href="#cb10-588" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-589"><a href="#cb10-589" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>P(gratuit|Spam) = 3/3 = 1.0</span>
<span id="cb10-590"><a href="#cb10-590" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>P(argent|Spam) = 2/3 $\approx$ 0.67</span>
<span id="cb10-591"><a href="#cb10-591" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-592"><a href="#cb10-592" aria-hidden="true" tabindex="-1"></a>Pour Ham:</span>
<span id="cb10-593"><a href="#cb10-593" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-594"><a href="#cb10-594" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>P(gratuit|Ham) = 0/2 = 0</span>
<span id="cb10-595"><a href="#cb10-595" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>P(argent|Ham) = 0/2 = 0</span>
<span id="cb10-596"><a href="#cb10-596" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-597"><a href="#cb10-597" aria-hidden="true" tabindex="-1"></a>**Étape 3: Application de Bayes**</span>
<span id="cb10-598"><a href="#cb10-598" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-599"><a href="#cb10-599" aria-hidden="true" tabindex="-1"></a>P(Spam | gratuit, argent) $\propto$ 1.0 × 0.67 × 0.6 = 0.4</span>
<span id="cb10-600"><a href="#cb10-600" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-601"><a href="#cb10-601" aria-hidden="true" tabindex="-1"></a>P(Ham | gratuit, argent) $\propto$ 0 × 0 × 0.4 = 0</span>
<span id="cb10-602"><a href="#cb10-602" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-603"><a href="#cb10-603" aria-hidden="true" tabindex="-1"></a>**Prédiction: Spam** (avec 100% de confiance)</span>
<span id="cb10-604"><a href="#cb10-604" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb10-605"><a href="#cb10-605" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-606"><a href="#cb10-606" aria-hidden="true" tabindex="-1"></a><span class="fu">## Partie 5: Gradient Boosting (XGBoost/LightGBM)</span></span>
<span id="cb10-607"><a href="#cb10-607" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-608"><a href="#cb10-608" aria-hidden="true" tabindex="-1"></a><span class="fu">### Exercice 5.1: Comprendre le Boosting</span></span>
<span id="cb10-609"><a href="#cb10-609" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-610"><a href="#cb10-610" aria-hidden="true" tabindex="-1"></a>**Questions conceptuelles:**</span>
<span id="cb10-611"><a href="#cb10-611" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-612"><a href="#cb10-612" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Quelle est la différence fondamentale entre Random Forest (Bagging) et Gradient Boosting?</span>
<span id="cb10-613"><a href="#cb10-613" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Pourquoi le Gradient Boosting est-il plus sensible à l'overfitting que Random Forest?</span>
<span id="cb10-614"><a href="#cb10-614" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Quels sont les 3 hyperparamètres les plus importants à ajuster pour XGBoost/LightGBM?</span>
<span id="cb10-615"><a href="#cb10-615" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-616"><a href="#cb10-616" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb10-617"><a href="#cb10-617" aria-hidden="true" tabindex="-1"></a><span class="fu">## Solution Exercice 5.1</span></span>
<span id="cb10-618"><a href="#cb10-618" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-619"><a href="#cb10-619" aria-hidden="true" tabindex="-1"></a>📎 **Lien du Slide  :** <span class="co">[</span><span class="ot">Gradient Boosting — Classification</span><span class="co">](https://nevermind78.github.io/AN_slides/GB_C.html#/title-slide)</span></span>
<span id="cb10-620"><a href="#cb10-620" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-621"><a href="#cb10-621" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-622"><a href="#cb10-622" aria-hidden="true" tabindex="-1"></a>**1. Différence Bagging vs Boosting:**</span>
<span id="cb10-623"><a href="#cb10-623" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-624"><a href="#cb10-624" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Aspect <span class="pp">|</span> Random Forest (Bagging) <span class="pp">|</span> Gradient Boosting <span class="pp">|</span></span>
<span id="cb10-625"><a href="#cb10-625" aria-hidden="true" tabindex="-1"></a><span class="pp">|--------|------------------------|-------------------|</span></span>
<span id="cb10-626"><a href="#cb10-626" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> **Construction** <span class="pp">|</span> Parallèle (arbres indépendants) <span class="pp">|</span> Séquentielle (arbres dépendants) <span class="pp">|</span></span>
<span id="cb10-627"><a href="#cb10-627" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> **Objectif** <span class="pp">|</span> Réduire la variance <span class="pp">|</span> Réduire le biais <span class="pp">|</span></span>
<span id="cb10-628"><a href="#cb10-628" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> **Données** <span class="pp">|</span> Bootstrap (échantillonnage) <span class="pp">|</span> Totalité des données <span class="pp">|</span></span>
<span id="cb10-629"><a href="#cb10-629" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> **Poids** <span class="pp">|</span> Tous arbres égaux <span class="pp">|</span> Arbres pondérés <span class="pp">|</span></span>
<span id="cb10-630"><a href="#cb10-630" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> **Prédiction** <span class="pp">|</span> Moyenne simple <span class="pp">|</span> Somme pondérée <span class="pp">|</span></span>
<span id="cb10-631"><a href="#cb10-631" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> **Focus** <span class="pp">|</span> Erreurs aléatoires <span class="pp">|</span> Erreurs résiduelles <span class="pp">|</span></span>
<span id="cb10-632"><a href="#cb10-632" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-633"><a href="#cb10-633" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-634"><a href="#cb10-634" aria-hidden="true" tabindex="-1"></a>**Diagramme :**</span>
<span id="cb10-635"><a href="#cb10-635" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-638"><a href="#cb10-638" aria-hidden="true" tabindex="-1"></a><span class="in">```{mermaid}</span></span>
<span id="cb10-639"><a href="#cb10-639" aria-hidden="true" tabindex="-1"></a>graph LR</span>
<span id="cb10-640"><a href="#cb10-640" aria-hidden="true" tabindex="-1"></a>    A[Random Forest] --&gt; B[Arbre <span class="dv">1</span>]</span>
<span id="cb10-641"><a href="#cb10-641" aria-hidden="true" tabindex="-1"></a>    A --&gt; C[Arbre <span class="dv">2</span>]</span>
<span id="cb10-642"><a href="#cb10-642" aria-hidden="true" tabindex="-1"></a>    A --&gt; D[Arbre N]</span>
<span id="cb10-643"><a href="#cb10-643" aria-hidden="true" tabindex="-1"></a>    B --&gt; E[Vote]</span>
<span id="cb10-644"><a href="#cb10-644" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb10-645"><a href="#cb10-645" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-646"><a href="#cb10-646" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-647"><a href="#cb10-647" aria-hidden="true" tabindex="-1"></a>**2. Sensibilité à l'overfitting:**</span>
<span id="cb10-648"><a href="#cb10-648" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-649"><a href="#cb10-649" aria-hidden="true" tabindex="-1"></a>Gradient Boosting est plus sensible car:</span>
<span id="cb10-650"><a href="#cb10-650" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Chaque arbre se concentre sur les erreurs précédentes</span>
<span id="cb10-651"><a href="#cb10-651" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Risque d'apprendre le bruit si trop d'itérations</span>
<span id="cb10-652"><a href="#cb10-652" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Peut "mémoriser" les cas difficiles du train set</span>
<span id="cb10-653"><a href="#cb10-653" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Pas de randomisation par défaut (contrairement à RF)</span>
<span id="cb10-654"><a href="#cb10-654" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-655"><a href="#cb10-655" aria-hidden="true" tabindex="-1"></a>**Solutions:**</span>
<span id="cb10-656"><a href="#cb10-656" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Limiter le nombre d'arbres (<span class="in">`n_estimators`</span>)</span>
<span id="cb10-657"><a href="#cb10-657" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Réduire le taux d'apprentissage (<span class="in">`learning_rate`</span>)</span>
<span id="cb10-658"><a href="#cb10-658" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Limiter la profondeur (<span class="in">`max_depth`</span>)</span>
<span id="cb10-659"><a href="#cb10-659" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Early stopping avec validation set</span>
<span id="cb10-660"><a href="#cb10-660" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-661"><a href="#cb10-661" aria-hidden="true" tabindex="-1"></a>**3. Hyperparamètres clés:**</span>
<span id="cb10-662"><a href="#cb10-662" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-665"><a href="#cb10-665" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb10-666"><a href="#cb10-666" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb10-667"><a href="#cb10-667" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb10-668"><a href="#cb10-668" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-669"><a href="#cb10-669" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> xgboost <span class="im">import</span> XGBClassifier</span>
<span id="cb10-670"><a href="#cb10-670" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-671"><a href="#cb10-671" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> XGBClassifier(</span>
<span id="cb10-672"><a href="#cb10-672" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 1. Nombre d'arbres</span></span>
<span id="cb10-673"><a href="#cb10-673" aria-hidden="true" tabindex="-1"></a>    n_estimators<span class="op">=</span><span class="dv">100</span>,  <span class="co"># Plus = meilleur mais risque overfitting</span></span>
<span id="cb10-674"><a href="#cb10-674" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-675"><a href="#cb10-675" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 2. Taux d'apprentissage</span></span>
<span id="cb10-676"><a href="#cb10-676" aria-hidden="true" tabindex="-1"></a>    learning_rate<span class="op">=</span><span class="fl">0.1</span>,  <span class="co"># Plus faible = besoin de plus d'arbres</span></span>
<span id="cb10-677"><a href="#cb10-677" aria-hidden="true" tabindex="-1"></a>                        <span class="co"># Typage: 0.01-0.3</span></span>
<span id="cb10-678"><a href="#cb10-678" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-679"><a href="#cb10-679" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 3. Profondeur maximale</span></span>
<span id="cb10-680"><a href="#cb10-680" aria-hidden="true" tabindex="-1"></a>    max_depth<span class="op">=</span><span class="dv">6</span>,  <span class="co"># Plus profond = plus complexe</span></span>
<span id="cb10-681"><a href="#cb10-681" aria-hidden="true" tabindex="-1"></a>                  <span class="co"># Typique: 3-10</span></span>
<span id="cb10-682"><a href="#cb10-682" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-683"><a href="#cb10-683" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Bonus importants:</span></span>
<span id="cb10-684"><a href="#cb10-684" aria-hidden="true" tabindex="-1"></a>    subsample<span class="op">=</span><span class="fl">0.8</span>,      <span class="co"># Échantillonnage des données (0.5-1.0)</span></span>
<span id="cb10-685"><a href="#cb10-685" aria-hidden="true" tabindex="-1"></a>    colsample_bytree<span class="op">=</span><span class="fl">0.8</span>,  <span class="co"># Échantillonnage des features</span></span>
<span id="cb10-686"><a href="#cb10-686" aria-hidden="true" tabindex="-1"></a>    min_child_weight<span class="op">=</span><span class="dv">1</span>,    <span class="co"># Régularisation</span></span>
<span id="cb10-687"><a href="#cb10-687" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-688"><a href="#cb10-688" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb10-689"><a href="#cb10-689" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb10-690"><a href="#cb10-690" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb10-691"><a href="#cb10-691" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-692"><a href="#cb10-692" aria-hidden="true" tabindex="-1"></a>**Recommandations de tuning:**</span>
<span id="cb10-693"><a href="#cb10-693" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-694"><a href="#cb10-694" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Commencer avec:**</span>
<span id="cb10-695"><a href="#cb10-695" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-696"><a href="#cb10-696" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span><span class="in">`learning_rate=0.1`</span></span>
<span id="cb10-697"><a href="#cb10-697" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span><span class="in">`max_depth=6`</span></span>
<span id="cb10-698"><a href="#cb10-698" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span><span class="in">`n_estimators=100`</span></span>
<span id="cb10-699"><a href="#cb10-699" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-700"><a href="#cb10-700" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Puis optimiser:**</span>
<span id="cb10-701"><a href="#cb10-701" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-702"><a href="#cb10-702" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Augmenter <span class="in">`n_estimators`</span> + réduire <span class="in">`learning_rate`</span></span>
<span id="cb10-703"><a href="#cb10-703" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Ajuster <span class="in">`max_depth`</span> (3-10)</span>
<span id="cb10-704"><a href="#cb10-704" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Ajouter régularisation (<span class="in">`subsample`</span>, <span class="in">`colsample_bytree`</span>)</span>
<span id="cb10-705"><a href="#cb10-705" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-706"><a href="#cb10-706" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**Utiliser early stopping:**</span>
<span id="cb10-707"><a href="#cb10-707" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-710"><a href="#cb10-710" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb10-711"><a href="#cb10-711" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb10-712"><a href="#cb10-712" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb10-713"><a href="#cb10-713" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-714"><a href="#cb10-714" aria-hidden="true" tabindex="-1"></a>model.fit(</span>
<span id="cb10-715"><a href="#cb10-715" aria-hidden="true" tabindex="-1"></a>    X_train, y_train,</span>
<span id="cb10-716"><a href="#cb10-716" aria-hidden="true" tabindex="-1"></a>    eval_set<span class="op">=</span>[(X_val, y_val)],</span>
<span id="cb10-717"><a href="#cb10-717" aria-hidden="true" tabindex="-1"></a>    early_stopping_rounds<span class="op">=</span><span class="dv">10</span>,  <span class="co"># Stop si pas d'amélioration</span></span>
<span id="cb10-718"><a href="#cb10-718" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="va">False</span></span>
<span id="cb10-719"><a href="#cb10-719" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb10-720"><a href="#cb10-720" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb10-721"><a href="#cb10-721" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb10-722"><a href="#cb10-722" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-723"><a href="#cb10-723" aria-hidden="true" tabindex="-1"></a><span class="fu">## Exercices Récapitulatifs</span></span>
<span id="cb10-724"><a href="#cb10-724" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-725"><a href="#cb10-725" aria-hidden="true" tabindex="-1"></a>::: {.callout-warning icon=false}</span>
<span id="cb10-726"><a href="#cb10-726" aria-hidden="true" tabindex="-1"></a><span class="fu">## Exercice Final: Choix d'Algorithme</span></span>
<span id="cb10-727"><a href="#cb10-727" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-728"><a href="#cb10-728" aria-hidden="true" tabindex="-1"></a>Pour chacun des scénarios suivants, recommandez un algorithme et justifiez:</span>
<span id="cb10-729"><a href="#cb10-729" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-730"><a href="#cb10-730" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Diagnostic médical** (interprétabilité cruciale, 1000 patients, 20 features)</span>
<span id="cb10-731"><a href="#cb10-731" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Détection de fraude** (millions de transactions, temps réel, déséquilibre 99/1)</span>
<span id="cb10-732"><a href="#cb10-732" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**Classification d'images** (50000 images, haute dimension, GPU disponible)</span>
<span id="cb10-733"><a href="#cb10-733" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>**Prédiction de churn** (10000 clients, features mixtes, besoin de probabilités calibrées)</span>
<span id="cb10-734"><a href="#cb10-734" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>**Classification de textes** (emails spam, 100000 emails, features = mots)</span>
<span id="cb10-735"><a href="#cb10-735" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb10-736"><a href="#cb10-736" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-737"><a href="#cb10-737" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb10-738"><a href="#cb10-738" aria-hidden="true" tabindex="-1"></a><span class="fu">## Solution Exercice Final</span></span>
<span id="cb10-739"><a href="#cb10-739" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-740"><a href="#cb10-740" aria-hidden="true" tabindex="-1"></a>**1. Diagnostic médical:**</span>
<span id="cb10-741"><a href="#cb10-741" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-742"><a href="#cb10-742" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Recommandation**: Decision Tree ou Régression Logistique</span>
<span id="cb10-743"><a href="#cb10-743" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Justification**:</span>
<span id="cb10-744"><a href="#cb10-744" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-745"><a href="#cb10-745" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Interprétabilité essentielle pour les médecins</span>
<span id="cb10-746"><a href="#cb10-746" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Dataset de taille modérée</span>
<span id="cb10-747"><a href="#cb10-747" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Besoin de comprendre les règles de décision</span>
<span id="cb10-748"><a href="#cb10-748" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Alternative: Random Forest + feature importance</span>
<span id="cb10-749"><a href="#cb10-749" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-750"><a href="#cb10-750" aria-hidden="true" tabindex="-1"></a>**2. Détection de fraude:**</span>
<span id="cb10-751"><a href="#cb10-751" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-752"><a href="#cb10-752" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Recommandation**: XGBoost/LightGBM</span>
<span id="cb10-753"><a href="#cb10-753" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-754"><a href="#cb10-754" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Justification**:</span>
<span id="cb10-755"><a href="#cb10-755" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-756"><a href="#cb10-756" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Excellent avec classes déséquilibrées (paramètre <span class="in">`scale_pos_weight`</span>)</span>
<span id="cb10-757"><a href="#cb10-757" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Très rapide en prédiction (important pour temps réel)</span>
<span id="cb10-758"><a href="#cb10-758" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Gère bien les grandes données</span>
<span id="cb10-759"><a href="#cb10-759" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Robuste et performant</span>
<span id="cb10-760"><a href="#cb10-760" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Peut utiliser early stopping</span>
<span id="cb10-761"><a href="#cb10-761" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-762"><a href="#cb10-762" aria-hidden="true" tabindex="-1"></a>**3. Classification d'images:**</span>
<span id="cb10-763"><a href="#cb10-763" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-764"><a href="#cb10-764" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Recommandation**: CNN (Deep Learning) - hors scope pour l'instant</span>
<span id="cb10-765"><a href="#cb10-765" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Justification actuelle avec ML classique**:</span>
<span id="cb10-766"><a href="#cb10-766" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-767"><a href="#cb10-767" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Random Forest avec features extraites (HOG, SIFT)</span>
<span id="cb10-768"><a href="#cb10-768" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>SVM avec kernel RBF</span>
<span id="cb10-769"><a href="#cb10-769" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Mais performances limitées vs Deep Learning</span>
<span id="cb10-770"><a href="#cb10-770" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-771"><a href="#cb10-771" aria-hidden="true" tabindex="-1"></a>**4. Prédiction de churn:**</span>
<span id="cb10-772"><a href="#cb10-772" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-773"><a href="#cb10-773" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Recommandation**: Régression Logistique ou Gradient Boosting</span>
<span id="cb10-774"><a href="#cb10-774" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Justification**:</span>
<span id="cb10-775"><a href="#cb10-775" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-776"><a href="#cb10-776" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Logistic Regression: probabilités bien calibrées, interprétable</span>
<span id="cb10-777"><a href="#cb10-777" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Gradient Boosting: meilleures performances, feature importance</span>
<span id="cb10-778"><a href="#cb10-778" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Dataset de taille moyenne</span>
<span id="cb10-779"><a href="#cb10-779" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Features mixtes gérées par les deux</span>
<span id="cb10-780"><a href="#cb10-780" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-781"><a href="#cb10-781" aria-hidden="true" tabindex="-1"></a>**5. Classification de textes:**</span>
<span id="cb10-782"><a href="#cb10-782" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-783"><a href="#cb10-783" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Recommandation**: Naive Bayes (Multinomial)</span>
<span id="cb10-784"><a href="#cb10-784" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Justification**:</span>
<span id="cb10-785"><a href="#cb10-785" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-786"><a href="#cb10-786" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Très performant pour la classification de texte</span>
<span id="cb10-787"><a href="#cb10-787" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Rapide à entraîner et prédire</span>
<span id="cb10-788"><a href="#cb10-788" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Gère bien les grandes dimensions (nombreux mots)</span>
<span id="cb10-789"><a href="#cb10-789" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Probabilités natives</span>
<span id="cb10-790"><a href="#cb10-790" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Alternative: Régression Logistique</span>
<span id="cb10-791"><a href="#cb10-791" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb10-792"><a href="#cb10-792" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-793"><a href="#cb10-793" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-794"><a href="#cb10-794" aria-hidden="true" tabindex="-1"></a><span class="fu">## Résumé du TD</span></span>
<span id="cb10-795"><a href="#cb10-795" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-796"><a href="#cb10-796" aria-hidden="true" tabindex="-1"></a>::: {.callout-important icon=false}</span>
<span id="cb10-797"><a href="#cb10-797" aria-hidden="true" tabindex="-1"></a><span class="fu">## Points clés à retenir</span></span>
<span id="cb10-798"><a href="#cb10-798" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-799"><a href="#cb10-799" aria-hidden="true" tabindex="-1"></a><span class="fu">### Algorithmes et leurs forces</span></span>
<span id="cb10-800"><a href="#cb10-800" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-801"><a href="#cb10-801" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Decision Tree**</span>
<span id="cb10-802"><a href="#cb10-802" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>$\checkmark$ Interprétable, visuel</span>
<span id="cb10-803"><a href="#cb10-803" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>X Overfitting, instable</span>
<span id="cb10-804"><a href="#cb10-804" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-805"><a href="#cb10-805" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Random Forest**</span>
<span id="cb10-806"><a href="#cb10-806" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>$\checkmark$ Robuste, performant</span>
<span id="cb10-807"><a href="#cb10-807" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>X Moins interprétable, mémoire</span>
<span id="cb10-808"><a href="#cb10-808" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-809"><a href="#cb10-809" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**SVM**</span>
<span id="cb10-810"><a href="#cb10-810" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>$\checkmark$ Excellent en haute dimension</span>
<span id="cb10-811"><a href="#cb10-811" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>X Lent, difficile à interpréter</span>
<span id="cb10-812"><a href="#cb10-812" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-813"><a href="#cb10-813" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>**Naive Bayes**</span>
<span id="cb10-814"><a href="#cb10-814" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>$\checkmark$ Rapide, bon pour texte</span>
<span id="cb10-815"><a href="#cb10-815" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>X Hypothèse d'indépendance forte</span>
<span id="cb10-816"><a href="#cb10-816" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-817"><a href="#cb10-817" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>**Régression Logistique**</span>
<span id="cb10-818"><a href="#cb10-818" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>$\checkmark$ Probabilités calibrées, interprétable</span>
<span id="cb10-819"><a href="#cb10-819" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>X Assume linéarité</span>
<span id="cb10-820"><a href="#cb10-820" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-821"><a href="#cb10-821" aria-hidden="true" tabindex="-1"></a><span class="ss">6. </span>**k-NN**</span>
<span id="cb10-822"><a href="#cb10-822" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>$\checkmark$ Simple, pas de training</span>
<span id="cb10-823"><a href="#cb10-823" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>X Lent en prédiction, besoin normalisation</span>
<span id="cb10-824"><a href="#cb10-824" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-825"><a href="#cb10-825" aria-hidden="true" tabindex="-1"></a><span class="ss">7. </span>**Gradient Boosting**</span>
<span id="cb10-826"><a href="#cb10-826" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>$\checkmark$ Très performant, gère déséquilibre</span>
<span id="cb10-827"><a href="#cb10-827" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>X Sensible overfitting, plus complexe</span>
<span id="cb10-828"><a href="#cb10-828" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb10-829"><a href="#cb10-829" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-830"><a href="#cb10-830" aria-hidden="true" tabindex="-1"></a><span class="fu">## Pour le Prochain Cours</span></span>
<span id="cb10-831"><a href="#cb10-831" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-832"><a href="#cb10-832" aria-hidden="true" tabindex="-1"></a>Préparez-vous pour le **TD2 sur les Critères d'Évaluation** où nous approfondirons:</span>
<span id="cb10-833"><a href="#cb10-833" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Matrice de confusion</span>
<span id="cb10-834"><a href="#cb10-834" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Precision, Recall, F1-score</span>
<span id="cb10-835"><a href="#cb10-835" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Courbe ROC et AUC</span>
<span id="cb10-836"><a href="#cb10-836" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Choix de métriques selon le contexte</span>
<span id="cb10-837"><a href="#cb10-837" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-838"><a href="#cb10-838" aria-hidden="true" tabindex="-1"></a><span class="fu">## Ressources Complémentaires</span></span>
<span id="cb10-839"><a href="#cb10-839" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-840"><a href="#cb10-840" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span><span class="co">[</span><span class="ot">Scikit-learn: Choosing the right estimator</span><span class="co">](https://scikit-learn.org/stable/tutorial/machine_learning_map/)</span></span>
<span id="cb10-841"><a href="#cb10-841" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span><span class="co">[</span><span class="ot">StatQuest: Decision Trees</span><span class="co">](https://www.youtube.com/watch?v=7VeUPuFGJHk)</span></span>
<span id="cb10-842"><a href="#cb10-842" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span><span class="co">[</span><span class="ot">XGBoost Documentation</span><span class="co">](https://xgboost.readthedocs.io/)</span><span class="dt">&lt;/</span><span class="kw">parameter</span><span class="dt">&gt;</span></span>
<span id="cb10-843"><a href="#cb10-843" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-844"><a href="#cb10-844" aria-hidden="true" tabindex="-1"></a><span class="fu">## Correction</span></span>
<span id="cb10-845"><a href="#cb10-845" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-846"><a href="#cb10-846" aria-hidden="true" tabindex="-1"></a>📎 **Lien de la correction  :** <span class="co">[</span><span class="ot">TD1 — Modèles de Classification de Base</span><span class="co">](https://nevermind78.github.io/AN_slides/td1_corr_eng.html#/title-slide)</span></span>
</code></pre></div><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></div>
</div></div></div></div></div>
</div> <!-- /content -->




</body></html>