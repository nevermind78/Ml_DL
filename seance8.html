<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.27">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Séance 8: TP3 - Régression &amp; Optimisation – Machine Learning et Deep Learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./seance9.html" rel="next">
<link href="./seance7.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-8b4baf804e461d9b72633f0de59a0cac.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark-f1aadacce99040138bbb613f9330654f.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-8b4baf804e461d9b72633f0de59a0cac.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-670c757105cc8b81a53606a71844536c.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark-b7200e4a2f6cd71dc52354e94e906ccc.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="site_libs/bootstrap/bootstrap-670c757105cc8b81a53606a71844536c.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<!-- Google Translate Widget -->
</head><body class="nav-sidebar floating quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script><div id="google_translate_element"></div>

<script type="text/javascript">
function googleTranslateElementInit() {
  new google.translate.TranslateElement({
    pageLanguage: 'fr',
    includedLanguages: 'fr,en', // Seulement FR et EN
    layout: google.translate.TranslateElement.InlineLayout.SIMPLE,
    autoDisplay: false
  }, 'google_translate_element');
}
</script>

<script type="text/javascript" src="https://translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script>

<style>
/* Style pour le widget Google Translate - MODIFIÉ */
#google_translate_element {
  position: fixed;
  top: 10px;
  right: 10px;
  z-index: 9999;
  background: white;
  padding: 2px;
  border-radius: 20px; /* Forme arrondie */
  box-shadow: 0 1px 3px rgba(0,0,0,0.1);
  border: 1px solid #ddd;
}

/* Cacher le branding Google */
.goog-te-gadget {
  font-size: 0 !important;
}

.goog-te-gadget-simple {
  background-color: transparent !important;
  border: none !important;
  padding: 0 !important;
}

.goog-te-menu-value span {
  color: #333 !important;
  font-size: 13px !important;
}

.goog-te-menu-value {
  color: #333 !important;
  border: none !important;
  background: transparent !important;
  padding: 4px 10px !important;
  border-radius: 15px !important;
}

/* Style personnalisé - Afficher seulement FR/EN */
.goog-te-gadget .goog-te-menu-value span:first-child {
  display: none !important;
}

/* Remplacer le texte par FR/EN seulement */
.goog-te-gadget .goog-te-menu-value span:last-child {
  display: inline-block;
  min-width: 30px;
  text-align: center;
}

/* Cacher la flèche */
.goog-te-gadget .goog-te-menu-value span:last-child:after {
  content: '';
  display: none;
}

/* Correction pour l'affichage */
.goog-te-banner-frame.skiptranslate {
  display: none !important;
}

body {
  top: 0px !important;
}

/* Style pour le menu déroulant */
.goog-te-menu2 {
  border-radius: 10px !important;
  box-shadow: 0 2px 8px rgba(0,0,0,0.15) !important;
  border: 1px solid #eee !important;
  min-width: 60px !important;
}

.goog-te-menu2-item {
  padding: 8px 12px !important;
  font-size: 13px !important;
  text-align: center;
}

/* Garder seulement FR et EN dans le menu */
.goog-te-menu2-item div:first-child {
  font-weight: 500;
}
</style>






<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./seance1.html">Partie 1: Machine Learning Fondamental</a></li><li class="breadcrumb-item"><a href="./seance8.html"><span class="chapter-title">Séance 8: TP3 - Régression &amp; Optimisation</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Machine Learning et Deep Learning</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/nevermind78/Ml_DL" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Présentation du Cours</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Partie 1: Machine Learning Fondamental</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./seance1.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Séance 1: Introduction IA et Machine Learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./seance2.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Séance 2: Apprentissage Supervisé - Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./seance3.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Séance 3: TP1 - Pipeline de Classification Binaire</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./seance4.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Séance 4: TD1 - Modèles de Classification de Base</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./seance5.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Séance 5: TD2 - Critères d’Évaluation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./seance6.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Séance 6: TP2 - Classification Multi-classes &amp; Optimisation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./seance7.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Séance 7: Cours - Apprentissage Supervisé : Régression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./seance8.html" class="sidebar-item-text sidebar-link active"><span class="chapter-title">Séance 8: TP3 - Régression &amp; Optimisation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./seance9.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Séance 9: Apprentissage Non Supervisé</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./seance10.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Séance 10: TP4 - Clustering &amp; Réduction de Dimension</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#chargement-et-exploration-du-dataset" id="toc-chargement-et-exploration-du-dataset" class="nav-link" data-scroll-target="#chargement-et-exploration-du-dataset">1. Chargement et Exploration du Dataset</a>
  <ul class="collapse">
  <li><a href="#exercice-1.1-analyse-exploratoire" id="toc-exercice-1.1-analyse-exploratoire" class="nav-link" data-scroll-target="#exercice-1.1-analyse-exploratoire">Exercice 1.1: Analyse Exploratoire</a></li>
  </ul></li>
  <li><a href="#prétraitement-et-split" id="toc-prétraitement-et-split" class="nav-link" data-scroll-target="#prétraitement-et-split">2. Prétraitement et Split</a></li>
  <li><a href="#modèles-de-base" id="toc-modèles-de-base" class="nav-link" data-scroll-target="#modèles-de-base">3. Modèles de Base</a>
  <ul class="collapse">
  <li><a href="#exercice-3.1-régression-linéaire-simple" id="toc-exercice-3.1-régression-linéaire-simple" class="nav-link" data-scroll-target="#exercice-3.1-régression-linéaire-simple">Exercice 3.1: Régression Linéaire Simple</a></li>
  </ul></li>
  <li><a href="#modèles-régularisés" id="toc-modèles-régularisés" class="nav-link" data-scroll-target="#modèles-régularisés">4. Modèles Régularisés</a>
  <ul class="collapse">
  <li><a href="#exercice-4.1-comparaison-ridge-lasso-elasticnet" id="toc-exercice-4.1-comparaison-ridge-lasso-elasticnet" class="nav-link" data-scroll-target="#exercice-4.1-comparaison-ridge-lasso-elasticnet">Exercice 4.1: Comparaison Ridge, Lasso, ElasticNet</a></li>
  <li><a href="#exercice-4.2-sélection-de-features-avec-lasso" id="toc-exercice-4.2-sélection-de-features-avec-lasso" class="nav-link" data-scroll-target="#exercice-4.2-sélection-de-features-avec-lasso">Exercice 4.2: Sélection de Features avec Lasso</a></li>
  </ul></li>
  <li><a href="#optimisation-avec-cross-validation" id="toc-optimisation-avec-cross-validation" class="nav-link" data-scroll-target="#optimisation-avec-cross-validation">5. Optimisation avec Cross-Validation</a>
  <ul class="collapse">
  <li><a href="#exercice-5.1-ridgecv-et-lassocv" id="toc-exercice-5.1-ridgecv-et-lassocv" class="nav-link" data-scroll-target="#exercice-5.1-ridgecv-et-lassocv">Exercice 5.1: RidgeCV et LassoCV</a></li>
  </ul></li>
  <li><a href="#svr-support-vector-regression" id="toc-svr-support-vector-regression" class="nav-link" data-scroll-target="#svr-support-vector-regression">6. SVR (Support Vector Regression)</a>
  <ul class="collapse">
  <li><a href="#exercice-6.1-svr-avec-différents-kernels" id="toc-exercice-6.1-svr-avec-différents-kernels" class="nav-link" data-scroll-target="#exercice-6.1-svr-avec-différents-kernels">Exercice 6.1: SVR avec différents kernels</a></li>
  </ul></li>
  <li><a href="#comparaison-finale-de-tous-les-modèles" id="toc-comparaison-finale-de-tous-les-modèles" class="nav-link" data-scroll-target="#comparaison-finale-de-tous-les-modèles">7. Comparaison Finale de Tous les Modèles</a>
  <ul class="collapse">
  <li><a href="#exercice-7.1-tableau-de-bord-complet" id="toc-exercice-7.1-tableau-de-bord-complet" class="nav-link" data-scroll-target="#exercice-7.1-tableau-de-bord-complet">Exercice 7.1: Tableau de Bord Complet</a></li>
  </ul></li>
  <li><a href="#projet-bonus-regression-avancée" id="toc-projet-bonus-regression-avancée" class="nav-link" data-scroll-target="#projet-bonus-regression-avancée">8. Projet Bonus: Regression Avancée</a>
  <ul class="collapse">
  <li><a href="#exercice-8.1-ensemble-methods" id="toc-exercice-8.1-ensemble-methods" class="nav-link" data-scroll-target="#exercice-8.1-ensemble-methods">Exercice 8.1: Ensemble Methods</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a>
  <ul class="collapse">
  <li><a href="#résumé-des-points-clés" id="toc-résumé-des-points-clés" class="nav-link" data-scroll-target="#résumé-des-points-clés">Résumé des Points Clés</a></li>
  <li><a href="#checklist-de-validation" id="toc-checklist-de-validation" class="nav-link" data-scroll-target="#checklist-de-validation">Checklist de Validation</a></li>
  <li><a href="#pour-aller-plus-loin" id="toc-pour-aller-plus-loin" class="nav-link" data-scroll-target="#pour-aller-plus-loin">Pour Aller Plus Loin</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./seance1.html">Partie 1: Machine Learning Fondamental</a></li><li class="breadcrumb-item"><a href="./seance8.html"><span class="chapter-title">Séance 8: TP3 - Régression &amp; Optimisation</span></a></li></ol></nav>
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span class="chapter-title">Séance 8: TP3 - Régression &amp; Optimisation</span></h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Informations de la séance
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>Type</strong>: Travaux Pratiques</li>
<li><strong>Durée</strong>: 2h</li>
<li><strong>Objectifs</strong>: Obj6, Obj7</li>
</ul>
</div>
</div>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Dans ce TP, nous allons mettre en pratique les concepts de régression vus en cours. Nous travaillerons sur un dataset réel pour prédire les prix de maisons, en comparant différents modèles de régression et en optimisant leurs hyperparamètres.</p>
<p><strong>Objectifs du TP:</strong></p>
<ol type="1">
<li>Prétraiter des données pour la régression</li>
<li>Implémenter et comparer Linear, Ridge, Lasso, ElasticNet, SVR</li>
<li>Optimiser les hyperparamètres avec CV</li>
<li>Évaluer avec métriques multiples (MAE, RMSE, R²)</li>
<li>Interpréter et visualiser les résultats</li>
</ol>
</section>
<section id="chargement-et-exploration-du-dataset" class="level2">
<h2 class="anchored" data-anchor-id="chargement-et-exploration-du-dataset">1. Chargement et Exploration du Dataset</h2>
<p>Nous utilisons le <strong>Boston Housing Dataset</strong> (ou California Housing si Boston non disponible).</p>
<div id="47d40bf4" class="cell" data-execution_count="1">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> fetch_california_housing</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Chargement</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>california <span class="op">=</span> fetch_california_housing()</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> california.data, california.target</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="co"># DataFrame pour exploration</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(X, columns<span class="op">=</span>california.feature_names)</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'MedHouseVal'</span>] <span class="op">=</span> y</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"DATASET: CALIFORNIA HOUSING"</span>)</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Shape: </span><span class="sc">{</span>X<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Features: </span><span class="sc">{</span>california<span class="sc">.</span>feature_names<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Description du target (prix médian en 100k$):"</span>)</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df[<span class="st">'MedHouseVal'</span>].describe())</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Statistiques descriptives</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"STATISTIQUES DESCRIPTIVES"</span>)</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df.describe().T)</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Vérifier les valeurs manquantes</span></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Valeurs manquantes par feature:"</span>)</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df.isnull().<span class="bu">sum</span>())</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualisations</span></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">10</span>))</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Distribution du target</span></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].hist(y, bins<span class="op">=</span><span class="dv">50</span>, edgecolor<span class="op">=</span><span class="st">'black'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].set_xlabel(<span class="st">'Prix Médian (100k$)'</span>)</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].set_ylabel(<span class="st">'Fréquence'</span>)</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].set_title(<span class="st">'Distribution des Prix'</span>)</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].axvline(y.mean(), color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, label<span class="op">=</span><span class="ss">f'Moyenne: </span><span class="sc">{</span>y<span class="sc">.</span>mean()<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].legend()</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a><span class="co"># Boxplot des features (normalisées pour comparaison)</span></span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>df_normalized <span class="op">=</span> (df <span class="op">-</span> df.mean()) <span class="op">/</span> df.std()</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">1</span>].boxplot([df_normalized[col] <span class="cf">for</span> col <span class="kw">in</span> california.feature_names],</span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>                    labels<span class="op">=</span>california.feature_names, vert<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">1</span>].set_xticklabels(california.feature_names, rotation<span class="op">=</span><span class="dv">45</span>, ha<span class="op">=</span><span class="st">'right'</span>)</span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">1</span>].set_ylabel(<span class="st">'Valeurs normalisées'</span>)</span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">1</span>].set_title(<span class="st">'Distribution des Features (normalisées)'</span>)</span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">1</span>].grid(alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a><span class="co"># Matrice de corrélation</span></span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>corr_matrix <span class="op">=</span> df.corr()</span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a>mask <span class="op">=</span> np.triu(np.ones_like(corr_matrix, dtype<span class="op">=</span><span class="bu">bool</span>))</span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a>sns.heatmap(corr_matrix, mask<span class="op">=</span>mask, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">'.2f'</span>, cmap<span class="op">=</span><span class="st">'coolwarm'</span>,</span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a>            center<span class="op">=</span><span class="dv">0</span>, ax<span class="op">=</span>axes[<span class="dv">1</span>, <span class="dv">0</span>], cbar_kws<span class="op">=</span>{<span class="st">'label'</span>: <span class="st">'Corrélation'</span>})</span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">0</span>].set_title(<span class="st">'Matrice de Corrélation'</span>)</span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a><span class="co"># Scatter: Feature la plus corrélée avec target</span></span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a>corr_with_target <span class="op">=</span> corr_matrix[<span class="st">'MedHouseVal'</span>].drop(<span class="st">'MedHouseVal'</span>).<span class="bu">abs</span>().sort_values(ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a>best_feature <span class="op">=</span> corr_with_target.index[<span class="dv">0</span>]</span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">1</span>].scatter(df[best_feature], df[<span class="st">'MedHouseVal'</span>], alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">1</span>].set_xlabel(best_feature)</span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">1</span>].set_ylabel(<span class="st">'Prix Médian'</span>)</span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">1</span>].set_title(<span class="ss">f'Prix vs </span><span class="sc">{</span>best_feature<span class="sc">}</span><span class="ss"> (corr=</span><span class="sc">{</span>corr_matrix<span class="sc">.</span>loc[best_feature, <span class="st">"MedHouseVal"</span>]<span class="sc">:.2f}</span><span class="ss">)'</span>)</span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">1</span>].grid(alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"CORRÉLATIONS AVEC LE TARGET"</span>)</span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(corr_with_target)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>======================================================================
DATASET: CALIFORNIA HOUSING
======================================================================

Shape: (20640, 8)
Features: ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']

Description du target (prix médian en 100k$):
count    20640.000000
mean         2.068558
std          1.153956
min          0.149990
25%          1.196000
50%          1.797000
75%          2.647250
max          5.000010
Name: MedHouseVal, dtype: float64

======================================================================
STATISTIQUES DESCRIPTIVES
======================================================================
               count         mean          std         min         25%  \
MedInc       20640.0     3.870671     1.899822    0.499900    2.563400   
HouseAge     20640.0    28.639486    12.585558    1.000000   18.000000   
AveRooms     20640.0     5.429000     2.474173    0.846154    4.440716   
AveBedrms    20640.0     1.096675     0.473911    0.333333    1.006079   
Population   20640.0  1425.476744  1132.462122    3.000000  787.000000   
AveOccup     20640.0     3.070655    10.386050    0.692308    2.429741   
Latitude     20640.0    35.631861     2.135952   32.540000   33.930000   
Longitude    20640.0  -119.569704     2.003532 -124.350000 -121.800000   
MedHouseVal  20640.0     2.068558     1.153956    0.149990    1.196000   

                     50%          75%           max  
MedInc          3.534800     4.743250     15.000100  
HouseAge       29.000000    37.000000     52.000000  
AveRooms        5.229129     6.052381    141.909091  
AveBedrms       1.048780     1.099526     34.066667  
Population   1166.000000  1725.000000  35682.000000  
AveOccup        2.818116     3.282261   1243.333333  
Latitude       34.260000    37.710000     41.950000  
Longitude    -118.490000  -118.010000   -114.310000  
MedHouseVal     1.797000     2.647250      5.000010  

Valeurs manquantes par feature:
MedInc         0
HouseAge       0
AveRooms       0
AveBedrms      0
Population     0
AveOccup       0
Latitude       0
Longitude      0
MedHouseVal    0
dtype: int64</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="seance8_files/figure-html/cell-2-output-2.png" width="1142" height="950" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
======================================================================
CORRÉLATIONS AVEC LE TARGET
======================================================================
MedInc        0.688075
AveRooms      0.151948
Latitude      0.144160
HouseAge      0.105623
AveBedrms     0.046701
Longitude     0.045967
Population    0.024650
AveOccup      0.023737
Name: MedHouseVal, dtype: float64</code></pre>
</div>
</div>
<section id="exercice-1.1-analyse-exploratoire" class="level3">
<h3 class="anchored" data-anchor-id="exercice-1.1-analyse-exploratoire">Exercice 1.1: Analyse Exploratoire</h3>
<p><strong>Questions:</strong></p>
<ol type="1">
<li>Quelle feature est la plus corrélée avec le prix?</li>
<li>Y a-t-il des features fortement corrélées entre elles? (Multicolinéarité potentielle?)</li>
<li>La distribution du target est-elle gaussienne? Quel traitement pourrait être appliqué si non?</li>
<li>Identifiez des outliers potentiels</li>
</ol>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Solution Exercice 1.1
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div id="d13bf2f7" class="cell" data-execution_count="2">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"ANALYSE EXPLORATOIRE - RÉPONSES"</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Feature la plus corrélée</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">1. Feature la plus corrélée avec le prix:"</span>)</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   → </span><span class="sc">{</span>best_feature<span class="sc">}</span><span class="ss"> (corrélation = </span><span class="sc">{</span>corr_matrix<span class="sc">.</span>loc[best_feature, <span class="st">'MedHouseVal'</span>]<span class="sc">:.3f}</span><span class="ss">)"</span>)</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Multicolinéarité</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">2. Paires de features fortement corrélées (|corr| &gt; 0.7):"</span>)</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>corr_pairs <span class="op">=</span> []</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(corr_matrix.columns)):</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(i<span class="op">+</span><span class="dv">1</span>, <span class="bu">len</span>(corr_matrix.columns)):</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> i <span class="op">!=</span> j:</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>            corr_val <span class="op">=</span> corr_matrix.iloc[i, j]</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">abs</span>(corr_val) <span class="op">&gt;</span> <span class="fl">0.7</span>:</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>                corr_pairs.append((corr_matrix.columns[i], corr_matrix.columns[j], corr_val))</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> corr_pairs:</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> feat1, feat2, corr_val <span class="kw">in</span> corr_pairs:</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"   • </span><span class="sc">{</span>feat1<span class="sc">}</span><span class="ss"> &lt;-&gt; </span><span class="sc">{</span>feat2<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>corr_val<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"   → Aucune multicolinéarité forte détectée"</span>)</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Distribution du target</span></span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy <span class="im">import</span> stats</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>shapiro_stat, shapiro_p <span class="op">=</span> stats.shapiro(y[:<span class="dv">1000</span>])  <span class="co"># Test sur échantillon</span></span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">3. Test de normalité (Shapiro-Wilk):"</span>)</span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   Statistique: </span><span class="sc">{</span>shapiro_stat<span class="sc">:.4f}</span><span class="ss">, p-value: </span><span class="sc">{</span>shapiro_p<span class="sc">:.4e}</span><span class="ss">"</span>)</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> shapiro_p <span class="op">&lt;</span> <span class="fl">0.05</span>:</span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"   → Distribution NON gaussienne (p &lt; 0.05)"</span>)</span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"   Traitements possibles:"</span>)</span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"   • Transformation log(y)"</span>)</span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"   • Transformation Box-Cox"</span>)</span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"   • Utiliser des modèles robustes aux distributions non-gaussiennes"</span>)</span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"   → Distribution gaussienne (p &gt;= 0.05)"</span>)</span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a><span class="co"># Skewness et Kurtosis</span></span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a>skewness <span class="op">=</span> stats.skew(y)</span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a>kurtosis <span class="op">=</span> stats.kurtosis(y)</span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   Asymétrie (Skewness): </span><span class="sc">{</span>skewness<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   Aplatissement (Kurtosis): </span><span class="sc">{</span>kurtosis<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-45"><a href="#cb4-45" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Outliers</span></span>
<span id="cb4-46"><a href="#cb4-46" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">4. Détection d'outliers:"</span>)</span>
<span id="cb4-47"><a href="#cb4-47" aria-hidden="true" tabindex="-1"></a>Q1 <span class="op">=</span> df[<span class="st">'MedHouseVal'</span>].quantile(<span class="fl">0.25</span>)</span>
<span id="cb4-48"><a href="#cb4-48" aria-hidden="true" tabindex="-1"></a>Q3 <span class="op">=</span> df[<span class="st">'MedHouseVal'</span>].quantile(<span class="fl">0.75</span>)</span>
<span id="cb4-49"><a href="#cb4-49" aria-hidden="true" tabindex="-1"></a>IQR <span class="op">=</span> Q3 <span class="op">-</span> Q1</span>
<span id="cb4-50"><a href="#cb4-50" aria-hidden="true" tabindex="-1"></a>lower_bound <span class="op">=</span> Q1 <span class="op">-</span> <span class="fl">1.5</span> <span class="op">*</span> IQR</span>
<span id="cb4-51"><a href="#cb4-51" aria-hidden="true" tabindex="-1"></a>upper_bound <span class="op">=</span> Q3 <span class="op">+</span> <span class="fl">1.5</span> <span class="op">*</span> IQR</span>
<span id="cb4-52"><a href="#cb4-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-53"><a href="#cb4-53" aria-hidden="true" tabindex="-1"></a>outliers <span class="op">=</span> df[(df[<span class="st">'MedHouseVal'</span>] <span class="op">&lt;</span> lower_bound) <span class="op">|</span> (df[<span class="st">'MedHouseVal'</span>] <span class="op">&gt;</span> upper_bound)]</span>
<span id="cb4-54"><a href="#cb4-54" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   Intervalle IQR: [</span><span class="sc">{</span>Q1<span class="sc">:.2f}</span><span class="ss">, </span><span class="sc">{</span>Q3<span class="sc">:.2f}</span><span class="ss">]"</span>)</span>
<span id="cb4-55"><a href="#cb4-55" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   Bornes: [</span><span class="sc">{</span>lower_bound<span class="sc">:.2f}</span><span class="ss">, </span><span class="sc">{</span>upper_bound<span class="sc">:.2f}</span><span class="ss">]"</span>)</span>
<span id="cb4-56"><a href="#cb4-56" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   Nombre d'outliers: </span><span class="sc">{</span><span class="bu">len</span>(outliers)<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span><span class="bu">len</span>(outliers)<span class="op">/</span><span class="bu">len</span>(df)<span class="op">*</span><span class="dv">100</span><span class="sc">:.1f}</span><span class="ss">%)"</span>)</span>
<span id="cb4-57"><a href="#cb4-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-58"><a href="#cb4-58" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualisation des outliers</span></span>
<span id="cb4-59"><a href="#cb4-59" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb4-60"><a href="#cb4-60" aria-hidden="true" tabindex="-1"></a>ax.scatter(<span class="bu">range</span>(<span class="bu">len</span>(y)), np.sort(y), alpha<span class="op">=</span><span class="fl">0.5</span>, s<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb4-61"><a href="#cb4-61" aria-hidden="true" tabindex="-1"></a>ax.axhline(lower_bound, color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, label<span class="op">=</span><span class="st">'Lower bound'</span>)</span>
<span id="cb4-62"><a href="#cb4-62" aria-hidden="true" tabindex="-1"></a>ax.axhline(upper_bound, color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, label<span class="op">=</span><span class="st">'Upper bound'</span>)</span>
<span id="cb4-63"><a href="#cb4-63" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'Index (trié)'</span>)</span>
<span id="cb4-64"><a href="#cb4-64" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'Prix'</span>)</span>
<span id="cb4-65"><a href="#cb4-65" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'Détection d</span><span class="ch">\'</span><span class="st">Outliers par IQR'</span>)</span>
<span id="cb4-66"><a href="#cb4-66" aria-hidden="true" tabindex="-1"></a>ax.legend()</span>
<span id="cb4-67"><a href="#cb4-67" aria-hidden="true" tabindex="-1"></a>ax.grid(alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb4-68"><a href="#cb4-68" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>======================================================================
ANALYSE EXPLORATOIRE - RÉPONSES
======================================================================

1. Feature la plus corrélée avec le prix:
   → MedInc (corrélation = 0.688)

2. Paires de features fortement corrélées (|corr| &gt; 0.7):
   • AveRooms &lt;-&gt; AveBedrms: 0.848
   • Latitude &lt;-&gt; Longitude: -0.925

3. Test de normalité (Shapiro-Wilk):
   Statistique: 0.9460, p-value: 1.2095e-18
   → Distribution NON gaussienne (p &lt; 0.05)
   Traitements possibles:
   • Transformation log(y)
   • Transformation Box-Cox
   • Utiliser des modèles robustes aux distributions non-gaussiennes
   Asymétrie (Skewness): 0.978
   Aplatissement (Kurtosis): 0.328

4. Détection d'outliers:
   Intervalle IQR: [1.20, 2.65]
   Bornes: [-0.98, 4.82]
   Nombre d'outliers: 1071 (5.2%)</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="seance8_files/figure-html/cell-3-output-2.png" width="811" height="524" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p><strong>Conclusions typiques:</strong></p>
<ol type="1">
<li><strong>MedInc</strong> (revenu médian) généralement le plus corrélé (~0.68)</li>
<li>Multicolinéarité possible → considérer Ridge/ElasticNet</li>
<li>Distribution souvent légèrement asymétrique → transformation log possible</li>
<li>Quelques outliers mais acceptable (&lt;5%)</li>
</ol>
</div>
</div>
</div>
</section>
</section>
<section id="prétraitement-et-split" class="level2">
<h2 class="anchored" data-anchor-id="prétraitement-et-split">2. Prétraitement et Split</h2>
<div id="6f7da103" class="cell" data-execution_count="3">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Split train/test (80/20)</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"SPLIT DES DONNÉES"</span>)</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Train set: </span><span class="sc">{</span>X_train<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Test set: </span><span class="sc">{</span>X_test<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Standardisation (importante pour Ridge, Lasso, SVR)</span></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>X_train_scaled <span class="op">=</span> scaler.fit_transform(X_train)</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>X_test_scaled <span class="op">=</span> scaler.transform(X_test)</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Standardisation:"</span>)</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Mean (train): </span><span class="sc">{</span>X_train_scaled<span class="sc">.</span>mean(axis<span class="op">=</span><span class="dv">0</span>)<span class="sc">}</span><span class="ss">"</span>)  <span class="co"># Devrait être ~0</span></span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Std (train): </span><span class="sc">{</span>X_train_scaled<span class="sc">.</span>std(axis<span class="op">=</span><span class="dv">0</span>)<span class="sc">}</span><span class="ss">"</span>)    <span class="co"># Devrait être ~1</span></span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Vérification</span></span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Vérification après scaling:"</span>)</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Mean proche de 0: </span><span class="sc">{</span>np<span class="sc">.</span>allclose(X_train_scaled.mean(axis<span class="op">=</span><span class="dv">0</span>), <span class="dv">0</span>, atol<span class="op">=</span><span class="fl">1e-10</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Std proche de 1: </span><span class="sc">{</span>np<span class="sc">.</span>allclose(X_train_scaled.std(axis<span class="op">=</span><span class="dv">0</span>), <span class="dv">1</span>, atol<span class="op">=</span><span class="fl">1e-2</span>)<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>======================================================================
SPLIT DES DONNÉES
======================================================================
Train set: (16512, 8)
Test set: (4128, 8)

Standardisation:
Mean (train): [-6.59266865e-15 -6.68608149e-17  8.01559239e-15 -1.17273358e-15
 -2.60880895e-18 -1.13675656e-16  7.99652724e-14 -3.87910056e-13]
Std (train): [1. 1. 1. 1. 1. 1. 1. 1.]

Vérification après scaling:
  Mean proche de 0: True
  Std proche de 1: True</code></pre>
</div>
</div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Warning</span>Importance de la Standardisation
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Pourquoi standardiser?</strong> - Ridge/Lasso: Pénalisation équitable des coefficients - SVR: Sensible à l’échelle des features - Convergence plus rapide des algorithmes itératifs</p>
<p><strong>Quand ne PAS standardiser?</strong> - Arbres de décision / Random Forest (invariants aux transformations monotones) - Régression linéaire simple (si pas de régularisation)</p>
<p><strong>Règle:</strong> Toujours fit sur train, transform sur test (éviter data leakage)</p>
</div>
</div>
</section>
<section id="modèles-de-base" class="level2">
<h2 class="anchored" data-anchor-id="modèles-de-base">3. Modèles de Base</h2>
<section id="exercice-3.1-régression-linéaire-simple" class="level3">
<h3 class="anchored" data-anchor-id="exercice-3.1-régression-linéaire-simple">Exercice 3.1: Régression Linéaire Simple</h3>
<p>Entraînez une régression linéaire et évaluez-la.</p>
<p><strong>Instructions:</strong> 1. Créez et entraînez le modèle 2. Prédisez sur train et test 3. Calculez MAE, RMSE, R² pour les deux ensembles 4. Affichez les 5 coefficients les plus importants 5. Visualisez prédictions vs vraies valeurs</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Solution Exercice 3.1
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div id="739645a4" class="cell" data-execution_count="4">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_absolute_error, mean_squared_error, r2_score</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"RÉGRESSION LINÉAIRE SIMPLE"</span>)</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Entraînement</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>model_lr <span class="op">=</span> LinearRegression()</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>model_lr.fit(X_train_scaled, y_train)</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Prédictions</span></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>y_train_pred <span class="op">=</span> model_lr.predict(X_train_scaled)</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>y_test_pred <span class="op">=</span> model_lr.predict(X_test_scaled)</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Métriques</span></span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> evaluate_model(y_true, y_pred, dataset_name<span class="op">=</span><span class="st">""</span>):</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>    mae <span class="op">=</span> mean_absolute_error(y_true, y_pred)</span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>    mse <span class="op">=</span> mean_squared_error(y_true, y_pred)</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>    rmse <span class="op">=</span> np.sqrt(mse)</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>    r2 <span class="op">=</span> r2_score(y_true, y_pred)</span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="sc">{</span>dataset_name<span class="sc">}</span><span class="ss">:"</span>)</span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  MAE:  </span><span class="sc">{</span>mae<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  RMSE: </span><span class="sc">{</span>rmse<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  R²:   </span><span class="sc">{</span>r2<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {<span class="st">'MAE'</span>: mae, <span class="st">'RMSE'</span>: rmse, <span class="st">'R2'</span>: r2}</span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a>train_metrics <span class="op">=</span> evaluate_model(y_train, y_train_pred, <span class="st">"Train Set"</span>)</span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a>test_metrics <span class="op">=</span> evaluate_model(y_test, y_test_pred, <span class="st">"Test Set"</span>)</span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Coefficients importants</span></span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true" tabindex="-1"></a>coef_df <span class="op">=</span> pd.DataFrame({</span>
<span id="cb8-35"><a href="#cb8-35" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Feature'</span>: california.feature_names,</span>
<span id="cb8-36"><a href="#cb8-36" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Coefficient'</span>: model_lr.coef_</span>
<span id="cb8-37"><a href="#cb8-37" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb8-38"><a href="#cb8-38" aria-hidden="true" tabindex="-1"></a>coef_df[<span class="st">'Abs_Coef'</span>] <span class="op">=</span> np.<span class="bu">abs</span>(coef_df[<span class="st">'Coefficient'</span>])</span>
<span id="cb8-39"><a href="#cb8-39" aria-hidden="true" tabindex="-1"></a>coef_df <span class="op">=</span> coef_df.sort_values(<span class="st">'Abs_Coef'</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb8-40"><a href="#cb8-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-41"><a href="#cb8-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb8-42"><a href="#cb8-42" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"COEFFICIENTS (TOP 5)"</span>)</span>
<span id="cb8-43"><a href="#cb8-43" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb8-44"><a href="#cb8-44" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(coef_df[[<span class="st">'Feature'</span>, <span class="st">'Coefficient'</span>]].head().to_string(index<span class="op">=</span><span class="va">False</span>))</span>
<span id="cb8-45"><a href="#cb8-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-46"><a href="#cb8-46" aria-hidden="true" tabindex="-1"></a><span class="co"># 5. Visualisation</span></span>
<span id="cb8-47"><a href="#cb8-47" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">5</span>))</span>
<span id="cb8-48"><a href="#cb8-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-49"><a href="#cb8-49" aria-hidden="true" tabindex="-1"></a><span class="co"># Prédictions vs Vraies valeurs (Test)</span></span>
<span id="cb8-50"><a href="#cb8-50" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].scatter(y_test, y_test_pred, alpha<span class="op">=</span><span class="fl">0.3</span>, s<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb8-51"><a href="#cb8-51" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].plot([y_test.<span class="bu">min</span>(), y_test.<span class="bu">max</span>()], [y_test.<span class="bu">min</span>(), y_test.<span class="bu">max</span>()], </span>
<span id="cb8-52"><a href="#cb8-52" aria-hidden="true" tabindex="-1"></a>             <span class="st">'r--'</span>, lw<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'Prédiction parfaite'</span>)</span>
<span id="cb8-53"><a href="#cb8-53" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_xlabel(<span class="st">'Vraie valeur'</span>)</span>
<span id="cb8-54"><a href="#cb8-54" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_ylabel(<span class="st">'Prédiction'</span>)</span>
<span id="cb8-55"><a href="#cb8-55" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="ss">f'Régression Linéaire (Test R²=</span><span class="sc">{</span>test_metrics[<span class="st">"R2"</span>]<span class="sc">:.3f}</span><span class="ss">)'</span>)</span>
<span id="cb8-56"><a href="#cb8-56" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].legend()</span>
<span id="cb8-57"><a href="#cb8-57" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].grid(alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb8-58"><a href="#cb8-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-59"><a href="#cb8-59" aria-hidden="true" tabindex="-1"></a><span class="co"># Résidus</span></span>
<span id="cb8-60"><a href="#cb8-60" aria-hidden="true" tabindex="-1"></a>residuals <span class="op">=</span> y_test <span class="op">-</span> y_test_pred</span>
<span id="cb8-61"><a href="#cb8-61" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].scatter(y_test_pred, residuals, alpha<span class="op">=</span><span class="fl">0.3</span>, s<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb8-62"><a href="#cb8-62" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].axhline(<span class="dv">0</span>, color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, lw<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb8-63"><a href="#cb8-63" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xlabel(<span class="st">'Prédictions'</span>)</span>
<span id="cb8-64"><a href="#cb8-64" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_ylabel(<span class="st">'Résidus'</span>)</span>
<span id="cb8-65"><a href="#cb8-65" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="st">'Graphique des Résidus'</span>)</span>
<span id="cb8-66"><a href="#cb8-66" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].grid(alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb8-67"><a href="#cb8-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-68"><a href="#cb8-68" aria-hidden="true" tabindex="-1"></a><span class="co"># Distribution des résidus</span></span>
<span id="cb8-69"><a href="#cb8-69" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].hist(residuals, bins<span class="op">=</span><span class="dv">50</span>, edgecolor<span class="op">=</span><span class="st">'black'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb8-70"><a href="#cb8-70" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].axvline(residuals.mean(), color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, </span>
<span id="cb8-71"><a href="#cb8-71" aria-hidden="true" tabindex="-1"></a>               label<span class="op">=</span><span class="ss">f'Moyenne: </span><span class="sc">{</span>residuals<span class="sc">.</span>mean()<span class="sc">:.4f}</span><span class="ss">'</span>)</span>
<span id="cb8-72"><a href="#cb8-72" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].set_xlabel(<span class="st">'Résidus'</span>)</span>
<span id="cb8-73"><a href="#cb8-73" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].set_ylabel(<span class="st">'Fréquence'</span>)</span>
<span id="cb8-74"><a href="#cb8-74" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].set_title(<span class="st">'Distribution des Résidus'</span>)</span>
<span id="cb8-75"><a href="#cb8-75" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].legend()</span>
<span id="cb8-76"><a href="#cb8-76" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].grid(alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb8-77"><a href="#cb8-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-78"><a href="#cb8-78" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb8-79"><a href="#cb8-79" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb8-80"><a href="#cb8-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-81"><a href="#cb8-81" aria-hidden="true" tabindex="-1"></a><span class="co"># Analyse des résidus</span></span>
<span id="cb8-82"><a href="#cb8-82" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb8-83"><a href="#cb8-83" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"ANALYSE DES RÉSIDUS"</span>)</span>
<span id="cb8-84"><a href="#cb8-84" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb8-85"><a href="#cb8-85" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Moyenne: </span><span class="sc">{</span>residuals<span class="sc">.</span>mean()<span class="sc">:.6f}</span><span class="ss"> (devrait être $</span><span class="ch">\a</span><span class="ss">pprox$ 0)"</span>)</span>
<span id="cb8-86"><a href="#cb8-86" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Std: </span><span class="sc">{</span>residuals<span class="sc">.</span>std()<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb8-87"><a href="#cb8-87" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Min: </span><span class="sc">{</span>residuals<span class="sc">.</span><span class="bu">min</span>()<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb8-88"><a href="#cb8-88" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Max: </span><span class="sc">{</span>residuals<span class="sc">.</span><span class="bu">max</span>()<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>======================================================================
RÉGRESSION LINÉAIRE SIMPLE
======================================================================

Train Set:
  MAE:  0.5286
  RMSE: 0.7197
  R²:   0.6126

Test Set:
  MAE:  0.5332
  RMSE: 0.7456
  R²:   0.5758

======================================================================
COEFFICIENTS (TOP 5)
======================================================================
  Feature  Coefficient
 Latitude    -0.896929
Longitude    -0.869842
   MedInc     0.854383
AveBedrms     0.339259
 AveRooms    -0.294410</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="seance8_files/figure-html/cell-5-output-2.png" width="1141" height="468" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
======================================================================
ANALYSE DES RÉSIDUS
======================================================================
Moyenne: 0.003479 (devrait être $pprox$ 0)
Std: 0.7456
Min: -9.8753
Max: 4.1484</code></pre>
</div>
</div>
<p><strong>Interprétation:</strong> - R² train &gt; R² test → léger surapprentissage (normal) - Résidus centrés sur 0 → modèle non biaisé - Distribution des résidus approximativement gaussienne → hypothèses vérifiées</p>
</div>
</div>
</div>
</section>
</section>
<section id="modèles-régularisés" class="level2">
<h2 class="anchored" data-anchor-id="modèles-régularisés">4. Modèles Régularisés</h2>
<section id="exercice-4.1-comparaison-ridge-lasso-elasticnet" class="level3">
<h3 class="anchored" data-anchor-id="exercice-4.1-comparaison-ridge-lasso-elasticnet">Exercice 4.1: Comparaison Ridge, Lasso, ElasticNet</h3>
<p>Comparez les 3 modèles régularisés avec différentes valeurs de alpha.</p>
<p><strong>Instructions:</strong></p>
<ol type="1">
<li>Testez alpha dans [0.001, 0.01, 0.1, 1, 10, 100]</li>
<li>Pour chaque modèle et chaque alpha:
<ul>
<li>Entraînez sur train</li>
<li>Calculez R² sur test</li>
</ul></li>
<li>Tracez R² vs alpha pour les 3 modèles</li>
<li>Identifiez le meilleur modèle et le meilleur alpha</li>
</ol>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Solution Exercice 4.1
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div id="7ced0077" class="cell" data-execution_count="5">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> Ridge, Lasso, ElasticNet</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"COMPARAISON RIDGE, LASSO, ELASTICNET"</span>)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Grille d'alphas</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>alphas <span class="op">=</span> [<span class="fl">0.001</span>, <span class="fl">0.01</span>, <span class="fl">0.1</span>, <span class="dv">1</span>, <span class="dv">10</span>, <span class="dv">100</span>]</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Stocker les résultats</span></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> {<span class="st">'Ridge'</span>: [], <span class="st">'Lasso'</span>: [], <span class="st">'ElasticNet'</span>: []}</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Entraînement</span></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> alpha <span class="kw">in</span> alphas:</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Ridge</span></span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>    ridge <span class="op">=</span> Ridge(alpha<span class="op">=</span>alpha)</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>    ridge.fit(X_train_scaled, y_train)</span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>    r2_ridge <span class="op">=</span> r2_score(y_test, ridge.predict(X_test_scaled))</span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>    results[<span class="st">'Ridge'</span>].append(r2_ridge)</span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Lasso</span></span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>    lasso <span class="op">=</span> Lasso(alpha<span class="op">=</span>alpha, max_iter<span class="op">=</span><span class="dv">10000</span>)</span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a>    lasso.fit(X_train_scaled, y_train)</span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a>    r2_lasso <span class="op">=</span> r2_score(y_test, lasso.predict(X_test_scaled))</span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a>    results[<span class="st">'Lasso'</span>].append(r2_lasso)</span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ElasticNet</span></span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a>    elastic <span class="op">=</span> ElasticNet(alpha<span class="op">=</span>alpha, l1_ratio<span class="op">=</span><span class="fl">0.5</span>, max_iter<span class="op">=</span><span class="dv">10000</span>)</span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a>    elastic.fit(X_train_scaled, y_train)</span>
<span id="cb11-30"><a href="#cb11-30" aria-hidden="true" tabindex="-1"></a>    r2_elastic <span class="op">=</span> r2_score(y_test, elastic.predict(X_test_scaled))</span>
<span id="cb11-31"><a href="#cb11-31" aria-hidden="true" tabindex="-1"></a>    results[<span class="st">'ElasticNet'</span>].append(r2_elastic)</span>
<span id="cb11-32"><a href="#cb11-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-33"><a href="#cb11-33" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Visualisation</span></span>
<span id="cb11-34"><a href="#cb11-34" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb11-35"><a href="#cb11-35" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> model_name, r2_scores <span class="kw">in</span> results.items():</span>
<span id="cb11-36"><a href="#cb11-36" aria-hidden="true" tabindex="-1"></a>    plt.plot(alphas, r2_scores, marker<span class="op">=</span><span class="st">'o'</span>, label<span class="op">=</span>model_name, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb11-37"><a href="#cb11-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-38"><a href="#cb11-38" aria-hidden="true" tabindex="-1"></a>plt.xscale(<span class="st">'log'</span>)</span>
<span id="cb11-39"><a href="#cb11-39" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'alpha (log scale)'</span>)</span>
<span id="cb11-40"><a href="#cb11-40" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'R² Score (Test)'</span>)</span>
<span id="cb11-41"><a href="#cb11-41" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Comparaison Ridge, Lasso, ElasticNet'</span>)</span>
<span id="cb11-42"><a href="#cb11-42" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb11-43"><a href="#cb11-43" aria-hidden="true" tabindex="-1"></a>plt.grid(alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb11-44"><a href="#cb11-44" aria-hidden="true" tabindex="-1"></a>plt.axhline(test_metrics[<span class="st">'R2'</span>], color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, </span>
<span id="cb11-45"><a href="#cb11-45" aria-hidden="true" tabindex="-1"></a>           label<span class="op">=</span><span class="ss">f'Linear (alpha=0): </span><span class="sc">{</span>test_metrics[<span class="st">"R2"</span>]<span class="sc">:.4f}</span><span class="ss">'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb11-46"><a href="#cb11-46" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb11-47"><a href="#cb11-47" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb11-48"><a href="#cb11-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-49"><a href="#cb11-49" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Meilleur modèle</span></span>
<span id="cb11-50"><a href="#cb11-50" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb11-51"><a href="#cb11-51" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"MEILLEURS HYPERPARAMÈTRES"</span>)</span>
<span id="cb11-52"><a href="#cb11-52" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb11-53"><a href="#cb11-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-54"><a href="#cb11-54" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> model_name, r2_scores <span class="kw">in</span> results.items():</span>
<span id="cb11-55"><a href="#cb11-55" aria-hidden="true" tabindex="-1"></a>    best_idx <span class="op">=</span> np.argmax(r2_scores)</span>
<span id="cb11-56"><a href="#cb11-56" aria-hidden="true" tabindex="-1"></a>    best_alpha <span class="op">=</span> alphas[best_idx]</span>
<span id="cb11-57"><a href="#cb11-57" aria-hidden="true" tabindex="-1"></a>    best_r2 <span class="op">=</span> r2_scores[best_idx]</span>
<span id="cb11-58"><a href="#cb11-58" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="sc">{</span>model_name<span class="sc">}</span><span class="ss">:"</span>)</span>
<span id="cb11-59"><a href="#cb11-59" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Meilleur alpha: </span><span class="sc">{</span>best_alpha<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb11-60"><a href="#cb11-60" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  R² Test: </span><span class="sc">{</span>best_r2<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb11-61"><a href="#cb11-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-62"><a href="#cb11-62" aria-hidden="true" tabindex="-1"></a><span class="co"># Tableau comparatif</span></span>
<span id="cb11-63"><a href="#cb11-63" aria-hidden="true" tabindex="-1"></a>df_comparison <span class="op">=</span> pd.DataFrame(results, index<span class="op">=</span>[<span class="ss">f'alpha=</span><span class="sc">{</span>a<span class="sc">}</span><span class="ss">'</span> <span class="cf">for</span> a <span class="kw">in</span> alphas])</span>
<span id="cb11-64"><a href="#cb11-64" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb11-65"><a href="#cb11-65" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"TABLEAU COMPARATIF (R² Test)"</span>)</span>
<span id="cb11-66"><a href="#cb11-66" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb11-67"><a href="#cb11-67" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df_comparison.to_string())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>======================================================================
COMPARAISON RIDGE, LASSO, ELASTICNET
======================================================================</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="seance8_files/figure-html/cell-6-output-2.png" width="1141" height="563" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
======================================================================
MEILLEURS HYPERPARAMÈTRES
======================================================================

Ridge:
  Meilleur alpha: 100
  R² Test: 0.5778

Lasso:
  Meilleur alpha: 0.01
  R² Test: 0.5816

ElasticNet:
  Meilleur alpha: 0.01
  R² Test: 0.5803

======================================================================
TABLEAU COMPARATIF (R² Test)
======================================================================
                Ridge     Lasso  ElasticNet
alpha=0.001  0.575788  0.576856    0.576543
alpha=0.01   0.575788  0.581615    0.580319
alpha=0.1    0.575791  0.481361    0.514765
alpha=1      0.575816 -0.000219    0.203126
alpha=10     0.576060 -0.000219   -0.000219
alpha=100    0.577791 -0.000219   -0.000219</code></pre>
</div>
</div>
<p><strong>Observations attendues:</strong> - Ridge: R² stable, peu sensible à alpha - Lasso: R² peut chuter si alpha trop élevé (trop de coefficients à 0) - ElasticNet: Compromis entre Ridge et Lasso</p>
</div>
</div>
</div>
</section>
<section id="exercice-4.2-sélection-de-features-avec-lasso" class="level3">
<h3 class="anchored" data-anchor-id="exercice-4.2-sélection-de-features-avec-lasso">Exercice 4.2: Sélection de Features avec Lasso</h3>
<p>Utilisez Lasso pour identifier les features importantes.</p>
<p><strong>Instructions:</strong> 1. Entraînez Lasso avec alpha=0.1 2. Affichez le nombre de coefficients non-nuls 3. Identifiez les features sélectionnées 4. Comparez les coefficients Lasso vs Linear</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Solution Exercice 4.2
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"SÉLECTION DE FEATURES AVEC LASSO"</span>)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Entraînement</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>lasso <span class="op">=</span> Lasso(alpha<span class="op">=</span><span class="fl">0.1</span>, max_iter<span class="op">=</span><span class="dv">10000</span>)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>lasso.fit(X_train_scaled, y_train)</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Coefficients non-nuls</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>non_zero_mask <span class="op">=</span> np.<span class="bu">abs</span>(lasso.coef_) <span class="op">&gt;</span> <span class="fl">1e-5</span></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>n_selected <span class="op">=</span> np.<span class="bu">sum</span>(non_zero_mask)</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>n_total <span class="op">=</span> <span class="bu">len</span>(lasso.coef_)</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Nombre de features sélectionnées: </span><span class="sc">{</span>n_selected<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>n_total<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Features sélectionnées</span></span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>selected_features <span class="op">=</span> pd.DataFrame({</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Feature'</span>: california.feature_names,</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Lasso_Coef'</span>: lasso.coef_,</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Linear_Coef'</span>: model_lr.coef_,</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Selected'</span>: non_zero_mask</span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>selected_features[<span class="st">'Abs_Lasso'</span>] <span class="op">=</span> np.<span class="bu">abs</span>(selected_features[<span class="st">'Lasso_Coef'</span>])</span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>selected_features <span class="op">=</span> selected_features.sort_values(<span class="st">'Abs_Lasso'</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"COMPARAISON COEFFICIENTS"</span>)</span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(selected_features[[<span class="st">'Feature'</span>, <span class="st">'Lasso_Coef'</span>, <span class="st">'Linear_Coef'</span>, <span class="st">'Selected'</span>]].to_string(index<span class="op">=</span><span class="va">False</span>))</span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Visualisation</span></span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb14-33"><a href="#cb14-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-34"><a href="#cb14-34" aria-hidden="true" tabindex="-1"></a><span class="co"># Barplot comparatif</span></span>
<span id="cb14-35"><a href="#cb14-35" aria-hidden="true" tabindex="-1"></a>x_pos <span class="op">=</span> np.arange(<span class="bu">len</span>(california.feature_names))</span>
<span id="cb14-36"><a href="#cb14-36" aria-hidden="true" tabindex="-1"></a>width <span class="op">=</span> <span class="fl">0.35</span></span>
<span id="cb14-37"><a href="#cb14-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-38"><a href="#cb14-38" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].bar(x_pos <span class="op">-</span> width<span class="op">/</span><span class="dv">2</span>, model_lr.coef_, width, label<span class="op">=</span><span class="st">'Linear'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb14-39"><a href="#cb14-39" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].bar(x_pos <span class="op">+</span> width<span class="op">/</span><span class="dv">2</span>, lasso.coef_, width, label<span class="op">=</span><span class="st">'Lasso (alpha=0.1)'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb14-40"><a href="#cb14-40" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_xticks(x_pos)</span>
<span id="cb14-41"><a href="#cb14-41" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_xticklabels(california.feature_names, rotation<span class="op">=</span><span class="dv">45</span>, ha<span class="op">=</span><span class="st">'right'</span>)</span>
<span id="cb14-42"><a href="#cb14-42" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_ylabel(<span class="st">'Coefficient'</span>)</span>
<span id="cb14-43"><a href="#cb14-43" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="st">'Comparaison Coefficients: Linear vs Lasso'</span>)</span>
<span id="cb14-44"><a href="#cb14-44" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].legend()</span>
<span id="cb14-45"><a href="#cb14-45" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].axhline(<span class="dv">0</span>, color<span class="op">=</span><span class="st">'black'</span>, linewidth<span class="op">=</span><span class="fl">0.8</span>)</span>
<span id="cb14-46"><a href="#cb14-46" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].grid(alpha<span class="op">=</span><span class="fl">0.3</span>, axis<span class="op">=</span><span class="st">'y'</span>)</span>
<span id="cb14-47"><a href="#cb14-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-48"><a href="#cb14-48" aria-hidden="true" tabindex="-1"></a><span class="co"># Scatter: Linear vs Lasso</span></span>
<span id="cb14-49"><a href="#cb14-49" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].scatter(model_lr.coef_, lasso.coef_, s<span class="op">=</span><span class="dv">100</span>, alpha<span class="op">=</span><span class="fl">0.6</span>)</span>
<span id="cb14-50"><a href="#cb14-50" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, feature <span class="kw">in</span> <span class="bu">enumerate</span>(california.feature_names):</span>
<span id="cb14-51"><a href="#cb14-51" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">1</span>].annotate(feature, (model_lr.coef_[i], lasso.coef_[i]),</span>
<span id="cb14-52"><a href="#cb14-52" aria-hidden="true" tabindex="-1"></a>                     fontsize<span class="op">=</span><span class="dv">8</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb14-53"><a href="#cb14-53" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].plot([model_lr.coef_.<span class="bu">min</span>(), model_lr.coef_.<span class="bu">max</span>()],</span>
<span id="cb14-54"><a href="#cb14-54" aria-hidden="true" tabindex="-1"></a>             [model_lr.coef_.<span class="bu">min</span>(), model_lr.coef_.<span class="bu">max</span>()],</span>
<span id="cb14-55"><a href="#cb14-55" aria-hidden="true" tabindex="-1"></a>             <span class="st">'r--'</span>, label<span class="op">=</span><span class="st">'y=x'</span>)</span>
<span id="cb14-56"><a href="#cb14-56" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xlabel(<span class="st">'Coefficient Linear'</span>)</span>
<span id="cb14-57"><a href="#cb14-57" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_ylabel(<span class="st">'Coefficient Lasso'</span>)</span>
<span id="cb14-58"><a href="#cb14-58" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="st">'Linear vs Lasso Coefficients'</span>)</span>
<span id="cb14-59"><a href="#cb14-59" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].legend()</span>
<span id="cb14-60"><a href="#cb14-60" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].grid(alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb14-61"><a href="#cb14-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-62"><a href="#cb14-62" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb14-63"><a href="#cb14-63" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb14-64"><a href="#cb14-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-65"><a href="#cb14-65" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb14-66"><a href="#cb14-66" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"FEATURES ÉLIMINÉES PAR LASSO"</span>)</span>
<span id="cb14-67"><a href="#cb14-67" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb14-68"><a href="#cb14-68" aria-hidden="true" tabindex="-1"></a>eliminated <span class="op">=</span> selected_features[<span class="op">~</span>selected_features[<span class="st">'Selected'</span>]][<span class="st">'Feature'</span>].tolist()</span>
<span id="cb14-69"><a href="#cb14-69" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> eliminated:</span>
<span id="cb14-70"><a href="#cb14-70" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Features mises à 0:"</span>)</span>
<span id="cb14-71"><a href="#cb14-71" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> feat <span class="kw">in</span> eliminated:</span>
<span id="cb14-72"><a href="#cb14-72" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  • </span><span class="sc">{</span>feat<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb14-73"><a href="#cb14-73" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb14-74"><a href="#cb14-74" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Aucune feature éliminée (alpha peut-être trop faible)"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><strong>Interprétation:</strong> - Lasso réduit certains coefficients exactement à 0 - Features éliminées = probablement redondantes ou peu informatives - Peut améliorer l’interprétabilité du modèle</p>
</div>
</div>
</div>
</section>
</section>
<section id="optimisation-avec-cross-validation" class="level2">
<h2 class="anchored" data-anchor-id="optimisation-avec-cross-validation">5. Optimisation avec Cross-Validation</h2>
<section id="exercice-5.1-ridgecv-et-lassocv" class="level3">
<h3 class="anchored" data-anchor-id="exercice-5.1-ridgecv-et-lassocv">Exercice 5.1: RidgeCV et LassoCV</h3>
<p>Utilisez les versions CV pour trouver automatiquement le meilleur alpha.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-7-contents" aria-controls="callout-7" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Solution Exercice 5.1
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-7" class="callout-7-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> RidgeCV, LassoCV</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"OPTIMISATION AUTOMATIQUE AVEC CV"</span>)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Grille d'alphas</span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>alphas_cv <span class="op">=</span> np.logspace(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">50</span>)</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a><span class="co"># RidgeCV</span></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">1. RidgeCV..."</span>)</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>ridge_cv <span class="op">=</span> RidgeCV(alphas<span class="op">=</span>alphas_cv, cv<span class="op">=</span><span class="dv">5</span>, scoring<span class="op">=</span><span class="st">'r2'</span>)</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>ridge_cv.fit(X_train_scaled, y_train)</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   Meilleur alpha: </span><span class="sc">{</span>ridge_cv<span class="sc">.</span>alpha_<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>y_pred_ridge <span class="op">=</span> ridge_cv.predict(X_test_scaled)</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>ridge_metrics <span class="op">=</span> evaluate_model(y_test, y_pred_ridge, <span class="st">"Ridge (CV)"</span>)</span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a><span class="co"># LassoCV</span></span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">2. LassoCV..."</span>)</span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a>lasso_cv <span class="op">=</span> LassoCV(alphas<span class="op">=</span>alphas_cv, cv<span class="op">=</span><span class="dv">5</span>, max_iter<span class="op">=</span><span class="dv">10000</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a>lasso_cv.fit(X_train_scaled, y_train)</span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   Meilleur alpha: </span><span class="sc">{</span>lasso_cv<span class="sc">.</span>alpha_<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a>y_pred_lasso <span class="op">=</span> lasso_cv.predict(X_test_scaled)</span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a>lasso_metrics <span class="op">=</span> evaluate_model(y_test, y_pred_lasso, <span class="st">"Lasso (CV)"</span>)</span>
<span id="cb15-27"><a href="#cb15-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-28"><a href="#cb15-28" aria-hidden="true" tabindex="-1"></a><span class="co"># ElasticNetCV</span></span>
<span id="cb15-29"><a href="#cb15-29" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> ElasticNetCV</span>
<span id="cb15-30"><a href="#cb15-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-31"><a href="#cb15-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">3. ElasticNetCV..."</span>)</span>
<span id="cb15-32"><a href="#cb15-32" aria-hidden="true" tabindex="-1"></a>elastic_cv <span class="op">=</span> ElasticNetCV(alphas<span class="op">=</span>alphas_cv, l1_ratio<span class="op">=</span>[<span class="fl">0.1</span>, <span class="fl">0.5</span>, <span class="fl">0.7</span>, <span class="fl">0.9</span>, <span class="fl">0.95</span>, <span class="fl">0.99</span>],</span>
<span id="cb15-33"><a href="#cb15-33" aria-hidden="true" tabindex="-1"></a>                          cv<span class="op">=</span><span class="dv">5</span>, max_iter<span class="op">=</span><span class="dv">10000</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb15-34"><a href="#cb15-34" aria-hidden="true" tabindex="-1"></a>elastic_cv.fit(X_train_scaled, y_train)</span>
<span id="cb15-35"><a href="#cb15-35" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   Meilleur alpha: </span><span class="sc">{</span>elastic_cv<span class="sc">.</span>alpha_<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb15-36"><a href="#cb15-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   Meilleur l1_ratio: </span><span class="sc">{</span>elastic_cv<span class="sc">.</span>l1_ratio_<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb15-37"><a href="#cb15-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-38"><a href="#cb15-38" aria-hidden="true" tabindex="-1"></a>y_pred_elastic <span class="op">=</span> elastic_cv.predict(X_test_scaled)</span>
<span id="cb15-39"><a href="#cb15-39" aria-hidden="true" tabindex="-1"></a>elastic_metrics <span class="op">=</span> evaluate_model(y_test, y_pred_elastic, <span class="st">"ElasticNet (CV)"</span>)</span>
<span id="cb15-40"><a href="#cb15-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-41"><a href="#cb15-41" aria-hidden="true" tabindex="-1"></a><span class="co"># Comparaison finale</span></span>
<span id="cb15-42"><a href="#cb15-42" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb15-43"><a href="#cb15-43" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"COMPARAISON FINALE"</span>)</span>
<span id="cb15-44"><a href="#cb15-44" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb15-45"><a href="#cb15-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-46"><a href="#cb15-46" aria-hidden="true" tabindex="-1"></a>final_comparison <span class="op">=</span> pd.DataFrame({</span>
<span id="cb15-47"><a href="#cb15-47" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Modèle'</span>: [<span class="st">'Linear'</span>, <span class="st">'Ridge (CV)'</span>, <span class="st">'Lasso (CV)'</span>, <span class="st">'ElasticNet (CV)'</span>],</span>
<span id="cb15-48"><a href="#cb15-48" aria-hidden="true" tabindex="-1"></a>    <span class="st">'MAE'</span>: [test_metrics[<span class="st">'MAE'</span>], ridge_metrics[<span class="st">'MAE'</span>], </span>
<span id="cb15-49"><a href="#cb15-49" aria-hidden="true" tabindex="-1"></a>            lasso_metrics[<span class="st">'MAE'</span>], elastic_metrics[<span class="st">'MAE'</span>]],</span>
<span id="cb15-50"><a href="#cb15-50" aria-hidden="true" tabindex="-1"></a>    <span class="st">'RMSE'</span>: [test_metrics[<span class="st">'RMSE'</span>], ridge_metrics[<span class="st">'RMSE'</span>], </span>
<span id="cb15-51"><a href="#cb15-51" aria-hidden="true" tabindex="-1"></a>             lasso_metrics[<span class="st">'RMSE'</span>], elastic_metrics[<span class="st">'RMSE'</span>]],</span>
<span id="cb15-52"><a href="#cb15-52" aria-hidden="true" tabindex="-1"></a>    <span class="st">'R²'</span>: [test_metrics[<span class="st">'R2'</span>], ridge_metrics[<span class="st">'R2'</span>], </span>
<span id="cb15-53"><a href="#cb15-53" aria-hidden="true" tabindex="-1"></a>           lasso_metrics[<span class="st">'R2'</span>], elastic_metrics[<span class="st">'R2'</span>]]</span>
<span id="cb15-54"><a href="#cb15-54" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb15-55"><a href="#cb15-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-56"><a href="#cb15-56" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(final_comparison.to_string(index<span class="op">=</span><span class="va">False</span>))</span>
<span id="cb15-57"><a href="#cb15-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-58"><a href="#cb15-58" aria-hidden="true" tabindex="-1"></a><span class="co"># Meilleur modèle</span></span>
<span id="cb15-59"><a href="#cb15-59" aria-hidden="true" tabindex="-1"></a>best_idx <span class="op">=</span> final_comparison[<span class="st">'R²'</span>].idxmax()</span>
<span id="cb15-60"><a href="#cb15-60" aria-hidden="true" tabindex="-1"></a>best_model_name <span class="op">=</span> final_comparison.loc[best_idx, <span class="st">'Modèle'</span>]</span>
<span id="cb15-61"><a href="#cb15-61" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">→ Meilleur modèle: </span><span class="sc">{</span>best_model_name<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</div>
</section>
</section>
<section id="svr-support-vector-regression" class="level2">
<h2 class="anchored" data-anchor-id="svr-support-vector-regression">6. SVR (Support Vector Regression)</h2>
<section id="exercice-6.1-svr-avec-différents-kernels" class="level3">
<h3 class="anchored" data-anchor-id="exercice-6.1-svr-avec-différents-kernels">Exercice 6.1: SVR avec différents kernels</h3>
<p>Comparez SVR linéaire et RBF.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-8-contents" aria-controls="callout-8" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Solution Exercice 6.1
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-8" class="callout-8-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> SVR</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> GridSearchCV</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"SUPPORT VECTOR REGRESSION"</span>)</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Note: SVR est lent, on réduit le dataset pour démo</span></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>X_train_small <span class="op">=</span> X_train_scaled[:<span class="dv">5000</span>]</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>y_train_small <span class="op">=</span> y_train[:<span class="dv">5000</span>]</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. SVR Linéaire</span></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">1. SVR Linéaire..."</span>)</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>svr_lin <span class="op">=</span> SVR(kernel<span class="op">=</span><span class="st">'linear'</span>, C<span class="op">=</span><span class="fl">1.0</span>)</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>svr_lin.fit(X_train_small, y_train_small)</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>y_pred_svr_lin <span class="op">=</span> svr_lin.predict(X_test_scaled)</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>svr_lin_metrics <span class="op">=</span> evaluate_model(y_test, y_pred_svr_lin, <span class="st">"SVR Linear"</span>)</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. SVR RBF</span></span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">2. SVR RBF..."</span>)</span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>svr_rbf <span class="op">=</span> SVR(kernel<span class="op">=</span><span class="st">'rbf'</span>, C<span class="op">=</span><span class="fl">1.0</span>, gamma<span class="op">=</span><span class="st">'scale'</span>)</span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>svr_rbf.fit(X_train_small, y_train_small)</span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>y_pred_svr_rbf <span class="op">=</span> svr_rbf.predict(X_test_scaled)</span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>svr_rbf_metrics <span class="op">=</span> evaluate_model(y_test, y_pred_svr_rbf, <span class="st">"SVR RBF"</span>)</span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Comparaison</span></span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"COMPARAISON SVR"</span>)</span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a>svr_comparison <span class="op">=</span> pd.DataFrame({</span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Kernel'</span>: [<span class="st">'linear'</span>, <span class="st">'rbf'</span>],</span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a>    <span class="st">'MAE'</span>: [svr_lin_metrics[<span class="st">'MAE'</span>], svr_rbf_metrics[<span class="st">'MAE'</span>]],</span>
<span id="cb16-34"><a href="#cb16-34" aria-hidden="true" tabindex="-1"></a>    <span class="st">'RMSE'</span>: [svr_lin_metrics[<span class="st">'RMSE'</span>], svr_rbf_metrics[<span class="st">'RMSE'</span>]],</span>
<span id="cb16-35"><a href="#cb16-35" aria-hidden="true" tabindex="-1"></a>    <span class="st">'R²'</span>: [svr_lin_metrics[<span class="st">'R2'</span>], svr_rbf_metrics[<span class="st">'R2'</span>]]</span>
<span id="cb16-36"><a href="#cb16-36" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb16-37"><a href="#cb16-37" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(svr_comparison.to_string(index<span class="op">=</span><span class="va">False</span>))</span>
<span id="cb16-38"><a href="#cb16-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-39"><a href="#cb16-39" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Optimisation SVR RBF</span></span>
<span id="cb16-40"><a href="#cb16-40" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb16-41"><a href="#cb16-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"OPTIMISATION SVR RBF AVEC GRIDSEARCH"</span>)</span>
<span id="cb16-42"><a href="#cb16-42" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb16-43"><a href="#cb16-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-44"><a href="#cb16-44" aria-hidden="true" tabindex="-1"></a><span class="co"># Réduction supplémentaire pour vitesse</span></span>
<span id="cb16-45"><a href="#cb16-45" aria-hidden="true" tabindex="-1"></a>X_val <span class="op">=</span> X_train_scaled[<span class="dv">5000</span>:<span class="dv">6000</span>]</span>
<span id="cb16-46"><a href="#cb16-46" aria-hidden="true" tabindex="-1"></a>y_val <span class="op">=</span> y_train[<span class="dv">5000</span>:<span class="dv">6000</span>]</span>
<span id="cb16-47"><a href="#cb16-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-48"><a href="#cb16-48" aria-hidden="true" tabindex="-1"></a>param_grid <span class="op">=</span> {</span>
<span id="cb16-49"><a href="#cb16-49" aria-hidden="true" tabindex="-1"></a>    <span class="st">'C'</span>: [<span class="fl">0.1</span>, <span class="dv">1</span>, <span class="dv">10</span>],</span>
<span id="cb16-50"><a href="#cb16-50" aria-hidden="true" tabindex="-1"></a>    <span class="st">'gamma'</span>: [<span class="st">'scale'</span>, <span class="st">'auto'</span>, <span class="fl">0.01</span>, <span class="fl">0.1</span>],</span>
<span id="cb16-51"><a href="#cb16-51" aria-hidden="true" tabindex="-1"></a>    <span class="st">'epsilon'</span>: [<span class="fl">0.01</span>, <span class="fl">0.1</span>, <span class="fl">0.5</span>]</span>
<span id="cb16-52"><a href="#cb16-52" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb16-53"><a href="#cb16-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-54"><a href="#cb16-54" aria-hidden="true" tabindex="-1"></a>grid_search <span class="op">=</span> GridSearchCV(</span>
<span id="cb16-55"><a href="#cb16-55" aria-hidden="true" tabindex="-1"></a>    SVR(kernel<span class="op">=</span><span class="st">'rbf'</span>),</span>
<span id="cb16-56"><a href="#cb16-56" aria-hidden="true" tabindex="-1"></a>    param_grid,</span>
<span id="cb16-57"><a href="#cb16-57" aria-hidden="true" tabindex="-1"></a>    cv<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb16-58"><a href="#cb16-58" aria-hidden="true" tabindex="-1"></a>    scoring<span class="op">=</span><span class="st">'r2'</span>,</span>
<span id="cb16-59"><a href="#cb16-59" aria-hidden="true" tabindex="-1"></a>    n_jobs<span class="op">=-</span><span class="dv">1</span>,</span>
<span id="cb16-60"><a href="#cb16-60" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="dv">1</span></span>
<span id="cb16-61"><a href="#cb16-61" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb16-62"><a href="#cb16-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-63"><a href="#cb16-63" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Entraînement GridSearch (peut être long)..."</span>)</span>
<span id="cb16-64"><a href="#cb16-64" aria-hidden="true" tabindex="-1"></a>grid_search.fit(X_train_small, y_train_small)</span>
<span id="cb16-65"><a href="#cb16-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-66"><a href="#cb16-66" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Meilleurs paramètres: </span><span class="sc">{</span>grid_search<span class="sc">.</span>best_params_<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb16-67"><a href="#cb16-67" aria-hidden="true" tabindex="-1"></a>best_svr <span class="op">=</span> grid_search.best_estimator_</span>
<span id="cb16-68"><a href="#cb16-68" aria-hidden="true" tabindex="-1"></a>y_pred_best_svr <span class="op">=</span> best_svr.predict(X_val)</span>
<span id="cb16-69"><a href="#cb16-69" aria-hidden="true" tabindex="-1"></a>best_svr_metrics <span class="op">=</span> evaluate_model(y_val, y_pred_best_svr, <span class="st">"SVR optimisé (val)"</span>)</span>
<span id="cb16-70"><a href="#cb16-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-71"><a href="#cb16-71" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualisation SVR</span></span>
<span id="cb16-72"><a href="#cb16-72" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">5</span>))</span>
<span id="cb16-73"><a href="#cb16-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-74"><a href="#cb16-74" aria-hidden="true" tabindex="-1"></a><span class="co"># Prédictions vs Vraies valeurs</span></span>
<span id="cb16-75"><a href="#cb16-75" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].scatter(y_val, y_pred_best_svr, alpha<span class="op">=</span><span class="fl">0.3</span>, s<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb16-76"><a href="#cb16-76" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].plot([y_val.<span class="bu">min</span>(), y_val.<span class="bu">max</span>()], [y_val.<span class="bu">min</span>(), y_val.<span class="bu">max</span>()], </span>
<span id="cb16-77"><a href="#cb16-77" aria-hidden="true" tabindex="-1"></a>             <span class="st">'r--'</span>, lw<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'Prédiction parfaite'</span>)</span>
<span id="cb16-78"><a href="#cb16-78" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_xlabel(<span class="st">'Vraie valeur'</span>)</span>
<span id="cb16-79"><a href="#cb16-79" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_ylabel(<span class="st">'Prédiction'</span>)</span>
<span id="cb16-80"><a href="#cb16-80" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="ss">f'SVR Optimisé (R²=</span><span class="sc">{</span>best_svr_metrics[<span class="st">"R2"</span>]<span class="sc">:.3f}</span><span class="ss">)'</span>)</span>
<span id="cb16-81"><a href="#cb16-81" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].legend()</span>
<span id="cb16-82"><a href="#cb16-82" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].grid(alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb16-83"><a href="#cb16-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-84"><a href="#cb16-84" aria-hidden="true" tabindex="-1"></a><span class="co"># Comparaison modèles</span></span>
<span id="cb16-85"><a href="#cb16-85" aria-hidden="true" tabindex="-1"></a>models_comparison <span class="op">=</span> pd.DataFrame({</span>
<span id="cb16-86"><a href="#cb16-86" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Modèle'</span>: [<span class="st">'Linear'</span>, <span class="st">'Ridge'</span>, <span class="st">'Lasso'</span>, <span class="st">'SVR Linear'</span>, <span class="st">'SVR RBF'</span>],</span>
<span id="cb16-87"><a href="#cb16-87" aria-hidden="true" tabindex="-1"></a>    <span class="st">'RMSE'</span>: [test_metrics[<span class="st">'RMSE'</span>], ridge_metrics[<span class="st">'RMSE'</span>], </span>
<span id="cb16-88"><a href="#cb16-88" aria-hidden="true" tabindex="-1"></a>             lasso_metrics[<span class="st">'RMSE'</span>], svr_lin_metrics[<span class="st">'RMSE'</span>], svr_rbf_metrics[<span class="st">'RMSE'</span>]],</span>
<span id="cb16-89"><a href="#cb16-89" aria-hidden="true" tabindex="-1"></a>    <span class="st">'R²'</span>: [test_metrics[<span class="st">'R2'</span>], ridge_metrics[<span class="st">'R2'</span>], </span>
<span id="cb16-90"><a href="#cb16-90" aria-hidden="true" tabindex="-1"></a>           lasso_metrics[<span class="st">'R2'</span>], svr_lin_metrics[<span class="st">'R2'</span>], svr_rbf_metrics[<span class="st">'R2'</span>]]</span>
<span id="cb16-91"><a href="#cb16-91" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb16-92"><a href="#cb16-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-93"><a href="#cb16-93" aria-hidden="true" tabindex="-1"></a>x_pos <span class="op">=</span> np.arange(<span class="bu">len</span>(models_comparison))</span>
<span id="cb16-94"><a href="#cb16-94" aria-hidden="true" tabindex="-1"></a>width <span class="op">=</span> <span class="fl">0.35</span></span>
<span id="cb16-95"><a href="#cb16-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-96"><a href="#cb16-96" aria-hidden="true" tabindex="-1"></a>bars1 <span class="op">=</span> axes[<span class="dv">1</span>].bar(x_pos <span class="op">-</span> width<span class="op">/</span><span class="dv">2</span>, models_comparison[<span class="st">'RMSE'</span>], width, label<span class="op">=</span><span class="st">'RMSE'</span>)</span>
<span id="cb16-97"><a href="#cb16-97" aria-hidden="true" tabindex="-1"></a>bars2 <span class="op">=</span> axes[<span class="dv">1</span>].bar(x_pos <span class="op">+</span> width<span class="op">/</span><span class="dv">2</span>, models_comparison[<span class="st">'R²'</span>], width, label<span class="op">=</span><span class="st">'R²'</span>)</span>
<span id="cb16-98"><a href="#cb16-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-99"><a href="#cb16-99" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xticks(x_pos)</span>
<span id="cb16-100"><a href="#cb16-100" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xticklabels(models_comparison[<span class="st">'Modèle'</span>], rotation<span class="op">=</span><span class="dv">45</span>, ha<span class="op">=</span><span class="st">'right'</span>)</span>
<span id="cb16-101"><a href="#cb16-101" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_ylabel(<span class="st">'Score'</span>)</span>
<span id="cb16-102"><a href="#cb16-102" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="st">'Comparaison Modèles de Régression'</span>)</span>
<span id="cb16-103"><a href="#cb16-103" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].legend()</span>
<span id="cb16-104"><a href="#cb16-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-105"><a href="#cb16-105" aria-hidden="true" tabindex="-1"></a><span class="co"># Annoter les barres</span></span>
<span id="cb16-106"><a href="#cb16-106" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> bars <span class="kw">in</span> [bars1, bars2]:</span>
<span id="cb16-107"><a href="#cb16-107" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> bar <span class="kw">in</span> bars:</span>
<span id="cb16-108"><a href="#cb16-108" aria-hidden="true" tabindex="-1"></a>        height <span class="op">=</span> bar.get_height()</span>
<span id="cb16-109"><a href="#cb16-109" aria-hidden="true" tabindex="-1"></a>        axes[<span class="dv">1</span>].annotate(<span class="ss">f'</span><span class="sc">{</span>height<span class="sc">:.3f}</span><span class="ss">'</span>,</span>
<span id="cb16-110"><a href="#cb16-110" aria-hidden="true" tabindex="-1"></a>                        xy<span class="op">=</span>(bar.get_x() <span class="op">+</span> bar.get_width() <span class="op">/</span> <span class="dv">2</span>, height),</span>
<span id="cb16-111"><a href="#cb16-111" aria-hidden="true" tabindex="-1"></a>                        xytext<span class="op">=</span>(<span class="dv">0</span>, <span class="dv">3</span>),</span>
<span id="cb16-112"><a href="#cb16-112" aria-hidden="true" tabindex="-1"></a>                        textcoords<span class="op">=</span><span class="st">"offset points"</span>,</span>
<span id="cb16-113"><a href="#cb16-113" aria-hidden="true" tabindex="-1"></a>                        ha<span class="op">=</span><span class="st">'center'</span>, va<span class="op">=</span><span class="st">'bottom'</span>, fontsize<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb16-114"><a href="#cb16-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-115"><a href="#cb16-115" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb16-116"><a href="#cb16-116" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb16-117"><a href="#cb16-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-118"><a href="#cb16-118" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb16-119"><a href="#cb16-119" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"CONSÉILS POUR SVR"</span>)</span>
<span id="cb16-120"><a href="#cb16-120" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb16-121"><a href="#cb16-121" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"""</span></span>
<span id="cb16-122"><a href="#cb16-122" aria-hidden="true" tabindex="-1"></a><span class="st">• SVR est puissant mais COMPUTATIONNELLEMENT COÛTEUX</span></span>
<span id="cb16-123"><a href="#cb16-123" aria-hidden="true" tabindex="-1"></a><span class="st">• Scaling des features OBLIGATOIRE</span></span>
<span id="cb16-124"><a href="#cb16-124" aria-hidden="true" tabindex="-1"></a><span class="st">• GridSearch peut être très long</span></span>
<span id="cb16-125"><a href="#cb16-125" aria-hidden="true" tabindex="-1"></a><span class="st">• Pour grands datasets, considérez:</span></span>
<span id="cb16-126"><a href="#cb16-126" aria-hidden="true" tabindex="-1"></a><span class="st">  - LinearSVR (plus rapide que SVR kernel='linear')</span></span>
<span id="cb16-127"><a href="#cb16-127" aria-hidden="true" tabindex="-1"></a><span class="st">  - Réduction de features (PCA) avant SVR</span></span>
<span id="cb16-128"><a href="#cb16-128" aria-hidden="true" tabindex="-1"></a><span class="st">  - Échantillonnage pour hyperparamètres</span></span>
<span id="cb16-129"><a href="#cb16-129" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</div>
</section>
</section>
<section id="comparaison-finale-de-tous-les-modèles" class="level2">
<h2 class="anchored" data-anchor-id="comparaison-finale-de-tous-les-modèles">7. Comparaison Finale de Tous les Modèles</h2>
<section id="exercice-7.1-tableau-de-bord-complet" class="level3">
<h3 class="anchored" data-anchor-id="exercice-7.1-tableau-de-bord-complet">Exercice 7.1: Tableau de Bord Complet</h3>
<p>Créez un tableau de bord comparatif de tous les modèles.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-9-contents" aria-controls="callout-9" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-9" class="callout-9-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"TABLEAU DE BORD COMPARATIF"</span>)</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Collecte de tous les résultats</span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>all_results <span class="op">=</span> []</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Fonction pour ajouter un modèle</span></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> add_result(name, y_pred, metrics_func<span class="op">=</span>evaluate_model):</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>    mae <span class="op">=</span> mean_absolute_error(y_test, y_pred)</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>    rmse <span class="op">=</span> np.sqrt(mean_squared_error(y_test, y_pred))</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>    r2 <span class="op">=</span> r2_score(y_test, y_pred)</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {<span class="st">'Modèle'</span>: name, <span class="st">'MAE'</span>: mae, <span class="st">'RMSE'</span>: rmse, <span class="st">'R²'</span>: r2}</span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Ajout de tous les modèles</span></span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>all_results.append(add_result(<span class="st">'Linear'</span>, y_test_pred))</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>all_results.append(add_result(<span class="st">'Ridge (CV)'</span>, y_pred_ridge))</span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>all_results.append(add_result(<span class="st">'Lasso (CV)'</span>, y_pred_lasso))</span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>all_results.append(add_result(<span class="st">'ElasticNet (CV)'</span>, y_pred_elastic))</span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>all_results.append(add_result(<span class="st">'SVR Linear'</span>, y_pred_svr_lin))</span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>all_results.append(add_result(<span class="st">'SVR RBF'</span>, y_pred_svr_rbf))</span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a>df_all_results <span class="op">=</span> pd.DataFrame(all_results)</span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Tri par R²</span></span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a>df_all_results <span class="op">=</span> df_all_results.sort_values(<span class="st">'R²'</span>, ascending<span class="op">=</span><span class="va">False</span>).reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Classement par R²:"</span>)</span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df_all_results.to_string(index<span class="op">=</span><span class="va">False</span>))</span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualisation</span></span>
<span id="cb17-32"><a href="#cb17-32" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">12</span>))</span>
<span id="cb17-33"><a href="#cb17-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-34"><a href="#cb17-34" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Barplot R²</span></span>
<span id="cb17-35"><a href="#cb17-35" aria-hidden="true" tabindex="-1"></a>x_pos <span class="op">=</span> np.arange(<span class="bu">len</span>(df_all_results))</span>
<span id="cb17-36"><a href="#cb17-36" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].barh(x_pos, df_all_results[<span class="st">'R²'</span>], color<span class="op">=</span><span class="st">'skyblue'</span>)</span>
<span id="cb17-37"><a href="#cb17-37" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].set_yticks(x_pos)</span>
<span id="cb17-38"><a href="#cb17-38" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].set_yticklabels(df_all_results[<span class="st">'Modèle'</span>])</span>
<span id="cb17-39"><a href="#cb17-39" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].set_xlabel(<span class="st">'R² Score'</span>)</span>
<span id="cb17-40"><a href="#cb17-40" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].set_title(<span class="st">'Comparaison R² des Modèles'</span>)</span>
<span id="cb17-41"><a href="#cb17-41" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].invert_yaxis()  <span class="co"># Meilleur en haut</span></span>
<span id="cb17-42"><a href="#cb17-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-43"><a href="#cb17-43" aria-hidden="true" tabindex="-1"></a><span class="co"># Annoter les valeurs</span></span>
<span id="cb17-44"><a href="#cb17-44" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, v <span class="kw">in</span> <span class="bu">enumerate</span>(df_all_results[<span class="st">'R²'</span>]):</span>
<span id="cb17-45"><a href="#cb17-45" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">0</span>, <span class="dv">0</span>].text(v <span class="op">+</span> <span class="fl">0.001</span>, i, <span class="ss">f'</span><span class="sc">{</span>v<span class="sc">:.4f}</span><span class="ss">'</span>, va<span class="op">=</span><span class="st">'center'</span>)</span>
<span id="cb17-46"><a href="#cb17-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-47"><a href="#cb17-47" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Comparaison MAE vs RMSE</span></span>
<span id="cb17-48"><a href="#cb17-48" aria-hidden="true" tabindex="-1"></a>scatter <span class="op">=</span> axes[<span class="dv">0</span>, <span class="dv">1</span>].scatter(df_all_results[<span class="st">'MAE'</span>], df_all_results[<span class="st">'RMSE'</span>], </span>
<span id="cb17-49"><a href="#cb17-49" aria-hidden="true" tabindex="-1"></a>                             s<span class="op">=</span><span class="dv">200</span>, alpha<span class="op">=</span><span class="fl">0.6</span>, c<span class="op">=</span>df_all_results[<span class="st">'R²'</span>], cmap<span class="op">=</span><span class="st">'viridis'</span>)</span>
<span id="cb17-50"><a href="#cb17-50" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, row <span class="kw">in</span> df_all_results.iterrows():</span>
<span id="cb17-51"><a href="#cb17-51" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">0</span>, <span class="dv">1</span>].annotate(row[<span class="st">'Modèle'</span>], (row[<span class="st">'MAE'</span>], row[<span class="st">'RMSE'</span>]), fontsize<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb17-52"><a href="#cb17-52" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">1</span>].set_xlabel(<span class="st">'MAE'</span>)</span>
<span id="cb17-53"><a href="#cb17-53" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">1</span>].set_ylabel(<span class="st">'RMSE'</span>)</span>
<span id="cb17-54"><a href="#cb17-54" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">1</span>].set_title(<span class="st">'MAE vs RMSE (couleur = R²)'</span>)</span>
<span id="cb17-55"><a href="#cb17-55" aria-hidden="true" tabindex="-1"></a>plt.colorbar(scatter, ax<span class="op">=</span>axes[<span class="dv">0</span>, <span class="dv">1</span>], label<span class="op">=</span><span class="st">'R² Score'</span>)</span>
<span id="cb17-56"><a href="#cb17-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-57"><a href="#cb17-57" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Temps d'entraînement (exemple)</span></span>
<span id="cb17-58"><a href="#cb17-58" aria-hidden="true" tabindex="-1"></a><span class="co"># Dans un cas réel, on mesurerait le temps</span></span>
<span id="cb17-59"><a href="#cb17-59" aria-hidden="true" tabindex="-1"></a>training_times <span class="op">=</span> [<span class="fl">0.1</span>, <span class="fl">0.2</span>, <span class="fl">0.3</span>, <span class="fl">0.4</span>, <span class="fl">2.0</span>, <span class="fl">5.0</span>]  <span class="co"># valeurs d'exemple</span></span>
<span id="cb17-60"><a href="#cb17-60" aria-hidden="true" tabindex="-1"></a>df_all_results[<span class="st">'Temps(s)'</span>] <span class="op">=</span> training_times</span>
<span id="cb17-61"><a href="#cb17-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-62"><a href="#cb17-62" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">0</span>].scatter(df_all_results[<span class="st">'Temps(s)'</span>], df_all_results[<span class="st">'R²'</span>], s<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb17-63"><a href="#cb17-63" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, row <span class="kw">in</span> df_all_results.iterrows():</span>
<span id="cb17-64"><a href="#cb17-64" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">1</span>, <span class="dv">0</span>].annotate(row[<span class="st">'Modèle'</span>], (row[<span class="st">'Temps(s)'</span>], row[<span class="st">'R²'</span>]), fontsize<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb17-65"><a href="#cb17-65" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">0</span>].set_xlabel(<span class="st">'Temps d</span><span class="ch">\'</span><span class="st">entraînement (s)'</span>)</span>
<span id="cb17-66"><a href="#cb17-66" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">0</span>].set_ylabel(<span class="st">'R² Score'</span>)</span>
<span id="cb17-67"><a href="#cb17-67" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">0</span>].set_title(<span class="st">'Performance vs Temps d</span><span class="ch">\'</span><span class="st">entraînement'</span>)</span>
<span id="cb17-68"><a href="#cb17-68" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">0</span>].grid(alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb17-69"><a href="#cb17-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-70"><a href="#cb17-70" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Heatmap des métriques</span></span>
<span id="cb17-71"><a href="#cb17-71" aria-hidden="true" tabindex="-1"></a>metrics_df <span class="op">=</span> df_all_results.set_index(<span class="st">'Modèle'</span>)[[<span class="st">'MAE'</span>, <span class="st">'RMSE'</span>, <span class="st">'R²'</span>]]</span>
<span id="cb17-72"><a href="#cb17-72" aria-hidden="true" tabindex="-1"></a>sns.heatmap(metrics_df, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">'.4f'</span>, cmap<span class="op">=</span><span class="st">'YlOrRd'</span>, </span>
<span id="cb17-73"><a href="#cb17-73" aria-hidden="true" tabindex="-1"></a>            center<span class="op">=</span><span class="dv">0</span>, ax<span class="op">=</span>axes[<span class="dv">1</span>, <span class="dv">1</span>], cbar_kws<span class="op">=</span>{<span class="st">'label'</span>: <span class="st">'Valeur'</span>})</span>
<span id="cb17-74"><a href="#cb17-74" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">1</span>].set_title(<span class="st">'Heatmap des Métriques par Modèle'</span>)</span>
<span id="cb17-75"><a href="#cb17-75" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">1</span>].tick_params(axis<span class="op">=</span><span class="st">'x'</span>, rotation<span class="op">=</span><span class="dv">45</span>)</span>
<span id="cb17-76"><a href="#cb17-76" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">1</span>].tick_params(axis<span class="op">=</span><span class="st">'y'</span>, rotation<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb17-77"><a href="#cb17-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-78"><a href="#cb17-78" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb17-79"><a href="#cb17-79" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb17-80"><a href="#cb17-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-81"><a href="#cb17-81" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb17-82"><a href="#cb17-82" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"RECOMMANDATIONS FINALES"</span>)</span>
<span id="cb17-83"><a href="#cb17-83" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb17-84"><a href="#cb17-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-85"><a href="#cb17-85" aria-hidden="true" tabindex="-1"></a><span class="co"># Recommandation basée sur différents critères</span></span>
<span id="cb17-86"><a href="#cb17-86" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"""</span></span>
<span id="cb17-87"><a href="#cb17-87" aria-hidden="true" tabindex="-1"></a><span class="st">1. Pour PERFORMANCE MAX (R²):</span></span>
<span id="cb17-88"><a href="#cb17-88" aria-hidden="true" tabindex="-1"></a><span class="st">   → </span><span class="sc">{}</span><span class="st"> (R²=</span><span class="sc">{:.4f}</span><span class="st">)</span></span>
<span id="cb17-89"><a href="#cb17-89" aria-hidden="true" tabindex="-1"></a><span class="st">   </span></span>
<span id="cb17-90"><a href="#cb17-90" aria-hidden="true" tabindex="-1"></a><span class="st">2. Pour INTERPRÉTABILITÉ (coefficients):</span></span>
<span id="cb17-91"><a href="#cb17-91" aria-hidden="true" tabindex="-1"></a><span class="st">   → Lasso (CV) (sélection de features)</span></span>
<span id="cb17-92"><a href="#cb17-92" aria-hidden="true" tabindex="-1"></a><span class="st">   </span></span>
<span id="cb17-93"><a href="#cb17-93" aria-hidden="true" tabindex="-1"></a><span class="st">3. Pour RAPIDITÉ:</span></span>
<span id="cb17-94"><a href="#cb17-94" aria-hidden="true" tabindex="-1"></a><span class="st">   → Linear ou Ridge (CV)</span></span>
<span id="cb17-95"><a href="#cb17-95" aria-hidden="true" tabindex="-1"></a><span class="st">   </span></span>
<span id="cb17-96"><a href="#cb17-96" aria-hidden="true" tabindex="-1"></a><span class="st">4. Pour COMPLEXITÉ NON-LINÉAIRE:</span></span>
<span id="cb17-97"><a href="#cb17-97" aria-hidden="true" tabindex="-1"></a><span class="st">   → SVR RBF (mais plus lent)</span></span>
<span id="cb17-98"><a href="#cb17-98" aria-hidden="true" tabindex="-1"></a><span class="st">   </span></span>
<span id="cb17-99"><a href="#cb17-99" aria-hidden="true" tabindex="-1"></a><span class="st">5. COMPROMIS PERFORMANCE/TEMPS:</span></span>
<span id="cb17-100"><a href="#cb17-100" aria-hidden="true" tabindex="-1"></a><span class="st">   → ElasticNet (CV)</span></span>
<span id="cb17-101"><a href="#cb17-101" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span>.<span class="bu">format</span>(df_all_results.iloc[<span class="dv">0</span>][<span class="st">'Modèle'</span>], df_all_results.iloc[<span class="dv">0</span>][<span class="st">'R²'</span>]))</span>
<span id="cb17-102"><a href="#cb17-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-103"><a href="#cb17-103" aria-hidden="true" tabindex="-1"></a><span class="co"># Sauvegarde des résultats</span></span>
<span id="cb17-104"><a href="#cb17-104" aria-hidden="true" tabindex="-1"></a>df_all_results.to_csv(<span class="st">'resultats_regression_comparaison.csv'</span>, index<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb17-105"><a href="#cb17-105" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Résultats sauvegardés dans 'resultats_regression_comparaison.csv'"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</div>
</section>
</section>
<section id="projet-bonus-regression-avancée" class="level2">
<h2 class="anchored" data-anchor-id="projet-bonus-regression-avancée">8. Projet Bonus: Regression Avancée</h2>
<section id="exercice-8.1-ensemble-methods" class="level3">
<h3 class="anchored" data-anchor-id="exercice-8.1-ensemble-methods">Exercice 8.1: Ensemble Methods</h3>
<p>Testez Random Forest et Gradient Boosting pour la régression.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestRegressor, GradientBoostingRegressor</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> RandomizedSearchCV</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="co"># </span><span class="al">TODO</span><span class="co">: Implémentez Random Forest et Gradient Boosting</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Optimisez avec RandomizedSearchCV</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Comparez avec les modèles linéaires</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><strong>Indices:</strong> - Pas besoin de standardisation pour les arbres - Optimisez: n_estimators, max_depth, min_samples_split - Métrique: RMSE ou MAE - Visualisez l’importance des features</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-10-contents" aria-controls="callout-10" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Solution Exercice 8.1
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-10" class="callout-10-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"ENSEMBLE METHODS: RANDOM FOREST &amp; GRADIENT BOOSTING"</span>)</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Pas besoin de scaling pour les arbres</span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>X_train_trees <span class="op">=</span> X_train</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>X_test_trees <span class="op">=</span> X_test</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Random Forest</span></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">1. Random Forest Regressor..."</span>)</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>rf <span class="op">=</span> RandomForestRegressor(random_state<span class="op">=</span><span class="dv">42</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Hyperparamètres</span></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>param_dist_rf <span class="op">=</span> {</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>    <span class="st">'n_estimators'</span>: [<span class="dv">100</span>, <span class="dv">200</span>, <span class="dv">300</span>],</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>    <span class="st">'max_depth'</span>: [<span class="va">None</span>, <span class="dv">10</span>, <span class="dv">20</span>, <span class="dv">30</span>],</span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>    <span class="st">'min_samples_split'</span>: [<span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">10</span>],</span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>    <span class="st">'min_samples_leaf'</span>: [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">4</span>]</span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>rf_random <span class="op">=</span> RandomizedSearchCV(</span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a>    rf, param_dist_rf, n_iter<span class="op">=</span><span class="dv">20</span>, cv<span class="op">=</span><span class="dv">3</span>, </span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a>    scoring<span class="op">=</span><span class="st">'neg_mean_squared_error'</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>, random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true" tabindex="-1"></a>rf_random.fit(X_train_trees, y_train)</span>
<span id="cb19-27"><a href="#cb19-27" aria-hidden="true" tabindex="-1"></a>best_rf <span class="op">=</span> rf_random.best_estimator_</span>
<span id="cb19-28"><a href="#cb19-28" aria-hidden="true" tabindex="-1"></a>y_pred_rf <span class="op">=</span> best_rf.predict(X_test_trees)</span>
<span id="cb19-29"><a href="#cb19-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-30"><a href="#cb19-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Meilleurs paramètres RF: </span><span class="sc">{</span>rf_random<span class="sc">.</span>best_params_<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-31"><a href="#cb19-31" aria-hidden="true" tabindex="-1"></a>rf_metrics <span class="op">=</span> evaluate_model(y_test, y_pred_rf, <span class="st">"Random Forest"</span>)</span>
<span id="cb19-32"><a href="#cb19-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-33"><a href="#cb19-33" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Gradient Boosting</span></span>
<span id="cb19-34"><a href="#cb19-34" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">2. Gradient Boosting Regressor..."</span>)</span>
<span id="cb19-35"><a href="#cb19-35" aria-hidden="true" tabindex="-1"></a>gbr <span class="op">=</span> GradientBoostingRegressor(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb19-36"><a href="#cb19-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-37"><a href="#cb19-37" aria-hidden="true" tabindex="-1"></a>param_dist_gbr <span class="op">=</span> {</span>
<span id="cb19-38"><a href="#cb19-38" aria-hidden="true" tabindex="-1"></a>    <span class="st">'n_estimators'</span>: [<span class="dv">100</span>, <span class="dv">200</span>],</span>
<span id="cb19-39"><a href="#cb19-39" aria-hidden="true" tabindex="-1"></a>    <span class="st">'learning_rate'</span>: [<span class="fl">0.01</span>, <span class="fl">0.05</span>, <span class="fl">0.1</span>],</span>
<span id="cb19-40"><a href="#cb19-40" aria-hidden="true" tabindex="-1"></a>    <span class="st">'max_depth'</span>: [<span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>],</span>
<span id="cb19-41"><a href="#cb19-41" aria-hidden="true" tabindex="-1"></a>    <span class="st">'subsample'</span>: [<span class="fl">0.8</span>, <span class="fl">0.9</span>, <span class="fl">1.0</span>]</span>
<span id="cb19-42"><a href="#cb19-42" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb19-43"><a href="#cb19-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-44"><a href="#cb19-44" aria-hidden="true" tabindex="-1"></a>gbr_random <span class="op">=</span> RandomizedSearchCV(</span>
<span id="cb19-45"><a href="#cb19-45" aria-hidden="true" tabindex="-1"></a>    gbr, param_dist_gbr, n_iter<span class="op">=</span><span class="dv">15</span>, cv<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb19-46"><a href="#cb19-46" aria-hidden="true" tabindex="-1"></a>    scoring<span class="op">=</span><span class="st">'neg_mean_squared_error'</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>, random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb19-47"><a href="#cb19-47" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb19-48"><a href="#cb19-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-49"><a href="#cb19-49" aria-hidden="true" tabindex="-1"></a>gbr_random.fit(X_train_trees, y_train)</span>
<span id="cb19-50"><a href="#cb19-50" aria-hidden="true" tabindex="-1"></a>best_gbr <span class="op">=</span> gbr_random.best_estimator_</span>
<span id="cb19-51"><a href="#cb19-51" aria-hidden="true" tabindex="-1"></a>y_pred_gbr <span class="op">=</span> best_gbr.predict(X_test_trees)</span>
<span id="cb19-52"><a href="#cb19-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-53"><a href="#cb19-53" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Meilleurs paramètres GBR: </span><span class="sc">{</span>gbr_random<span class="sc">.</span>best_params_<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-54"><a href="#cb19-54" aria-hidden="true" tabindex="-1"></a>gbr_metrics <span class="op">=</span> evaluate_model(y_test, y_pred_gbr, <span class="st">"Gradient Boosting"</span>)</span>
<span id="cb19-55"><a href="#cb19-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-56"><a href="#cb19-56" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Comparaison</span></span>
<span id="cb19-57"><a href="#cb19-57" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb19-58"><a href="#cb19-58" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"COMPARAISON MODÈLES AVANCÉS"</span>)</span>
<span id="cb19-59"><a href="#cb19-59" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb19-60"><a href="#cb19-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-61"><a href="#cb19-61" aria-hidden="true" tabindex="-1"></a>ensemble_results <span class="op">=</span> pd.DataFrame([</span>
<span id="cb19-62"><a href="#cb19-62" aria-hidden="true" tabindex="-1"></a>    {<span class="st">'Modèle'</span>: <span class="st">'Random Forest'</span>, <span class="st">'MAE'</span>: rf_metrics[<span class="st">'MAE'</span>], </span>
<span id="cb19-63"><a href="#cb19-63" aria-hidden="true" tabindex="-1"></a>     <span class="st">'RMSE'</span>: rf_metrics[<span class="st">'RMSE'</span>], <span class="st">'R²'</span>: rf_metrics[<span class="st">'R2'</span>]},</span>
<span id="cb19-64"><a href="#cb19-64" aria-hidden="true" tabindex="-1"></a>    {<span class="st">'Modèle'</span>: <span class="st">'Gradient Boosting'</span>, <span class="st">'MAE'</span>: gbr_metrics[<span class="st">'MAE'</span>], </span>
<span id="cb19-65"><a href="#cb19-65" aria-hidden="true" tabindex="-1"></a>     <span class="st">'RMSE'</span>: gbr_metrics[<span class="st">'RMSE'</span>], <span class="st">'R²'</span>: gbr_metrics[<span class="st">'R2'</span>]},</span>
<span id="cb19-66"><a href="#cb19-66" aria-hidden="true" tabindex="-1"></a>    {<span class="st">'Modèle'</span>: <span class="st">'Meilleur Linéaire'</span>, <span class="st">'MAE'</span>: df_all_results.iloc[<span class="dv">0</span>][<span class="st">'MAE'</span>],</span>
<span id="cb19-67"><a href="#cb19-67" aria-hidden="true" tabindex="-1"></a>     <span class="st">'RMSE'</span>: df_all_results.iloc[<span class="dv">0</span>][<span class="st">'RMSE'</span>], <span class="st">'R²'</span>: df_all_results.iloc[<span class="dv">0</span>][<span class="st">'R²'</span>]}</span>
<span id="cb19-68"><a href="#cb19-68" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb19-69"><a href="#cb19-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-70"><a href="#cb19-70" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(ensemble_results.to_string(index<span class="op">=</span><span class="va">False</span>))</span>
<span id="cb19-71"><a href="#cb19-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-72"><a href="#cb19-72" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Importance des features</span></span>
<span id="cb19-73"><a href="#cb19-73" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb19-74"><a href="#cb19-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-75"><a href="#cb19-75" aria-hidden="true" tabindex="-1"></a><span class="co"># Random Forest</span></span>
<span id="cb19-76"><a href="#cb19-76" aria-hidden="true" tabindex="-1"></a>rf_importances <span class="op">=</span> pd.DataFrame({</span>
<span id="cb19-77"><a href="#cb19-77" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Feature'</span>: california.feature_names,</span>
<span id="cb19-78"><a href="#cb19-78" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Importance'</span>: best_rf.feature_importances_</span>
<span id="cb19-79"><a href="#cb19-79" aria-hidden="true" tabindex="-1"></a>}).sort_values(<span class="st">'Importance'</span>, ascending<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb19-80"><a href="#cb19-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-81"><a href="#cb19-81" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].barh(rf_importances[<span class="st">'Feature'</span>], rf_importances[<span class="st">'Importance'</span>])</span>
<span id="cb19-82"><a href="#cb19-82" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_xlabel(<span class="st">'Importance'</span>)</span>
<span id="cb19-83"><a href="#cb19-83" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="st">'Importance des Features - Random Forest'</span>)</span>
<span id="cb19-84"><a href="#cb19-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-85"><a href="#cb19-85" aria-hidden="true" tabindex="-1"></a><span class="co"># Gradient Boosting</span></span>
<span id="cb19-86"><a href="#cb19-86" aria-hidden="true" tabindex="-1"></a>gbr_importances <span class="op">=</span> pd.DataFrame({</span>
<span id="cb19-87"><a href="#cb19-87" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Feature'</span>: california.feature_names,</span>
<span id="cb19-88"><a href="#cb19-88" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Importance'</span>: best_gbr.feature_importances_</span>
<span id="cb19-89"><a href="#cb19-89" aria-hidden="true" tabindex="-1"></a>}).sort_values(<span class="st">'Importance'</span>, ascending<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb19-90"><a href="#cb19-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-91"><a href="#cb19-91" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].barh(gbr_importances[<span class="st">'Feature'</span>], gbr_importances[<span class="st">'Importance'</span>])</span>
<span id="cb19-92"><a href="#cb19-92" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xlabel(<span class="st">'Importance'</span>)</span>
<span id="cb19-93"><a href="#cb19-93" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="st">'Importance des Features - Gradient Boosting'</span>)</span>
<span id="cb19-94"><a href="#cb19-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-95"><a href="#cb19-95" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb19-96"><a href="#cb19-96" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb19-97"><a href="#cb19-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-98"><a href="#cb19-98" aria-hidden="true" tabindex="-1"></a><span class="co"># 5. Visualisation prédictions</span></span>
<span id="cb19-99"><a href="#cb19-99" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">5</span>))</span>
<span id="cb19-100"><a href="#cb19-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-101"><a href="#cb19-101" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].scatter(y_test, y_pred_rf, alpha<span class="op">=</span><span class="fl">0.3</span>, s<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb19-102"><a href="#cb19-102" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].plot([y_test.<span class="bu">min</span>(), y_test.<span class="bu">max</span>()], [y_test.<span class="bu">min</span>(), y_test.<span class="bu">max</span>()], <span class="st">'r--'</span>)</span>
<span id="cb19-103"><a href="#cb19-103" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_xlabel(<span class="st">'Vraie valeur'</span>)</span>
<span id="cb19-104"><a href="#cb19-104" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_ylabel(<span class="st">'Prédiction'</span>)</span>
<span id="cb19-105"><a href="#cb19-105" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="ss">f'Random Forest (R²=</span><span class="sc">{</span>rf_metrics[<span class="st">"R2"</span>]<span class="sc">:.3f}</span><span class="ss">)'</span>)</span>
<span id="cb19-106"><a href="#cb19-106" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].grid(alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb19-107"><a href="#cb19-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-108"><a href="#cb19-108" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].scatter(y_test, y_pred_gbr, alpha<span class="op">=</span><span class="fl">0.3</span>, s<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb19-109"><a href="#cb19-109" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].plot([y_test.<span class="bu">min</span>(), y_test.<span class="bu">max</span>()], [y_test.<span class="bu">min</span>(), y_test.<span class="bu">max</span>()], <span class="st">'r--'</span>)</span>
<span id="cb19-110"><a href="#cb19-110" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xlabel(<span class="st">'Vraie valeur'</span>)</span>
<span id="cb19-111"><a href="#cb19-111" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_ylabel(<span class="st">'Prédiction'</span>)</span>
<span id="cb19-112"><a href="#cb19-112" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="ss">f'Gradient Boosting (R²=</span><span class="sc">{</span>gbr_metrics[<span class="st">"R2"</span>]<span class="sc">:.3f}</span><span class="ss">)'</span>)</span>
<span id="cb19-113"><a href="#cb19-113" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].grid(alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb19-114"><a href="#cb19-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-115"><a href="#cb19-115" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb19-116"><a href="#cb19-116" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb19-117"><a href="#cb19-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-118"><a href="#cb19-118" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb19-119"><a href="#cb19-119" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"CONCLUSION ENSEMBLE METHODS"</span>)</span>
<span id="cb19-120"><a href="#cb19-120" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb19-121"><a href="#cb19-121" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"""</span></span>
<span id="cb19-122"><a href="#cb19-122" aria-hidden="true" tabindex="-1"></a><span class="st">• Random Forest et Gradient Boosting PERFORMENT TRÈS BIEN</span></span>
<span id="cb19-123"><a href="#cb19-123" aria-hidden="true" tabindex="-1"></a><span class="st">• Pas besoin de feature scaling</span></span>
<span id="cb19-124"><a href="#cb19-124" aria-hidden="true" tabindex="-1"></a><span class="st">• Capturent relations non-linéaires complexes</span></span>
<span id="cb19-125"><a href="#cb19-125" aria-hidden="true" tabindex="-1"></a><span class="st">• MOINS INTERPRÉTABLES que les modèles linéaires</span></span>
<span id="cb19-126"><a href="#cb19-126" aria-hidden="true" tabindex="-1"></a><span class="st">• PLUS LENTS à entraîner</span></span>
<span id="cb19-127"><a href="#cb19-127" aria-hidden="true" tabindex="-1"></a><span class="st">• Risque de surapprentissage si pas bien régularisés</span></span>
<span id="cb19-128"><a href="#cb19-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-129"><a href="#cb19-129" aria-hidden="true" tabindex="-1"></a><span class="st">→ Recommandation: Utiliser pour compétitions Kaggle</span></span>
<span id="cb19-130"><a href="#cb19-130" aria-hidden="true" tabindex="-1"></a><span class="st">→ Pour production: Privilégier modèles plus simples si performance similaire</span></span>
<span id="cb19-131"><a href="#cb19-131" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</div>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<section id="résumé-des-points-clés" class="level3">
<h3 class="anchored" data-anchor-id="résumé-des-points-clés">Résumé des Points Clés</h3>
<ol type="1">
<li><strong>Prétraitement</strong>:
<ul>
<li>Standardisation cruciale pour modèles régularisés et SVR</li>
<li>Split stratifié (si target stratifiable)</li>
<li>Pas de data leakage</li>
</ul></li>
<li><strong>Modèles Linéaires</strong>:
<ul>
<li><strong>Linear</strong>: Simple, rapide, interprétable</li>
<li><strong>Ridge</strong>: Régularisation L2, réduit overfitting</li>
<li><strong>Lasso</strong>: Régularisation L1, sélection features</li>
<li><strong>ElasticNet</strong>: Compromis L1+L2</li>
</ul></li>
<li><strong>Modèles Non-Linéaires</strong>:
<ul>
<li><strong>SVR</strong>: Puissant mais lent, sensible aux hyperparamètres</li>
<li><strong>Random Forest</strong>: Robuste, capture non-linéarités</li>
<li><strong>Gradient Boosting</strong>: Souvent meilleure performance</li>
</ul></li>
<li><strong>Optimisation</strong>:
<ul>
<li>Utiliser *CV (RidgeCV, LassoCV) pour alpha automatique</li>
<li>GridSearch pour petit espace</li>
<li>RandomizedSearch pour grand espace</li>
</ul></li>
<li><strong>Évaluation</strong>:
<ul>
<li>Multiples métriques: MAE, RMSE, R²</li>
<li>Visualisations: résidus, prédictions vs vraies valeurs</li>
<li>Importance des features pour interprétation</li>
</ul></li>
</ol>
</section>
<section id="checklist-de-validation" class="level3">
<h3 class="anchored" data-anchor-id="checklist-de-validation">Checklist de Validation</h3>
<p>Avant de soumettre votre travail:</p>
<ul class="task-list">
<li><label><input type="checkbox">Exploratory Data Analysis complète</label></li>
<li><label><input type="checkbox">Prétraitement correct (train/test séparés)</label></li>
<li><label><input type="checkbox">Au moins 4 modèles comparés</label></li>
<li><label><input type="checkbox">Optimisation hyperparamètres avec CV</label></li>
<li><label><input type="checkbox">Évaluation sur test set (une seule fois)</label></li>
<li><label><input type="checkbox">Visualisations claires et annotées</label></li>
<li><label><input type="checkbox">Interprétation des résultats</label></li>
<li><label><input type="checkbox">Code commenté et organisé</label></li>
</ul>
</section>
<section id="pour-aller-plus-loin" class="level3">
<h3 class="anchored" data-anchor-id="pour-aller-plus-loin">Pour Aller Plus Loin</h3>
<p><strong>Extensions possibles:</strong></p>
<ol type="1">
<li><p><strong>Feature Engineering</strong>:</p>
<ul>
<li>Créer interactions entre features</li>
<li>Transformations polynomiales</li>
<li>Variables dummy pour catégorielles</li>
</ul></li>
<li><p><strong>Pipeline Scikit-learn</strong>:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> Pipeline</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.compose <span class="im">import</span> ColumnTransformer</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>pipeline <span class="op">=</span> Pipeline([</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'scaler'</span>, StandardScaler()),</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'regressor'</span>, RidgeCV())</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div></li>
<li><p><strong>Validation Croisée Temporelle</strong>:</p>
<ul>
<li>Pour données chronologiques</li>
<li>TimeSeriesSplit au lieu de KFold</li>
</ul></li>
<li><p><strong>Prédiction d’Intervalles</strong>:</p>
<ul>
<li>Quantile Regression</li>
<li>Bootstrap pour incertitude</li>
</ul></li>
<li><p><strong>Déploiement</strong>:</p>
<ul>
<li>Sauvegarde modèle (joblib)</li>
<li>API avec FastAPI/Flask</li>
<li>Monitoring des performances</li>
</ul></li>
</ol>
<p><strong>Exercices supplémentaires:</strong></p>
<ol type="1">
<li>Testez PolynomialFeatures + Regression</li>
<li>Implémentez une validation croisée imbriquée</li>
<li>Ajoutez XGBoost ou LightGBM à la comparaison</li>
<li>Créez un dashboard interactif avec Plotly</li>
</ol>
<p><strong>Prochain TP:</strong> Séries Temporelles ou Deep Learning</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Astuce Finale
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>La meilleure pratique:</strong> Commencez toujours par un modèle simple (régression linéaire), puis complexifiez si nécessaire. Souvent, les modèles simples suffisent et sont plus faciles à maintenir en production!</p>
</div>
</div>


<!-- -->

</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/nevermind78\.github\.io\/Ml_DL\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./seance7.html" class="pagination-link" aria-label="Séance 7: Cours - Apprentissage Supervisé : Régression">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-title">Séance 7: Cours - Apprentissage Supervisé : Régression</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./seance9.html" class="pagination-link" aria-label="Séance 9: Apprentissage Non Supervisé">
        <span class="nav-page-text"><span class="chapter-title">Séance 9: Apprentissage Non Supervisé</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb21" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># Séance 8: TP3 - Régression &amp; Optimisation</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>::: {.callout-note icon=false}</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="fu">## Informations de la séance</span></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Type**: Travaux Pratiques</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Durée**: 2h</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Objectifs**: Obj6, Obj7</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a><span class="fu">## Introduction</span></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>Dans ce TP, nous allons mettre en pratique les concepts de régression vus en cours. Nous travaillerons sur un dataset réel pour prédire les prix de maisons, en comparant différents modèles de régression et en optimisant leurs hyperparamètres.</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>**Objectifs du TP:**</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Prétraiter des données pour la régression</span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Implémenter et comparer Linear, Ridge, Lasso, ElasticNet, SVR</span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Optimiser les hyperparamètres avec CV</span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>Évaluer avec métriques multiples (MAE, RMSE, R²)</span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>Interpréter et visualiser les résultats</span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a><span class="fu">## 1. Chargement et Exploration du Dataset</span></span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>Nous utilisons le **Boston Housing Dataset** (ou California Housing si Boston non disponible).</span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb21-29"><a href="#cb21-29" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: true</span></span>
<span id="cb21-30"><a href="#cb21-30" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb21-31"><a href="#cb21-31" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb21-32"><a href="#cb21-32" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb21-33"><a href="#cb21-33" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb21-34"><a href="#cb21-34" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> fetch_california_housing</span>
<span id="cb21-35"><a href="#cb21-35" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb21-36"><a href="#cb21-36" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb21-37"><a href="#cb21-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-38"><a href="#cb21-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Chargement</span></span>
<span id="cb21-39"><a href="#cb21-39" aria-hidden="true" tabindex="-1"></a>california <span class="op">=</span> fetch_california_housing()</span>
<span id="cb21-40"><a href="#cb21-40" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> california.data, california.target</span>
<span id="cb21-41"><a href="#cb21-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-42"><a href="#cb21-42" aria-hidden="true" tabindex="-1"></a><span class="co"># DataFrame pour exploration</span></span>
<span id="cb21-43"><a href="#cb21-43" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(X, columns<span class="op">=</span>california.feature_names)</span>
<span id="cb21-44"><a href="#cb21-44" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'MedHouseVal'</span>] <span class="op">=</span> y</span>
<span id="cb21-45"><a href="#cb21-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-46"><a href="#cb21-46" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb21-47"><a href="#cb21-47" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"DATASET: CALIFORNIA HOUSING"</span>)</span>
<span id="cb21-48"><a href="#cb21-48" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb21-49"><a href="#cb21-49" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Shape: </span><span class="sc">{</span>X<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-50"><a href="#cb21-50" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Features: </span><span class="sc">{</span>california<span class="sc">.</span>feature_names<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-51"><a href="#cb21-51" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Description du target (prix médian en 100k$):"</span>)</span>
<span id="cb21-52"><a href="#cb21-52" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df[<span class="st">'MedHouseVal'</span>].describe())</span>
<span id="cb21-53"><a href="#cb21-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-54"><a href="#cb21-54" aria-hidden="true" tabindex="-1"></a><span class="co"># Statistiques descriptives</span></span>
<span id="cb21-55"><a href="#cb21-55" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb21-56"><a href="#cb21-56" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"STATISTIQUES DESCRIPTIVES"</span>)</span>
<span id="cb21-57"><a href="#cb21-57" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb21-58"><a href="#cb21-58" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df.describe().T)</span>
<span id="cb21-59"><a href="#cb21-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-60"><a href="#cb21-60" aria-hidden="true" tabindex="-1"></a><span class="co"># Vérifier les valeurs manquantes</span></span>
<span id="cb21-61"><a href="#cb21-61" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Valeurs manquantes par feature:"</span>)</span>
<span id="cb21-62"><a href="#cb21-62" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df.isnull().<span class="bu">sum</span>())</span>
<span id="cb21-63"><a href="#cb21-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-64"><a href="#cb21-64" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualisations</span></span>
<span id="cb21-65"><a href="#cb21-65" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">10</span>))</span>
<span id="cb21-66"><a href="#cb21-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-67"><a href="#cb21-67" aria-hidden="true" tabindex="-1"></a><span class="co"># Distribution du target</span></span>
<span id="cb21-68"><a href="#cb21-68" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].hist(y, bins<span class="op">=</span><span class="dv">50</span>, edgecolor<span class="op">=</span><span class="st">'black'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb21-69"><a href="#cb21-69" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].set_xlabel(<span class="st">'Prix Médian (100k$)'</span>)</span>
<span id="cb21-70"><a href="#cb21-70" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].set_ylabel(<span class="st">'Fréquence'</span>)</span>
<span id="cb21-71"><a href="#cb21-71" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].set_title(<span class="st">'Distribution des Prix'</span>)</span>
<span id="cb21-72"><a href="#cb21-72" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].axvline(y.mean(), color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, label<span class="op">=</span><span class="ss">f'Moyenne: </span><span class="sc">{</span>y<span class="sc">.</span>mean()<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb21-73"><a href="#cb21-73" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].legend()</span>
<span id="cb21-74"><a href="#cb21-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-75"><a href="#cb21-75" aria-hidden="true" tabindex="-1"></a><span class="co"># Boxplot des features (normalisées pour comparaison)</span></span>
<span id="cb21-76"><a href="#cb21-76" aria-hidden="true" tabindex="-1"></a>df_normalized <span class="op">=</span> (df <span class="op">-</span> df.mean()) <span class="op">/</span> df.std()</span>
<span id="cb21-77"><a href="#cb21-77" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">1</span>].boxplot([df_normalized[col] <span class="cf">for</span> col <span class="kw">in</span> california.feature_names],</span>
<span id="cb21-78"><a href="#cb21-78" aria-hidden="true" tabindex="-1"></a>                    labels<span class="op">=</span>california.feature_names, vert<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb21-79"><a href="#cb21-79" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">1</span>].set_xticklabels(california.feature_names, rotation<span class="op">=</span><span class="dv">45</span>, ha<span class="op">=</span><span class="st">'right'</span>)</span>
<span id="cb21-80"><a href="#cb21-80" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">1</span>].set_ylabel(<span class="st">'Valeurs normalisées'</span>)</span>
<span id="cb21-81"><a href="#cb21-81" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">1</span>].set_title(<span class="st">'Distribution des Features (normalisées)'</span>)</span>
<span id="cb21-82"><a href="#cb21-82" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">1</span>].grid(alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb21-83"><a href="#cb21-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-84"><a href="#cb21-84" aria-hidden="true" tabindex="-1"></a><span class="co"># Matrice de corrélation</span></span>
<span id="cb21-85"><a href="#cb21-85" aria-hidden="true" tabindex="-1"></a>corr_matrix <span class="op">=</span> df.corr()</span>
<span id="cb21-86"><a href="#cb21-86" aria-hidden="true" tabindex="-1"></a>mask <span class="op">=</span> np.triu(np.ones_like(corr_matrix, dtype<span class="op">=</span><span class="bu">bool</span>))</span>
<span id="cb21-87"><a href="#cb21-87" aria-hidden="true" tabindex="-1"></a>sns.heatmap(corr_matrix, mask<span class="op">=</span>mask, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">'.2f'</span>, cmap<span class="op">=</span><span class="st">'coolwarm'</span>,</span>
<span id="cb21-88"><a href="#cb21-88" aria-hidden="true" tabindex="-1"></a>            center<span class="op">=</span><span class="dv">0</span>, ax<span class="op">=</span>axes[<span class="dv">1</span>, <span class="dv">0</span>], cbar_kws<span class="op">=</span>{<span class="st">'label'</span>: <span class="st">'Corrélation'</span>})</span>
<span id="cb21-89"><a href="#cb21-89" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">0</span>].set_title(<span class="st">'Matrice de Corrélation'</span>)</span>
<span id="cb21-90"><a href="#cb21-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-91"><a href="#cb21-91" aria-hidden="true" tabindex="-1"></a><span class="co"># Scatter: Feature la plus corrélée avec target</span></span>
<span id="cb21-92"><a href="#cb21-92" aria-hidden="true" tabindex="-1"></a>corr_with_target <span class="op">=</span> corr_matrix[<span class="st">'MedHouseVal'</span>].drop(<span class="st">'MedHouseVal'</span>).<span class="bu">abs</span>().sort_values(ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb21-93"><a href="#cb21-93" aria-hidden="true" tabindex="-1"></a>best_feature <span class="op">=</span> corr_with_target.index[<span class="dv">0</span>]</span>
<span id="cb21-94"><a href="#cb21-94" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">1</span>].scatter(df[best_feature], df[<span class="st">'MedHouseVal'</span>], alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb21-95"><a href="#cb21-95" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">1</span>].set_xlabel(best_feature)</span>
<span id="cb21-96"><a href="#cb21-96" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">1</span>].set_ylabel(<span class="st">'Prix Médian'</span>)</span>
<span id="cb21-97"><a href="#cb21-97" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">1</span>].set_title(<span class="ss">f'Prix vs </span><span class="sc">{</span>best_feature<span class="sc">}</span><span class="ss"> (corr=</span><span class="sc">{</span>corr_matrix<span class="sc">.</span>loc[best_feature, <span class="st">"MedHouseVal"</span>]<span class="sc">:.2f}</span><span class="ss">)'</span>)</span>
<span id="cb21-98"><a href="#cb21-98" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">1</span>].grid(alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb21-99"><a href="#cb21-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-100"><a href="#cb21-100" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb21-101"><a href="#cb21-101" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb21-102"><a href="#cb21-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-103"><a href="#cb21-103" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb21-104"><a href="#cb21-104" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"CORRÉLATIONS AVEC LE TARGET"</span>)</span>
<span id="cb21-105"><a href="#cb21-105" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb21-106"><a href="#cb21-106" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(corr_with_target)</span>
<span id="cb21-107"><a href="#cb21-107" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb21-108"><a href="#cb21-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-109"><a href="#cb21-109" aria-hidden="true" tabindex="-1"></a><span class="fu">### Exercice 1.1: Analyse Exploratoire</span></span>
<span id="cb21-110"><a href="#cb21-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-111"><a href="#cb21-111" aria-hidden="true" tabindex="-1"></a>**Questions:**</span>
<span id="cb21-112"><a href="#cb21-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-113"><a href="#cb21-113" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Quelle feature est la plus corrélée avec le prix?</span>
<span id="cb21-114"><a href="#cb21-114" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Y a-t-il des features fortement corrélées entre elles? (Multicolinéarité potentielle?)</span>
<span id="cb21-115"><a href="#cb21-115" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>La distribution du target est-elle gaussienne? Quel traitement pourrait être appliqué si non?</span>
<span id="cb21-116"><a href="#cb21-116" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>Identifiez des outliers potentiels</span>
<span id="cb21-117"><a href="#cb21-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-118"><a href="#cb21-118" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb21-119"><a href="#cb21-119" aria-hidden="true" tabindex="-1"></a><span class="fu">## Solution Exercice 1.1</span></span>
<span id="cb21-120"><a href="#cb21-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-123"><a href="#cb21-123" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb21-124"><a href="#cb21-124" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb21-125"><a href="#cb21-125" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: true</span></span>
<span id="cb21-126"><a href="#cb21-126" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb21-127"><a href="#cb21-127" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"ANALYSE EXPLORATOIRE - RÉPONSES"</span>)</span>
<span id="cb21-128"><a href="#cb21-128" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb21-129"><a href="#cb21-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-130"><a href="#cb21-130" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Feature la plus corrélée</span></span>
<span id="cb21-131"><a href="#cb21-131" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">1. Feature la plus corrélée avec le prix:"</span>)</span>
<span id="cb21-132"><a href="#cb21-132" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   → </span><span class="sc">{</span>best_feature<span class="sc">}</span><span class="ss"> (corrélation = </span><span class="sc">{</span>corr_matrix<span class="sc">.</span>loc[best_feature, <span class="st">'MedHouseVal'</span>]<span class="sc">:.3f}</span><span class="ss">)"</span>)</span>
<span id="cb21-133"><a href="#cb21-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-134"><a href="#cb21-134" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Multicolinéarité</span></span>
<span id="cb21-135"><a href="#cb21-135" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">2. Paires de features fortement corrélées (|corr| &gt; 0.7):"</span>)</span>
<span id="cb21-136"><a href="#cb21-136" aria-hidden="true" tabindex="-1"></a>corr_pairs <span class="op">=</span> []</span>
<span id="cb21-137"><a href="#cb21-137" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(corr_matrix.columns)):</span>
<span id="cb21-138"><a href="#cb21-138" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(i<span class="op">+</span><span class="dv">1</span>, <span class="bu">len</span>(corr_matrix.columns)):</span>
<span id="cb21-139"><a href="#cb21-139" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> i <span class="op">!=</span> j:</span>
<span id="cb21-140"><a href="#cb21-140" aria-hidden="true" tabindex="-1"></a>            corr_val <span class="op">=</span> corr_matrix.iloc[i, j]</span>
<span id="cb21-141"><a href="#cb21-141" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">abs</span>(corr_val) <span class="op">&gt;</span> <span class="fl">0.7</span>:</span>
<span id="cb21-142"><a href="#cb21-142" aria-hidden="true" tabindex="-1"></a>                corr_pairs.append((corr_matrix.columns[i], corr_matrix.columns[j], corr_val))</span>
<span id="cb21-143"><a href="#cb21-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-144"><a href="#cb21-144" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> corr_pairs:</span>
<span id="cb21-145"><a href="#cb21-145" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> feat1, feat2, corr_val <span class="kw">in</span> corr_pairs:</span>
<span id="cb21-146"><a href="#cb21-146" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"   • </span><span class="sc">{</span>feat1<span class="sc">}</span><span class="ss"> &lt;-&gt; </span><span class="sc">{</span>feat2<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>corr_val<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb21-147"><a href="#cb21-147" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb21-148"><a href="#cb21-148" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"   → Aucune multicolinéarité forte détectée"</span>)</span>
<span id="cb21-149"><a href="#cb21-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-150"><a href="#cb21-150" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Distribution du target</span></span>
<span id="cb21-151"><a href="#cb21-151" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy <span class="im">import</span> stats</span>
<span id="cb21-152"><a href="#cb21-152" aria-hidden="true" tabindex="-1"></a>shapiro_stat, shapiro_p <span class="op">=</span> stats.shapiro(y[:<span class="dv">1000</span>])  <span class="co"># Test sur échantillon</span></span>
<span id="cb21-153"><a href="#cb21-153" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">3. Test de normalité (Shapiro-Wilk):"</span>)</span>
<span id="cb21-154"><a href="#cb21-154" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   Statistique: </span><span class="sc">{</span>shapiro_stat<span class="sc">:.4f}</span><span class="ss">, p-value: </span><span class="sc">{</span>shapiro_p<span class="sc">:.4e}</span><span class="ss">"</span>)</span>
<span id="cb21-155"><a href="#cb21-155" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> shapiro_p <span class="op">&lt;</span> <span class="fl">0.05</span>:</span>
<span id="cb21-156"><a href="#cb21-156" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"   → Distribution NON gaussienne (p &lt; 0.05)"</span>)</span>
<span id="cb21-157"><a href="#cb21-157" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"   Traitements possibles:"</span>)</span>
<span id="cb21-158"><a href="#cb21-158" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"   • Transformation log(y)"</span>)</span>
<span id="cb21-159"><a href="#cb21-159" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"   • Transformation Box-Cox"</span>)</span>
<span id="cb21-160"><a href="#cb21-160" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"   • Utiliser des modèles robustes aux distributions non-gaussiennes"</span>)</span>
<span id="cb21-161"><a href="#cb21-161" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb21-162"><a href="#cb21-162" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"   → Distribution gaussienne (p &gt;= 0.05)"</span>)</span>
<span id="cb21-163"><a href="#cb21-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-164"><a href="#cb21-164" aria-hidden="true" tabindex="-1"></a><span class="co"># Skewness et Kurtosis</span></span>
<span id="cb21-165"><a href="#cb21-165" aria-hidden="true" tabindex="-1"></a>skewness <span class="op">=</span> stats.skew(y)</span>
<span id="cb21-166"><a href="#cb21-166" aria-hidden="true" tabindex="-1"></a>kurtosis <span class="op">=</span> stats.kurtosis(y)</span>
<span id="cb21-167"><a href="#cb21-167" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   Asymétrie (Skewness): </span><span class="sc">{</span>skewness<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb21-168"><a href="#cb21-168" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   Aplatissement (Kurtosis): </span><span class="sc">{</span>kurtosis<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb21-169"><a href="#cb21-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-170"><a href="#cb21-170" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Outliers</span></span>
<span id="cb21-171"><a href="#cb21-171" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">4. Détection d'outliers:"</span>)</span>
<span id="cb21-172"><a href="#cb21-172" aria-hidden="true" tabindex="-1"></a>Q1 <span class="op">=</span> df[<span class="st">'MedHouseVal'</span>].quantile(<span class="fl">0.25</span>)</span>
<span id="cb21-173"><a href="#cb21-173" aria-hidden="true" tabindex="-1"></a>Q3 <span class="op">=</span> df[<span class="st">'MedHouseVal'</span>].quantile(<span class="fl">0.75</span>)</span>
<span id="cb21-174"><a href="#cb21-174" aria-hidden="true" tabindex="-1"></a>IQR <span class="op">=</span> Q3 <span class="op">-</span> Q1</span>
<span id="cb21-175"><a href="#cb21-175" aria-hidden="true" tabindex="-1"></a>lower_bound <span class="op">=</span> Q1 <span class="op">-</span> <span class="fl">1.5</span> <span class="op">*</span> IQR</span>
<span id="cb21-176"><a href="#cb21-176" aria-hidden="true" tabindex="-1"></a>upper_bound <span class="op">=</span> Q3 <span class="op">+</span> <span class="fl">1.5</span> <span class="op">*</span> IQR</span>
<span id="cb21-177"><a href="#cb21-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-178"><a href="#cb21-178" aria-hidden="true" tabindex="-1"></a>outliers <span class="op">=</span> df[(df[<span class="st">'MedHouseVal'</span>] <span class="op">&lt;</span> lower_bound) <span class="op">|</span> (df[<span class="st">'MedHouseVal'</span>] <span class="op">&gt;</span> upper_bound)]</span>
<span id="cb21-179"><a href="#cb21-179" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   Intervalle IQR: [</span><span class="sc">{</span>Q1<span class="sc">:.2f}</span><span class="ss">, </span><span class="sc">{</span>Q3<span class="sc">:.2f}</span><span class="ss">]"</span>)</span>
<span id="cb21-180"><a href="#cb21-180" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   Bornes: [</span><span class="sc">{</span>lower_bound<span class="sc">:.2f}</span><span class="ss">, </span><span class="sc">{</span>upper_bound<span class="sc">:.2f}</span><span class="ss">]"</span>)</span>
<span id="cb21-181"><a href="#cb21-181" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   Nombre d'outliers: </span><span class="sc">{</span><span class="bu">len</span>(outliers)<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span><span class="bu">len</span>(outliers)<span class="op">/</span><span class="bu">len</span>(df)<span class="op">*</span><span class="dv">100</span><span class="sc">:.1f}</span><span class="ss">%)"</span>)</span>
<span id="cb21-182"><a href="#cb21-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-183"><a href="#cb21-183" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualisation des outliers</span></span>
<span id="cb21-184"><a href="#cb21-184" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb21-185"><a href="#cb21-185" aria-hidden="true" tabindex="-1"></a>ax.scatter(<span class="bu">range</span>(<span class="bu">len</span>(y)), np.sort(y), alpha<span class="op">=</span><span class="fl">0.5</span>, s<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb21-186"><a href="#cb21-186" aria-hidden="true" tabindex="-1"></a>ax.axhline(lower_bound, color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, label<span class="op">=</span><span class="st">'Lower bound'</span>)</span>
<span id="cb21-187"><a href="#cb21-187" aria-hidden="true" tabindex="-1"></a>ax.axhline(upper_bound, color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, label<span class="op">=</span><span class="st">'Upper bound'</span>)</span>
<span id="cb21-188"><a href="#cb21-188" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'Index (trié)'</span>)</span>
<span id="cb21-189"><a href="#cb21-189" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'Prix'</span>)</span>
<span id="cb21-190"><a href="#cb21-190" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'Détection d</span><span class="ch">\'</span><span class="st">Outliers par IQR'</span>)</span>
<span id="cb21-191"><a href="#cb21-191" aria-hidden="true" tabindex="-1"></a>ax.legend()</span>
<span id="cb21-192"><a href="#cb21-192" aria-hidden="true" tabindex="-1"></a>ax.grid(alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb21-193"><a href="#cb21-193" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb21-194"><a href="#cb21-194" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb21-195"><a href="#cb21-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-196"><a href="#cb21-196" aria-hidden="true" tabindex="-1"></a>**Conclusions typiques:**</span>
<span id="cb21-197"><a href="#cb21-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-198"><a href="#cb21-198" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**MedInc** (revenu médian) généralement le plus corrélé (~0.68)</span>
<span id="cb21-199"><a href="#cb21-199" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Multicolinéarité possible → considérer Ridge/ElasticNet</span>
<span id="cb21-200"><a href="#cb21-200" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Distribution souvent légèrement asymétrique → transformation log possible</span>
<span id="cb21-201"><a href="#cb21-201" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>Quelques outliers mais acceptable (&lt;5%)</span>
<span id="cb21-202"><a href="#cb21-202" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb21-203"><a href="#cb21-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-204"><a href="#cb21-204" aria-hidden="true" tabindex="-1"></a><span class="fu">## 2. Prétraitement et Split</span></span>
<span id="cb21-205"><a href="#cb21-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-208"><a href="#cb21-208" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb21-209"><a href="#cb21-209" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb21-210"><a href="#cb21-210" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: true</span></span>
<span id="cb21-211"><a href="#cb21-211" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb21-212"><a href="#cb21-212" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb21-213"><a href="#cb21-213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-214"><a href="#cb21-214" aria-hidden="true" tabindex="-1"></a><span class="co"># Split train/test (80/20)</span></span>
<span id="cb21-215"><a href="#cb21-215" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb21-216"><a href="#cb21-216" aria-hidden="true" tabindex="-1"></a>    X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb21-217"><a href="#cb21-217" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb21-218"><a href="#cb21-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-219"><a href="#cb21-219" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb21-220"><a href="#cb21-220" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"SPLIT DES DONNÉES"</span>)</span>
<span id="cb21-221"><a href="#cb21-221" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb21-222"><a href="#cb21-222" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Train set: </span><span class="sc">{</span>X_train<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-223"><a href="#cb21-223" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Test set: </span><span class="sc">{</span>X_test<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-224"><a href="#cb21-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-225"><a href="#cb21-225" aria-hidden="true" tabindex="-1"></a><span class="co"># Standardisation (importante pour Ridge, Lasso, SVR)</span></span>
<span id="cb21-226"><a href="#cb21-226" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb21-227"><a href="#cb21-227" aria-hidden="true" tabindex="-1"></a>X_train_scaled <span class="op">=</span> scaler.fit_transform(X_train)</span>
<span id="cb21-228"><a href="#cb21-228" aria-hidden="true" tabindex="-1"></a>X_test_scaled <span class="op">=</span> scaler.transform(X_test)</span>
<span id="cb21-229"><a href="#cb21-229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-230"><a href="#cb21-230" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Standardisation:"</span>)</span>
<span id="cb21-231"><a href="#cb21-231" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Mean (train): </span><span class="sc">{</span>X_train_scaled<span class="sc">.</span>mean(axis<span class="op">=</span><span class="dv">0</span>)<span class="sc">}</span><span class="ss">"</span>)  <span class="co"># Devrait être ~0</span></span>
<span id="cb21-232"><a href="#cb21-232" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Std (train): </span><span class="sc">{</span>X_train_scaled<span class="sc">.</span>std(axis<span class="op">=</span><span class="dv">0</span>)<span class="sc">}</span><span class="ss">"</span>)    <span class="co"># Devrait être ~1</span></span>
<span id="cb21-233"><a href="#cb21-233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-234"><a href="#cb21-234" aria-hidden="true" tabindex="-1"></a><span class="co"># Vérification</span></span>
<span id="cb21-235"><a href="#cb21-235" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Vérification après scaling:"</span>)</span>
<span id="cb21-236"><a href="#cb21-236" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Mean proche de 0: </span><span class="sc">{</span>np<span class="sc">.</span>allclose(X_train_scaled.mean(axis<span class="op">=</span><span class="dv">0</span>), <span class="dv">0</span>, atol<span class="op">=</span><span class="fl">1e-10</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-237"><a href="#cb21-237" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Std proche de 1: </span><span class="sc">{</span>np<span class="sc">.</span>allclose(X_train_scaled.std(axis<span class="op">=</span><span class="dv">0</span>), <span class="dv">1</span>, atol<span class="op">=</span><span class="fl">1e-2</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-238"><a href="#cb21-238" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb21-239"><a href="#cb21-239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-240"><a href="#cb21-240" aria-hidden="true" tabindex="-1"></a>::: {.callout-warning}</span>
<span id="cb21-241"><a href="#cb21-241" aria-hidden="true" tabindex="-1"></a><span class="fu">## Importance de la Standardisation</span></span>
<span id="cb21-242"><a href="#cb21-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-243"><a href="#cb21-243" aria-hidden="true" tabindex="-1"></a>**Pourquoi standardiser?**</span>
<span id="cb21-244"><a href="#cb21-244" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Ridge/Lasso: Pénalisation équitable des coefficients</span>
<span id="cb21-245"><a href="#cb21-245" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>SVR: Sensible à l'échelle des features</span>
<span id="cb21-246"><a href="#cb21-246" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Convergence plus rapide des algorithmes itératifs</span>
<span id="cb21-247"><a href="#cb21-247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-248"><a href="#cb21-248" aria-hidden="true" tabindex="-1"></a>**Quand ne PAS standardiser?**</span>
<span id="cb21-249"><a href="#cb21-249" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Arbres de décision / Random Forest (invariants aux transformations monotones)</span>
<span id="cb21-250"><a href="#cb21-250" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Régression linéaire simple (si pas de régularisation)</span>
<span id="cb21-251"><a href="#cb21-251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-252"><a href="#cb21-252" aria-hidden="true" tabindex="-1"></a>**Règle:** Toujours fit sur train, transform sur test (éviter data leakage)</span>
<span id="cb21-253"><a href="#cb21-253" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb21-254"><a href="#cb21-254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-255"><a href="#cb21-255" aria-hidden="true" tabindex="-1"></a><span class="fu">## 3. Modèles de Base</span></span>
<span id="cb21-256"><a href="#cb21-256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-257"><a href="#cb21-257" aria-hidden="true" tabindex="-1"></a><span class="fu">### Exercice 3.1: Régression Linéaire Simple</span></span>
<span id="cb21-258"><a href="#cb21-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-259"><a href="#cb21-259" aria-hidden="true" tabindex="-1"></a>Entraînez une régression linéaire et évaluez-la.</span>
<span id="cb21-260"><a href="#cb21-260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-261"><a href="#cb21-261" aria-hidden="true" tabindex="-1"></a>**Instructions:**</span>
<span id="cb21-262"><a href="#cb21-262" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Créez et entraînez le modèle</span>
<span id="cb21-263"><a href="#cb21-263" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Prédisez sur train et test</span>
<span id="cb21-264"><a href="#cb21-264" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Calculez MAE, RMSE, R² pour les deux ensembles</span>
<span id="cb21-265"><a href="#cb21-265" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>Affichez les 5 coefficients les plus importants</span>
<span id="cb21-266"><a href="#cb21-266" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>Visualisez prédictions vs vraies valeurs</span>
<span id="cb21-267"><a href="#cb21-267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-268"><a href="#cb21-268" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb21-269"><a href="#cb21-269" aria-hidden="true" tabindex="-1"></a><span class="fu">## Solution Exercice 3.1</span></span>
<span id="cb21-270"><a href="#cb21-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-273"><a href="#cb21-273" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb21-274"><a href="#cb21-274" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb21-275"><a href="#cb21-275" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: true</span></span>
<span id="cb21-276"><a href="#cb21-276" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb21-277"><a href="#cb21-277" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_absolute_error, mean_squared_error, r2_score</span>
<span id="cb21-278"><a href="#cb21-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-279"><a href="#cb21-279" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb21-280"><a href="#cb21-280" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"RÉGRESSION LINÉAIRE SIMPLE"</span>)</span>
<span id="cb21-281"><a href="#cb21-281" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb21-282"><a href="#cb21-282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-283"><a href="#cb21-283" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Entraînement</span></span>
<span id="cb21-284"><a href="#cb21-284" aria-hidden="true" tabindex="-1"></a>model_lr <span class="op">=</span> LinearRegression()</span>
<span id="cb21-285"><a href="#cb21-285" aria-hidden="true" tabindex="-1"></a>model_lr.fit(X_train_scaled, y_train)</span>
<span id="cb21-286"><a href="#cb21-286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-287"><a href="#cb21-287" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Prédictions</span></span>
<span id="cb21-288"><a href="#cb21-288" aria-hidden="true" tabindex="-1"></a>y_train_pred <span class="op">=</span> model_lr.predict(X_train_scaled)</span>
<span id="cb21-289"><a href="#cb21-289" aria-hidden="true" tabindex="-1"></a>y_test_pred <span class="op">=</span> model_lr.predict(X_test_scaled)</span>
<span id="cb21-290"><a href="#cb21-290" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-291"><a href="#cb21-291" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Métriques</span></span>
<span id="cb21-292"><a href="#cb21-292" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> evaluate_model(y_true, y_pred, dataset_name<span class="op">=</span><span class="st">""</span>):</span>
<span id="cb21-293"><a href="#cb21-293" aria-hidden="true" tabindex="-1"></a>    mae <span class="op">=</span> mean_absolute_error(y_true, y_pred)</span>
<span id="cb21-294"><a href="#cb21-294" aria-hidden="true" tabindex="-1"></a>    mse <span class="op">=</span> mean_squared_error(y_true, y_pred)</span>
<span id="cb21-295"><a href="#cb21-295" aria-hidden="true" tabindex="-1"></a>    rmse <span class="op">=</span> np.sqrt(mse)</span>
<span id="cb21-296"><a href="#cb21-296" aria-hidden="true" tabindex="-1"></a>    r2 <span class="op">=</span> r2_score(y_true, y_pred)</span>
<span id="cb21-297"><a href="#cb21-297" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-298"><a href="#cb21-298" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="sc">{</span>dataset_name<span class="sc">}</span><span class="ss">:"</span>)</span>
<span id="cb21-299"><a href="#cb21-299" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  MAE:  </span><span class="sc">{</span>mae<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb21-300"><a href="#cb21-300" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  RMSE: </span><span class="sc">{</span>rmse<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb21-301"><a href="#cb21-301" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  R²:   </span><span class="sc">{</span>r2<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb21-302"><a href="#cb21-302" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-303"><a href="#cb21-303" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {<span class="st">'MAE'</span>: mae, <span class="st">'RMSE'</span>: rmse, <span class="st">'R2'</span>: r2}</span>
<span id="cb21-304"><a href="#cb21-304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-305"><a href="#cb21-305" aria-hidden="true" tabindex="-1"></a>train_metrics <span class="op">=</span> evaluate_model(y_train, y_train_pred, <span class="st">"Train Set"</span>)</span>
<span id="cb21-306"><a href="#cb21-306" aria-hidden="true" tabindex="-1"></a>test_metrics <span class="op">=</span> evaluate_model(y_test, y_test_pred, <span class="st">"Test Set"</span>)</span>
<span id="cb21-307"><a href="#cb21-307" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-308"><a href="#cb21-308" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Coefficients importants</span></span>
<span id="cb21-309"><a href="#cb21-309" aria-hidden="true" tabindex="-1"></a>coef_df <span class="op">=</span> pd.DataFrame({</span>
<span id="cb21-310"><a href="#cb21-310" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Feature'</span>: california.feature_names,</span>
<span id="cb21-311"><a href="#cb21-311" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Coefficient'</span>: model_lr.coef_</span>
<span id="cb21-312"><a href="#cb21-312" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb21-313"><a href="#cb21-313" aria-hidden="true" tabindex="-1"></a>coef_df[<span class="st">'Abs_Coef'</span>] <span class="op">=</span> np.<span class="bu">abs</span>(coef_df[<span class="st">'Coefficient'</span>])</span>
<span id="cb21-314"><a href="#cb21-314" aria-hidden="true" tabindex="-1"></a>coef_df <span class="op">=</span> coef_df.sort_values(<span class="st">'Abs_Coef'</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb21-315"><a href="#cb21-315" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-316"><a href="#cb21-316" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb21-317"><a href="#cb21-317" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"COEFFICIENTS (TOP 5)"</span>)</span>
<span id="cb21-318"><a href="#cb21-318" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb21-319"><a href="#cb21-319" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(coef_df[[<span class="st">'Feature'</span>, <span class="st">'Coefficient'</span>]].head().to_string(index<span class="op">=</span><span class="va">False</span>))</span>
<span id="cb21-320"><a href="#cb21-320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-321"><a href="#cb21-321" aria-hidden="true" tabindex="-1"></a><span class="co"># 5. Visualisation</span></span>
<span id="cb21-322"><a href="#cb21-322" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">5</span>))</span>
<span id="cb21-323"><a href="#cb21-323" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-324"><a href="#cb21-324" aria-hidden="true" tabindex="-1"></a><span class="co"># Prédictions vs Vraies valeurs (Test)</span></span>
<span id="cb21-325"><a href="#cb21-325" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].scatter(y_test, y_test_pred, alpha<span class="op">=</span><span class="fl">0.3</span>, s<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb21-326"><a href="#cb21-326" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].plot([y_test.<span class="bu">min</span>(), y_test.<span class="bu">max</span>()], [y_test.<span class="bu">min</span>(), y_test.<span class="bu">max</span>()], </span>
<span id="cb21-327"><a href="#cb21-327" aria-hidden="true" tabindex="-1"></a>             <span class="st">'r--'</span>, lw<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'Prédiction parfaite'</span>)</span>
<span id="cb21-328"><a href="#cb21-328" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_xlabel(<span class="st">'Vraie valeur'</span>)</span>
<span id="cb21-329"><a href="#cb21-329" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_ylabel(<span class="st">'Prédiction'</span>)</span>
<span id="cb21-330"><a href="#cb21-330" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="ss">f'Régression Linéaire (Test R²=</span><span class="sc">{</span>test_metrics[<span class="st">"R2"</span>]<span class="sc">:.3f}</span><span class="ss">)'</span>)</span>
<span id="cb21-331"><a href="#cb21-331" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].legend()</span>
<span id="cb21-332"><a href="#cb21-332" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].grid(alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb21-333"><a href="#cb21-333" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-334"><a href="#cb21-334" aria-hidden="true" tabindex="-1"></a><span class="co"># Résidus</span></span>
<span id="cb21-335"><a href="#cb21-335" aria-hidden="true" tabindex="-1"></a>residuals <span class="op">=</span> y_test <span class="op">-</span> y_test_pred</span>
<span id="cb21-336"><a href="#cb21-336" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].scatter(y_test_pred, residuals, alpha<span class="op">=</span><span class="fl">0.3</span>, s<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb21-337"><a href="#cb21-337" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].axhline(<span class="dv">0</span>, color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, lw<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb21-338"><a href="#cb21-338" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xlabel(<span class="st">'Prédictions'</span>)</span>
<span id="cb21-339"><a href="#cb21-339" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_ylabel(<span class="st">'Résidus'</span>)</span>
<span id="cb21-340"><a href="#cb21-340" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="st">'Graphique des Résidus'</span>)</span>
<span id="cb21-341"><a href="#cb21-341" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].grid(alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb21-342"><a href="#cb21-342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-343"><a href="#cb21-343" aria-hidden="true" tabindex="-1"></a><span class="co"># Distribution des résidus</span></span>
<span id="cb21-344"><a href="#cb21-344" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].hist(residuals, bins<span class="op">=</span><span class="dv">50</span>, edgecolor<span class="op">=</span><span class="st">'black'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb21-345"><a href="#cb21-345" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].axvline(residuals.mean(), color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, </span>
<span id="cb21-346"><a href="#cb21-346" aria-hidden="true" tabindex="-1"></a>               label<span class="op">=</span><span class="ss">f'Moyenne: </span><span class="sc">{</span>residuals<span class="sc">.</span>mean()<span class="sc">:.4f}</span><span class="ss">'</span>)</span>
<span id="cb21-347"><a href="#cb21-347" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].set_xlabel(<span class="st">'Résidus'</span>)</span>
<span id="cb21-348"><a href="#cb21-348" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].set_ylabel(<span class="st">'Fréquence'</span>)</span>
<span id="cb21-349"><a href="#cb21-349" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].set_title(<span class="st">'Distribution des Résidus'</span>)</span>
<span id="cb21-350"><a href="#cb21-350" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].legend()</span>
<span id="cb21-351"><a href="#cb21-351" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].grid(alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb21-352"><a href="#cb21-352" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-353"><a href="#cb21-353" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb21-354"><a href="#cb21-354" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb21-355"><a href="#cb21-355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-356"><a href="#cb21-356" aria-hidden="true" tabindex="-1"></a><span class="co"># Analyse des résidus</span></span>
<span id="cb21-357"><a href="#cb21-357" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb21-358"><a href="#cb21-358" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"ANALYSE DES RÉSIDUS"</span>)</span>
<span id="cb21-359"><a href="#cb21-359" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb21-360"><a href="#cb21-360" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Moyenne: </span><span class="sc">{</span>residuals<span class="sc">.</span>mean()<span class="sc">:.6f}</span><span class="ss"> (devrait être $</span><span class="ch">\a</span><span class="ss">pprox$ 0)"</span>)</span>
<span id="cb21-361"><a href="#cb21-361" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Std: </span><span class="sc">{</span>residuals<span class="sc">.</span>std()<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb21-362"><a href="#cb21-362" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Min: </span><span class="sc">{</span>residuals<span class="sc">.</span><span class="bu">min</span>()<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb21-363"><a href="#cb21-363" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Max: </span><span class="sc">{</span>residuals<span class="sc">.</span><span class="bu">max</span>()<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb21-364"><a href="#cb21-364" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb21-365"><a href="#cb21-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-366"><a href="#cb21-366" aria-hidden="true" tabindex="-1"></a>**Interprétation:**</span>
<span id="cb21-367"><a href="#cb21-367" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>R² train &gt; R² test → léger surapprentissage (normal)</span>
<span id="cb21-368"><a href="#cb21-368" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Résidus centrés sur 0 → modèle non biaisé</span>
<span id="cb21-369"><a href="#cb21-369" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Distribution des résidus approximativement gaussienne → hypothèses vérifiées</span>
<span id="cb21-370"><a href="#cb21-370" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb21-371"><a href="#cb21-371" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-372"><a href="#cb21-372" aria-hidden="true" tabindex="-1"></a><span class="fu">## 4. Modèles Régularisés</span></span>
<span id="cb21-373"><a href="#cb21-373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-374"><a href="#cb21-374" aria-hidden="true" tabindex="-1"></a><span class="fu">### Exercice 4.1: Comparaison Ridge, Lasso, ElasticNet</span></span>
<span id="cb21-375"><a href="#cb21-375" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-376"><a href="#cb21-376" aria-hidden="true" tabindex="-1"></a>Comparez les 3 modèles régularisés avec différentes valeurs de alpha.</span>
<span id="cb21-377"><a href="#cb21-377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-378"><a href="#cb21-378" aria-hidden="true" tabindex="-1"></a>**Instructions:**</span>
<span id="cb21-379"><a href="#cb21-379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-380"><a href="#cb21-380" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Testez alpha dans <span class="co">[</span><span class="ot">0.001, 0.01, 0.1, 1, 10, 100</span><span class="co">]</span></span>
<span id="cb21-381"><a href="#cb21-381" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Pour chaque modèle et chaque alpha:</span>
<span id="cb21-382"><a href="#cb21-382" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Entraînez sur train</span>
<span id="cb21-383"><a href="#cb21-383" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Calculez R² sur test</span>
<span id="cb21-384"><a href="#cb21-384" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Tracez R² vs alpha pour les 3 modèles</span>
<span id="cb21-385"><a href="#cb21-385" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>Identifiez le meilleur modèle et le meilleur alpha</span>
<span id="cb21-386"><a href="#cb21-386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-387"><a href="#cb21-387" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb21-388"><a href="#cb21-388" aria-hidden="true" tabindex="-1"></a><span class="fu">## Solution Exercice 4.1</span></span>
<span id="cb21-389"><a href="#cb21-389" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-392"><a href="#cb21-392" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb21-393"><a href="#cb21-393" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb21-394"><a href="#cb21-394" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: true</span></span>
<span id="cb21-395"><a href="#cb21-395" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> Ridge, Lasso, ElasticNet</span>
<span id="cb21-396"><a href="#cb21-396" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-397"><a href="#cb21-397" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb21-398"><a href="#cb21-398" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"COMPARAISON RIDGE, LASSO, ELASTICNET"</span>)</span>
<span id="cb21-399"><a href="#cb21-399" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb21-400"><a href="#cb21-400" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-401"><a href="#cb21-401" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Grille d'alphas</span></span>
<span id="cb21-402"><a href="#cb21-402" aria-hidden="true" tabindex="-1"></a>alphas <span class="op">=</span> [<span class="fl">0.001</span>, <span class="fl">0.01</span>, <span class="fl">0.1</span>, <span class="dv">1</span>, <span class="dv">10</span>, <span class="dv">100</span>]</span>
<span id="cb21-403"><a href="#cb21-403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-404"><a href="#cb21-404" aria-hidden="true" tabindex="-1"></a><span class="co"># Stocker les résultats</span></span>
<span id="cb21-405"><a href="#cb21-405" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> {<span class="st">'Ridge'</span>: [], <span class="st">'Lasso'</span>: [], <span class="st">'ElasticNet'</span>: []}</span>
<span id="cb21-406"><a href="#cb21-406" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-407"><a href="#cb21-407" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Entraînement</span></span>
<span id="cb21-408"><a href="#cb21-408" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> alpha <span class="kw">in</span> alphas:</span>
<span id="cb21-409"><a href="#cb21-409" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Ridge</span></span>
<span id="cb21-410"><a href="#cb21-410" aria-hidden="true" tabindex="-1"></a>    ridge <span class="op">=</span> Ridge(alpha<span class="op">=</span>alpha)</span>
<span id="cb21-411"><a href="#cb21-411" aria-hidden="true" tabindex="-1"></a>    ridge.fit(X_train_scaled, y_train)</span>
<span id="cb21-412"><a href="#cb21-412" aria-hidden="true" tabindex="-1"></a>    r2_ridge <span class="op">=</span> r2_score(y_test, ridge.predict(X_test_scaled))</span>
<span id="cb21-413"><a href="#cb21-413" aria-hidden="true" tabindex="-1"></a>    results[<span class="st">'Ridge'</span>].append(r2_ridge)</span>
<span id="cb21-414"><a href="#cb21-414" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-415"><a href="#cb21-415" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Lasso</span></span>
<span id="cb21-416"><a href="#cb21-416" aria-hidden="true" tabindex="-1"></a>    lasso <span class="op">=</span> Lasso(alpha<span class="op">=</span>alpha, max_iter<span class="op">=</span><span class="dv">10000</span>)</span>
<span id="cb21-417"><a href="#cb21-417" aria-hidden="true" tabindex="-1"></a>    lasso.fit(X_train_scaled, y_train)</span>
<span id="cb21-418"><a href="#cb21-418" aria-hidden="true" tabindex="-1"></a>    r2_lasso <span class="op">=</span> r2_score(y_test, lasso.predict(X_test_scaled))</span>
<span id="cb21-419"><a href="#cb21-419" aria-hidden="true" tabindex="-1"></a>    results[<span class="st">'Lasso'</span>].append(r2_lasso)</span>
<span id="cb21-420"><a href="#cb21-420" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-421"><a href="#cb21-421" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ElasticNet</span></span>
<span id="cb21-422"><a href="#cb21-422" aria-hidden="true" tabindex="-1"></a>    elastic <span class="op">=</span> ElasticNet(alpha<span class="op">=</span>alpha, l1_ratio<span class="op">=</span><span class="fl">0.5</span>, max_iter<span class="op">=</span><span class="dv">10000</span>)</span>
<span id="cb21-423"><a href="#cb21-423" aria-hidden="true" tabindex="-1"></a>    elastic.fit(X_train_scaled, y_train)</span>
<span id="cb21-424"><a href="#cb21-424" aria-hidden="true" tabindex="-1"></a>    r2_elastic <span class="op">=</span> r2_score(y_test, elastic.predict(X_test_scaled))</span>
<span id="cb21-425"><a href="#cb21-425" aria-hidden="true" tabindex="-1"></a>    results[<span class="st">'ElasticNet'</span>].append(r2_elastic)</span>
<span id="cb21-426"><a href="#cb21-426" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-427"><a href="#cb21-427" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Visualisation</span></span>
<span id="cb21-428"><a href="#cb21-428" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb21-429"><a href="#cb21-429" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> model_name, r2_scores <span class="kw">in</span> results.items():</span>
<span id="cb21-430"><a href="#cb21-430" aria-hidden="true" tabindex="-1"></a>    plt.plot(alphas, r2_scores, marker<span class="op">=</span><span class="st">'o'</span>, label<span class="op">=</span>model_name, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb21-431"><a href="#cb21-431" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-432"><a href="#cb21-432" aria-hidden="true" tabindex="-1"></a>plt.xscale(<span class="st">'log'</span>)</span>
<span id="cb21-433"><a href="#cb21-433" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'alpha (log scale)'</span>)</span>
<span id="cb21-434"><a href="#cb21-434" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'R² Score (Test)'</span>)</span>
<span id="cb21-435"><a href="#cb21-435" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Comparaison Ridge, Lasso, ElasticNet'</span>)</span>
<span id="cb21-436"><a href="#cb21-436" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb21-437"><a href="#cb21-437" aria-hidden="true" tabindex="-1"></a>plt.grid(alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb21-438"><a href="#cb21-438" aria-hidden="true" tabindex="-1"></a>plt.axhline(test_metrics[<span class="st">'R2'</span>], color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, </span>
<span id="cb21-439"><a href="#cb21-439" aria-hidden="true" tabindex="-1"></a>           label<span class="op">=</span><span class="ss">f'Linear (alpha=0): </span><span class="sc">{</span>test_metrics[<span class="st">"R2"</span>]<span class="sc">:.4f}</span><span class="ss">'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb21-440"><a href="#cb21-440" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb21-441"><a href="#cb21-441" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb21-442"><a href="#cb21-442" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-443"><a href="#cb21-443" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Meilleur modèle</span></span>
<span id="cb21-444"><a href="#cb21-444" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb21-445"><a href="#cb21-445" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"MEILLEURS HYPERPARAMÈTRES"</span>)</span>
<span id="cb21-446"><a href="#cb21-446" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb21-447"><a href="#cb21-447" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-448"><a href="#cb21-448" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> model_name, r2_scores <span class="kw">in</span> results.items():</span>
<span id="cb21-449"><a href="#cb21-449" aria-hidden="true" tabindex="-1"></a>    best_idx <span class="op">=</span> np.argmax(r2_scores)</span>
<span id="cb21-450"><a href="#cb21-450" aria-hidden="true" tabindex="-1"></a>    best_alpha <span class="op">=</span> alphas[best_idx]</span>
<span id="cb21-451"><a href="#cb21-451" aria-hidden="true" tabindex="-1"></a>    best_r2 <span class="op">=</span> r2_scores[best_idx]</span>
<span id="cb21-452"><a href="#cb21-452" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="sc">{</span>model_name<span class="sc">}</span><span class="ss">:"</span>)</span>
<span id="cb21-453"><a href="#cb21-453" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Meilleur alpha: </span><span class="sc">{</span>best_alpha<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-454"><a href="#cb21-454" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  R² Test: </span><span class="sc">{</span>best_r2<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb21-455"><a href="#cb21-455" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-456"><a href="#cb21-456" aria-hidden="true" tabindex="-1"></a><span class="co"># Tableau comparatif</span></span>
<span id="cb21-457"><a href="#cb21-457" aria-hidden="true" tabindex="-1"></a>df_comparison <span class="op">=</span> pd.DataFrame(results, index<span class="op">=</span>[<span class="ss">f'alpha=</span><span class="sc">{</span>a<span class="sc">}</span><span class="ss">'</span> <span class="cf">for</span> a <span class="kw">in</span> alphas])</span>
<span id="cb21-458"><a href="#cb21-458" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb21-459"><a href="#cb21-459" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"TABLEAU COMPARATIF (R² Test)"</span>)</span>
<span id="cb21-460"><a href="#cb21-460" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb21-461"><a href="#cb21-461" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df_comparison.to_string())</span>
<span id="cb21-462"><a href="#cb21-462" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb21-463"><a href="#cb21-463" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-464"><a href="#cb21-464" aria-hidden="true" tabindex="-1"></a>**Observations attendues:**</span>
<span id="cb21-465"><a href="#cb21-465" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Ridge: R² stable, peu sensible à alpha</span>
<span id="cb21-466"><a href="#cb21-466" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Lasso: R² peut chuter si alpha trop élevé (trop de coefficients à 0)</span>
<span id="cb21-467"><a href="#cb21-467" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>ElasticNet: Compromis entre Ridge et Lasso</span>
<span id="cb21-468"><a href="#cb21-468" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb21-469"><a href="#cb21-469" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-470"><a href="#cb21-470" aria-hidden="true" tabindex="-1"></a><span class="fu">### Exercice 4.2: Sélection de Features avec Lasso</span></span>
<span id="cb21-471"><a href="#cb21-471" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-472"><a href="#cb21-472" aria-hidden="true" tabindex="-1"></a>Utilisez Lasso pour identifier les features importantes.</span>
<span id="cb21-473"><a href="#cb21-473" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-474"><a href="#cb21-474" aria-hidden="true" tabindex="-1"></a>**Instructions:**</span>
<span id="cb21-475"><a href="#cb21-475" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Entraînez Lasso avec alpha=0.1</span>
<span id="cb21-476"><a href="#cb21-476" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Affichez le nombre de coefficients non-nuls</span>
<span id="cb21-477"><a href="#cb21-477" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Identifiez les features sélectionnées</span>
<span id="cb21-478"><a href="#cb21-478" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>Comparez les coefficients Lasso vs Linear</span>
<span id="cb21-479"><a href="#cb21-479" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-480"><a href="#cb21-480" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb21-481"><a href="#cb21-481" aria-hidden="true" tabindex="-1"></a><span class="fu">## Solution Exercice 4.2</span></span>
<span id="cb21-482"><a href="#cb21-482" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-483"><a href="#cb21-483" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb21-484"><a href="#cb21-484" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb21-485"><a href="#cb21-485" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"SÉLECTION DE FEATURES AVEC LASSO"</span>)</span>
<span id="cb21-486"><a href="#cb21-486" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb21-487"><a href="#cb21-487" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-488"><a href="#cb21-488" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Entraînement</span></span>
<span id="cb21-489"><a href="#cb21-489" aria-hidden="true" tabindex="-1"></a>lasso <span class="op">=</span> Lasso(alpha<span class="op">=</span><span class="fl">0.1</span>, max_iter<span class="op">=</span><span class="dv">10000</span>)</span>
<span id="cb21-490"><a href="#cb21-490" aria-hidden="true" tabindex="-1"></a>lasso.fit(X_train_scaled, y_train)</span>
<span id="cb21-491"><a href="#cb21-491" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-492"><a href="#cb21-492" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Coefficients non-nuls</span></span>
<span id="cb21-493"><a href="#cb21-493" aria-hidden="true" tabindex="-1"></a>non_zero_mask <span class="op">=</span> np.<span class="bu">abs</span>(lasso.coef_) <span class="op">&gt;</span> <span class="fl">1e-5</span></span>
<span id="cb21-494"><a href="#cb21-494" aria-hidden="true" tabindex="-1"></a>n_selected <span class="op">=</span> np.<span class="bu">sum</span>(non_zero_mask)</span>
<span id="cb21-495"><a href="#cb21-495" aria-hidden="true" tabindex="-1"></a>n_total <span class="op">=</span> <span class="bu">len</span>(lasso.coef_)</span>
<span id="cb21-496"><a href="#cb21-496" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-497"><a href="#cb21-497" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Nombre de features sélectionnées: </span><span class="sc">{</span>n_selected<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>n_total<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-498"><a href="#cb21-498" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-499"><a href="#cb21-499" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Features sélectionnées</span></span>
<span id="cb21-500"><a href="#cb21-500" aria-hidden="true" tabindex="-1"></a>selected_features <span class="op">=</span> pd.DataFrame({</span>
<span id="cb21-501"><a href="#cb21-501" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Feature'</span>: california.feature_names,</span>
<span id="cb21-502"><a href="#cb21-502" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Lasso_Coef'</span>: lasso.coef_,</span>
<span id="cb21-503"><a href="#cb21-503" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Linear_Coef'</span>: model_lr.coef_,</span>
<span id="cb21-504"><a href="#cb21-504" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Selected'</span>: non_zero_mask</span>
<span id="cb21-505"><a href="#cb21-505" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb21-506"><a href="#cb21-506" aria-hidden="true" tabindex="-1"></a>selected_features[<span class="st">'Abs_Lasso'</span>] <span class="op">=</span> np.<span class="bu">abs</span>(selected_features[<span class="st">'Lasso_Coef'</span>])</span>
<span id="cb21-507"><a href="#cb21-507" aria-hidden="true" tabindex="-1"></a>selected_features <span class="op">=</span> selected_features.sort_values(<span class="st">'Abs_Lasso'</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb21-508"><a href="#cb21-508" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-509"><a href="#cb21-509" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb21-510"><a href="#cb21-510" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"COMPARAISON COEFFICIENTS"</span>)</span>
<span id="cb21-511"><a href="#cb21-511" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb21-512"><a href="#cb21-512" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(selected_features[[<span class="st">'Feature'</span>, <span class="st">'Lasso_Coef'</span>, <span class="st">'Linear_Coef'</span>, <span class="st">'Selected'</span>]].to_string(index<span class="op">=</span><span class="va">False</span>))</span>
<span id="cb21-513"><a href="#cb21-513" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-514"><a href="#cb21-514" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Visualisation</span></span>
<span id="cb21-515"><a href="#cb21-515" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb21-516"><a href="#cb21-516" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-517"><a href="#cb21-517" aria-hidden="true" tabindex="-1"></a><span class="co"># Barplot comparatif</span></span>
<span id="cb21-518"><a href="#cb21-518" aria-hidden="true" tabindex="-1"></a>x_pos <span class="op">=</span> np.arange(<span class="bu">len</span>(california.feature_names))</span>
<span id="cb21-519"><a href="#cb21-519" aria-hidden="true" tabindex="-1"></a>width <span class="op">=</span> <span class="fl">0.35</span></span>
<span id="cb21-520"><a href="#cb21-520" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-521"><a href="#cb21-521" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].bar(x_pos <span class="op">-</span> width<span class="op">/</span><span class="dv">2</span>, model_lr.coef_, width, label<span class="op">=</span><span class="st">'Linear'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb21-522"><a href="#cb21-522" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].bar(x_pos <span class="op">+</span> width<span class="op">/</span><span class="dv">2</span>, lasso.coef_, width, label<span class="op">=</span><span class="st">'Lasso (alpha=0.1)'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb21-523"><a href="#cb21-523" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_xticks(x_pos)</span>
<span id="cb21-524"><a href="#cb21-524" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_xticklabels(california.feature_names, rotation<span class="op">=</span><span class="dv">45</span>, ha<span class="op">=</span><span class="st">'right'</span>)</span>
<span id="cb21-525"><a href="#cb21-525" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_ylabel(<span class="st">'Coefficient'</span>)</span>
<span id="cb21-526"><a href="#cb21-526" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="st">'Comparaison Coefficients: Linear vs Lasso'</span>)</span>
<span id="cb21-527"><a href="#cb21-527" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].legend()</span>
<span id="cb21-528"><a href="#cb21-528" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].axhline(<span class="dv">0</span>, color<span class="op">=</span><span class="st">'black'</span>, linewidth<span class="op">=</span><span class="fl">0.8</span>)</span>
<span id="cb21-529"><a href="#cb21-529" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].grid(alpha<span class="op">=</span><span class="fl">0.3</span>, axis<span class="op">=</span><span class="st">'y'</span>)</span>
<span id="cb21-530"><a href="#cb21-530" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-531"><a href="#cb21-531" aria-hidden="true" tabindex="-1"></a><span class="co"># Scatter: Linear vs Lasso</span></span>
<span id="cb21-532"><a href="#cb21-532" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].scatter(model_lr.coef_, lasso.coef_, s<span class="op">=</span><span class="dv">100</span>, alpha<span class="op">=</span><span class="fl">0.6</span>)</span>
<span id="cb21-533"><a href="#cb21-533" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, feature <span class="kw">in</span> <span class="bu">enumerate</span>(california.feature_names):</span>
<span id="cb21-534"><a href="#cb21-534" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">1</span>].annotate(feature, (model_lr.coef_[i], lasso.coef_[i]),</span>
<span id="cb21-535"><a href="#cb21-535" aria-hidden="true" tabindex="-1"></a>                     fontsize<span class="op">=</span><span class="dv">8</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb21-536"><a href="#cb21-536" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].plot([model_lr.coef_.<span class="bu">min</span>(), model_lr.coef_.<span class="bu">max</span>()],</span>
<span id="cb21-537"><a href="#cb21-537" aria-hidden="true" tabindex="-1"></a>             [model_lr.coef_.<span class="bu">min</span>(), model_lr.coef_.<span class="bu">max</span>()],</span>
<span id="cb21-538"><a href="#cb21-538" aria-hidden="true" tabindex="-1"></a>             <span class="st">'r--'</span>, label<span class="op">=</span><span class="st">'y=x'</span>)</span>
<span id="cb21-539"><a href="#cb21-539" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xlabel(<span class="st">'Coefficient Linear'</span>)</span>
<span id="cb21-540"><a href="#cb21-540" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_ylabel(<span class="st">'Coefficient Lasso'</span>)</span>
<span id="cb21-541"><a href="#cb21-541" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="st">'Linear vs Lasso Coefficients'</span>)</span>
<span id="cb21-542"><a href="#cb21-542" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].legend()</span>
<span id="cb21-543"><a href="#cb21-543" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].grid(alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb21-544"><a href="#cb21-544" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-545"><a href="#cb21-545" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb21-546"><a href="#cb21-546" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb21-547"><a href="#cb21-547" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-548"><a href="#cb21-548" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb21-549"><a href="#cb21-549" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"FEATURES ÉLIMINÉES PAR LASSO"</span>)</span>
<span id="cb21-550"><a href="#cb21-550" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb21-551"><a href="#cb21-551" aria-hidden="true" tabindex="-1"></a>eliminated <span class="op">=</span> selected_features[<span class="op">~</span>selected_features[<span class="st">'Selected'</span>]][<span class="st">'Feature'</span>].tolist()</span>
<span id="cb21-552"><a href="#cb21-552" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> eliminated:</span>
<span id="cb21-553"><a href="#cb21-553" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Features mises à 0:"</span>)</span>
<span id="cb21-554"><a href="#cb21-554" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> feat <span class="kw">in</span> eliminated:</span>
<span id="cb21-555"><a href="#cb21-555" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  • </span><span class="sc">{</span>feat<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-556"><a href="#cb21-556" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb21-557"><a href="#cb21-557" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Aucune feature éliminée (alpha peut-être trop faible)"</span>)</span>
<span id="cb21-558"><a href="#cb21-558" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb21-559"><a href="#cb21-559" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-560"><a href="#cb21-560" aria-hidden="true" tabindex="-1"></a>**Interprétation:**</span>
<span id="cb21-561"><a href="#cb21-561" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Lasso réduit certains coefficients exactement à 0</span>
<span id="cb21-562"><a href="#cb21-562" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Features éliminées = probablement redondantes ou peu informatives</span>
<span id="cb21-563"><a href="#cb21-563" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Peut améliorer l'interprétabilité du modèle</span>
<span id="cb21-564"><a href="#cb21-564" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb21-565"><a href="#cb21-565" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-566"><a href="#cb21-566" aria-hidden="true" tabindex="-1"></a><span class="fu">## 5. Optimisation avec Cross-Validation</span></span>
<span id="cb21-567"><a href="#cb21-567" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-568"><a href="#cb21-568" aria-hidden="true" tabindex="-1"></a><span class="fu">### Exercice 5.1: RidgeCV et LassoCV</span></span>
<span id="cb21-569"><a href="#cb21-569" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-570"><a href="#cb21-570" aria-hidden="true" tabindex="-1"></a>Utilisez les versions CV pour trouver automatiquement le meilleur alpha.</span>
<span id="cb21-571"><a href="#cb21-571" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-572"><a href="#cb21-572" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb21-573"><a href="#cb21-573" aria-hidden="true" tabindex="-1"></a><span class="fu">## Solution Exercice 5.1</span></span>
<span id="cb21-574"><a href="#cb21-574" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-575"><a href="#cb21-575" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb21-576"><a href="#cb21-576" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> RidgeCV, LassoCV</span>
<span id="cb21-577"><a href="#cb21-577" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-578"><a href="#cb21-578" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb21-579"><a href="#cb21-579" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"OPTIMISATION AUTOMATIQUE AVEC CV"</span>)</span>
<span id="cb21-580"><a href="#cb21-580" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb21-581"><a href="#cb21-581" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-582"><a href="#cb21-582" aria-hidden="true" tabindex="-1"></a><span class="co"># Grille d'alphas</span></span>
<span id="cb21-583"><a href="#cb21-583" aria-hidden="true" tabindex="-1"></a>alphas_cv <span class="op">=</span> np.logspace(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">50</span>)</span>
<span id="cb21-584"><a href="#cb21-584" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-585"><a href="#cb21-585" aria-hidden="true" tabindex="-1"></a><span class="co"># RidgeCV</span></span>
<span id="cb21-586"><a href="#cb21-586" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">1. RidgeCV..."</span>)</span>
<span id="cb21-587"><a href="#cb21-587" aria-hidden="true" tabindex="-1"></a>ridge_cv <span class="op">=</span> RidgeCV(alphas<span class="op">=</span>alphas_cv, cv<span class="op">=</span><span class="dv">5</span>, scoring<span class="op">=</span><span class="st">'r2'</span>)</span>
<span id="cb21-588"><a href="#cb21-588" aria-hidden="true" tabindex="-1"></a>ridge_cv.fit(X_train_scaled, y_train)</span>
<span id="cb21-589"><a href="#cb21-589" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   Meilleur alpha: </span><span class="sc">{</span>ridge_cv<span class="sc">.</span>alpha_<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb21-590"><a href="#cb21-590" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-591"><a href="#cb21-591" aria-hidden="true" tabindex="-1"></a>y_pred_ridge <span class="op">=</span> ridge_cv.predict(X_test_scaled)</span>
<span id="cb21-592"><a href="#cb21-592" aria-hidden="true" tabindex="-1"></a>ridge_metrics <span class="op">=</span> evaluate_model(y_test, y_pred_ridge, <span class="st">"Ridge (CV)"</span>)</span>
<span id="cb21-593"><a href="#cb21-593" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-594"><a href="#cb21-594" aria-hidden="true" tabindex="-1"></a><span class="co"># LassoCV</span></span>
<span id="cb21-595"><a href="#cb21-595" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">2. LassoCV..."</span>)</span>
<span id="cb21-596"><a href="#cb21-596" aria-hidden="true" tabindex="-1"></a>lasso_cv <span class="op">=</span> LassoCV(alphas<span class="op">=</span>alphas_cv, cv<span class="op">=</span><span class="dv">5</span>, max_iter<span class="op">=</span><span class="dv">10000</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb21-597"><a href="#cb21-597" aria-hidden="true" tabindex="-1"></a>lasso_cv.fit(X_train_scaled, y_train)</span>
<span id="cb21-598"><a href="#cb21-598" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   Meilleur alpha: </span><span class="sc">{</span>lasso_cv<span class="sc">.</span>alpha_<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb21-599"><a href="#cb21-599" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-600"><a href="#cb21-600" aria-hidden="true" tabindex="-1"></a>y_pred_lasso <span class="op">=</span> lasso_cv.predict(X_test_scaled)</span>
<span id="cb21-601"><a href="#cb21-601" aria-hidden="true" tabindex="-1"></a>lasso_metrics <span class="op">=</span> evaluate_model(y_test, y_pred_lasso, <span class="st">"Lasso (CV)"</span>)</span>
<span id="cb21-602"><a href="#cb21-602" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-603"><a href="#cb21-603" aria-hidden="true" tabindex="-1"></a><span class="co"># ElasticNetCV</span></span>
<span id="cb21-604"><a href="#cb21-604" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> ElasticNetCV</span>
<span id="cb21-605"><a href="#cb21-605" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-606"><a href="#cb21-606" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">3. ElasticNetCV..."</span>)</span>
<span id="cb21-607"><a href="#cb21-607" aria-hidden="true" tabindex="-1"></a>elastic_cv <span class="op">=</span> ElasticNetCV(alphas<span class="op">=</span>alphas_cv, l1_ratio<span class="op">=</span>[<span class="fl">0.1</span>, <span class="fl">0.5</span>, <span class="fl">0.7</span>, <span class="fl">0.9</span>, <span class="fl">0.95</span>, <span class="fl">0.99</span>],</span>
<span id="cb21-608"><a href="#cb21-608" aria-hidden="true" tabindex="-1"></a>                          cv<span class="op">=</span><span class="dv">5</span>, max_iter<span class="op">=</span><span class="dv">10000</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb21-609"><a href="#cb21-609" aria-hidden="true" tabindex="-1"></a>elastic_cv.fit(X_train_scaled, y_train)</span>
<span id="cb21-610"><a href="#cb21-610" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   Meilleur alpha: </span><span class="sc">{</span>elastic_cv<span class="sc">.</span>alpha_<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb21-611"><a href="#cb21-611" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   Meilleur l1_ratio: </span><span class="sc">{</span>elastic_cv<span class="sc">.</span>l1_ratio_<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb21-612"><a href="#cb21-612" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-613"><a href="#cb21-613" aria-hidden="true" tabindex="-1"></a>y_pred_elastic <span class="op">=</span> elastic_cv.predict(X_test_scaled)</span>
<span id="cb21-614"><a href="#cb21-614" aria-hidden="true" tabindex="-1"></a>elastic_metrics <span class="op">=</span> evaluate_model(y_test, y_pred_elastic, <span class="st">"ElasticNet (CV)"</span>)</span>
<span id="cb21-615"><a href="#cb21-615" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-616"><a href="#cb21-616" aria-hidden="true" tabindex="-1"></a><span class="co"># Comparaison finale</span></span>
<span id="cb21-617"><a href="#cb21-617" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb21-618"><a href="#cb21-618" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"COMPARAISON FINALE"</span>)</span>
<span id="cb21-619"><a href="#cb21-619" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb21-620"><a href="#cb21-620" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-621"><a href="#cb21-621" aria-hidden="true" tabindex="-1"></a>final_comparison <span class="op">=</span> pd.DataFrame({</span>
<span id="cb21-622"><a href="#cb21-622" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Modèle'</span>: [<span class="st">'Linear'</span>, <span class="st">'Ridge (CV)'</span>, <span class="st">'Lasso (CV)'</span>, <span class="st">'ElasticNet (CV)'</span>],</span>
<span id="cb21-623"><a href="#cb21-623" aria-hidden="true" tabindex="-1"></a>    <span class="st">'MAE'</span>: [test_metrics[<span class="st">'MAE'</span>], ridge_metrics[<span class="st">'MAE'</span>], </span>
<span id="cb21-624"><a href="#cb21-624" aria-hidden="true" tabindex="-1"></a>            lasso_metrics[<span class="st">'MAE'</span>], elastic_metrics[<span class="st">'MAE'</span>]],</span>
<span id="cb21-625"><a href="#cb21-625" aria-hidden="true" tabindex="-1"></a>    <span class="st">'RMSE'</span>: [test_metrics[<span class="st">'RMSE'</span>], ridge_metrics[<span class="st">'RMSE'</span>], </span>
<span id="cb21-626"><a href="#cb21-626" aria-hidden="true" tabindex="-1"></a>             lasso_metrics[<span class="st">'RMSE'</span>], elastic_metrics[<span class="st">'RMSE'</span>]],</span>
<span id="cb21-627"><a href="#cb21-627" aria-hidden="true" tabindex="-1"></a>    <span class="st">'R²'</span>: [test_metrics[<span class="st">'R2'</span>], ridge_metrics[<span class="st">'R2'</span>], </span>
<span id="cb21-628"><a href="#cb21-628" aria-hidden="true" tabindex="-1"></a>           lasso_metrics[<span class="st">'R2'</span>], elastic_metrics[<span class="st">'R2'</span>]]</span>
<span id="cb21-629"><a href="#cb21-629" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb21-630"><a href="#cb21-630" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-631"><a href="#cb21-631" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(final_comparison.to_string(index<span class="op">=</span><span class="va">False</span>))</span>
<span id="cb21-632"><a href="#cb21-632" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-633"><a href="#cb21-633" aria-hidden="true" tabindex="-1"></a><span class="co"># Meilleur modèle</span></span>
<span id="cb21-634"><a href="#cb21-634" aria-hidden="true" tabindex="-1"></a>best_idx <span class="op">=</span> final_comparison[<span class="st">'R²'</span>].idxmax()</span>
<span id="cb21-635"><a href="#cb21-635" aria-hidden="true" tabindex="-1"></a>best_model_name <span class="op">=</span> final_comparison.loc[best_idx, <span class="st">'Modèle'</span>]</span>
<span id="cb21-636"><a href="#cb21-636" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">→ Meilleur modèle: </span><span class="sc">{</span>best_model_name<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-637"><a href="#cb21-637" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb21-638"><a href="#cb21-638" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb21-639"><a href="#cb21-639" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-640"><a href="#cb21-640" aria-hidden="true" tabindex="-1"></a><span class="fu">## 6. SVR (Support Vector Regression)</span></span>
<span id="cb21-641"><a href="#cb21-641" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-642"><a href="#cb21-642" aria-hidden="true" tabindex="-1"></a><span class="fu">### Exercice 6.1: SVR avec différents kernels</span></span>
<span id="cb21-643"><a href="#cb21-643" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-644"><a href="#cb21-644" aria-hidden="true" tabindex="-1"></a>Comparez SVR linéaire et RBF.</span>
<span id="cb21-645"><a href="#cb21-645" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-646"><a href="#cb21-646" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb21-647"><a href="#cb21-647" aria-hidden="true" tabindex="-1"></a><span class="fu">## Solution Exercice 6.1</span></span>
<span id="cb21-648"><a href="#cb21-648" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-649"><a href="#cb21-649" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb21-650"><a href="#cb21-650" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> SVR</span>
<span id="cb21-651"><a href="#cb21-651" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> GridSearchCV</span>
<span id="cb21-652"><a href="#cb21-652" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-653"><a href="#cb21-653" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb21-654"><a href="#cb21-654" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"SUPPORT VECTOR REGRESSION"</span>)</span>
<span id="cb21-655"><a href="#cb21-655" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb21-656"><a href="#cb21-656" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-657"><a href="#cb21-657" aria-hidden="true" tabindex="-1"></a><span class="co"># Note: SVR est lent, on réduit le dataset pour démo</span></span>
<span id="cb21-658"><a href="#cb21-658" aria-hidden="true" tabindex="-1"></a>X_train_small <span class="op">=</span> X_train_scaled[:<span class="dv">5000</span>]</span>
<span id="cb21-659"><a href="#cb21-659" aria-hidden="true" tabindex="-1"></a>y_train_small <span class="op">=</span> y_train[:<span class="dv">5000</span>]</span>
<span id="cb21-660"><a href="#cb21-660" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-661"><a href="#cb21-661" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. SVR Linéaire</span></span>
<span id="cb21-662"><a href="#cb21-662" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">1. SVR Linéaire..."</span>)</span>
<span id="cb21-663"><a href="#cb21-663" aria-hidden="true" tabindex="-1"></a>svr_lin <span class="op">=</span> SVR(kernel<span class="op">=</span><span class="st">'linear'</span>, C<span class="op">=</span><span class="fl">1.0</span>)</span>
<span id="cb21-664"><a href="#cb21-664" aria-hidden="true" tabindex="-1"></a>svr_lin.fit(X_train_small, y_train_small)</span>
<span id="cb21-665"><a href="#cb21-665" aria-hidden="true" tabindex="-1"></a>y_pred_svr_lin <span class="op">=</span> svr_lin.predict(X_test_scaled)</span>
<span id="cb21-666"><a href="#cb21-666" aria-hidden="true" tabindex="-1"></a>svr_lin_metrics <span class="op">=</span> evaluate_model(y_test, y_pred_svr_lin, <span class="st">"SVR Linear"</span>)</span>
<span id="cb21-667"><a href="#cb21-667" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-668"><a href="#cb21-668" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. SVR RBF</span></span>
<span id="cb21-669"><a href="#cb21-669" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">2. SVR RBF..."</span>)</span>
<span id="cb21-670"><a href="#cb21-670" aria-hidden="true" tabindex="-1"></a>svr_rbf <span class="op">=</span> SVR(kernel<span class="op">=</span><span class="st">'rbf'</span>, C<span class="op">=</span><span class="fl">1.0</span>, gamma<span class="op">=</span><span class="st">'scale'</span>)</span>
<span id="cb21-671"><a href="#cb21-671" aria-hidden="true" tabindex="-1"></a>svr_rbf.fit(X_train_small, y_train_small)</span>
<span id="cb21-672"><a href="#cb21-672" aria-hidden="true" tabindex="-1"></a>y_pred_svr_rbf <span class="op">=</span> svr_rbf.predict(X_test_scaled)</span>
<span id="cb21-673"><a href="#cb21-673" aria-hidden="true" tabindex="-1"></a>svr_rbf_metrics <span class="op">=</span> evaluate_model(y_test, y_pred_svr_rbf, <span class="st">"SVR RBF"</span>)</span>
<span id="cb21-674"><a href="#cb21-674" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-675"><a href="#cb21-675" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Comparaison</span></span>
<span id="cb21-676"><a href="#cb21-676" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb21-677"><a href="#cb21-677" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"COMPARAISON SVR"</span>)</span>
<span id="cb21-678"><a href="#cb21-678" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb21-679"><a href="#cb21-679" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-680"><a href="#cb21-680" aria-hidden="true" tabindex="-1"></a>svr_comparison <span class="op">=</span> pd.DataFrame({</span>
<span id="cb21-681"><a href="#cb21-681" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Kernel'</span>: [<span class="st">'linear'</span>, <span class="st">'rbf'</span>],</span>
<span id="cb21-682"><a href="#cb21-682" aria-hidden="true" tabindex="-1"></a>    <span class="st">'MAE'</span>: [svr_lin_metrics[<span class="st">'MAE'</span>], svr_rbf_metrics[<span class="st">'MAE'</span>]],</span>
<span id="cb21-683"><a href="#cb21-683" aria-hidden="true" tabindex="-1"></a>    <span class="st">'RMSE'</span>: [svr_lin_metrics[<span class="st">'RMSE'</span>], svr_rbf_metrics[<span class="st">'RMSE'</span>]],</span>
<span id="cb21-684"><a href="#cb21-684" aria-hidden="true" tabindex="-1"></a>    <span class="st">'R²'</span>: [svr_lin_metrics[<span class="st">'R2'</span>], svr_rbf_metrics[<span class="st">'R2'</span>]]</span>
<span id="cb21-685"><a href="#cb21-685" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb21-686"><a href="#cb21-686" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(svr_comparison.to_string(index<span class="op">=</span><span class="va">False</span>))</span>
<span id="cb21-687"><a href="#cb21-687" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-688"><a href="#cb21-688" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Optimisation SVR RBF</span></span>
<span id="cb21-689"><a href="#cb21-689" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb21-690"><a href="#cb21-690" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"OPTIMISATION SVR RBF AVEC GRIDSEARCH"</span>)</span>
<span id="cb21-691"><a href="#cb21-691" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb21-692"><a href="#cb21-692" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-693"><a href="#cb21-693" aria-hidden="true" tabindex="-1"></a><span class="co"># Réduction supplémentaire pour vitesse</span></span>
<span id="cb21-694"><a href="#cb21-694" aria-hidden="true" tabindex="-1"></a>X_val <span class="op">=</span> X_train_scaled[<span class="dv">5000</span>:<span class="dv">6000</span>]</span>
<span id="cb21-695"><a href="#cb21-695" aria-hidden="true" tabindex="-1"></a>y_val <span class="op">=</span> y_train[<span class="dv">5000</span>:<span class="dv">6000</span>]</span>
<span id="cb21-696"><a href="#cb21-696" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-697"><a href="#cb21-697" aria-hidden="true" tabindex="-1"></a>param_grid <span class="op">=</span> {</span>
<span id="cb21-698"><a href="#cb21-698" aria-hidden="true" tabindex="-1"></a>    <span class="st">'C'</span>: [<span class="fl">0.1</span>, <span class="dv">1</span>, <span class="dv">10</span>],</span>
<span id="cb21-699"><a href="#cb21-699" aria-hidden="true" tabindex="-1"></a>    <span class="st">'gamma'</span>: [<span class="st">'scale'</span>, <span class="st">'auto'</span>, <span class="fl">0.01</span>, <span class="fl">0.1</span>],</span>
<span id="cb21-700"><a href="#cb21-700" aria-hidden="true" tabindex="-1"></a>    <span class="st">'epsilon'</span>: [<span class="fl">0.01</span>, <span class="fl">0.1</span>, <span class="fl">0.5</span>]</span>
<span id="cb21-701"><a href="#cb21-701" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb21-702"><a href="#cb21-702" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-703"><a href="#cb21-703" aria-hidden="true" tabindex="-1"></a>grid_search <span class="op">=</span> GridSearchCV(</span>
<span id="cb21-704"><a href="#cb21-704" aria-hidden="true" tabindex="-1"></a>    SVR(kernel<span class="op">=</span><span class="st">'rbf'</span>),</span>
<span id="cb21-705"><a href="#cb21-705" aria-hidden="true" tabindex="-1"></a>    param_grid,</span>
<span id="cb21-706"><a href="#cb21-706" aria-hidden="true" tabindex="-1"></a>    cv<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb21-707"><a href="#cb21-707" aria-hidden="true" tabindex="-1"></a>    scoring<span class="op">=</span><span class="st">'r2'</span>,</span>
<span id="cb21-708"><a href="#cb21-708" aria-hidden="true" tabindex="-1"></a>    n_jobs<span class="op">=-</span><span class="dv">1</span>,</span>
<span id="cb21-709"><a href="#cb21-709" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="dv">1</span></span>
<span id="cb21-710"><a href="#cb21-710" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb21-711"><a href="#cb21-711" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-712"><a href="#cb21-712" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Entraînement GridSearch (peut être long)..."</span>)</span>
<span id="cb21-713"><a href="#cb21-713" aria-hidden="true" tabindex="-1"></a>grid_search.fit(X_train_small, y_train_small)</span>
<span id="cb21-714"><a href="#cb21-714" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-715"><a href="#cb21-715" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Meilleurs paramètres: </span><span class="sc">{</span>grid_search<span class="sc">.</span>best_params_<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-716"><a href="#cb21-716" aria-hidden="true" tabindex="-1"></a>best_svr <span class="op">=</span> grid_search.best_estimator_</span>
<span id="cb21-717"><a href="#cb21-717" aria-hidden="true" tabindex="-1"></a>y_pred_best_svr <span class="op">=</span> best_svr.predict(X_val)</span>
<span id="cb21-718"><a href="#cb21-718" aria-hidden="true" tabindex="-1"></a>best_svr_metrics <span class="op">=</span> evaluate_model(y_val, y_pred_best_svr, <span class="st">"SVR optimisé (val)"</span>)</span>
<span id="cb21-719"><a href="#cb21-719" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-720"><a href="#cb21-720" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualisation SVR</span></span>
<span id="cb21-721"><a href="#cb21-721" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">5</span>))</span>
<span id="cb21-722"><a href="#cb21-722" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-723"><a href="#cb21-723" aria-hidden="true" tabindex="-1"></a><span class="co"># Prédictions vs Vraies valeurs</span></span>
<span id="cb21-724"><a href="#cb21-724" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].scatter(y_val, y_pred_best_svr, alpha<span class="op">=</span><span class="fl">0.3</span>, s<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb21-725"><a href="#cb21-725" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].plot([y_val.<span class="bu">min</span>(), y_val.<span class="bu">max</span>()], [y_val.<span class="bu">min</span>(), y_val.<span class="bu">max</span>()], </span>
<span id="cb21-726"><a href="#cb21-726" aria-hidden="true" tabindex="-1"></a>             <span class="st">'r--'</span>, lw<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'Prédiction parfaite'</span>)</span>
<span id="cb21-727"><a href="#cb21-727" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_xlabel(<span class="st">'Vraie valeur'</span>)</span>
<span id="cb21-728"><a href="#cb21-728" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_ylabel(<span class="st">'Prédiction'</span>)</span>
<span id="cb21-729"><a href="#cb21-729" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="ss">f'SVR Optimisé (R²=</span><span class="sc">{</span>best_svr_metrics[<span class="st">"R2"</span>]<span class="sc">:.3f}</span><span class="ss">)'</span>)</span>
<span id="cb21-730"><a href="#cb21-730" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].legend()</span>
<span id="cb21-731"><a href="#cb21-731" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].grid(alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb21-732"><a href="#cb21-732" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-733"><a href="#cb21-733" aria-hidden="true" tabindex="-1"></a><span class="co"># Comparaison modèles</span></span>
<span id="cb21-734"><a href="#cb21-734" aria-hidden="true" tabindex="-1"></a>models_comparison <span class="op">=</span> pd.DataFrame({</span>
<span id="cb21-735"><a href="#cb21-735" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Modèle'</span>: [<span class="st">'Linear'</span>, <span class="st">'Ridge'</span>, <span class="st">'Lasso'</span>, <span class="st">'SVR Linear'</span>, <span class="st">'SVR RBF'</span>],</span>
<span id="cb21-736"><a href="#cb21-736" aria-hidden="true" tabindex="-1"></a>    <span class="st">'RMSE'</span>: [test_metrics[<span class="st">'RMSE'</span>], ridge_metrics[<span class="st">'RMSE'</span>], </span>
<span id="cb21-737"><a href="#cb21-737" aria-hidden="true" tabindex="-1"></a>             lasso_metrics[<span class="st">'RMSE'</span>], svr_lin_metrics[<span class="st">'RMSE'</span>], svr_rbf_metrics[<span class="st">'RMSE'</span>]],</span>
<span id="cb21-738"><a href="#cb21-738" aria-hidden="true" tabindex="-1"></a>    <span class="st">'R²'</span>: [test_metrics[<span class="st">'R2'</span>], ridge_metrics[<span class="st">'R2'</span>], </span>
<span id="cb21-739"><a href="#cb21-739" aria-hidden="true" tabindex="-1"></a>           lasso_metrics[<span class="st">'R2'</span>], svr_lin_metrics[<span class="st">'R2'</span>], svr_rbf_metrics[<span class="st">'R2'</span>]]</span>
<span id="cb21-740"><a href="#cb21-740" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb21-741"><a href="#cb21-741" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-742"><a href="#cb21-742" aria-hidden="true" tabindex="-1"></a>x_pos <span class="op">=</span> np.arange(<span class="bu">len</span>(models_comparison))</span>
<span id="cb21-743"><a href="#cb21-743" aria-hidden="true" tabindex="-1"></a>width <span class="op">=</span> <span class="fl">0.35</span></span>
<span id="cb21-744"><a href="#cb21-744" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-745"><a href="#cb21-745" aria-hidden="true" tabindex="-1"></a>bars1 <span class="op">=</span> axes[<span class="dv">1</span>].bar(x_pos <span class="op">-</span> width<span class="op">/</span><span class="dv">2</span>, models_comparison[<span class="st">'RMSE'</span>], width, label<span class="op">=</span><span class="st">'RMSE'</span>)</span>
<span id="cb21-746"><a href="#cb21-746" aria-hidden="true" tabindex="-1"></a>bars2 <span class="op">=</span> axes[<span class="dv">1</span>].bar(x_pos <span class="op">+</span> width<span class="op">/</span><span class="dv">2</span>, models_comparison[<span class="st">'R²'</span>], width, label<span class="op">=</span><span class="st">'R²'</span>)</span>
<span id="cb21-747"><a href="#cb21-747" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-748"><a href="#cb21-748" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xticks(x_pos)</span>
<span id="cb21-749"><a href="#cb21-749" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xticklabels(models_comparison[<span class="st">'Modèle'</span>], rotation<span class="op">=</span><span class="dv">45</span>, ha<span class="op">=</span><span class="st">'right'</span>)</span>
<span id="cb21-750"><a href="#cb21-750" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_ylabel(<span class="st">'Score'</span>)</span>
<span id="cb21-751"><a href="#cb21-751" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="st">'Comparaison Modèles de Régression'</span>)</span>
<span id="cb21-752"><a href="#cb21-752" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].legend()</span>
<span id="cb21-753"><a href="#cb21-753" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-754"><a href="#cb21-754" aria-hidden="true" tabindex="-1"></a><span class="co"># Annoter les barres</span></span>
<span id="cb21-755"><a href="#cb21-755" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> bars <span class="kw">in</span> [bars1, bars2]:</span>
<span id="cb21-756"><a href="#cb21-756" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> bar <span class="kw">in</span> bars:</span>
<span id="cb21-757"><a href="#cb21-757" aria-hidden="true" tabindex="-1"></a>        height <span class="op">=</span> bar.get_height()</span>
<span id="cb21-758"><a href="#cb21-758" aria-hidden="true" tabindex="-1"></a>        axes[<span class="dv">1</span>].annotate(<span class="ss">f'</span><span class="sc">{</span>height<span class="sc">:.3f}</span><span class="ss">'</span>,</span>
<span id="cb21-759"><a href="#cb21-759" aria-hidden="true" tabindex="-1"></a>                        xy<span class="op">=</span>(bar.get_x() <span class="op">+</span> bar.get_width() <span class="op">/</span> <span class="dv">2</span>, height),</span>
<span id="cb21-760"><a href="#cb21-760" aria-hidden="true" tabindex="-1"></a>                        xytext<span class="op">=</span>(<span class="dv">0</span>, <span class="dv">3</span>),</span>
<span id="cb21-761"><a href="#cb21-761" aria-hidden="true" tabindex="-1"></a>                        textcoords<span class="op">=</span><span class="st">"offset points"</span>,</span>
<span id="cb21-762"><a href="#cb21-762" aria-hidden="true" tabindex="-1"></a>                        ha<span class="op">=</span><span class="st">'center'</span>, va<span class="op">=</span><span class="st">'bottom'</span>, fontsize<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb21-763"><a href="#cb21-763" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-764"><a href="#cb21-764" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb21-765"><a href="#cb21-765" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb21-766"><a href="#cb21-766" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-767"><a href="#cb21-767" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb21-768"><a href="#cb21-768" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"CONSÉILS POUR SVR"</span>)</span>
<span id="cb21-769"><a href="#cb21-769" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb21-770"><a href="#cb21-770" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"""</span></span>
<span id="cb21-771"><a href="#cb21-771" aria-hidden="true" tabindex="-1"></a><span class="st">• SVR est puissant mais COMPUTATIONNELLEMENT COÛTEUX</span></span>
<span id="cb21-772"><a href="#cb21-772" aria-hidden="true" tabindex="-1"></a><span class="st">• Scaling des features OBLIGATOIRE</span></span>
<span id="cb21-773"><a href="#cb21-773" aria-hidden="true" tabindex="-1"></a><span class="st">• GridSearch peut être très long</span></span>
<span id="cb21-774"><a href="#cb21-774" aria-hidden="true" tabindex="-1"></a><span class="st">• Pour grands datasets, considérez:</span></span>
<span id="cb21-775"><a href="#cb21-775" aria-hidden="true" tabindex="-1"></a><span class="st">  - LinearSVR (plus rapide que SVR kernel='linear')</span></span>
<span id="cb21-776"><a href="#cb21-776" aria-hidden="true" tabindex="-1"></a><span class="st">  - Réduction de features (PCA) avant SVR</span></span>
<span id="cb21-777"><a href="#cb21-777" aria-hidden="true" tabindex="-1"></a><span class="st">  - Échantillonnage pour hyperparamètres</span></span>
<span id="cb21-778"><a href="#cb21-778" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span>)</span>
<span id="cb21-779"><a href="#cb21-779" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb21-780"><a href="#cb21-780" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb21-781"><a href="#cb21-781" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-782"><a href="#cb21-782" aria-hidden="true" tabindex="-1"></a><span class="fu">## 7. Comparaison Finale de Tous les Modèles</span></span>
<span id="cb21-783"><a href="#cb21-783" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-784"><a href="#cb21-784" aria-hidden="true" tabindex="-1"></a><span class="fu">### Exercice 7.1: Tableau de Bord Complet</span></span>
<span id="cb21-785"><a href="#cb21-785" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-786"><a href="#cb21-786" aria-hidden="true" tabindex="-1"></a>Créez un tableau de bord comparatif de tous les modèles.</span>
<span id="cb21-787"><a href="#cb21-787" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-788"><a href="#cb21-788" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb21-789"><a href="#cb21-789" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb21-790"><a href="#cb21-790" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb21-791"><a href="#cb21-791" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"TABLEAU DE BORD COMPARATIF"</span>)</span>
<span id="cb21-792"><a href="#cb21-792" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb21-793"><a href="#cb21-793" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-794"><a href="#cb21-794" aria-hidden="true" tabindex="-1"></a><span class="co"># Collecte de tous les résultats</span></span>
<span id="cb21-795"><a href="#cb21-795" aria-hidden="true" tabindex="-1"></a>all_results <span class="op">=</span> []</span>
<span id="cb21-796"><a href="#cb21-796" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-797"><a href="#cb21-797" aria-hidden="true" tabindex="-1"></a><span class="co"># Fonction pour ajouter un modèle</span></span>
<span id="cb21-798"><a href="#cb21-798" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> add_result(name, y_pred, metrics_func<span class="op">=</span>evaluate_model):</span>
<span id="cb21-799"><a href="#cb21-799" aria-hidden="true" tabindex="-1"></a>    mae <span class="op">=</span> mean_absolute_error(y_test, y_pred)</span>
<span id="cb21-800"><a href="#cb21-800" aria-hidden="true" tabindex="-1"></a>    rmse <span class="op">=</span> np.sqrt(mean_squared_error(y_test, y_pred))</span>
<span id="cb21-801"><a href="#cb21-801" aria-hidden="true" tabindex="-1"></a>    r2 <span class="op">=</span> r2_score(y_test, y_pred)</span>
<span id="cb21-802"><a href="#cb21-802" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {<span class="st">'Modèle'</span>: name, <span class="st">'MAE'</span>: mae, <span class="st">'RMSE'</span>: rmse, <span class="st">'R²'</span>: r2}</span>
<span id="cb21-803"><a href="#cb21-803" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-804"><a href="#cb21-804" aria-hidden="true" tabindex="-1"></a><span class="co"># Ajout de tous les modèles</span></span>
<span id="cb21-805"><a href="#cb21-805" aria-hidden="true" tabindex="-1"></a>all_results.append(add_result(<span class="st">'Linear'</span>, y_test_pred))</span>
<span id="cb21-806"><a href="#cb21-806" aria-hidden="true" tabindex="-1"></a>all_results.append(add_result(<span class="st">'Ridge (CV)'</span>, y_pred_ridge))</span>
<span id="cb21-807"><a href="#cb21-807" aria-hidden="true" tabindex="-1"></a>all_results.append(add_result(<span class="st">'Lasso (CV)'</span>, y_pred_lasso))</span>
<span id="cb21-808"><a href="#cb21-808" aria-hidden="true" tabindex="-1"></a>all_results.append(add_result(<span class="st">'ElasticNet (CV)'</span>, y_pred_elastic))</span>
<span id="cb21-809"><a href="#cb21-809" aria-hidden="true" tabindex="-1"></a>all_results.append(add_result(<span class="st">'SVR Linear'</span>, y_pred_svr_lin))</span>
<span id="cb21-810"><a href="#cb21-810" aria-hidden="true" tabindex="-1"></a>all_results.append(add_result(<span class="st">'SVR RBF'</span>, y_pred_svr_rbf))</span>
<span id="cb21-811"><a href="#cb21-811" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-812"><a href="#cb21-812" aria-hidden="true" tabindex="-1"></a>df_all_results <span class="op">=</span> pd.DataFrame(all_results)</span>
<span id="cb21-813"><a href="#cb21-813" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-814"><a href="#cb21-814" aria-hidden="true" tabindex="-1"></a><span class="co"># Tri par R²</span></span>
<span id="cb21-815"><a href="#cb21-815" aria-hidden="true" tabindex="-1"></a>df_all_results <span class="op">=</span> df_all_results.sort_values(<span class="st">'R²'</span>, ascending<span class="op">=</span><span class="va">False</span>).reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb21-816"><a href="#cb21-816" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-817"><a href="#cb21-817" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Classement par R²:"</span>)</span>
<span id="cb21-818"><a href="#cb21-818" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df_all_results.to_string(index<span class="op">=</span><span class="va">False</span>))</span>
<span id="cb21-819"><a href="#cb21-819" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-820"><a href="#cb21-820" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualisation</span></span>
<span id="cb21-821"><a href="#cb21-821" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">12</span>))</span>
<span id="cb21-822"><a href="#cb21-822" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-823"><a href="#cb21-823" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Barplot R²</span></span>
<span id="cb21-824"><a href="#cb21-824" aria-hidden="true" tabindex="-1"></a>x_pos <span class="op">=</span> np.arange(<span class="bu">len</span>(df_all_results))</span>
<span id="cb21-825"><a href="#cb21-825" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].barh(x_pos, df_all_results[<span class="st">'R²'</span>], color<span class="op">=</span><span class="st">'skyblue'</span>)</span>
<span id="cb21-826"><a href="#cb21-826" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].set_yticks(x_pos)</span>
<span id="cb21-827"><a href="#cb21-827" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].set_yticklabels(df_all_results[<span class="st">'Modèle'</span>])</span>
<span id="cb21-828"><a href="#cb21-828" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].set_xlabel(<span class="st">'R² Score'</span>)</span>
<span id="cb21-829"><a href="#cb21-829" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].set_title(<span class="st">'Comparaison R² des Modèles'</span>)</span>
<span id="cb21-830"><a href="#cb21-830" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].invert_yaxis()  <span class="co"># Meilleur en haut</span></span>
<span id="cb21-831"><a href="#cb21-831" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-832"><a href="#cb21-832" aria-hidden="true" tabindex="-1"></a><span class="co"># Annoter les valeurs</span></span>
<span id="cb21-833"><a href="#cb21-833" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, v <span class="kw">in</span> <span class="bu">enumerate</span>(df_all_results[<span class="st">'R²'</span>]):</span>
<span id="cb21-834"><a href="#cb21-834" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">0</span>, <span class="dv">0</span>].text(v <span class="op">+</span> <span class="fl">0.001</span>, i, <span class="ss">f'</span><span class="sc">{</span>v<span class="sc">:.4f}</span><span class="ss">'</span>, va<span class="op">=</span><span class="st">'center'</span>)</span>
<span id="cb21-835"><a href="#cb21-835" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-836"><a href="#cb21-836" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Comparaison MAE vs RMSE</span></span>
<span id="cb21-837"><a href="#cb21-837" aria-hidden="true" tabindex="-1"></a>scatter <span class="op">=</span> axes[<span class="dv">0</span>, <span class="dv">1</span>].scatter(df_all_results[<span class="st">'MAE'</span>], df_all_results[<span class="st">'RMSE'</span>], </span>
<span id="cb21-838"><a href="#cb21-838" aria-hidden="true" tabindex="-1"></a>                             s<span class="op">=</span><span class="dv">200</span>, alpha<span class="op">=</span><span class="fl">0.6</span>, c<span class="op">=</span>df_all_results[<span class="st">'R²'</span>], cmap<span class="op">=</span><span class="st">'viridis'</span>)</span>
<span id="cb21-839"><a href="#cb21-839" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, row <span class="kw">in</span> df_all_results.iterrows():</span>
<span id="cb21-840"><a href="#cb21-840" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">0</span>, <span class="dv">1</span>].annotate(row[<span class="st">'Modèle'</span>], (row[<span class="st">'MAE'</span>], row[<span class="st">'RMSE'</span>]), fontsize<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb21-841"><a href="#cb21-841" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">1</span>].set_xlabel(<span class="st">'MAE'</span>)</span>
<span id="cb21-842"><a href="#cb21-842" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">1</span>].set_ylabel(<span class="st">'RMSE'</span>)</span>
<span id="cb21-843"><a href="#cb21-843" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">1</span>].set_title(<span class="st">'MAE vs RMSE (couleur = R²)'</span>)</span>
<span id="cb21-844"><a href="#cb21-844" aria-hidden="true" tabindex="-1"></a>plt.colorbar(scatter, ax<span class="op">=</span>axes[<span class="dv">0</span>, <span class="dv">1</span>], label<span class="op">=</span><span class="st">'R² Score'</span>)</span>
<span id="cb21-845"><a href="#cb21-845" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-846"><a href="#cb21-846" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Temps d'entraînement (exemple)</span></span>
<span id="cb21-847"><a href="#cb21-847" aria-hidden="true" tabindex="-1"></a><span class="co"># Dans un cas réel, on mesurerait le temps</span></span>
<span id="cb21-848"><a href="#cb21-848" aria-hidden="true" tabindex="-1"></a>training_times <span class="op">=</span> [<span class="fl">0.1</span>, <span class="fl">0.2</span>, <span class="fl">0.3</span>, <span class="fl">0.4</span>, <span class="fl">2.0</span>, <span class="fl">5.0</span>]  <span class="co"># valeurs d'exemple</span></span>
<span id="cb21-849"><a href="#cb21-849" aria-hidden="true" tabindex="-1"></a>df_all_results[<span class="st">'Temps(s)'</span>] <span class="op">=</span> training_times</span>
<span id="cb21-850"><a href="#cb21-850" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-851"><a href="#cb21-851" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">0</span>].scatter(df_all_results[<span class="st">'Temps(s)'</span>], df_all_results[<span class="st">'R²'</span>], s<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb21-852"><a href="#cb21-852" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, row <span class="kw">in</span> df_all_results.iterrows():</span>
<span id="cb21-853"><a href="#cb21-853" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">1</span>, <span class="dv">0</span>].annotate(row[<span class="st">'Modèle'</span>], (row[<span class="st">'Temps(s)'</span>], row[<span class="st">'R²'</span>]), fontsize<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb21-854"><a href="#cb21-854" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">0</span>].set_xlabel(<span class="st">'Temps d</span><span class="ch">\'</span><span class="st">entraînement (s)'</span>)</span>
<span id="cb21-855"><a href="#cb21-855" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">0</span>].set_ylabel(<span class="st">'R² Score'</span>)</span>
<span id="cb21-856"><a href="#cb21-856" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">0</span>].set_title(<span class="st">'Performance vs Temps d</span><span class="ch">\'</span><span class="st">entraînement'</span>)</span>
<span id="cb21-857"><a href="#cb21-857" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">0</span>].grid(alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb21-858"><a href="#cb21-858" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-859"><a href="#cb21-859" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Heatmap des métriques</span></span>
<span id="cb21-860"><a href="#cb21-860" aria-hidden="true" tabindex="-1"></a>metrics_df <span class="op">=</span> df_all_results.set_index(<span class="st">'Modèle'</span>)[[<span class="st">'MAE'</span>, <span class="st">'RMSE'</span>, <span class="st">'R²'</span>]]</span>
<span id="cb21-861"><a href="#cb21-861" aria-hidden="true" tabindex="-1"></a>sns.heatmap(metrics_df, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">'.4f'</span>, cmap<span class="op">=</span><span class="st">'YlOrRd'</span>, </span>
<span id="cb21-862"><a href="#cb21-862" aria-hidden="true" tabindex="-1"></a>            center<span class="op">=</span><span class="dv">0</span>, ax<span class="op">=</span>axes[<span class="dv">1</span>, <span class="dv">1</span>], cbar_kws<span class="op">=</span>{<span class="st">'label'</span>: <span class="st">'Valeur'</span>})</span>
<span id="cb21-863"><a href="#cb21-863" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">1</span>].set_title(<span class="st">'Heatmap des Métriques par Modèle'</span>)</span>
<span id="cb21-864"><a href="#cb21-864" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">1</span>].tick_params(axis<span class="op">=</span><span class="st">'x'</span>, rotation<span class="op">=</span><span class="dv">45</span>)</span>
<span id="cb21-865"><a href="#cb21-865" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">1</span>].tick_params(axis<span class="op">=</span><span class="st">'y'</span>, rotation<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb21-866"><a href="#cb21-866" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-867"><a href="#cb21-867" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb21-868"><a href="#cb21-868" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb21-869"><a href="#cb21-869" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-870"><a href="#cb21-870" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb21-871"><a href="#cb21-871" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"RECOMMANDATIONS FINALES"</span>)</span>
<span id="cb21-872"><a href="#cb21-872" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb21-873"><a href="#cb21-873" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-874"><a href="#cb21-874" aria-hidden="true" tabindex="-1"></a><span class="co"># Recommandation basée sur différents critères</span></span>
<span id="cb21-875"><a href="#cb21-875" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"""</span></span>
<span id="cb21-876"><a href="#cb21-876" aria-hidden="true" tabindex="-1"></a><span class="st">1. Pour PERFORMANCE MAX (R²):</span></span>
<span id="cb21-877"><a href="#cb21-877" aria-hidden="true" tabindex="-1"></a><span class="st">   → </span><span class="sc">{}</span><span class="st"> (R²=</span><span class="sc">{:.4f}</span><span class="st">)</span></span>
<span id="cb21-878"><a href="#cb21-878" aria-hidden="true" tabindex="-1"></a><span class="st">   </span></span>
<span id="cb21-879"><a href="#cb21-879" aria-hidden="true" tabindex="-1"></a><span class="st">2. Pour INTERPRÉTABILITÉ (coefficients):</span></span>
<span id="cb21-880"><a href="#cb21-880" aria-hidden="true" tabindex="-1"></a><span class="st">   → Lasso (CV) (sélection de features)</span></span>
<span id="cb21-881"><a href="#cb21-881" aria-hidden="true" tabindex="-1"></a><span class="st">   </span></span>
<span id="cb21-882"><a href="#cb21-882" aria-hidden="true" tabindex="-1"></a><span class="st">3. Pour RAPIDITÉ:</span></span>
<span id="cb21-883"><a href="#cb21-883" aria-hidden="true" tabindex="-1"></a><span class="st">   → Linear ou Ridge (CV)</span></span>
<span id="cb21-884"><a href="#cb21-884" aria-hidden="true" tabindex="-1"></a><span class="st">   </span></span>
<span id="cb21-885"><a href="#cb21-885" aria-hidden="true" tabindex="-1"></a><span class="st">4. Pour COMPLEXITÉ NON-LINÉAIRE:</span></span>
<span id="cb21-886"><a href="#cb21-886" aria-hidden="true" tabindex="-1"></a><span class="st">   → SVR RBF (mais plus lent)</span></span>
<span id="cb21-887"><a href="#cb21-887" aria-hidden="true" tabindex="-1"></a><span class="st">   </span></span>
<span id="cb21-888"><a href="#cb21-888" aria-hidden="true" tabindex="-1"></a><span class="st">5. COMPROMIS PERFORMANCE/TEMPS:</span></span>
<span id="cb21-889"><a href="#cb21-889" aria-hidden="true" tabindex="-1"></a><span class="st">   → ElasticNet (CV)</span></span>
<span id="cb21-890"><a href="#cb21-890" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span>.<span class="bu">format</span>(df_all_results.iloc[<span class="dv">0</span>][<span class="st">'Modèle'</span>], df_all_results.iloc[<span class="dv">0</span>][<span class="st">'R²'</span>]))</span>
<span id="cb21-891"><a href="#cb21-891" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-892"><a href="#cb21-892" aria-hidden="true" tabindex="-1"></a><span class="co"># Sauvegarde des résultats</span></span>
<span id="cb21-893"><a href="#cb21-893" aria-hidden="true" tabindex="-1"></a>df_all_results.to_csv(<span class="st">'resultats_regression_comparaison.csv'</span>, index<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb21-894"><a href="#cb21-894" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Résultats sauvegardés dans 'resultats_regression_comparaison.csv'"</span>)</span>
<span id="cb21-895"><a href="#cb21-895" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb21-896"><a href="#cb21-896" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb21-897"><a href="#cb21-897" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-898"><a href="#cb21-898" aria-hidden="true" tabindex="-1"></a><span class="fu">## 8. Projet Bonus: Regression Avancée</span></span>
<span id="cb21-899"><a href="#cb21-899" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-900"><a href="#cb21-900" aria-hidden="true" tabindex="-1"></a><span class="fu">### Exercice 8.1: Ensemble Methods</span></span>
<span id="cb21-901"><a href="#cb21-901" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-902"><a href="#cb21-902" aria-hidden="true" tabindex="-1"></a>Testez Random Forest et Gradient Boosting pour la régression.</span>
<span id="cb21-903"><a href="#cb21-903" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-904"><a href="#cb21-904" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb21-905"><a href="#cb21-905" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestRegressor, GradientBoostingRegressor</span>
<span id="cb21-906"><a href="#cb21-906" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> RandomizedSearchCV</span>
<span id="cb21-907"><a href="#cb21-907" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-908"><a href="#cb21-908" aria-hidden="true" tabindex="-1"></a><span class="co"># </span><span class="al">TODO</span><span class="co">: Implémentez Random Forest et Gradient Boosting</span></span>
<span id="cb21-909"><a href="#cb21-909" aria-hidden="true" tabindex="-1"></a><span class="co"># Optimisez avec RandomizedSearchCV</span></span>
<span id="cb21-910"><a href="#cb21-910" aria-hidden="true" tabindex="-1"></a><span class="co"># Comparez avec les modèles linéaires</span></span>
<span id="cb21-911"><a href="#cb21-911" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb21-912"><a href="#cb21-912" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-913"><a href="#cb21-913" aria-hidden="true" tabindex="-1"></a>**Indices:**</span>
<span id="cb21-914"><a href="#cb21-914" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Pas besoin de standardisation pour les arbres</span>
<span id="cb21-915"><a href="#cb21-915" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Optimisez: n_estimators, max_depth, min_samples_split</span>
<span id="cb21-916"><a href="#cb21-916" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Métrique: RMSE ou MAE</span>
<span id="cb21-917"><a href="#cb21-917" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Visualisez l'importance des features</span>
<span id="cb21-918"><a href="#cb21-918" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-919"><a href="#cb21-919" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb21-920"><a href="#cb21-920" aria-hidden="true" tabindex="-1"></a><span class="fu">## Solution Exercice 8.1</span></span>
<span id="cb21-921"><a href="#cb21-921" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-922"><a href="#cb21-922" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb21-923"><a href="#cb21-923" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb21-924"><a href="#cb21-924" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"ENSEMBLE METHODS: RANDOM FOREST &amp; GRADIENT BOOSTING"</span>)</span>
<span id="cb21-925"><a href="#cb21-925" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb21-926"><a href="#cb21-926" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-927"><a href="#cb21-927" aria-hidden="true" tabindex="-1"></a><span class="co"># Pas besoin de scaling pour les arbres</span></span>
<span id="cb21-928"><a href="#cb21-928" aria-hidden="true" tabindex="-1"></a>X_train_trees <span class="op">=</span> X_train</span>
<span id="cb21-929"><a href="#cb21-929" aria-hidden="true" tabindex="-1"></a>X_test_trees <span class="op">=</span> X_test</span>
<span id="cb21-930"><a href="#cb21-930" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-931"><a href="#cb21-931" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Random Forest</span></span>
<span id="cb21-932"><a href="#cb21-932" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">1. Random Forest Regressor..."</span>)</span>
<span id="cb21-933"><a href="#cb21-933" aria-hidden="true" tabindex="-1"></a>rf <span class="op">=</span> RandomForestRegressor(random_state<span class="op">=</span><span class="dv">42</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb21-934"><a href="#cb21-934" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-935"><a href="#cb21-935" aria-hidden="true" tabindex="-1"></a><span class="co"># Hyperparamètres</span></span>
<span id="cb21-936"><a href="#cb21-936" aria-hidden="true" tabindex="-1"></a>param_dist_rf <span class="op">=</span> {</span>
<span id="cb21-937"><a href="#cb21-937" aria-hidden="true" tabindex="-1"></a>    <span class="st">'n_estimators'</span>: [<span class="dv">100</span>, <span class="dv">200</span>, <span class="dv">300</span>],</span>
<span id="cb21-938"><a href="#cb21-938" aria-hidden="true" tabindex="-1"></a>    <span class="st">'max_depth'</span>: [<span class="va">None</span>, <span class="dv">10</span>, <span class="dv">20</span>, <span class="dv">30</span>],</span>
<span id="cb21-939"><a href="#cb21-939" aria-hidden="true" tabindex="-1"></a>    <span class="st">'min_samples_split'</span>: [<span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">10</span>],</span>
<span id="cb21-940"><a href="#cb21-940" aria-hidden="true" tabindex="-1"></a>    <span class="st">'min_samples_leaf'</span>: [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">4</span>]</span>
<span id="cb21-941"><a href="#cb21-941" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb21-942"><a href="#cb21-942" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-943"><a href="#cb21-943" aria-hidden="true" tabindex="-1"></a>rf_random <span class="op">=</span> RandomizedSearchCV(</span>
<span id="cb21-944"><a href="#cb21-944" aria-hidden="true" tabindex="-1"></a>    rf, param_dist_rf, n_iter<span class="op">=</span><span class="dv">20</span>, cv<span class="op">=</span><span class="dv">3</span>, </span>
<span id="cb21-945"><a href="#cb21-945" aria-hidden="true" tabindex="-1"></a>    scoring<span class="op">=</span><span class="st">'neg_mean_squared_error'</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>, random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb21-946"><a href="#cb21-946" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb21-947"><a href="#cb21-947" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-948"><a href="#cb21-948" aria-hidden="true" tabindex="-1"></a>rf_random.fit(X_train_trees, y_train)</span>
<span id="cb21-949"><a href="#cb21-949" aria-hidden="true" tabindex="-1"></a>best_rf <span class="op">=</span> rf_random.best_estimator_</span>
<span id="cb21-950"><a href="#cb21-950" aria-hidden="true" tabindex="-1"></a>y_pred_rf <span class="op">=</span> best_rf.predict(X_test_trees)</span>
<span id="cb21-951"><a href="#cb21-951" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-952"><a href="#cb21-952" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Meilleurs paramètres RF: </span><span class="sc">{</span>rf_random<span class="sc">.</span>best_params_<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-953"><a href="#cb21-953" aria-hidden="true" tabindex="-1"></a>rf_metrics <span class="op">=</span> evaluate_model(y_test, y_pred_rf, <span class="st">"Random Forest"</span>)</span>
<span id="cb21-954"><a href="#cb21-954" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-955"><a href="#cb21-955" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Gradient Boosting</span></span>
<span id="cb21-956"><a href="#cb21-956" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">2. Gradient Boosting Regressor..."</span>)</span>
<span id="cb21-957"><a href="#cb21-957" aria-hidden="true" tabindex="-1"></a>gbr <span class="op">=</span> GradientBoostingRegressor(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb21-958"><a href="#cb21-958" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-959"><a href="#cb21-959" aria-hidden="true" tabindex="-1"></a>param_dist_gbr <span class="op">=</span> {</span>
<span id="cb21-960"><a href="#cb21-960" aria-hidden="true" tabindex="-1"></a>    <span class="st">'n_estimators'</span>: [<span class="dv">100</span>, <span class="dv">200</span>],</span>
<span id="cb21-961"><a href="#cb21-961" aria-hidden="true" tabindex="-1"></a>    <span class="st">'learning_rate'</span>: [<span class="fl">0.01</span>, <span class="fl">0.05</span>, <span class="fl">0.1</span>],</span>
<span id="cb21-962"><a href="#cb21-962" aria-hidden="true" tabindex="-1"></a>    <span class="st">'max_depth'</span>: [<span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>],</span>
<span id="cb21-963"><a href="#cb21-963" aria-hidden="true" tabindex="-1"></a>    <span class="st">'subsample'</span>: [<span class="fl">0.8</span>, <span class="fl">0.9</span>, <span class="fl">1.0</span>]</span>
<span id="cb21-964"><a href="#cb21-964" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb21-965"><a href="#cb21-965" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-966"><a href="#cb21-966" aria-hidden="true" tabindex="-1"></a>gbr_random <span class="op">=</span> RandomizedSearchCV(</span>
<span id="cb21-967"><a href="#cb21-967" aria-hidden="true" tabindex="-1"></a>    gbr, param_dist_gbr, n_iter<span class="op">=</span><span class="dv">15</span>, cv<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb21-968"><a href="#cb21-968" aria-hidden="true" tabindex="-1"></a>    scoring<span class="op">=</span><span class="st">'neg_mean_squared_error'</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>, random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb21-969"><a href="#cb21-969" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb21-970"><a href="#cb21-970" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-971"><a href="#cb21-971" aria-hidden="true" tabindex="-1"></a>gbr_random.fit(X_train_trees, y_train)</span>
<span id="cb21-972"><a href="#cb21-972" aria-hidden="true" tabindex="-1"></a>best_gbr <span class="op">=</span> gbr_random.best_estimator_</span>
<span id="cb21-973"><a href="#cb21-973" aria-hidden="true" tabindex="-1"></a>y_pred_gbr <span class="op">=</span> best_gbr.predict(X_test_trees)</span>
<span id="cb21-974"><a href="#cb21-974" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-975"><a href="#cb21-975" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Meilleurs paramètres GBR: </span><span class="sc">{</span>gbr_random<span class="sc">.</span>best_params_<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-976"><a href="#cb21-976" aria-hidden="true" tabindex="-1"></a>gbr_metrics <span class="op">=</span> evaluate_model(y_test, y_pred_gbr, <span class="st">"Gradient Boosting"</span>)</span>
<span id="cb21-977"><a href="#cb21-977" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-978"><a href="#cb21-978" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Comparaison</span></span>
<span id="cb21-979"><a href="#cb21-979" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb21-980"><a href="#cb21-980" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"COMPARAISON MODÈLES AVANCÉS"</span>)</span>
<span id="cb21-981"><a href="#cb21-981" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb21-982"><a href="#cb21-982" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-983"><a href="#cb21-983" aria-hidden="true" tabindex="-1"></a>ensemble_results <span class="op">=</span> pd.DataFrame([</span>
<span id="cb21-984"><a href="#cb21-984" aria-hidden="true" tabindex="-1"></a>    {<span class="st">'Modèle'</span>: <span class="st">'Random Forest'</span>, <span class="st">'MAE'</span>: rf_metrics[<span class="st">'MAE'</span>], </span>
<span id="cb21-985"><a href="#cb21-985" aria-hidden="true" tabindex="-1"></a>     <span class="st">'RMSE'</span>: rf_metrics[<span class="st">'RMSE'</span>], <span class="st">'R²'</span>: rf_metrics[<span class="st">'R2'</span>]},</span>
<span id="cb21-986"><a href="#cb21-986" aria-hidden="true" tabindex="-1"></a>    {<span class="st">'Modèle'</span>: <span class="st">'Gradient Boosting'</span>, <span class="st">'MAE'</span>: gbr_metrics[<span class="st">'MAE'</span>], </span>
<span id="cb21-987"><a href="#cb21-987" aria-hidden="true" tabindex="-1"></a>     <span class="st">'RMSE'</span>: gbr_metrics[<span class="st">'RMSE'</span>], <span class="st">'R²'</span>: gbr_metrics[<span class="st">'R2'</span>]},</span>
<span id="cb21-988"><a href="#cb21-988" aria-hidden="true" tabindex="-1"></a>    {<span class="st">'Modèle'</span>: <span class="st">'Meilleur Linéaire'</span>, <span class="st">'MAE'</span>: df_all_results.iloc[<span class="dv">0</span>][<span class="st">'MAE'</span>],</span>
<span id="cb21-989"><a href="#cb21-989" aria-hidden="true" tabindex="-1"></a>     <span class="st">'RMSE'</span>: df_all_results.iloc[<span class="dv">0</span>][<span class="st">'RMSE'</span>], <span class="st">'R²'</span>: df_all_results.iloc[<span class="dv">0</span>][<span class="st">'R²'</span>]}</span>
<span id="cb21-990"><a href="#cb21-990" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb21-991"><a href="#cb21-991" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-992"><a href="#cb21-992" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(ensemble_results.to_string(index<span class="op">=</span><span class="va">False</span>))</span>
<span id="cb21-993"><a href="#cb21-993" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-994"><a href="#cb21-994" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Importance des features</span></span>
<span id="cb21-995"><a href="#cb21-995" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb21-996"><a href="#cb21-996" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-997"><a href="#cb21-997" aria-hidden="true" tabindex="-1"></a><span class="co"># Random Forest</span></span>
<span id="cb21-998"><a href="#cb21-998" aria-hidden="true" tabindex="-1"></a>rf_importances <span class="op">=</span> pd.DataFrame({</span>
<span id="cb21-999"><a href="#cb21-999" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Feature'</span>: california.feature_names,</span>
<span id="cb21-1000"><a href="#cb21-1000" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Importance'</span>: best_rf.feature_importances_</span>
<span id="cb21-1001"><a href="#cb21-1001" aria-hidden="true" tabindex="-1"></a>}).sort_values(<span class="st">'Importance'</span>, ascending<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb21-1002"><a href="#cb21-1002" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-1003"><a href="#cb21-1003" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].barh(rf_importances[<span class="st">'Feature'</span>], rf_importances[<span class="st">'Importance'</span>])</span>
<span id="cb21-1004"><a href="#cb21-1004" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_xlabel(<span class="st">'Importance'</span>)</span>
<span id="cb21-1005"><a href="#cb21-1005" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="st">'Importance des Features - Random Forest'</span>)</span>
<span id="cb21-1006"><a href="#cb21-1006" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-1007"><a href="#cb21-1007" aria-hidden="true" tabindex="-1"></a><span class="co"># Gradient Boosting</span></span>
<span id="cb21-1008"><a href="#cb21-1008" aria-hidden="true" tabindex="-1"></a>gbr_importances <span class="op">=</span> pd.DataFrame({</span>
<span id="cb21-1009"><a href="#cb21-1009" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Feature'</span>: california.feature_names,</span>
<span id="cb21-1010"><a href="#cb21-1010" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Importance'</span>: best_gbr.feature_importances_</span>
<span id="cb21-1011"><a href="#cb21-1011" aria-hidden="true" tabindex="-1"></a>}).sort_values(<span class="st">'Importance'</span>, ascending<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb21-1012"><a href="#cb21-1012" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-1013"><a href="#cb21-1013" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].barh(gbr_importances[<span class="st">'Feature'</span>], gbr_importances[<span class="st">'Importance'</span>])</span>
<span id="cb21-1014"><a href="#cb21-1014" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xlabel(<span class="st">'Importance'</span>)</span>
<span id="cb21-1015"><a href="#cb21-1015" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="st">'Importance des Features - Gradient Boosting'</span>)</span>
<span id="cb21-1016"><a href="#cb21-1016" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-1017"><a href="#cb21-1017" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb21-1018"><a href="#cb21-1018" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb21-1019"><a href="#cb21-1019" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-1020"><a href="#cb21-1020" aria-hidden="true" tabindex="-1"></a><span class="co"># 5. Visualisation prédictions</span></span>
<span id="cb21-1021"><a href="#cb21-1021" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">5</span>))</span>
<span id="cb21-1022"><a href="#cb21-1022" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-1023"><a href="#cb21-1023" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].scatter(y_test, y_pred_rf, alpha<span class="op">=</span><span class="fl">0.3</span>, s<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb21-1024"><a href="#cb21-1024" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].plot([y_test.<span class="bu">min</span>(), y_test.<span class="bu">max</span>()], [y_test.<span class="bu">min</span>(), y_test.<span class="bu">max</span>()], <span class="st">'r--'</span>)</span>
<span id="cb21-1025"><a href="#cb21-1025" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_xlabel(<span class="st">'Vraie valeur'</span>)</span>
<span id="cb21-1026"><a href="#cb21-1026" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_ylabel(<span class="st">'Prédiction'</span>)</span>
<span id="cb21-1027"><a href="#cb21-1027" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="ss">f'Random Forest (R²=</span><span class="sc">{</span>rf_metrics[<span class="st">"R2"</span>]<span class="sc">:.3f}</span><span class="ss">)'</span>)</span>
<span id="cb21-1028"><a href="#cb21-1028" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].grid(alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb21-1029"><a href="#cb21-1029" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-1030"><a href="#cb21-1030" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].scatter(y_test, y_pred_gbr, alpha<span class="op">=</span><span class="fl">0.3</span>, s<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb21-1031"><a href="#cb21-1031" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].plot([y_test.<span class="bu">min</span>(), y_test.<span class="bu">max</span>()], [y_test.<span class="bu">min</span>(), y_test.<span class="bu">max</span>()], <span class="st">'r--'</span>)</span>
<span id="cb21-1032"><a href="#cb21-1032" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xlabel(<span class="st">'Vraie valeur'</span>)</span>
<span id="cb21-1033"><a href="#cb21-1033" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_ylabel(<span class="st">'Prédiction'</span>)</span>
<span id="cb21-1034"><a href="#cb21-1034" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="ss">f'Gradient Boosting (R²=</span><span class="sc">{</span>gbr_metrics[<span class="st">"R2"</span>]<span class="sc">:.3f}</span><span class="ss">)'</span>)</span>
<span id="cb21-1035"><a href="#cb21-1035" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].grid(alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb21-1036"><a href="#cb21-1036" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-1037"><a href="#cb21-1037" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb21-1038"><a href="#cb21-1038" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb21-1039"><a href="#cb21-1039" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-1040"><a href="#cb21-1040" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb21-1041"><a href="#cb21-1041" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"CONCLUSION ENSEMBLE METHODS"</span>)</span>
<span id="cb21-1042"><a href="#cb21-1042" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb21-1043"><a href="#cb21-1043" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"""</span></span>
<span id="cb21-1044"><a href="#cb21-1044" aria-hidden="true" tabindex="-1"></a><span class="st">• Random Forest et Gradient Boosting PERFORMENT TRÈS BIEN</span></span>
<span id="cb21-1045"><a href="#cb21-1045" aria-hidden="true" tabindex="-1"></a><span class="st">• Pas besoin de feature scaling</span></span>
<span id="cb21-1046"><a href="#cb21-1046" aria-hidden="true" tabindex="-1"></a><span class="st">• Capturent relations non-linéaires complexes</span></span>
<span id="cb21-1047"><a href="#cb21-1047" aria-hidden="true" tabindex="-1"></a><span class="st">• MOINS INTERPRÉTABLES que les modèles linéaires</span></span>
<span id="cb21-1048"><a href="#cb21-1048" aria-hidden="true" tabindex="-1"></a><span class="st">• PLUS LENTS à entraîner</span></span>
<span id="cb21-1049"><a href="#cb21-1049" aria-hidden="true" tabindex="-1"></a><span class="st">• Risque de surapprentissage si pas bien régularisés</span></span>
<span id="cb21-1050"><a href="#cb21-1050" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-1051"><a href="#cb21-1051" aria-hidden="true" tabindex="-1"></a><span class="st">→ Recommandation: Utiliser pour compétitions Kaggle</span></span>
<span id="cb21-1052"><a href="#cb21-1052" aria-hidden="true" tabindex="-1"></a><span class="st">→ Pour production: Privilégier modèles plus simples si performance similaire</span></span>
<span id="cb21-1053"><a href="#cb21-1053" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span>)</span>
<span id="cb21-1054"><a href="#cb21-1054" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb21-1055"><a href="#cb21-1055" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb21-1056"><a href="#cb21-1056" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-1057"><a href="#cb21-1057" aria-hidden="true" tabindex="-1"></a><span class="fu">## Conclusion</span></span>
<span id="cb21-1058"><a href="#cb21-1058" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-1059"><a href="#cb21-1059" aria-hidden="true" tabindex="-1"></a><span class="fu">### Résumé des Points Clés</span></span>
<span id="cb21-1060"><a href="#cb21-1060" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-1061"><a href="#cb21-1061" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Prétraitement**:</span>
<span id="cb21-1062"><a href="#cb21-1062" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Standardisation cruciale pour modèles régularisés et SVR</span>
<span id="cb21-1063"><a href="#cb21-1063" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Split stratifié (si target stratifiable)</span>
<span id="cb21-1064"><a href="#cb21-1064" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Pas de data leakage</span>
<span id="cb21-1065"><a href="#cb21-1065" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-1066"><a href="#cb21-1066" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Modèles Linéaires**:</span>
<span id="cb21-1067"><a href="#cb21-1067" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>**Linear**: Simple, rapide, interprétable</span>
<span id="cb21-1068"><a href="#cb21-1068" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>**Ridge**: Régularisation L2, réduit overfitting</span>
<span id="cb21-1069"><a href="#cb21-1069" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>**Lasso**: Régularisation L1, sélection features</span>
<span id="cb21-1070"><a href="#cb21-1070" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>**ElasticNet**: Compromis L1+L2</span>
<span id="cb21-1071"><a href="#cb21-1071" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-1072"><a href="#cb21-1072" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**Modèles Non-Linéaires**:</span>
<span id="cb21-1073"><a href="#cb21-1073" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>**SVR**: Puissant mais lent, sensible aux hyperparamètres</span>
<span id="cb21-1074"><a href="#cb21-1074" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>**Random Forest**: Robuste, capture non-linéarités</span>
<span id="cb21-1075"><a href="#cb21-1075" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>**Gradient Boosting**: Souvent meilleure performance</span>
<span id="cb21-1076"><a href="#cb21-1076" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-1077"><a href="#cb21-1077" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>**Optimisation**:</span>
<span id="cb21-1078"><a href="#cb21-1078" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Utiliser *CV (RidgeCV, LassoCV) pour alpha automatique</span>
<span id="cb21-1079"><a href="#cb21-1079" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>GridSearch pour petit espace</span>
<span id="cb21-1080"><a href="#cb21-1080" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>RandomizedSearch pour grand espace</span>
<span id="cb21-1081"><a href="#cb21-1081" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-1082"><a href="#cb21-1082" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>**Évaluation**:</span>
<span id="cb21-1083"><a href="#cb21-1083" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Multiples métriques: MAE, RMSE, R²</span>
<span id="cb21-1084"><a href="#cb21-1084" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Visualisations: résidus, prédictions vs vraies valeurs</span>
<span id="cb21-1085"><a href="#cb21-1085" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Importance des features pour interprétation</span>
<span id="cb21-1086"><a href="#cb21-1086" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-1087"><a href="#cb21-1087" aria-hidden="true" tabindex="-1"></a><span class="fu">### Checklist de Validation</span></span>
<span id="cb21-1088"><a href="#cb21-1088" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-1089"><a href="#cb21-1089" aria-hidden="true" tabindex="-1"></a>Avant de soumettre votre travail:</span>
<span id="cb21-1090"><a href="#cb21-1090" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-1091"><a href="#cb21-1091" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="va">[ ]</span> Exploratory Data Analysis complète</span>
<span id="cb21-1092"><a href="#cb21-1092" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="va">[ ]</span> Prétraitement correct (train/test séparés)</span>
<span id="cb21-1093"><a href="#cb21-1093" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="va">[ ]</span> Au moins 4 modèles comparés</span>
<span id="cb21-1094"><a href="#cb21-1094" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="va">[ ]</span> Optimisation hyperparamètres avec CV</span>
<span id="cb21-1095"><a href="#cb21-1095" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="va">[ ]</span> Évaluation sur test set (une seule fois)</span>
<span id="cb21-1096"><a href="#cb21-1096" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="va">[ ]</span> Visualisations claires et annotées</span>
<span id="cb21-1097"><a href="#cb21-1097" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="va">[ ]</span> Interprétation des résultats</span>
<span id="cb21-1098"><a href="#cb21-1098" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="va">[ ]</span> Code commenté et organisé</span>
<span id="cb21-1099"><a href="#cb21-1099" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-1100"><a href="#cb21-1100" aria-hidden="true" tabindex="-1"></a><span class="fu">### Pour Aller Plus Loin</span></span>
<span id="cb21-1101"><a href="#cb21-1101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-1102"><a href="#cb21-1102" aria-hidden="true" tabindex="-1"></a>**Extensions possibles:**</span>
<span id="cb21-1103"><a href="#cb21-1103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-1104"><a href="#cb21-1104" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Feature Engineering**:</span>
<span id="cb21-1105"><a href="#cb21-1105" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Créer interactions entre features</span>
<span id="cb21-1106"><a href="#cb21-1106" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Transformations polynomiales</span>
<span id="cb21-1107"><a href="#cb21-1107" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Variables dummy pour catégorielles</span>
<span id="cb21-1108"><a href="#cb21-1108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-1109"><a href="#cb21-1109" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Pipeline Scikit-learn**:</span>
<span id="cb21-1110"><a href="#cb21-1110" aria-hidden="true" tabindex="-1"></a>   <span class="in">```python</span></span>
<span id="cb21-1111"><a href="#cb21-1111" aria-hidden="true" tabindex="-1"></a>   <span class="im">from</span> sklearn.pipeline <span class="im">import</span> Pipeline</span>
<span id="cb21-1112"><a href="#cb21-1112" aria-hidden="true" tabindex="-1"></a>   <span class="im">from</span> sklearn.compose <span class="im">import</span> ColumnTransformer</span>
<span id="cb21-1113"><a href="#cb21-1113" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb21-1114"><a href="#cb21-1114" aria-hidden="true" tabindex="-1"></a>   pipeline <span class="op">=</span> Pipeline([</span>
<span id="cb21-1115"><a href="#cb21-1115" aria-hidden="true" tabindex="-1"></a>       (<span class="st">'scaler'</span>, StandardScaler()),</span>
<span id="cb21-1116"><a href="#cb21-1116" aria-hidden="true" tabindex="-1"></a>       (<span class="st">'regressor'</span>, RidgeCV())</span>
<span id="cb21-1117"><a href="#cb21-1117" aria-hidden="true" tabindex="-1"></a>   ])</span>
<span id="cb21-1118"><a href="#cb21-1118" aria-hidden="true" tabindex="-1"></a>   <span class="in">```</span></span>
<span id="cb21-1119"><a href="#cb21-1119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-1120"><a href="#cb21-1120" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**Validation Croisée Temporelle**:</span>
<span id="cb21-1121"><a href="#cb21-1121" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Pour données chronologiques</span>
<span id="cb21-1122"><a href="#cb21-1122" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>TimeSeriesSplit au lieu de KFold</span>
<span id="cb21-1123"><a href="#cb21-1123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-1124"><a href="#cb21-1124" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>**Prédiction d'Intervalles**:</span>
<span id="cb21-1125"><a href="#cb21-1125" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Quantile Regression</span>
<span id="cb21-1126"><a href="#cb21-1126" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Bootstrap pour incertitude</span>
<span id="cb21-1127"><a href="#cb21-1127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-1128"><a href="#cb21-1128" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>**Déploiement**:</span>
<span id="cb21-1129"><a href="#cb21-1129" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Sauvegarde modèle (joblib)</span>
<span id="cb21-1130"><a href="#cb21-1130" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>API avec FastAPI/Flask</span>
<span id="cb21-1131"><a href="#cb21-1131" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Monitoring des performances</span>
<span id="cb21-1132"><a href="#cb21-1132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-1133"><a href="#cb21-1133" aria-hidden="true" tabindex="-1"></a>**Exercices supplémentaires:**</span>
<span id="cb21-1134"><a href="#cb21-1134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-1135"><a href="#cb21-1135" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Testez PolynomialFeatures + Regression</span>
<span id="cb21-1136"><a href="#cb21-1136" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Implémentez une validation croisée imbriquée</span>
<span id="cb21-1137"><a href="#cb21-1137" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Ajoutez XGBoost ou LightGBM à la comparaison</span>
<span id="cb21-1138"><a href="#cb21-1138" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>Créez un dashboard interactif avec Plotly</span>
<span id="cb21-1139"><a href="#cb21-1139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-1140"><a href="#cb21-1140" aria-hidden="true" tabindex="-1"></a>**Prochain TP:** Séries Temporelles ou Deep Learning</span>
<span id="cb21-1141"><a href="#cb21-1141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-1142"><a href="#cb21-1142" aria-hidden="true" tabindex="-1"></a>:::{.callout-tip}</span>
<span id="cb21-1143"><a href="#cb21-1143" aria-hidden="true" tabindex="-1"></a><span class="fu">## Astuce Finale</span></span>
<span id="cb21-1144"><a href="#cb21-1144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-1145"><a href="#cb21-1145" aria-hidden="true" tabindex="-1"></a>**La meilleure pratique:** Commencez toujours par un modèle simple (régression linéaire), puis complexifiez si nécessaire. Souvent, les modèles simples suffisent et sont plus faciles à maintenir en production!</span>
<span id="cb21-1146"><a href="#cb21-1146" aria-hidden="true" tabindex="-1"></a>:::</span>
</code></pre></div><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></div>
</div></div></div></div></div>
</div> <!-- /content -->




</body></html>