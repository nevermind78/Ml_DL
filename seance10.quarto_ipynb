{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# S√©ance 10: TP4 - Clustering & R√©duction de Dimension\n",
        "\n",
        "::: {.callout-note icon=false}\n",
        "## Informations de la s√©ance\n",
        "- **Type**: TP\n",
        "- **Dur√©e**: 2h\n",
        "- **Objectifs**: Obj9, Obj10\n",
        ":::\n",
        "\n",
        "## 1. Objectifs du TP\n",
        "\n",
        "Dans ce TP, vous allez :\n",
        "\n",
        "1. Appliquer diff√©rentes m√©thodes de clustering sur des datasets r√©els\n",
        "2. Utiliser des techniques pour d√©terminer le nombre optimal de clusters\n",
        "3. Visualiser et interpr√©ter les r√©sultats de clustering\n",
        "4. Utiliser PCA pour am√©liorer l'analyse et la visualisation\n",
        "5. Interpr√©ter les r√©sultats dans un contexte m√©tier\n",
        "\n",
        "## 2. Pr√©paration de l'Environnement"
      ],
      "id": "bbda039f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "#| eval: true\n",
        "\n",
        "# Importations n√©cessaires\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
        "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
        "from sklearn.manifold import TSNE\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "\n",
        "# Configuration des graphiques\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "%matplotlib inline\n",
        "\n",
        "print(\"‚úÖ Environnement pr√™t!\")"
      ],
      "id": "5ff9e59f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Dataset 1: Mall Customers Segmentation\n",
        "\n",
        "### 3.1 Chargement et Exploration"
      ],
      "id": "bde18fab"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "#| eval: true\n",
        "\n",
        "# Dataset: Caract√©ristiques de clients d'un centre commercial\n",
        "# Source: https://www.kaggle.com/vjchoudhary7/customer-segmentation-tutorial-in-python\n",
        "\n",
        "# Cr√©ation d'un dataset synth√©tique pour l'exemple\n",
        "np.random.seed(42)\n",
        "n_samples = 300\n",
        "\n",
        "# G√©n√©ration de donn√©es\n",
        "age = np.random.normal(35, 10, n_samples).clip(18, 70)\n",
        "annual_income = np.random.normal(60, 20, n_samples).clip(15, 140)\n",
        "spending_score = np.random.normal(50, 25, n_samples).clip(1, 100)\n",
        "\n",
        "# Cr√©ation de clusters artificiels\n",
        "# Cluster 1: Jeunes d√©pensiers\n",
        "mask1 = (age < 30) & (spending_score > 60)\n",
        "annual_income[mask1] = np.random.normal(40, 5, mask1.sum()).clip(30, 50)\n",
        "\n",
        "# Cluster 2: Seniors √©conomes\n",
        "mask2 = (age > 50) & (spending_score < 40)\n",
        "annual_income[mask2] = np.random.normal(70, 10, mask2.sum()).clip(60, 90)\n",
        "\n",
        "# DataFrame\n",
        "mall_data = pd.DataFrame({\n",
        "    'Age': age,\n",
        "    'Annual_Income_k': annual_income,\n",
        "    'Spending_Score': spending_score\n",
        "})\n",
        "\n",
        "# Affichage des premi√®res lignes\n",
        "print(\"üìä Dataset Mall Customers:\")\n",
        "print(f\"Dimensions: {mall_data.shape}\")\n",
        "print(\"\\nPremi√®res lignes:\")\n",
        "print(mall_data.head())\n",
        "print(\"\\nStatistiques descriptives:\")\n",
        "print(mall_data.describe())\n",
        "\n",
        "# Visualisation 3D\n",
        "fig = plt.figure(figsize=(12, 8))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "scatter = ax.scatter(mall_data['Age'], \n",
        "                     mall_data['Annual_Income_k'], \n",
        "                     mall_data['Spending_Score'],\n",
        "                     c='blue', alpha=0.6, edgecolors='w', s=50)\n",
        "ax.set_xlabel('Age')\n",
        "ax.set_ylabel('Revenu Annuel (k$)')\n",
        "ax.set_zlabel('Score de D√©pense')\n",
        "ax.set_title('Distribution des Clients - 3D')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "3e61cac8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Pr√©traitement des Donn√©es"
      ],
      "id": "0fb8e448"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "#| eval: true\n",
        "\n",
        "# Normalisation des donn√©es\n",
        "scaler = StandardScaler()\n",
        "mall_scaled = scaler.fit_transform(mall_data)\n",
        "\n",
        "print(\"‚úÖ Donn√©es normalis√©es (moyenne=0, √©cart-type=1)\")\n",
        "print(f\"Moyennes apr√®s normalisation: {mall_scaled.mean(axis=0).round(2)}\")\n",
        "print(f\"√âcarts-types apr√®s normalisation: {mall_scaled.std(axis=0).round(2)}\")"
      ],
      "id": "d002a065",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3 D√©termination du Nombre Optimal de Clusters"
      ],
      "id": "fc7b90b2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "#| eval: true\n",
        "\n",
        "# M√©thode du coude (Elbow Method)\n",
        "inertias = []\n",
        "silhouette_scores = []\n",
        "K_range = range(2, 11)\n",
        "\n",
        "for k in K_range:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    kmeans.fit(mall_scaled)\n",
        "    inertias.append(kmeans.inertia_)\n",
        "    \n",
        "    if k > 1:  # silhouette_score n√©cessite au moins 2 clusters\n",
        "        score = silhouette_score(mall_scaled, kmeans.labels_)\n",
        "        silhouette_scores.append(score)\n",
        "\n",
        "# Graphique Elbow Method\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Courbe d'inertie\n",
        "ax1.plot(K_range, inertias, 'bo-')\n",
        "ax1.set_xlabel('Nombre de clusters (k)')\n",
        "ax1.set_ylabel('Inertie')\n",
        "ax1.set_title('M√©thode du Coude')\n",
        "ax1.grid(True)\n",
        "\n",
        "# Score silhouette\n",
        "ax2.plot(range(2, 11), silhouette_scores, 'go-')\n",
        "ax2.set_xlabel('Nombre de clusters (k)')\n",
        "ax2.set_ylabel('Score Silhouette')\n",
        "ax2.set_title('Score Silhouette par k')\n",
        "ax2.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üìà Analyse:\")\n",
        "print(f\"Inertie pour k=3: {inertias[1]:.2f}\")\n",
        "print(f\"Inertie pour k=4: {inertias[2]:.2f}\")\n",
        "print(f\"Silhouette pour k=3: {silhouette_scores[1]:.3f}\")\n",
        "print(f\"Silhouette pour k=4: {silhouette_scores[2]:.3f}\")"
      ],
      "id": "46978a31",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.4 Application de k-means"
      ],
      "id": "128aa595"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "#| eval: true\n",
        "\n",
        "# Clustering avec k=3 (choisi d'apr√®s l'analyse)\n",
        "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
        "mall_data['Cluster_kmeans'] = kmeans.fit_predict(mall_scaled)\n",
        "\n",
        "# Affichage des r√©sultats\n",
        "print(\"üéØ R√©sultats du clustering k-means (k=3):\")\n",
        "print(f\"Taille des clusters: {np.bincount(mall_data['Cluster_kmeans'])}\")\n",
        "\n",
        "# Caract√©ristiques par cluster\n",
        "cluster_stats = mall_data.groupby('Cluster_kmeans').agg({\n",
        "    'Age': ['mean', 'std', 'count'],\n",
        "    'Annual_Income_k': ['mean', 'std'],\n",
        "    'Spending_Score': ['mean', 'std']\n",
        "}).round(2)\n",
        "\n",
        "print(\"\\nüìä Statistiques par cluster:\")\n",
        "print(cluster_stats)\n",
        "\n",
        "# Interpr√©tation m√©tier\n",
        "print(\"\\nüí° Interpr√©tation m√©tier:\")\n",
        "print(\"Cluster 0: Clients moyens (√¢ge et revenu moyens, d√©penses moyennes)\")\n",
        "print(\"Cluster 1: Jeunes d√©pensiers (√¢ge jeune, revenu mod√©r√©, d√©penses √©lev√©es)\")\n",
        "print(\"Cluster 2: Seniors √©conomes (√¢ge √©lev√©, revenu √©lev√©, d√©penses faibles)\")"
      ],
      "id": "7d22e177",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.5 Visualisation avec PCA"
      ],
      "id": "1efb512d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "#| eval: true\n",
        "\n",
        "# R√©duction √† 2D avec PCA pour visualisation\n",
        "pca = PCA(n_components=2)\n",
        "mall_pca = pca.fit_transform(mall_scaled)\n",
        "\n",
        "# Ajout des composantes principales au DataFrame\n",
        "mall_data['PCA1'] = mall_pca[:, 0]\n",
        "mall_data['PCA2'] = mall_pca[:, 1]\n",
        "\n",
        "print(f\"üìâ Variance expliqu√©e par PCA: {pca.explained_variance_ratio_.round(3)}\")\n",
        "print(f\"üìä Variance totale expliqu√©e: {sum(pca.explained_variance_ratio_):.2%}\")\n",
        "\n",
        "# Visualisation des clusters avec PCA\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "scatter = plt.scatter(mall_data['PCA1'], mall_data['PCA2'], \n",
        "                     c=mall_data['Cluster_kmeans'], cmap='viridis', \n",
        "                     alpha=0.7, s=50)\n",
        "plt.xlabel(f'Premi√®re Composante Principale ({pca.explained_variance_ratio_[0]:.1%})')\n",
        "plt.ylabel(f'Deuxi√®me Composante Principale ({pca.explained_variance_ratio_[1]:.1%})')\n",
        "plt.title('Clusters k-means visualis√©s avec PCA')\n",
        "plt.colorbar(scatter, label='Cluster')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Visualisation t-SNE (comparaison)\n",
        "plt.subplot(1, 2, 2)\n",
        "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
        "mall_tsne = tsne.fit_transform(mall_scaled)\n",
        "\n",
        "plt.scatter(mall_tsne[:, 0], mall_tsne[:, 1], \n",
        "           c=mall_data['Cluster_kmeans'], cmap='viridis', \n",
        "           alpha=0.7, s=50)\n",
        "plt.xlabel('t-SNE 1')\n",
        "plt.ylabel('t-SNE 2')\n",
        "plt.title('Clusters k-means visualis√©s avec t-SNE')\n",
        "plt.colorbar(scatter, label='Cluster')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "14a30691",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Dataset 2: Clustering Hi√©rarchique sur Donn√©es de Fleurs\n",
        "\n",
        "### 4.1 Chargement et Exploration"
      ],
      "id": "b6da0fc5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "#| eval: true\n",
        "\n",
        "# Chargement du dataset Iris (sans utiliser les labels pour l'apprentissage non supervis√©)\n",
        "iris = datasets.load_iris()\n",
        "iris_data = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "\n",
        "print(\"üå∏ Dataset Iris (sans les labels):\")\n",
        "print(f\"Dimensions: {iris_data.shape}\")\n",
        "print(\"\\nDescription:\")\n",
        "print(iris_data.describe())\n",
        "\n",
        "# Matrice de corr√©lation\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(iris_data.corr(), annot=True, cmap='coolwarm', center=0)\n",
        "plt.title('Matrice de Corr√©lation - Dataset Iris')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "9052afb8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 Clustering Hi√©rarchique"
      ],
      "id": "1f672db9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "#| eval: true\n",
        "\n",
        "# Normalisation\n",
        "iris_scaled = StandardScaler().fit_transform(iris_data)\n",
        "\n",
        "# Clustering hi√©rarchique agglom√©ratif\n",
        "agg_clustering = AgglomerativeClustering(n_clusters=3, linkage='ward')\n",
        "iris_labels = agg_clustering.fit_predict(iris_scaled)\n",
        "\n",
        "# Dendrogramme\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Sous-√©chantillon pour le dendrogramme (pour lisibilit√©)\n",
        "linkage_matrix = linkage(iris_scaled[:50], method='ward')\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "dendrogram(linkage_matrix, truncate_mode='level', p=5)\n",
        "plt.xlabel('Indices des √©chantillons')\n",
        "plt.ylabel('Distance')\n",
        "plt.title('Dendrogramme - Clustering Hi√©rarchique')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Visualisation avec PCA\n",
        "plt.subplot(1, 2, 2)\n",
        "iris_pca = PCA(n_components=2).fit_transform(iris_scaled)\n",
        "plt.scatter(iris_pca[:, 0], iris_pca[:, 1], c=iris_labels, cmap='tab20c', s=50)\n",
        "plt.xlabel('Premi√®re Composante Principale')\n",
        "plt.ylabel('Deuxi√®me Composante Principale')\n",
        "plt.title('Clusters Hi√©rarchiques - Visualisation PCA')\n",
        "plt.colorbar(label='Cluster')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# √âvaluation\n",
        "print(\"üìä √âvaluation du clustering hi√©rarchique:\")\n",
        "print(f\"Silhouette Score: {silhouette_score(iris_scaled, iris_labels):.3f}\")\n",
        "print(f\"Calinski-Harabasz Score: {calinski_harabasz_score(iris_scaled, iris_labels):.2f}\")\n",
        "print(f\"Davies-Bouldin Score: {davies_bouldin_score(iris_scaled, iris_labels):.3f}\")"
      ],
      "id": "4bc01192",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Comparaison des M√©thodes de Clustering"
      ],
      "id": "d5c3f7d6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "#| eval: true\n",
        "\n",
        "# Test de diff√©rentes m√©thodes sur le dataset Iris\n",
        "methods = {\n",
        "    'K-means (k=3)': KMeans(n_clusters=3, random_state=42, n_init=10),\n",
        "    'DBSCAN': DBSCAN(eps=0.5, min_samples=5),\n",
        "    'Agglomerative (Ward)': AgglomerativeClustering(n_clusters=3, linkage='ward'),\n",
        "    'Agglomerative (Average)': AgglomerativeClustering(n_clusters=3, linkage='average')\n",
        "}\n",
        "\n",
        "results = []\n",
        "\n",
        "for name, model in methods.items():\n",
        "    labels = model.fit_predict(iris_scaled)\n",
        "    \n",
        "    if len(set(labels)) > 1:  # Au moins 2 clusters\n",
        "        silhouette = silhouette_score(iris_scaled, labels)\n",
        "        n_clusters = len(set(labels))\n",
        "    else:\n",
        "        silhouette = np.nan\n",
        "        n_clusters = len(set(labels))\n",
        "    \n",
        "    results.append({\n",
        "        'M√©thode': name,\n",
        "        'Nombre de clusters': n_clusters,\n",
        "        'Silhouette Score': silhouette\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"üìã Comparaison des m√©thodes de clustering:\")\n",
        "print(results_df.to_string(index=False))"
      ],
      "id": "cff4ca86",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Exercice Pratique Guid√©\n",
        "\n",
        "::: {.callout-warning icon=false}\n",
        "## Exercice 1: Dataset Wine\n",
        "1. Chargez le dataset Wine de scikit-learn (`datasets.load_wine()`)\n",
        "2. Normalisez les donn√©es\n",
        "3. D√©terminez le nombre optimal de clusters avec la m√©thode du coude et le silhouette score\n",
        "4. Appliquez k-means avec le k optimal\n",
        "5. Visualisez les clusters avec PCA\n",
        "6. Interpr√©tez les r√©sultats en termes de caract√©ristiques des vins\n",
        ":::\n",
        "::: {.callout-note collapse=\"true\"}\n",
        "### Solution Exercice 1"
      ],
      "id": "cfb820a0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "#| eval: true\n",
        "\n",
        "print(\"üç∑ Dataset Wine - Analyse compl√®te\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 1. Chargement\n",
        "wine = datasets.load_wine()\n",
        "wine_data = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
        "\n",
        "print(f\"\\nüìä Dimensions: {wine_data.shape}\")\n",
        "print(f\"Nombre de classes originales: {len(np.unique(wine.target))}\")\n",
        "print(f\"\\nCaract√©ristiques: {wine.feature_names}\")\n",
        "\n",
        "# Exploration initiale\n",
        "print(\"\\nüìà Statistiques descriptives:\")\n",
        "print(wine_data.describe())\n",
        "\n",
        "# 2. Normalisation\n",
        "wine_scaled = StandardScaler().fit_transform(wine_data)\n",
        "print(\"\\n‚úÖ Donn√©es normalis√©es\")\n",
        "\n",
        "# 3. D√©termination du nombre optimal de clusters\n",
        "print(\"\\nüîç D√©termination du nombre optimal de clusters...\")\n",
        "\n",
        "inertias_wine = []\n",
        "silhouette_scores_wine = []\n",
        "K_range = range(2, 11)\n",
        "\n",
        "for k in K_range:\n",
        "    kmeans_wine = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    kmeans_wine.fit(wine_scaled)\n",
        "    inertias_wine.append(kmeans_wine.inertia_)\n",
        "    \n",
        "    score = silhouette_score(wine_scaled, kmeans_wine.labels_)\n",
        "    silhouette_scores_wine.append(score)\n",
        "\n",
        "# Visualisation\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Courbe d'inertie\n",
        "ax1.plot(K_range, inertias_wine, 'bo-', linewidth=2, markersize=8)\n",
        "ax1.set_xlabel('Nombre de clusters (k)', fontsize=12)\n",
        "ax1.set_ylabel('Inertie', fontsize=12)\n",
        "ax1.set_title('M√©thode du Coude - Dataset Wine', fontsize=14, fontweight='bold')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.axvline(x=3, color='r', linestyle='--', alpha=0.5, label='k optimal sugg√©r√©')\n",
        "ax1.legend()\n",
        "\n",
        "# Score silhouette\n",
        "ax2.plot(K_range, silhouette_scores_wine, 'go-', linewidth=2, markersize=8)\n",
        "ax2.set_xlabel('Nombre de clusters (k)', fontsize=12)\n",
        "ax2.set_ylabel('Score Silhouette', fontsize=12)\n",
        "ax2.set_title('Score Silhouette - Dataset Wine', fontsize=14, fontweight='bold')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "ax2.axvline(x=3, color='r', linestyle='--', alpha=0.5, label='k optimal sugg√©r√©')\n",
        "ax2.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Analyse des scores\n",
        "print(\"\\nüìä Analyse des m√©triques:\")\n",
        "for i, k in enumerate(K_range):\n",
        "    print(f\"k={k}: Inertie={inertias_wine[i]:.2f}, Silhouette={silhouette_scores_wine[i]:.3f}\")\n",
        "\n",
        "# Identification du k optimal\n",
        "optimal_k = K_range[np.argmax(silhouette_scores_wine)]\n",
        "print(f\"\\nüéØ Nombre optimal de clusters sugg√©r√©: k={optimal_k}\")\n",
        "\n",
        "# 4. Application de k-means avec k optimal\n",
        "kmeans_final = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
        "wine_clusters = kmeans_final.fit_predict(wine_scaled)\n",
        "\n",
        "print(f\"\\n‚úÖ Clustering effectu√© avec k={optimal_k}\")\n",
        "print(f\"Taille des clusters: {np.bincount(wine_clusters)}\")\n",
        "\n",
        "# Ajout des clusters au DataFrame\n",
        "wine_data['Cluster'] = wine_clusters\n",
        "\n",
        "# Statistiques par cluster\n",
        "print(\"\\nüìä Caract√©ristiques moyennes par cluster:\")\n",
        "cluster_profiles = wine_data.groupby('Cluster').mean()\n",
        "print(cluster_profiles.round(2))\n",
        "\n",
        "# 5. Visualisation avec PCA\n",
        "pca_wine = PCA(n_components=2)\n",
        "wine_pca = pca_wine.fit_transform(wine_scaled)\n",
        "\n",
        "print(f\"\\nüìâ Variance expliqu√©e par PCA:\")\n",
        "print(f\"PC1: {pca_wine.explained_variance_ratio_[0]:.2%}\")\n",
        "print(f\"PC2: {pca_wine.explained_variance_ratio_[1]:.2%}\")\n",
        "print(f\"Total: {sum(pca_wine.explained_variance_ratio_):.2%}\")\n",
        "\n",
        "# Visualisation\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Clusters identifi√©s\n",
        "scatter1 = axes[0].scatter(wine_pca[:, 0], wine_pca[:, 1], \n",
        "                          c=wine_clusters, cmap='viridis', \n",
        "                          s=100, alpha=0.7, edgecolors='black', linewidth=0.5)\n",
        "axes[0].set_xlabel(f'PC1 ({pca_wine.explained_variance_ratio_[0]:.1%})', fontsize=12)\n",
        "axes[0].set_ylabel(f'PC2 ({pca_wine.explained_variance_ratio_[1]:.1%})', fontsize=12)\n",
        "axes[0].set_title('Clusters identifi√©s - k-means', fontsize=14, fontweight='bold')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "plt.colorbar(scatter1, ax=axes[0], label='Cluster')\n",
        "\n",
        "# Vraies classes (pour comparaison)\n",
        "scatter2 = axes[1].scatter(wine_pca[:, 0], wine_pca[:, 1], \n",
        "                          c=wine.target, cmap='plasma', \n",
        "                          s=100, alpha=0.7, edgecolors='black', linewidth=0.5)\n",
        "axes[1].set_xlabel(f'PC1 ({pca_wine.explained_variance_ratio_[0]:.1%})', fontsize=12)\n",
        "axes[1].set_ylabel(f'PC2 ({pca_wine.explained_variance_ratio_[1]:.1%})', fontsize=12)\n",
        "axes[1].set_title('Vraies classes (r√©f√©rence)', fontsize=14, fontweight='bold')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "plt.colorbar(scatter2, ax=axes[1], label='Classe r√©elle')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 6. Interpr√©tation en termes de caract√©ristiques des vins\n",
        "print(\"\\nüçá Interpr√©tation m√©tier - Profils des clusters de vins:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for cluster_id in range(optimal_k):\n",
        "    cluster_mask = wine_data['Cluster'] == cluster_id\n",
        "    cluster_subset = wine_data[cluster_mask]\n",
        "    \n",
        "    print(f\"\\nüç∑ CLUSTER {cluster_id} ({cluster_mask.sum()} vins):\")\n",
        "    print(\"-\" * 60)\n",
        "    \n",
        "    # Caract√©ristiques principales\n",
        "    top_features = cluster_profiles.loc[cluster_id].nlargest(5)\n",
        "    print(f\"Caract√©ristiques dominantes:\")\n",
        "    for feat, val in top_features.items():\n",
        "        if feat != 'Cluster':\n",
        "            print(f\"  ‚Ä¢ {feat}: {val:.2f}\")\n",
        "    \n",
        "    # Interpr√©tation qualitative\n",
        "    alcohol = cluster_profiles.loc[cluster_id, 'alcohol']\n",
        "    color_intensity = cluster_profiles.loc[cluster_id, 'color_intensity']\n",
        "    flavanoids = cluster_profiles.loc[cluster_id, 'flavanoids']\n",
        "    \n",
        "    print(f\"\\nProfil g√©n√©ral:\")\n",
        "    if alcohol > 13:\n",
        "        print(f\"  ‚Ä¢ Teneur en alcool √©lev√©e ({alcohol:.1f}%)\")\n",
        "    elif alcohol < 12:\n",
        "        print(f\"  ‚Ä¢ Teneur en alcool mod√©r√©e ({alcohol:.1f}%)\")\n",
        "    else:\n",
        "        print(f\"  ‚Ä¢ Teneur en alcool moyenne ({alcohol:.1f}%)\")\n",
        "    \n",
        "    if color_intensity > 5:\n",
        "        print(f\"  ‚Ä¢ Couleur intense ({color_intensity:.1f})\")\n",
        "    else:\n",
        "        print(f\"  ‚Ä¢ Couleur l√©g√®re ({color_intensity:.1f})\")\n",
        "    \n",
        "    if flavanoids > 2.5:\n",
        "        print(f\"  ‚Ä¢ Riche en flavono√Ødes ({flavanoids:.1f})\")\n",
        "    else:\n",
        "        print(f\"  ‚Ä¢ Pauvre en flavono√Ødes ({flavanoids:.1f})\")\n",
        "\n",
        "# M√©triques de qualit√© du clustering\n",
        "print(\"\\nüìä √âvaluation de la qualit√© du clustering:\")\n",
        "print(f\"Silhouette Score: {silhouette_score(wine_scaled, wine_clusters):.3f}\")\n",
        "print(f\"Calinski-Harabasz Score: {calinski_harabasz_score(wine_scaled, wine_clusters):.2f}\")\n",
        "print(f\"Davies-Bouldin Score: {davies_bouldin_score(wine_scaled, wine_clusters):.3f}\")\n",
        "print(\"\\nüí° Note: Un bon silhouette score > 0.5, plus il est proche de 1, mieux c'est\")"
      ],
      "id": "affd677c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "::: {.callout-warning icon=true}\n",
        "## Exercice 2: Clustering DBSCAN\n",
        "1. Sur le dataset Mall Customers, testez DBSCAN avec diff√©rents param√®tres\n",
        "2. Comparez les r√©sultats avec k-means\n",
        "3. Visualisez les clusters obtenus\n",
        "4. Identifiez les points consid√©r√©s comme bruit (-1)\n",
        "5. Analysez les avantages/inconv√©nients de DBSCAN pour ce dataset\n",
        ":::\n",
        "\n",
        "::: {.callout-note collapse=\"true\"}\n",
        "### Solution Exercice 2"
      ],
      "id": "227bda23"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "#| eval: true\n",
        "\n",
        "print(\"üõçÔ∏è Clustering DBSCAN sur Mall Customers\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Test de diff√©rents param√®tres DBSCAN\n",
        "eps_values = [0.3, 0.5, 0.7, 1.0]\n",
        "min_samples_values = [3, 5, 10]\n",
        "\n",
        "print(\"\\nüîç Test de diff√©rentes configurations DBSCAN:\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "best_config = {'eps': None, 'min_samples': None, 'score': -1, 'n_clusters': 0}\n",
        "dbscan_results = []\n",
        "\n",
        "for eps in eps_values:\n",
        "    for min_samples in min_samples_values:\n",
        "        dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
        "        labels = dbscan.fit_predict(mall_scaled)\n",
        "        \n",
        "        n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
        "        n_noise = list(labels).count(-1)\n",
        "        \n",
        "        # Calcul du silhouette score (si au moins 2 clusters)\n",
        "        if n_clusters >= 2:\n",
        "            # Exclure les points de bruit pour le calcul du score\n",
        "            mask = labels != -1\n",
        "            if mask.sum() > 0:\n",
        "                score = silhouette_score(mall_scaled[mask], labels[mask])\n",
        "            else:\n",
        "                score = -1\n",
        "        else:\n",
        "            score = -1\n",
        "        \n",
        "        dbscan_results.append({\n",
        "            'eps': eps,\n",
        "            'min_samples': min_samples,\n",
        "            'n_clusters': n_clusters,\n",
        "            'n_noise': n_noise,\n",
        "            'silhouette': score\n",
        "        })\n",
        "        \n",
        "        print(f\"eps={eps}, min_samples={min_samples}: \"\n",
        "              f\"{n_clusters} clusters, {n_noise} points de bruit, \"\n",
        "              f\"silhouette={score:.3f}\")\n",
        "        \n",
        "        if score > best_config['score'] and n_clusters > 0:\n",
        "            best_config = {\n",
        "                'eps': eps,\n",
        "                'min_samples': min_samples,\n",
        "                'score': score,\n",
        "                'n_clusters': n_clusters,\n",
        "                'labels': labels\n",
        "            }\n",
        "\n",
        "print(f\"\\nüéØ Meilleure configuration: eps={best_config['eps']}, \"\n",
        "      f\"min_samples={best_config['min_samples']}\")\n",
        "\n",
        "# Application de DBSCAN avec les meilleurs param√®tres\n",
        "dbscan_best = DBSCAN(eps=best_config['eps'], min_samples=best_config['min_samples'])\n",
        "mall_data['Cluster_DBSCAN'] = dbscan_best.fit_predict(mall_scaled)\n",
        "\n",
        "# Analyse des r√©sultats\n",
        "n_clusters_dbscan = len(set(mall_data['Cluster_DBSCAN'])) - (1 if -1 in mall_data['Cluster_DBSCAN'].values else 0)\n",
        "n_noise_dbscan = (mall_data['Cluster_DBSCAN'] == -1).sum()\n",
        "\n",
        "print(f\"\\nüìä R√©sultats DBSCAN:\")\n",
        "print(f\"Nombre de clusters: {n_clusters_dbscan}\")\n",
        "print(f\"Nombre de points de bruit: {n_noise_dbscan} ({n_noise_dbscan/len(mall_data)*100:.1f}%)\")\n",
        "\n",
        "# Statistiques par cluster (sans le bruit)\n",
        "print(\"\\nüìä Taille des clusters (hors bruit):\")\n",
        "cluster_counts = mall_data[mall_data['Cluster_DBSCAN'] != -1]['Cluster_DBSCAN'].value_counts().sort_index()\n",
        "for cluster_id, count in cluster_counts.items():\n",
        "    print(f\"Cluster {cluster_id}: {count} clients\")\n",
        "\n",
        "# Comparaison avec k-means\n",
        "print(\"\\n‚öñÔ∏è Comparaison K-means vs DBSCAN:\")\n",
        "print(\"-\" * 60)\n",
        "print(f\"K-means:\")\n",
        "print(f\"  ‚Ä¢ Nombre de clusters: 3 (pr√©d√©fini)\")\n",
        "print(f\"  ‚Ä¢ Silhouette score: {silhouette_score(mall_scaled, mall_data['Cluster_kmeans']):.3f}\")\n",
        "print(f\"  ‚Ä¢ Tous les points assign√©s\")\n",
        "\n",
        "if n_clusters_dbscan >= 2:\n",
        "    mask_dbscan = mall_data['Cluster_DBSCAN'] != -1\n",
        "    score_dbscan = silhouette_score(mall_scaled[mask_dbscan], \n",
        "                                    mall_data.loc[mask_dbscan, 'Cluster_DBSCAN'])\n",
        "    print(f\"\\nDBSCAN:\")\n",
        "    print(f\"  ‚Ä¢ Nombre de clusters: {n_clusters_dbscan} (automatique)\")\n",
        "    print(f\"  ‚Ä¢ Silhouette score: {score_dbscan:.3f}\")\n",
        "    print(f\"  ‚Ä¢ Points de bruit: {n_noise_dbscan}\")\n",
        "\n",
        "# Visualisation comparative\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "# K-means - 2D (Age vs Income)\n",
        "ax1 = axes[0, 0]\n",
        "scatter1 = ax1.scatter(mall_data['Age'], mall_data['Annual_Income_k'],\n",
        "                      c=mall_data['Cluster_kmeans'], cmap='viridis',\n",
        "                      s=100, alpha=0.6, edgecolors='black', linewidth=0.5)\n",
        "ax1.set_xlabel('Age', fontsize=12)\n",
        "ax1.set_ylabel('Revenu Annuel (k$)', fontsize=12)\n",
        "ax1.set_title('K-means: Age vs Revenu', fontsize=14, fontweight='bold')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "plt.colorbar(scatter1, ax=ax1, label='Cluster')\n",
        "\n",
        "# DBSCAN - 2D (Age vs Income)\n",
        "ax2 = axes[0, 1]\n",
        "scatter2 = ax2.scatter(mall_data['Age'], mall_data['Annual_Income_k'],\n",
        "                      c=mall_data['Cluster_DBSCAN'], cmap='viridis',\n",
        "                      s=100, alpha=0.6, edgecolors='black', linewidth=0.5)\n",
        "ax2.set_xlabel('Age', fontsize=12)\n",
        "ax2.set_ylabel('Revenu Annuel (k$)', fontsize=12)\n",
        "ax2.set_title('DBSCAN: Age vs Revenu (points noirs = bruit)', fontsize=14, fontweight='bold')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "plt.colorbar(scatter2, ax=ax2, label='Cluster')\n",
        "\n",
        "# K-means - PCA\n",
        "ax3 = axes[1, 0]\n",
        "scatter3 = ax3.scatter(mall_data['PCA1'], mall_data['PCA2'],\n",
        "                      c=mall_data['Cluster_kmeans'], cmap='viridis',\n",
        "                      s=100, alpha=0.6, edgecolors='black', linewidth=0.5)\n",
        "ax3.set_xlabel('PCA1', fontsize=12)\n",
        "ax3.set_ylabel('PCA2', fontsize=12)\n",
        "ax3.set_title('K-means: Visualisation PCA', fontsize=14, fontweight='bold')\n",
        "ax3.grid(True, alpha=0.3)\n",
        "plt.colorbar(scatter3, ax=ax3, label='Cluster')\n",
        "\n",
        "# DBSCAN - PCA\n",
        "ax4 = axes[1, 1]\n",
        "scatter4 = ax4.scatter(mall_data['PCA1'], mall_data['PCA2'],\n",
        "                      c=mall_data['Cluster_DBSCAN'], cmap='viridis',\n",
        "                      s=100, alpha=0.6, edgecolors='black', linewidth=0.5)\n",
        "ax4.set_xlabel('PCA1', fontsize=12)\n",
        "ax4.set_ylabel('PCA2', fontsize=12)\n",
        "ax4.set_title('DBSCAN: Visualisation PCA (points noirs = bruit)', fontsize=14, fontweight='bold')\n",
        "ax4.grid(True, alpha=0.3)\n",
        "plt.colorbar(scatter4, ax=ax4, label='Cluster')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Analyse des points de bruit\n",
        "if n_noise_dbscan > 0:\n",
        "    noise_points = mall_data[mall_data['Cluster_DBSCAN'] == -1]\n",
        "    print(\"\\nüîç Analyse des points de bruit (outliers):\")\n",
        "    print(\"-\" * 60)\n",
        "    print(f\"Nombre: {len(noise_points)}\")\n",
        "    print(\"\\nCaract√©ristiques moyennes des outliers:\")\n",
        "    print(noise_points[['Age', 'Annual_Income_k', 'Spending_Score']].describe())\n",
        "    \n",
        "    print(\"\\nüí° Interpr√©tation:\")\n",
        "    print(\"Les points de bruit repr√©sentent des clients atypiques qui ne correspondent\")\n",
        "    print(\"√† aucun segment majeur - ils peuvent √™tre des cas particuliers √† traiter\")\n",
        "    print(\"individuellement en marketing.\")\n",
        "\n",
        "# Profils des clusters DBSCAN\n",
        "print(\"\\nüìä Profils des clusters DBSCAN:\")\n",
        "print(\"-\" * 60)\n",
        "for cluster_id in sorted(mall_data['Cluster_DBSCAN'].unique()):\n",
        "    if cluster_id != -1:\n",
        "        cluster_data = mall_data[mall_data['Cluster_DBSCAN'] == cluster_id]\n",
        "        print(f\"\\nCluster {cluster_id} ({len(cluster_data)} clients):\")\n",
        "        print(f\"  ‚Ä¢ Age moyen: {cluster_data['Age'].mean():.1f} ans\")\n",
        "        print(f\"  ‚Ä¢ Revenu moyen: {cluster_data['Annual_Income_k'].mean():.1f}k$\")\n",
        "        print(f\"  ‚Ä¢ Score de d√©pense moyen: {cluster_data['Spending_Score'].mean():.1f}\")\n",
        "\n",
        "# Avantages et inconv√©nients\n",
        "print(\"\\n‚úÖ Avantages de DBSCAN pour ce dataset:\")\n",
        "print(\"-\" * 60)\n",
        "print(\"1. D√©tection automatique du nombre de clusters\")\n",
        "print(\"2. Identification des outliers (points atypiques)\")\n",
        "print(\"3. Capacit√© √† d√©tecter des clusters de formes non-sph√©riques\")\n",
        "print(\"4. Robustesse face au bruit dans les donn√©es\")\n",
        "\n",
        "print(\"\\n‚ùå Inconv√©nients de DBSCAN pour ce dataset:\")\n",
        "print(\"-\" * 60)\n",
        "print(\"1. Sensibilit√© aux param√®tres eps et min_samples\")\n",
        "print(\"2. Difficult√© avec des clusters de densit√©s variables\")\n",
        "print(\"3. Certains clients sont exclus (marqu√©s comme bruit)\")\n",
        "print(\"4. Moins intuitif pour la segmentation marketing traditionnelle\")\n",
        "\n",
        "print(\"\\nüéØ Recommandation:\")\n",
        "print(\"Pour ce dataset de segmentation client:\")\n",
        "print(\"‚Ä¢ K-means est pr√©f√©rable si on veut assigner TOUS les clients √† un segment\")\n",
        "print(\"‚Ä¢ DBSCAN est utile si on veut identifier les clients atypiques s√©par√©ment\")\n",
        "print(\"‚Ä¢ Une approche hybride pourrait combiner les deux m√©thodes\")"
      ],
      "id": "400be51e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "## 7. Questions de R√©flexion\n",
        "\n",
        "::: {.callout-note icon=false}\n",
        "## Question 1\n",
        "Dans l'analyse des clients du centre commercial, quelles actions marketing pourriez-vous recommander pour chaque segment identifi√© ?\n",
        ":::\n",
        "\n",
        "::: {.callout-note collapse=\"true\"}\n",
        "## R√©ponse Question 1\n",
        "\n",
        "**Analyse des segments et recommandations marketing:**\n",
        "\n",
        "**Cluster 0 - Clients Moyens (Segment Mainstream)**\n",
        "\n",
        "- **Profil**: √Çge moyen (30-45 ans), revenu moyen (50-70k$), d√©penses mod√©r√©es\n",
        "- **Taille estim√©e**: ~40% de la client√®le\n",
        "- **Actions recommand√©es**:\n",
        "  - Programmes de fid√©lit√© avec r√©compenses progressives\n",
        "  - Promotions r√©guli√®res sur des produits de consommation courante\n",
        "  - Communication √©quilibr√©e entre qualit√© et prix\n",
        "  - Campagnes saisonni√®res cibl√©es\n",
        "  - Cross-selling sur produits compl√©mentaires\n",
        "\n",
        "**Cluster 1 - Jeunes D√©pensiers (Segment Premium Jeune)**\n",
        "\n",
        "- **Profil**: Jeunes (18-30 ans), revenu mod√©r√© (30-50k$), score de d√©pense √©lev√© (>60)\n",
        "- **Taille estim√©e**: ~25% de la client√®le\n",
        "- **Actions recommand√©es**:\n",
        "  - Marketing digital et r√©seaux sociaux intensif\n",
        "  - Lancements de nouveaux produits tendance\n",
        "  - √âv√©nements exclusifs et exp√©riences immersives\n",
        "  - Programmes de parrainage avec r√©compenses imm√©diates\n",
        "  - Offres \"acheter maintenant, payer plus tard\"\n",
        "  - Collaboration avec influenceurs\n",
        "  - Collections capsules et √©ditions limit√©es\n",
        "\n",
        "**Cluster 2 - Seniors √âconomes (Segment Conservateur Ais√©)**\n",
        "\n",
        "- **Profil**: √Çge √©lev√© (>50 ans), revenu √©lev√© (70-90k$), d√©penses faibles (<40)\n",
        "- **Taille estim√©e**: ~35% de la client√®le\n",
        "- **Actions recommand√©es**:\n",
        "  - Mise en avant du rapport qualit√©-prix\n",
        "  - Service client premium et personnalis√©\n",
        "  - Programmes de points avec avantages √† long terme\n",
        "  - Communication par email et courrier traditionnel\n",
        "  - Offres exclusives sur des produits durables et de qualit√©\n",
        "  - Conseils personnalis√©s et service apr√®s-vente renforc√©\n",
        "  - √âv√©nements VIP en petit comit√©\n",
        "\n",
        "**Strat√©gie globale recommand√©e**:\n",
        "\n",
        "- Personnalisation des campagnes par segment\n",
        "- A/B testing des messages marketing par cluster\n",
        "- Optimisation de l'assortiment produit par profil\n",
        "- Formation du personnel √† la reconnaissance des profils\n",
        "- Mesure du ROI par segment pour allocation budg√©taire optimale\n",
        ":::\n",
        "\n",
        "::: {.callout-note icon=false}\n",
        "## Question 2\n",
        "Quand choisiriez-vous PCA vs t-SNE pour la visualisation des clusters ? Justifiez avec des exemples concrets.\n",
        ":::\n",
        "\n",
        "::: {.callout-note collapse=\"true\"}\n",
        "## R√©ponse Question 2\n",
        "\n",
        "**Comparaison PCA vs t-SNE pour la visualisation de clusters:**\n",
        "\n",
        "**Choisir PCA quand:**\n",
        "\n",
        "1. **Interpr√©tabilit√© requise**\n",
        "\n",
        "   - Exemple: Rapport pour la direction n√©cessitant de comprendre quelles variables contribuent aux axes\n",
        "   - Les composantes principales sont des combinaisons lin√©aires interpr√©tables\n",
        "   - On peut expliquer \"PC1 repr√©sente 45% de la variance et combine principalement le revenu et l'√©ducation\"\n",
        "\n",
        "2. **Analyse de la variance**\n",
        "\n",
        "   - Exemple: D√©terminer combien de dimensions conserver\n",
        "   - Permet de quantifier l'information perdue: \"2 composantes capturent 78% de la variance\"\n",
        "   - Utile pour la r√©duction de dimension avant clustering\n",
        "\n",
        "3. **Datasets de taille moyenne √† grande**\n",
        "\n",
        "   - Exemple: 10,000+ observations\n",
        "   - PCA est beaucoup plus rapide (complexit√© lin√©aire vs quadratique)\n",
        "   - Scalabilit√© pour les applications en production\n",
        "\n",
        "4. **Stabilit√© et reproductibilit√©**\n",
        "\n",
        "   - Exemple: Dashboards actualis√©s quotidiennement\n",
        "   - PCA donne toujours le m√™me r√©sultat (d√©terministe)\n",
        "   - t-SNE peut varier √† chaque ex√©cution\n",
        "\n",
        "5. **Relations lin√©aires √† pr√©server**\n",
        "\n",
        "   - Exemple: Variables √©conomiques corr√©l√©es lin√©airement\n",
        "   - PCA pr√©serve les distances globales\n",
        "   - Meilleur pour comprendre la structure g√©n√©rale\n",
        "\n",
        "**Choisir t-SNE quand:**\n",
        "\n",
        "1. **Visualisation pure pour exploration**\n",
        "   - Exemple: Premi√®re exploration d'un dataset complexe\n",
        "   - R√©v√®le des structures non-lin√©aires cach√©es\n",
        "   - Meilleur pour \"voir\" les groupements naturels\n",
        "\n",
        "2. **Structures non-lin√©aires complexes**\n",
        "\n",
        "   - Exemple: Donn√©es d'images, de textes, ou g√©nomiques\n",
        "   - t-SNE peut \"d√©rouler\" des manifolds non-lin√©aires\n",
        "   - Cas o√π PCA montre un nuage de points uniforme\n",
        "\n",
        "3. **Pr√©servation des voisinages locaux**\n",
        "\n",
        "   - Exemple: Analyse de sous-populations fines\n",
        "   - t-SNE garde ensemble les points similaires\n",
        "   - Meilleur pour identifier des micro-clusters\n",
        "\n",
        "4. **Datasets de petite √† moyenne taille**\n",
        "\n",
        "   - Exemple: <5,000 observations\n",
        "   - Le co√ªt computationnel reste acceptable\n",
        "   - Permet d'optimiser les hyperparam√®tres (perplexity)\n",
        "\n",
        "5. **Pr√©sentation/communication visuelle**\n",
        "\n",
        "   - Exemple: Publications scientifiques, pr√©sentations\n",
        "   - Souvent plus \"impressionnant\" visuellement\n",
        "   - Clusters plus clairement s√©par√©s\n",
        "\n",
        "**Approche recommand√©e - Utiliser les DEUX:**\n",
        "\n",
        "```python\n",
        "# Strat√©gie optimale pour un projet r√©el\n",
        "# 1. PCA d'abord pour comprendre\n",
        "pca = PCA(n_components=0.95)  # 95% de variance\n",
        "data_pca = pca.fit_transform(data_scaled)\n",
        "print(f\"Dimensions r√©duites de {data.shape[1]} √† {data_pca.shape[1]}\")\n",
        "\n",
        "# 2. PCA pour le clustering\n",
        "kmeans = KMeans(n_clusters=k)\n",
        "clusters = kmeans.fit_predict(data_pca)\n",
        "\n",
        "# 3. PCA pour visualisation interpr√©table\n",
        "pca_2d = PCA(n_components=2)\n",
        "viz_pca = pca_2d.fit_transform(data_scaled)\n",
        "\n",
        "# 4. t-SNE pour visualisation exploratoire\n",
        "tsne_2d = TSNE(n_components=2, perplexity=30)\n",
        "viz_tsne = tsne_2d.fit_transform(data_scaled)\n",
        "\n",
        "# 5. Comparaison visuelle\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "ax1.scatter(viz_pca[:, 0], viz_pca[:, 1], c=clusters)\n",
        "ax1.set_title('PCA - Variance pr√©serv√©e')\n",
        "ax2.scatter(viz_tsne[:, 0], viz_tsne[:, 1], c=clusters)\n",
        "ax2.set_title('t-SNE - Voisinages pr√©serv√©s')\n",
        "```\n",
        "\n",
        "**Cas pratiques concrets:**\n",
        "\n",
        "| Situation | Choix | Raison |\n",
        "|-----------|-------|--------|\n",
        "| Segmentation clients bancaires (50k clients) | PCA | Scalabilit√© + interpr√©tabilit√© pour r√©gulation |\n",
        "| Exploration de donn√©es g√©n√©tiques (500 √©chantillons) | t-SNE | Structures biologiques non-lin√©aires |\n",
        "| Dashboard temps r√©el e-commerce | PCA | Rapidit√© + reproductibilit√© |\n",
        "| Publication recherche (clustering cellules) | Les deux | PCA pour m√©thode, t-SNE pour figures |\n",
        "| R√©duction avant ML (100k lignes) | PCA | Performance computationnelle |\n",
        "\n",
        "**Erreurs √† √©viter:**\n",
        "\n",
        "- ‚ùå Utiliser t-SNE pour des donn√©es tr√®s high-dimensional sans pr√©-r√©duction PCA\n",
        "- ‚ùå Interpr√©ter les distances absolues dans t-SNE (seuls les voisinages comptent)\n",
        "- ‚ùå Utiliser PCA sur donn√©es non-normalis√©es\n",
        "- ‚ùå Fixer perplexity=30 sans tester d'autres valeurs pour t-SNE\n",
        "- ‚ùå Utiliser t-SNE en production sans consid√©rer le temps de calcul\n",
        ":::\n",
        "\n",
        "::: {.callout-note icon=false}\n",
        "## Question 3\n",
        "Proposez une m√©trique business pour √©valuer l'efficacit√© du clustering au-del√† des m√©triques techniques.\n",
        ":::\n",
        "\n",
        "::: {.callout-note collapse=\"true\"}\n",
        "## R√©ponse Question 3\n",
        "\n",
        "**M√©triques Business pour √âvaluer l'Efficacit√© du Clustering**\n",
        "\n",
        "Les m√©triques techniques (silhouette score, inertie) mesurent la qualit√© math√©matique, mais pas l'impact business. Voici des m√©triques orient√©es valeur:\n",
        "\n",
        "---\n",
        "\n",
        "**1. AUGMENTATION DU TAUX DE CONVERSION PAR SEGMENT**\n",
        "\n",
        "**D√©finition:**\n",
        "```\n",
        "Taux conversion post-segmentation - Taux conversion baseline\n",
        "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ √ó 100\n",
        "           Taux conversion baseline\n",
        "```\n",
        "\n",
        "**Exemple concret:**\n",
        "\n",
        "```\n",
        "Baseline (pas de segmentation): 2.5% conversion\n",
        "Apr√®s segmentation et marketing cibl√©:\n",
        "- Segment Premium: 5.2% (+108%)\n",
        "- Segment √âconome: 3.1% (+24%)\n",
        "- Segment Moyen: 2.8% (+12%)\n",
        "\n",
        "M√©trique globale: +45% conversion moyenne pond√©r√©e\n",
        "```\n",
        "\n",
        "**Avantages:**\n",
        "- Mesure directe de l'impact financier\n",
        "- Facile √† communiquer aux stakeholders\n",
        "- Comparable dans le temps\n",
        "\n",
        "---\n",
        "\n",
        "**2. CUSTOMER LIFETIME VALUE (CLV) PAR SEGMENT**\n",
        "\n",
        "**D√©finition:**\n",
        "```\n",
        "CLV_segment = (Revenu moyen par achat √ó Fr√©quence d'achat √ó Dur√©e de vie client)\n",
        "              - (Co√ªt acquisition + Co√ªt service)\n",
        "```\n",
        "\n",
        "**Application:**\n",
        "```python\n",
        "# Calcul apr√®s 6 mois de campagnes segment√©es\n",
        "segments_clv = {\n",
        "    'Cluster 0': {\n",
        "        'CLV': 1250‚Ç¨,\n",
        "        'Co√ªt acquisition': 45‚Ç¨,\n",
        "        'ROI': 27.8\n",
        "    },\n",
        "    'Cluster 1': {\n",
        "        'CLV': 2100‚Ç¨,\n",
        "        'Co√ªt acquisition': 85‚Ç¨,\n",
        "        'ROI': 24.7\n",
        "    },\n",
        "    'Cluster 2': {\n",
        "        'CLV': 890‚Ç¨,\n",
        "        'Co√ªt acquisition': 35‚Ç¨,\n",
        "        'ROI': 25.4\n",
        "    }\n",
        "}\n",
        "\n",
        "# M√©trique: CLV pond√©r√© total vs approche non-segment√©e\n",
        "CLV_improvement = (weighted_avg_clv_segmented - clv_baseline) / clv_baseline\n",
        "```\n",
        "\n",
        "**KPI d'√©valuation:**\n",
        "- CLV moyen par segment > CLV baseline\n",
        "- Variance du CLV entre segments (plus √©lev√©e = meilleure diff√©renciation)\n",
        "- Budget marketing optimis√© selon CLV/segment\n",
        "\n",
        "---\n",
        "\n",
        "**3. TAUX DE R√âTENTION DIFF√âRENTIEL**\n",
        "\n",
        "**D√©finition:**\n",
        "```\n",
        "R√©tention_segment(t) = Clients actifs en t / Clients actifs en t-1\n",
        "\n",
        "M√©trique: Diff√©rence de r√©tention entre segments vs approche globale\n",
        "```\n",
        "\n",
        "**Tableau de bord:**\n",
        "\n",
        "\n",
        "| Segment        | R√©tention M+3 | R√©tention M+6 | R√©tention M+12 | Am√©lioration vs baseline |\n",
        "|----------------|---------------|---------------|----------------|--------------------------|\n",
        "| Premium Jeune  | 92%           | 85%           | 78%            | +15%                     |\n",
        "| Conservateurs  | 95%           | 91%           | 88%            | +22%                     |\n",
        "| Mainstream     | 88%           | 79%           | 71%            | +8%                      |\n",
        "| Baseline       | 82%           | 73%           | 65%            | -                        |\n",
        "\n",
        "\n",
        "\n",
        "**M√©trique synth√©tique:**\n",
        "```\n",
        "Score_Efficacit√©_R√©tention = Œ£(R√©tention_segment √ó Poids_segment) - R√©tention_baseline\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "**4. EFFICACIT√â OP√âRATIONNELLE DES CAMPAGNES**\n",
        "\n",
        "**D√©finition:**\n",
        "```\n",
        "Co√ªt par Acquisition (CPA) par segment\n",
        "ROI marketing = (Revenu g√©n√©r√© - Co√ªt campagne) / Co√ªt campagne\n",
        "```\n",
        "\n",
        "**Exemple d'√©valuation:**\n",
        "```\n",
        "Campagne Email Marketing:\n",
        "\n",
        "Sans segmentation:\n",
        "- Envois: 100,000\n",
        "- Taux ouverture: 18%\n",
        "- Conversions: 450\n",
        "- CPA: 22‚Ç¨\n",
        "\n",
        "Avec segmentation (3 messages adapt√©s):\n",
        "- Segment A: 35,000 envois, 28% ouverture, 280 conversions, CPA: 15‚Ç¨\n",
        "- Segment B: 40,000 envois, 22% ouverture, 200 conversions, CPA: 18‚Ç¨\n",
        "- Segment C: 25,000 envois, 32% ouverture, 220 conversions, CPA: 12‚Ç¨\n",
        "\n",
        "Total conversions: 700 (+55%)\n",
        "CPA moyen pond√©r√©: 15.2‚Ç¨ (-31%)\n",
        "\n",
        "M√©trique: Efficacit√© = (700-450)/450 √ó (22-15.2)/22 = +90% d'efficacit√©\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "**5. INDICE DE STABILIT√â DES SEGMENTS (ISS)**\n",
        "\n",
        "**D√©finition:**\n",
        "Mesure si les segments restent coh√©rents dans le temps (crucial pour strat√©gie long-terme)\n",
        "\n",
        "```python\n",
        "def indice_stabilite_segment(labels_t1, labels_t2):\n",
        "    \"\"\"\n",
        "    Mesure la stabilit√©: clients restent-ils dans leur segment?\n",
        "    \"\"\"\n",
        "    # Matrice de transition\n",
        "    transition_matrix = pd.crosstab(labels_t1, labels_t2, normalize='index')\n",
        "    \n",
        "    # Stabilit√© = moyenne des probabilit√©s diagonales\n",
        "    stabilite = np.mean(np.diag(transition_matrix))\n",
        "    \n",
        "    return stabilite\n",
        "\n",
        "# Exemple\n",
        "stabilite_3_mois = 0.87  # 87% des clients restent dans leur segment\n",
        "stabilite_6_mois = 0.82\n",
        "stabilite_12_mois = 0.76\n",
        "\n",
        "# M√©trique: Si stabilit√© < 0.7, les segments ne sont pas fiables\n",
        "```\n",
        "\n",
        "**Interpr√©tation:**\n",
        "- ISS > 0.80: Excellente stabilit√©, segments bien d√©finis\n",
        "- ISS 0.60-0.80: Stabilit√© acceptable, ajustements mineurs\n",
        "- ISS < 0.60: Segments peu fiables, revoir la segmentation\n",
        "\n",
        "---\n",
        "\n",
        "**6. SCORE DE DIFF√âRENCIATION ACTIONNABLE**\n",
        "\n",
        "**D√©finition:**\n",
        "Les segments doivent √™tre suffisamment diff√©rents pour justifier des actions distinctes\n",
        "\n",
        "```python\n",
        "def score_differenciation_business(segments_data):\n",
        "    \"\"\"\n",
        "    Mesure si les segments justifient des strat√©gies diff√©rentes\n",
        "    \"\"\"\n",
        "    scores = []\n",
        "    \n",
        "    # 1. Diff√©rence de comportement d'achat\n",
        "    purchase_variance = segments_data.groupby('segment')['purchase_frequency'].var()\n",
        "    scores.append(normalize(purchase_variance.mean()))\n",
        "    \n",
        "    # 2. Diff√©rence de pr√©f√©rences produits\n",
        "    product_affinity_diff = calculate_product_affinity_distance(segments_data)\n",
        "    scores.append(normalize(product_affinity_diff))\n",
        "    \n",
        "    # 3. Diff√©rence de sensibilit√© prix\n",
        "    price_sensitivity_diff = calculate_price_elasticity_diff(segments_data)\n",
        "    scores.append(normalize(price_sensitivity_diff))\n",
        "    \n",
        "    # 4. Diff√©rence de canaux pr√©f√©r√©s\n",
        "    channel_preference_diff = calculate_channel_divergence(segments_data)\n",
        "    scores.append(normalize(channel_preference_diff))\n",
        "    \n",
        "    # Score final (0-100)\n",
        "    return np.mean(scores) * 100\n",
        "\n",
        "# Interpr√©tation:\n",
        "# Score > 70: Segments tr√®s diff√©renci√©s, strat√©gies distinctes justifi√©es\n",
        "# Score 40-70: Diff√©renciation mod√©r√©e, personnalisation partielle\n",
        "# Score < 40: Segments trop similaires, clustering peu utile\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "**7. M√âTRIQUE COMPOSITE: BUSINESS VALUE SCORE (BVS)**\n",
        "\n",
        "**Formule int√©gr√©e:**\n",
        "```\n",
        "BVS = w1√ó(Lift_Conversion) + w2√ó(Am√©lioration_CLV) + w3√ó(R√©duction_CPA) \n",
        "      + w4√ó(Stabilit√©) + w5√ó(Diff√©renciation)\n",
        "\n",
        "Avec: Œ£wi = 1 (pond√©rations selon priorit√©s business)\n",
        "```\n",
        "\n",
        "**Exemple de calcul:**\n",
        "```python\n",
        "# Pond√©rations pour un e-commerce\n",
        "weights = {\n",
        "    'conversion_lift': 0.30,      # Priorit√© maximale\n",
        "    'clv_improvement': 0.25,\n",
        "    'cpa_reduction': 0.20,\n",
        "    'stability': 0.15,\n",
        "    'differentiation': 0.10\n",
        "}\n",
        "\n",
        "metrics = {\n",
        "    'conversion_lift': 0.45,      # +45%\n",
        "    'clv_improvement': 0.32,      # +32%\n",
        "    'cpa_reduction': 0.28,        # -28% (normalis√© positivement)\n",
        "    'stability': 0.82,            # ISS = 0.82\n",
        "    'differentiation': 0.73       # Score = 73/100\n",
        "}\n",
        "\n",
        "BVS = sum(weights[k] * metrics[k] for k in weights.keys())\n",
        "# BVS = 0.456 ‚Üí Score de 45.6/100\n",
        "\n",
        "# Interpr√©tation:\n",
        "# BVS > 0.60: Clustering tr√®s efficace\n",
        "# BVS 0.40-0.60: Clustering efficace\n",
        "# BVS < 0.40: Revoir la segmentation\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "**DASHBOARD DE SUIVI RECOMMAND√â:**\n",
        "\n",
        "```\n",
        "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "‚ïë                 √âVALUATION BUSINESS DU CLUSTERING - Q1 2025      ‚ïë\n",
        "‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n",
        "‚ïë Business Value Score (BVS):                        47.2/100  [‚úì] ‚ïë\n",
        "‚ïë                                                                  ‚ïë\n",
        "‚ïë M√©triques D√©taill√©es:                                            ‚ïë\n",
        "‚ïë ‚îú‚îÄ Conversion Lift:                                +38%     [‚úì]  ‚ïë\n",
        "‚ïë ‚îú‚îÄ CLV Am√©lioration:                               +28%     [‚úì]  ‚ïë\n",
        "‚ïë ‚îú‚îÄ CPA R√©duction:                                  -22%     [‚úì]  ‚ïë\n",
        "‚ïë ‚îú‚îÄ Indice Stabilit√© (6 mois):                     0.79      [‚úì]  ‚ïë\n",
        "‚ïë ‚îî‚îÄ Score Diff√©renciation:                          68/100   [‚úì]  ‚ïë\n",
        "‚ïë                                                                  ‚ïë\n",
        "‚ïë ROI Global Clustering:                             324%          ‚ïë\n",
        "‚ïë Co√ªt impl√©mentation:                               45K‚Ç¨          ‚ïë\n",
        "‚ïë Gain annuel estim√©:                                146K‚Ç¨         ‚ïë\n",
        "‚ïë                                                                  ‚ïë\n",
        "‚ïë Recommandation:                     ‚úÖ Poursuivre et optimiser   ‚ïë     \n",
        "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "**CONCLUSION:**\n",
        "\n",
        "La meilleure approche combine:\n",
        "1. **M√©trique primaire**: Conversion Lift ou CLV (selon objectif business)\n",
        "2. **M√©trique secondaire**: Efficacit√© op√©rationnelle (CPA, ROI marketing)\n",
        "3. **M√©trique de contr√¥le**: Stabilit√© et diff√©renciation\n",
        "\n",
        "**R√®gle d'or**: Si le clustering n'am√©liore pas au moins une m√©trique business de 15-20% sur 3-6 mois, il faut revoir la segmentation ou son utilisation op√©rationnelle.\n",
        ":::\n",
        "\n",
        "## 8. R√©sum√© et Bonnes Pratiques\n",
        "\n",
        "::: {.callout-important icon=false}\n",
        "## Checklist des √©tapes d'un projet de clustering\n",
        "\n",
        "‚úÖ **1. Compr√©hension du probl√®me m√©tier**\n",
        "   - Quel est l'objectif business ?\n",
        "   - Comment les clusters seront-ils utilis√©s ?\n",
        "\n",
        "‚úÖ **2. Exploration et pr√©traitement**\n",
        "   - Analyse des distributions\n",
        "   - Traitement des valeurs manquantes\n",
        "   - Normalisation/standardisation\n",
        "\n",
        "‚úÖ **3. D√©termination du nombre de clusters**\n",
        "   - M√©thode du coude\n",
        "   - Score silhouette\n",
        "   - Analyse de stabilit√©\n",
        "\n",
        "‚úÖ **4. Application des algorithmes**\n",
        "   - Test de plusieurs m√©thodes\n",
        "   - Ajustement des hyperparam√®tres\n",
        "   - Validation des r√©sultats\n",
        "\n",
        "‚úÖ **5. √âvaluation et interpr√©tation**\n",
        "   - M√©triques internes (silhouette, etc.)\n",
        "   - Visualisation (PCA, t-SNE)\n",
        "   - Profilage des clusters\n",
        "   - Interpr√©tation m√©tier\n",
        "\n",
        "‚úÖ **6. D√©ploiement et monitoring**\n",
        "   - Documentation des segments\n",
        "   - Mise √† jour p√©riodique\n",
        "   - Suivi de la stabilit√© des clusters\n",
        ":::\n",
        "\n",
        "## 9. Ressources Compl√©mentaires\n",
        "\n",
        "1. [Scikit-learn Clustering Guide](https://scikit-learn.org/stable/modules/clustering.html)\n",
        "2. [Interactive Clustering Visualization](https://www.naftaliharris.com/blog/visualizing-k-means-clustering/)\n",
        "3. [PCA vs t-SNE Explained](https://towardsdatascience.com/pca-vs-t-sne-257d2b9cc7cb)\n",
        "4. [Customer Segmentation Case Study](https://towardsdatascience.com/customer-segmentation-using-k-means-clustering-d33964f238c3)\n",
        "\n",
        "---\n",
        "\n",
        "**Fichiers √† rendre**:\n",
        "1. Notebook Jupyter complet avec code et commentaires\n",
        "2. Rapport d'analyse (1-2 pages) incluant :\n",
        "   - M√©thodologie choisie\n",
        "   - R√©sultats obtenus\n",
        "   - Visualisations cl√©s\n",
        "   - Recommandations m√©tier"
      ],
      "id": "da0ecb79"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "test_env",
      "language": "python",
      "display_name": "Python (test_env)",
      "path": "C:\\Users\\abdal\\AppData\\Roaming\\jupyter\\kernels\\test_env"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}