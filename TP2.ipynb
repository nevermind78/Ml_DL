{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S√©ance 2: Apprentissage Supervis√© - Classification\n",
    "\n",
    "::: {.callout-note icon=false}\n",
    "## Informations de la s√©ance\n",
    "- **Type**: Cours\n",
    "- **Dur√©e**: 2h\n",
    "- **Objectifs**: Obj5, Obj6\n",
    ":::\n",
    "\n",
    "## 1. Introduction √† la Classification\n",
    "\n",
    "### 1.1 D√©finition\n",
    "\n",
    "La **classification** est une t√¢che d'apprentissage supervis√© o√π l'objectif est de pr√©dire une **classe** ou **cat√©gorie** discr√®te √† partir de caract√©ristiques d'entr√©e.\n",
    "\n",
    "::: {.callout-note}\n",
    "## Exemple\n",
    "**Entr√©e**: Caract√©ristiques d'un email (mots, exp√©diteur, longueur, etc.)  \n",
    "**Sortie**: Classe = \"Spam\" ou \"Non Spam\"\n",
    ":::\n",
    "\n",
    "### 1.2 Diff√©rence Classification vs R√©gression\n",
    "\n",
    "| Caract√©ristique | Classification | R√©gression |\n",
    "|----------------|----------------|------------|\n",
    "| **Sortie** | Cat√©gorie discr√®te | Valeur continue |\n",
    "| **Exemple** | Spam/Non spam | Prix d'une maison |\n",
    "| **M√©trique** | Accuracy, F1-score | MAE, RMSE |\n",
    "| **Fonction** | Probabilit√© ‚Üí Classe | Valeur num√©rique |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Types de Classification\n",
    "\n",
    "### 2.1 Classification Binaire\n",
    "\n",
    "Deux classes possibles: 0 ou 1, Vrai ou Faux, Positif ou N√©gatif\n",
    "\n",
    "**Exemples**:\n",
    "- D√©tection de spam (spam/non spam)\n",
    "- Diagnostic m√©dical (malade/sain)\n",
    "- D√©tection de fraude (fraude/l√©gitime)\n",
    "- Approbation de cr√©dit (approuv√©/rejet√©)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple: Classification binaire\n",
    "y_binary = [0, 1, 1, 0, 1, 0, 0, 1]  # 0 = n√©gatif, 1 = positif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Classification Multi-classes\n",
    "\n",
    "Plus de deux classes **mutuellement exclusives** (une seule classe par instance)\n",
    "\n",
    "**Exemples**:\n",
    "- Reconnaissance de chiffres manuscrits (0-9 = 10 classes)\n",
    "- Classification de fleurs Iris (Setosa, Versicolor, Virginica)\n",
    "- Cat√©gorisation d'articles (Sport, Politique, √âconomie, Culture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple: Classification multi-classes\n",
    "y_multiclass = [0, 1, 2, 1, 0, 2, 1]  # 3 classes: 0, 1, 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Classification Multi-label\n",
    "\n",
    "Plusieurs classes **simultan√©es** possibles pour une instance\n",
    "\n",
    "**Exemples**:\n",
    "- √âtiquetage de photos (peut contenir: personne, chien, ext√©rieur)\n",
    "- Cat√©gorisation de films (peut √™tre: Action, Com√©die, Drame)\n",
    "- Analyse de sentiments multiple (joie + surprise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple: Classification multi-label\n",
    "y_multilabel = [\n",
    "    [1, 0, 1],  # instance a les labels 0 et 2\n",
    "    [0, 1, 1],  # instance a les labels 1 et 2\n",
    "    [1, 1, 0]   # instance a les labels 0 et 1\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Algorithmes de Classification\n",
    "\n",
    "### 3.1 Arbre de D√©cision (Decision Tree)\n",
    "\n",
    "Mod√®le qui prend des d√©cisions bas√©es sur des questions successives.\n",
    "\n",
    "#### Principe\n",
    "\n",
    "L'arbre divise l'espace des caract√©ristiques en r√©gions par des questions binaires.\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[Age > 30?] -->|Oui| B[Revenu > 50k?]\n",
    "    A -->|Non| C[√âtudiant?]\n",
    "    B -->|Oui| D[Approuv√© ‚úì]\n",
    "    B -->|Non| E[Rejet√© ‚úó]\n",
    "    C -->|Oui| F[Rejet√© ‚úó]\n",
    "    C -->|Non| G[Approuv√© ‚úì]\n",
    "```\n",
    "\n",
    "#### Avantages\n",
    "- Facile √† interpr√©ter et visualiser\n",
    "- Pas besoin de normalisation des donn√©es\n",
    "- G√®re les donn√©es non lin√©aires\n",
    "- G√®re les variables cat√©gorielles et num√©riques\n",
    "\n",
    "#### Inconv√©nients\n",
    "- Tendance √† l'overfitting\n",
    "- Instable (petits changements de donn√©es ‚Üí arbre diff√©rent)\n",
    "- Biais vers les classes majoritaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Chargement des donn√©es\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Entra√Ænement\n",
    "clf = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Pr√©diction\n",
    "y_pred = clf.predict(X_test)\n",
    "print(f\"Accuracy: {clf.score(X_test, y_test):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "604b72b59fb541c9bdf7ab7100dd1b3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<h1>üå∑ Classificateur d'Iris avec Arbre de D√©cision</h1>\")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d45479cf7fee41f7b5b3914560b7ac31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<p>Cette interface permet d'entra√Æner un mod√®le et de tester des pr√©dictions sur des exemples manu‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a797a0a563a240efbd6f848aaabe7aa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"\\n<div style='background-color: #f0f8ff; padding: 10px; border-radius: 5px; margin: 10px 0;'>\\n<h3‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77ff5e3be1564440bb804393317eb542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(HTML(value='<h3>Param√®tres du Mod√®le</h3>'), IntSlider(value=3, description='Pro‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "080c4b7e28274f6d937cdca6035816e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"\\n<div style='background-color: #fff3cd; padding: 10px; border-radius: 5px; margin: 10px 0; border‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2f69bf98f554e10b5092c818350da48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>üå∫ Exemples Pr√©d√©finis</h3>'), HTML(value='<p>S√©lectionnez un exemple pour rempl‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Chargement des donn√©es\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "feature_names = iris.feature_names\n",
    "target_names = iris.target_names\n",
    "\n",
    "# Split initial\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Fonction principale d'entra√Ænement et d'√©valuation\n",
    "def train_and_evaluate(max_depth=3, random_state=42):\n",
    "    \"\"\"Entra√Æne et √©value un arbre de d√©cision avec les param√®tres donn√©s\"\"\"\n",
    "    \n",
    "    # Entra√Ænement\n",
    "    clf = DecisionTreeClassifier(max_depth=max_depth, random_state=random_state)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Pr√©diction\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = clf.score(X_test, y_test)\n",
    "    \n",
    "    return clf, y_pred, accuracy\n",
    "\n",
    "# Fonction pour tester sur un exemple manuel\n",
    "def predict_manual_example(model, sepal_length, sepal_width, petal_length, petal_width):\n",
    "    \"\"\"Pr√©dit la classe d'une fleur bas√©e sur ses caract√©ristiques\"\"\"\n",
    "    example = np.array([[sepal_length, sepal_width, petal_length, petal_width]])\n",
    "    prediction = model.predict(example)[0]\n",
    "    probabilities = model.predict_proba(example)[0]\n",
    "    \n",
    "    return prediction, probabilities\n",
    "\n",
    "# Cr√©ation des widgets\n",
    "max_depth_slider = widgets.IntSlider(\n",
    "    value=3,\n",
    "    min=1,\n",
    "    max=10,\n",
    "    step=1,\n",
    "    description='Profondeur max:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "random_state_slider = widgets.IntSlider(\n",
    "    value=42,\n",
    "    min=0,\n",
    "    max=100,\n",
    "    step=1,\n",
    "    description='Random state:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# Widgets pour les caract√©ristiques manuelles\n",
    "sepal_length_slider = widgets.FloatSlider(\n",
    "    value=5.0,\n",
    "    min=4.0,\n",
    "    max=8.0,\n",
    "    step=0.1,\n",
    "    description='Sepal Length (cm):',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "sepal_width_slider = widgets.FloatSlider(\n",
    "    value=3.0,\n",
    "    min=2.0,\n",
    "    max=4.5,\n",
    "    step=0.1,\n",
    "    description='Sepal Width (cm):',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "petal_length_slider = widgets.FloatSlider(\n",
    "    value=1.5,\n",
    "    min=0.0,\n",
    "    max=7.0,\n",
    "    step=0.1,\n",
    "    description='Petal Length (cm):',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "petal_width_slider = widgets.FloatSlider(\n",
    "    value=0.2,\n",
    "    min=0.0,\n",
    "    max=2.5,\n",
    "    step=0.1,\n",
    "    description='Petal Width (cm):',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# Boutons\n",
    "train_button = widgets.Button(\n",
    "    description='Entra√Æner et √âvaluer',\n",
    "    button_style='primary',\n",
    "    icon='play'\n",
    ")\n",
    "\n",
    "predict_button = widgets.Button(\n",
    "    description='Pr√©dire sur l\\'exemple',\n",
    "    button_style='success',\n",
    "    icon='magic'\n",
    ")\n",
    "\n",
    "reset_button = widgets.Button(\n",
    "    description='R√©initialiser',\n",
    "    button_style='warning',\n",
    "    icon='refresh'\n",
    ")\n",
    "\n",
    "# Zone d'affichage\n",
    "output = widgets.Output()\n",
    "\n",
    "# Conteneurs pour l'organisation\n",
    "params_box = widgets.VBox([\n",
    "    widgets.HTML(\"<h3>Param√®tres du Mod√®le</h3>\"),\n",
    "    max_depth_slider,\n",
    "    random_state_slider,\n",
    "    train_button,\n",
    "    widgets.HTML(\"<hr>\"),\n",
    "    widgets.HTML(\"<h3>Caract√©ristiques de la Fleur</h3>\"),\n",
    "    sepal_length_slider,\n",
    "    sepal_width_slider,\n",
    "    petal_length_slider,\n",
    "    petal_width_slider,\n",
    "    predict_button,\n",
    "    reset_button\n",
    "])\n",
    "\n",
    "# Variables globales\n",
    "current_model = None\n",
    "current_accuracy = None\n",
    "\n",
    "# Fonction de rappel pour l'entra√Ænement\n",
    "def on_train_button_clicked(b):\n",
    "    global current_model, current_accuracy\n",
    "    \n",
    "    with output:\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        print(\"üîß Entra√Ænement en cours...\")\n",
    "        current_model, y_pred, current_accuracy = train_and_evaluate(\n",
    "            max_depth=max_depth_slider.value,\n",
    "            random_state=random_state_slider.value\n",
    "        )\n",
    "        \n",
    "        print(\"‚úÖ Entra√Ænement termin√©!\")\n",
    "        print(f\"\\nüìä Param√®tres utilis√©s:\")\n",
    "        print(f\"   ‚Ä¢ Profondeur max: {max_depth_slider.value}\")\n",
    "        print(f\"   ‚Ä¢ Random state: {random_state_slider.value}\")\n",
    "        \n",
    "        print(f\"\\nüéØ Accuracy sur le test set: {current_accuracy:.4f} ({current_accuracy*100:.1f}%)\")\n",
    "        \n",
    "        # Rapport de classification\n",
    "        print(f\"\\nüìã Rapport de Classification:\")\n",
    "        report = classification_report(y_test, y_pred, target_names=target_names, output_dict=False)\n",
    "        print(report)\n",
    "        \n",
    "        # Matrice de confusion\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        # Affichage graphique\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        \n",
    "        # Arbre de d√©cision\n",
    "        plot_tree(current_model, \n",
    "                  feature_names=feature_names,\n",
    "                  class_names=target_names,\n",
    "                  filled=True, \n",
    "                  rounded=True,\n",
    "                  ax=axes[0])\n",
    "        axes[0].set_title(f'Arbre de D√©cision (Profondeur max: {max_depth_slider.value})')\n",
    "        \n",
    "        # Matrice de confusion\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                   xticklabels=target_names,\n",
    "                   yticklabels=target_names,\n",
    "                   ax=axes[1])\n",
    "        axes[1].set_xlabel('Pr√©diction')\n",
    "        axes[1].set_ylabel('V√©rit√©')\n",
    "        axes[1].set_title('Matrice de Confusion')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Fonction de rappel pour la pr√©diction\n",
    "def on_predict_button_clicked(b):\n",
    "    with output:\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        if current_model is None:\n",
    "            print(\"‚ö†Ô∏è Veuillez d'abord entra√Æner le mod√®le!\")\n",
    "            return\n",
    "            \n",
    "        # R√©cup√©ration des valeurs\n",
    "        sl = sepal_length_slider.value\n",
    "        sw = sepal_width_slider.value\n",
    "        pl = petal_length_slider.value\n",
    "        pw = petal_width_slider.value\n",
    "        \n",
    "        print(f\"üå∫ Caract√©ristiques de la fleur:\")\n",
    "        print(f\"   ‚Ä¢ Sepal Length: {sl} cm\")\n",
    "        print(f\"   ‚Ä¢ Sepal Width: {sw} cm\")\n",
    "        print(f\"   ‚Ä¢ Petal Length: {pl} cm\")\n",
    "        print(f\"   ‚Ä¢ Petal Width: {pw} cm\")\n",
    "        \n",
    "        # Pr√©diction\n",
    "        prediction, probabilities = predict_manual_example(current_model, sl, sw, pl, pw)\n",
    "        \n",
    "        print(f\"\\nüîÆ Pr√©diction:\")\n",
    "        print(f\"   ‚Üí Classe: {target_names[prediction]}\")\n",
    "        \n",
    "        print(f\"\\nüìà Probabilit√©s par classe:\")\n",
    "        for i, prob in enumerate(probabilities):\n",
    "            bar = \"‚ñà\" * int(prob * 20)\n",
    "            print(f\"   ‚Ä¢ {target_names[i]}: {prob:.3f} {bar}\")\n",
    "        \n",
    "        # Visualisation dans l'espace des features\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        \n",
    "        # Feature 1 vs Feature 2 (Sepal)\n",
    "        scatter1 = axes[0].scatter(X[:, 0], X[:, 1], c=y, cmap='viridis', alpha=0.6, s=20)\n",
    "        axes[0].scatter(sl, sw, c='red', s=100, marker='*', edgecolor='black', linewidth=2)\n",
    "        axes[0].set_xlabel(feature_names[0])\n",
    "        axes[0].set_ylabel(feature_names[1])\n",
    "        axes[0].set_title('Sepal Length vs Sepal Width')\n",
    "        axes[0].legend(handles=[plt.Line2D([0], [0], marker='*', color='w', \n",
    "                                         markerfacecolor='red', markersize=10,\n",
    "                                         label='Notre fleur')])\n",
    "        \n",
    "        # Feature 3 vs Feature 4 (Petal)\n",
    "        scatter2 = axes[1].scatter(X[:, 2], X[:, 3], c=y, cmap='viridis', alpha=0.6, s=20)\n",
    "        axes[1].scatter(pl, pw, c='red', s=100, marker='*', edgecolor='black', linewidth=2)\n",
    "        axes[1].set_xlabel(feature_names[2])\n",
    "        axes[1].set_ylabel(feature_names[3])\n",
    "        axes[1].set_title('Petal Length vs Petal Width')\n",
    "        \n",
    "        plt.colorbar(scatter1, ax=axes[0], label='Classe')\n",
    "        plt.colorbar(scatter2, ax=axes[1], label='Classe')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Fonction de r√©initialisation\n",
    "def on_reset_button_clicked(b):\n",
    "    max_depth_slider.value = 3\n",
    "    random_state_slider.value = 42\n",
    "    sepal_length_slider.value = 5.0\n",
    "    sepal_width_slider.value = 3.0\n",
    "    petal_length_slider.value = 1.5\n",
    "    petal_width_slider.value = 0.2\n",
    "    \n",
    "    with output:\n",
    "        clear_output()\n",
    "        print(\"üîÑ Param√®tres r√©initialis√©s!\")\n",
    "        print(\"üî∏ Profondeur max: 3\")\n",
    "        print(\"üî∏ Random state: 42\")\n",
    "        print(\"üî∏ Exemple fleur r√©initialis√© aux valeurs moyennes\")\n",
    "\n",
    "# Assignation des fonctions de rappel\n",
    "train_button.on_click(on_train_button_clicked)\n",
    "predict_button.on_click(on_predict_button_clicked)\n",
    "reset_button.on_click(on_reset_button_clicked)\n",
    "\n",
    "# Interface principale\n",
    "display(widgets.HTML(\"<h1>üå∑ Classificateur d'Iris avec Arbre de D√©cision</h1>\"))\n",
    "display(widgets.HTML(\"<p>Cette interface permet d'entra√Æner un mod√®le et de tester des pr√©dictions sur des exemples manuels.</p>\"))\n",
    "\n",
    "# Affichage des statistiques du dataset\n",
    "display(widgets.HTML(f\"\"\"\n",
    "<div style='background-color: #f0f8ff; padding: 10px; border-radius: 5px; margin: 10px 0;'>\n",
    "<h3>üìä Statistiques du Dataset Iris</h3>\n",
    "<ul>\n",
    "<li>üìà Nombre total d'√©chantillons: {len(X)}</li>\n",
    "<li>üéØ Classes: {', '.join(target_names)}</li>\n",
    "<li>üìè Features: {', '.join(feature_names)}</li>\n",
    "<li>üß† Train set: {len(X_train)} √©chantillons</li>\n",
    "<li>üìù Test set: {len(X_test)} √©chantillons</li>\n",
    "</ul>\n",
    "</div>\n",
    "\"\"\"))\n",
    "\n",
    "# Layout principal\n",
    "main_layout = widgets.HBox([params_box, output])\n",
    "display(main_layout)\n",
    "\n",
    "# Instructions\n",
    "display(widgets.HTML(\"\"\"\n",
    "<div style='background-color: #fff3cd; padding: 10px; border-radius: 5px; margin: 10px 0; border: 1px solid #ffeaa7;'>\n",
    "<h3>üìã Instructions:</h3>\n",
    "<ol>\n",
    "<li>üìå Ajustez les <strong>Param√®tres du Mod√®le</strong> (profondeur et random state)</li>\n",
    "<li>üîß Cliquez sur <strong>Entra√Æner et √âvaluer</strong> pour cr√©er le mod√®le</li>\n",
    "<li>üå∫ Modifiez les <strong>Caract√©ristiques de la Fleur</strong> avec les curseurs</li>\n",
    "<li>üîÆ Cliquez sur <strong>Pr√©dire sur l'exemple</strong> pour voir la pr√©diction</li>\n",
    "<li>üîÑ Utilisez <strong>R√©initialiser</strong> pour revenir aux valeurs par d√©faut</li>\n",
    "</ol>\n",
    "</div>\n",
    "\"\"\"))\n",
    "\n",
    "# Exemples pr√©d√©finis\n",
    "examples_box = widgets.VBox([\n",
    "    widgets.HTML(\"<h3>üå∫ Exemples Pr√©d√©finis</h3>\"),\n",
    "    widgets.HTML(\"<p>S√©lectionnez un exemple pour remplir automatiquement les caract√©ristiques:</p>\"),\n",
    "    widgets.HBox([\n",
    "        widgets.Button(\n",
    "            description='Setosa typique',\n",
    "            button_style='info',\n",
    "            layout=widgets.Layout(width='150px')\n",
    "        ),\n",
    "        widgets.Button(\n",
    "            description='Versicolor typique',\n",
    "            button_style='info',\n",
    "            layout=widgets.Layout(width='150px')\n",
    "        ),\n",
    "        widgets.Button(\n",
    "            description='Virginica typique',\n",
    "            button_style='info',\n",
    "            layout=widgets.Layout(width='150px')\n",
    "        )\n",
    "    ])\n",
    "])\n",
    "\n",
    "def on_example_button_clicked(b, example_type):\n",
    "    if example_type == 'setosa':\n",
    "        sepal_length_slider.value = 5.0\n",
    "        sepal_width_slider.value = 3.5\n",
    "        petal_length_slider.value = 1.4\n",
    "        petal_width_slider.value = 0.2\n",
    "    elif example_type == 'versicolor':\n",
    "        sepal_length_slider.value = 6.0\n",
    "        sepal_width_slider.value = 2.8\n",
    "        petal_length_slider.value = 4.5\n",
    "        petal_width_slider.value = 1.5\n",
    "    elif example_type == 'virginica':\n",
    "        sepal_length_slider.value = 6.5\n",
    "        sepal_width_slider.value = 3.0\n",
    "        petal_length_slider.value = 5.5\n",
    "        petal_width_slider.value = 2.0\n",
    "    \n",
    "    with output:\n",
    "        clear_output(wait=True)\n",
    "        print(f\"‚úÖ Exemple {example_type} charg√©!\")\n",
    "\n",
    "# Configuration des boutons d'exemples\n",
    "example_buttons = examples_box.children[2].children\n",
    "example_buttons[0].on_click(lambda b: on_example_button_clicked(b, 'setosa'))\n",
    "example_buttons[1].on_click(lambda b: on_example_button_clicked(b, 'versicolor'))\n",
    "example_buttons[2].on_click(lambda b: on_example_button_clicked(b, 'virginica'))\n",
    "\n",
    "display(examples_box)\n",
    "\n",
    "# Entra√Ænement initial automatique\n",
    "with output:\n",
    "    print(\"üéØ Interface pr√™te!\")\n",
    "    print(\"Cliquez sur 'Entra√Æner et √âvaluer' pour commencer ou utilisez les boutons d'exemples pr√©d√©finis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Random Forest\n",
    "\n",
    "Ensemble d'arbres de d√©cision qui votent ensemble.\n",
    "\n",
    "#### Principe\n",
    "\n",
    "1. Cr√©er N arbres sur des sous-ensembles al√©atoires de donn√©es\n",
    "2. Chaque arbre vote pour une classe\n",
    "3. Pr√©diction finale = vote majoritaire\n",
    "\n",
    "#### Avantages\n",
    "- Tr√®s performant et robuste\n",
    "- R√©duit l'overfitting par rapport √† un arbre unique\n",
    "- G√®re bien les grandes dimensions\n",
    "- Donne l'importance des features\n",
    "\n",
    "#### Inconv√©nients\n",
    "- Moins interpr√©table qu'un arbre unique\n",
    "- Plus lent √† entra√Æner et pr√©dire\n",
    "- M√©moire importante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n",
      "Feature sepal length (cm): 0.106\n",
      "Feature sepal width (cm): 0.010\n",
      "Feature petal length (cm): 0.452\n",
      "Feature petal width (cm): 0.432\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Entra√Ænement\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Pr√©diction\n",
    "y_pred = rf.predict(X_test)\n",
    "print(f\"Accuracy: {rf.score(X_test, y_test):.2f}\")\n",
    "\n",
    "# Importance des features\n",
    "importances = rf.feature_importances_\n",
    "for i, imp in enumerate(importances):\n",
    "    print(f\"Feature {iris.feature_names[i]}: {imp:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Support Vector Machine (SVM)\n",
    "\n",
    "Trouve l'hyperplan optimal qui s√©pare les classes avec la marge maximale.\n",
    "\n",
    "#### Principe\n",
    "\n",
    "- **Marge**: distance entre l'hyperplan et les points les plus proches (vecteurs de support)\n",
    "- **Objectif**: Maximiser cette marge\n",
    "- **Kernel trick**: Permet de g√©rer des donn√©es non lin√©airement s√©parables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Linear Accuracy: 1.00\n",
      "SVM RBF Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# SVM lin√©aire\n",
    "svm_linear = SVC(kernel='linear', C=1.0)\n",
    "svm_linear.fit(X_train, y_train)\n",
    "\n",
    "# SVM avec kernel RBF (pour donn√©es non lin√©aires)\n",
    "svm_rbf = SVC(kernel='rbf', C=1.0, gamma='scale')\n",
    "svm_rbf.fit(X_train, y_train)\n",
    "\n",
    "print(f\"SVM Linear Accuracy: {svm_linear.score(X_test, y_test):.2f}\")\n",
    "print(f\"SVM RBF Accuracy: {svm_rbf.score(X_test, y_test):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avantages\n",
    "- Tr√®s efficace en haute dimension\n",
    "- Robuste aux outliers\n",
    "- Versatile (diff√©rents kernels)\n",
    "\n",
    "#### Inconv√©nients\n",
    "- Lent sur de grandes donn√©es\n",
    "- Difficile √† interpr√©ter\n",
    "- Sensible au choix des hyperparam√®tres\n",
    "\n",
    "### 3.4 Na√Øve Bayes\n",
    "\n",
    "Bas√© sur le th√©or√®me de Bayes avec hypoth√®se d'ind√©pendance des features.\n",
    "\n",
    "#### Principe - Th√©or√®me de Bayes\n",
    "\n",
    "$$P(y|X) = \\frac{P(X|y) \\cdot P(y)}{P(X)}$$\n",
    "\n",
    "O√π:\n",
    "- $P(y|X)$ = probabilit√© de la classe $y$ sachant les features $X$ (posterior)\n",
    "- $P(X|y)$ = vraisemblance\n",
    "- $P(y)$ = probabilit√© a priori de la classe\n",
    "- $P(X)$ = √©vidence (constante)\n",
    "\n",
    "#### Hypoth√®se \"Na√Øve\"\n",
    "\n",
    "Les features sont **ind√©pendantes** conditionnellement √† la classe:\n",
    "\n",
    "$$P(X|y) = P(x_1|y) \\cdot P(x_2|y) \\cdot ... \\cdot P(x_n|y)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian NB Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "\n",
    "# Gaussian Naive Bayes (pour features continues)\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Gaussian NB Accuracy: {gnb.score(X_test, y_test):.2f}\")\n",
    "\n",
    "# Multinomial NB (pour comptages, ex: mots dans un texte)\n",
    "# mnb = MultinomialNB()\n",
    "# mnb.fit(X_train_counts, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avantages\n",
    "- Tr√®s rapide (entra√Ænement et pr√©diction)\n",
    "- Fonctionne bien avec peu de donn√©es\n",
    "- Excellent pour la classification de texte\n",
    "\n",
    "#### Inconv√©nients\n",
    "- Hypoth√®se d'ind√©pendance rarement vraie\n",
    "- Performance limit√©e si hypoth√®se viol√©e\n",
    "\n",
    "### 3.5 R√©gression Logistique\n",
    "\n",
    "**Attention**: Malgr√© son nom, c'est un algorithme de **classification** !\n",
    "\n",
    "#### Principe\n",
    "\n",
    "Mod√®le lin√©aire qui utilise la fonction sigmo√Øde pour produire des probabilit√©s.\n",
    "\n",
    "**Fonction sigmo√Øde**:\n",
    "$$\\sigma(z) = \\frac{1}{1 + e^{-z}}$$\n",
    "\n",
    "**Mod√®le**:\n",
    "$$P(y=1|X) = \\sigma(w^T X + b) = \\frac{1}{1 + e^{-(w^T X + b)}}$$\n",
    "\n",
    "#### Interpr√©tation Probabiliste\n",
    "\n",
    "- Sortie $\\in [0, 1]$ : probabilit√© d'appartenance √† la classe positive\n",
    "- Si $P(y=1|X) \\geq 0.5$ ‚Üí pr√©diction = classe 1\n",
    "- Si $P(y=1|X) < 0.5$ ‚Üí pr√©diction = classe 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n",
      "\n",
      "Premi√®re pr√©diction:\n",
      "  Probabilit√©s: [0.00380344 0.82773956 0.168457  ]\n",
      "  Classe pr√©dite: 1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Entra√Ænement\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Pr√©diction de classes\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Pr√©diction de probabilit√©s\n",
    "y_proba = log_reg.predict_proba(X_test)\n",
    "\n",
    "print(f\"Accuracy: {log_reg.score(X_test, y_test):.2f}\")\n",
    "print(f\"\\nPremi√®re pr√©diction:\")\n",
    "print(f\"  Probabilit√©s: {y_proba[0]}\")\n",
    "print(f\"  Classe pr√©dite: {y_pred[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avantages\n",
    "- Simple et interpr√©table\n",
    "- Donne des probabilit√©s (utile pour la prise de d√©cision)\n",
    "- Peu de param√®tres √† ajuster\n",
    "- Fonctionne bien sur donn√©es lin√©airement s√©parables\n",
    "\n",
    "#### Inconv√©nients\n",
    "- Assume une relation lin√©aire\n",
    "- Sensible aux outliers\n",
    "- N√©cessite feature engineering pour les relations non lin√©aires\n",
    "\n",
    "### 3.6 k-Nearest Neighbors (k-NN)\n",
    "\n",
    "Classification bas√©e sur la proximit√© avec les voisins.\n",
    "\n",
    "#### Principe\n",
    "\n",
    "1. Calculer la distance entre le nouveau point et tous les points d'entra√Ænement\n",
    "2. S√©lectionner les k points les plus proches\n",
    "3. Vote majoritaire parmi ces k voisins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-NN Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# k=5 voisins\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "print(f\"k-NN Accuracy: {knn.score(X_test, y_test):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avantages\n",
    "- Simple et intuitif\n",
    "- Pas d'entra√Ænement (lazy learning)\n",
    "- Fonctionne bien pour des fronti√®res complexes\n",
    "\n",
    "#### Inconv√©nients\n",
    "- Lent pour la pr√©diction (calcule toutes les distances)\n",
    "- Sensible √† l'√©chelle des features (n√©cessite normalisation)\n",
    "- Curse of dimensionality (mauvais en haute dimension)\n",
    "\n",
    "## 4. Crit√®res d'√âvaluation (Aper√ßu)\n",
    "\n",
    "### 4.1 M√©triques Principales\n",
    "\n",
    "- **Accuracy**: Proportion de pr√©dictions correctes\n",
    "- **Precision**: Proportion de vrais positifs parmi les pr√©dictions positives\n",
    "- **Recall**: Proportion de vrais positifs parmi les cas r√©ellement positifs\n",
    "- **F1-Score**: Moyenne harmonique de Precision et Recall\n",
    "\n",
    "::: {.callout-important}\n",
    "Ces m√©triques seront d√©taill√©es en profondeur dans la **S√©ance 5 - TD2**\n",
    ":::\n",
    "\n",
    "### 4.2 Exemple Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       1.00      1.00      1.00         9\n",
      "   virginica       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Calcul de l'accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Rapport complet\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=iris.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Exemple Complet: Comparaison d'Algorithmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree       : 0.9150\n",
      "Random Forest       : 0.9300\n",
      "SVM                 : 0.9400\n",
      "Logistic Regression : 0.9000\n",
      "Naive Bayes         : 0.9050\n",
      "k-NN                : 0.9250\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Cr√©ation d'un dataset synth√©tique\n",
    "X, y = make_classification(\n",
    "    n_samples=1000, \n",
    "    n_features=2, \n",
    "    n_redundant=0,\n",
    "    n_clusters_per_class=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Split et normalisation\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Entra√Ænement de plusieurs mod√®les\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "models = {\n",
    "    'Decision Tree': DecisionTreeClassifier(max_depth=5, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'SVM': SVC(kernel='rbf', random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'k-NN': KNeighborsClassifier(n_neighbors=5)\n",
    "}\n",
    "\n",
    "# Comparaison des performances\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    score = model.score(X_test_scaled, y_test)\n",
    "    results[name] = score\n",
    "    print(f\"{name:20s}: {score:.4f}\")\n",
    "\n",
    "# Visualisation\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(list(results.keys()), list(results.values()))\n",
    "plt.xlabel('Accuracy')\n",
    "plt.title('Comparaison des Algorithmes de Classification')\n",
    "plt.xlim([0, 1])\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R√©sum√© de la S√©ance\n",
    "\n",
    "::: {.callout-important icon=false}\n",
    "## Points cl√©s √† retenir\n",
    "\n",
    "1. **Classification** = pr√©dire une cat√©gorie discr√®te\n",
    "2. **Types**: Binaire, Multi-classes, Multi-label\n",
    "3. **Algorithmes principaux**:\n",
    "   - Decision Tree: interpr√©table mais tendance √† l'overfitting\n",
    "   - Random Forest: robuste et performant\n",
    "   - SVM: excellent en haute dimension\n",
    "   - Na√Øve Bayes: rapide, bon pour le texte\n",
    "   - R√©gression Logistique: simple, interpr√©table, probabiliste\n",
    "   - k-NN: simple mais co√ªteux en pr√©diction\n",
    "4. **Choix du mod√®le** d√©pend de: taille des donn√©es, interpr√©tabilit√©, performance, ressources\n",
    "5. **√âvaluation** avec m√©triques appropri√©es (d√©tails en TD2)\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercices\n",
    "\n",
    "::: {.callout-warning icon=false}\n",
    "## Exercice 1\n",
    "Impl√©mentez une r√©gression logistique sur le dataset Iris et analysez les coefficients appris. Que repr√©sentent-ils?\n",
    ":::\n",
    "\n",
    "::: {.callout-warning icon=false}\n",
    "## Exercice 2\n",
    "Comparez les performances de Decision Tree vs Random Forest sur le dataset digits de sklearn. Expliquez les diff√©rences observ√©es.\n",
    ":::\n",
    "\n",
    "::: {.callout-warning icon=false}\n",
    "## Exercice 3\n",
    "Pour un probl√®me de d√©tection de fraude bancaire, quel algorithme recommanderiez-vous et pourquoi? Consid√©rez les aspects: interpr√©tabilit√©, temps r√©el, d√©s√©quilibre des classes.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectures Compl√©mentaires\n",
    "\n",
    "1. G√©ron, A. (2019) - Chapitre 3: Classification\n",
    "2. Scikit-learn Documentation: [Supervised Learning](https://scikit-learn.org/stable/supervised_learning.html)\n",
    "3. [StatQuest: Logistic Regression](https://www.youtube.com/watch?v=yIYKR4sgzI8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d52d63a05bba4cee865232697e1c295c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<h1>üå∑ Comparaison de Mod√®les de Classification</h1>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7051bcc5636a4f6db0a4ae170ee82451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<h3>Arbre de D√©cision vs Random Forest vs SVM</h3>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbe0707f1e4d414db2f76b8ffb106728",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"\\n<div style='background-color: #f8f9fa; padding: 15px; border-radius: 8px; margin: 10px 0; border‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75578ccf3ecc426a8d89e088d96c0bb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(HTML(value='<h3>‚öôÔ∏è Param√®tres des Mod√®les</h3>'), Tab(children=(VBox(children=(H‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88edbd6378af4f33b4fd9d81425b2b5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='\\n<div style=\\'background-color: #fff3cd; padding: 15px; border-radius: 8px; margin: 20px 0; borde‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, HTML\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (accuracy_score, classification_report, \n",
    "                           confusion_matrix, precision_score, recall_score, f1_score)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Chargement des donn√©es\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "feature_names = iris.feature_names\n",
    "target_names = iris.target_names\n",
    "\n",
    "# Split des donn√©es\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Standardisation (important pour SVM)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialisation des mod√®les\n",
    "models = {\n",
    "    \"Arbre de D√©cision\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"SVM\": SVC(random_state=42, probability=True)\n",
    "}\n",
    "\n",
    "# Variables globales\n",
    "current_models = {}\n",
    "current_predictions = {}\n",
    "current_accuracies = {}\n",
    "current_metrics = {}\n",
    "\n",
    "# Fonction pour entra√Æner tous les mod√®les\n",
    "def train_all_models(tree_params, rf_params, svm_params):\n",
    "    \"\"\"Entra√Æne les trois mod√®les avec les param√®tres donn√©s\"\"\"\n",
    "    \n",
    "    models_trained = {}\n",
    "    predictions = {}\n",
    "    accuracies = {}\n",
    "    metrics = {}\n",
    "    \n",
    "    # 1. Arbre de D√©cision\n",
    "    dt = DecisionTreeClassifier(\n",
    "        max_depth=tree_params['max_depth'],\n",
    "        min_samples_split=tree_params['min_samples_split'],\n",
    "        min_samples_leaf=tree_params['min_samples_leaf'],\n",
    "        random_state=42\n",
    "    )\n",
    "    dt.fit(X_train, y_train)\n",
    "    y_pred_dt = dt.predict(X_test)\n",
    "    models_trained['Arbre de D√©cision'] = dt\n",
    "    predictions['Arbre de D√©cision'] = y_pred_dt\n",
    "    accuracies['Arbre de D√©cision'] = accuracy_score(y_test, y_pred_dt)\n",
    "    metrics['Arbre de D√©cision'] = {\n",
    "        'precision': precision_score(y_test, y_pred_dt, average='weighted'),\n",
    "        'recall': recall_score(y_test, y_pred_dt, average='weighted'),\n",
    "        'f1': f1_score(y_test, y_pred_dt, average='weighted')\n",
    "    }\n",
    "    \n",
    "    # 2. Random Forest\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=rf_params['n_estimators'],\n",
    "        max_depth=rf_params['max_depth'],\n",
    "        min_samples_split=rf_params['min_samples_split'],\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred_rf = rf.predict(X_test)\n",
    "    models_trained['Random Forest'] = rf\n",
    "    predictions['Random Forest'] = y_pred_rf\n",
    "    accuracies['Random Forest'] = accuracy_score(y_test, y_pred_rf)\n",
    "    metrics['Random Forest'] = {\n",
    "        'precision': precision_score(y_test, y_pred_rf, average='weighted'),\n",
    "        'recall': recall_score(y_test, y_pred_rf, average='weighted'),\n",
    "        'f1': f1_score(y_test, y_pred_rf, average='weighted')\n",
    "    }\n",
    "    \n",
    "    # 3. SVM (n√©cessite scaling)\n",
    "    svm = SVC(\n",
    "        C=svm_params['C'],\n",
    "        kernel=svm_params['kernel'],\n",
    "        gamma=svm_params['gamma'],\n",
    "        random_state=42,\n",
    "        probability=True\n",
    "    )\n",
    "    svm.fit(X_train_scaled, y_train)\n",
    "    y_pred_svm = svm.predict(X_test_scaled)\n",
    "    models_trained['SVM'] = svm\n",
    "    predictions['SVM'] = y_pred_svm\n",
    "    accuracies['SVM'] = accuracy_score(y_test, y_pred_svm)\n",
    "    metrics['SVM'] = {\n",
    "        'precision': precision_score(y_test, y_pred_svm, average='weighted'),\n",
    "        'recall': recall_score(y_test, y_pred_svm, average='weighted'),\n",
    "        'f1': f1_score(y_test, y_pred_svm, average='weighted')\n",
    "    }\n",
    "    \n",
    "    return models_trained, predictions, accuracies, metrics\n",
    "\n",
    "# Fonction pour pr√©dire avec tous les mod√®les\n",
    "def predict_all_models(models_dict, sepal_length, sepal_width, petal_length, petal_width):\n",
    "    \"\"\"Pr√©dit avec les trois mod√®les sur un exemple donn√©\"\"\"\n",
    "    \n",
    "    example = np.array([[sepal_length, sepal_width, petal_length, petal_width]])\n",
    "    example_scaled = scaler.transform(example)\n",
    "    \n",
    "    predictions = {}\n",
    "    probabilities = {}\n",
    "    \n",
    "    for name, model in models_dict.items():\n",
    "        if name == 'SVM':\n",
    "            pred = model.predict(example_scaled)[0]\n",
    "            proba = model.predict_proba(example_scaled)[0]\n",
    "        else:\n",
    "            pred = model.predict(example)[0]\n",
    "            proba = model.predict_proba(example)[0]\n",
    "        \n",
    "        predictions[name] = pred\n",
    "        probabilities[name] = proba\n",
    "    \n",
    "    return predictions, probabilities\n",
    "\n",
    "# ============ CR√âATION DES WIDGETS ============\n",
    "\n",
    "# Titre principal\n",
    "title = widgets.HTML(\"<h1>üå∑ Comparaison de Mod√®les de Classification</h1>\")\n",
    "subtitle = widgets.HTML(\"<h3>Arbre de D√©cision vs Random Forest vs SVM</h3>\")\n",
    "\n",
    "# === Onglets pour les param√®tres de chaque mod√®le ===\n",
    "model_tabs = widgets.Tab()\n",
    "\n",
    "# --- Onglet 1: Arbre de D√©cision ---\n",
    "tree_max_depth = widgets.IntSlider(\n",
    "    value=3, min=1, max=10, step=1,\n",
    "    description='Profondeur max:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='400px')\n",
    ")\n",
    "\n",
    "tree_min_samples_split = widgets.IntSlider(\n",
    "    value=2, min=2, max=20, step=1,\n",
    "    description='Min samples split:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='400px')\n",
    ")\n",
    "\n",
    "tree_min_samples_leaf = widgets.IntSlider(\n",
    "    value=1, min=1, max=10, step=1,\n",
    "    description='Min samples leaf:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='400px')\n",
    ")\n",
    "\n",
    "tree_tab = widgets.VBox([\n",
    "    widgets.HTML(\"<h4>Param√®tres de l'Arbre de D√©cision</h4>\"),\n",
    "    tree_max_depth,\n",
    "    tree_min_samples_split,\n",
    "    tree_min_samples_leaf,\n",
    "    widgets.HTML(\"\"\"\n",
    "    <div style='background-color: #e8f4f8; padding: 10px; border-radius: 5px; margin-top: 10px;'>\n",
    "    <strong>Explications:</strong>\n",
    "    <ul>\n",
    "    <li><strong>Profondeur max</strong>: Limite la profondeur de l'arbre (√©vite l'overfitting)</li>\n",
    "    <li><strong>Min samples split</strong>: Nombre minimum d'√©chantillons requis pour diviser un n≈ìud</li>\n",
    "    <li><strong>Min samples leaf</strong>: Nombre minimum d'√©chantillons dans une feuille</li>\n",
    "    </ul>\n",
    "    </div>\n",
    "    \"\"\")\n",
    "])\n",
    "\n",
    "# --- Onglet 2: Random Forest ---\n",
    "rf_n_estimators = widgets.IntSlider(\n",
    "    value=100, min=10, max=200, step=10,\n",
    "    description='Nombre d\\'arbres:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='400px')\n",
    ")\n",
    "\n",
    "rf_max_depth = widgets.IntSlider(\n",
    "    value=5, min=1, max=20, step=1,\n",
    "    description='Profondeur max:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='400px')\n",
    ")\n",
    "\n",
    "rf_min_samples_split = widgets.IntSlider(\n",
    "    value=2, min=2, max=20, step=1,\n",
    "    description='Min samples split:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='400px')\n",
    ")\n",
    "\n",
    "rf_tab = widgets.VBox([\n",
    "    widgets.HTML(\"<h4>Param√®tres du Random Forest</h4>\"),\n",
    "    rf_n_estimators,\n",
    "    rf_max_depth,\n",
    "    rf_min_samples_split,\n",
    "    widgets.HTML(\"\"\"\n",
    "    <div style='background-color: #e8f4f8; padding: 10px; border-radius: 5px; margin-top: 10px;'>\n",
    "    <strong>Explications:</strong>\n",
    "    <ul>\n",
    "    <li><strong>Nombre d'arbres</strong>: Plus d'arbres am√©liore la stabilit√© mais augmente le temps de calcul</li>\n",
    "    <li><strong>Profondeur max</strong>: Limite la profondeur de chaque arbre</li>\n",
    "    <li><strong>Min samples split</strong>: Contr√¥le la division des n≈ìuds</li>\n",
    "    </ul>\n",
    "    </div>\n",
    "    \"\"\")\n",
    "])\n",
    "\n",
    "# --- Onglet 3: SVM ---\n",
    "svm_C = widgets.FloatLogSlider(\n",
    "    value=1.0, base=10, min=-2, max=3, step=0.1,\n",
    "    description='Param√®tre C:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='400px')\n",
    ")\n",
    "\n",
    "svm_kernel = widgets.Dropdown(\n",
    "    options=['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "    value='rbf',\n",
    "    description='Type de kernel:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='400px')\n",
    ")\n",
    "\n",
    "svm_gamma = widgets.Dropdown(\n",
    "    options=['scale', 'auto'] + [f'{10**i}' for i in range(-4, 2)],\n",
    "    value='scale',\n",
    "    description='Param√®tre gamma:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='400px')\n",
    ")\n",
    "\n",
    "svm_tab = widgets.VBox([\n",
    "    widgets.HTML(\"<h4>Param√®tres du SVM</h4>\"),\n",
    "    svm_C,\n",
    "    svm_kernel,\n",
    "    svm_gamma,\n",
    "    widgets.HTML(\"\"\"\n",
    "    <div style='background-color: #e8f4f8; padding: 10px; border-radius: 5px; margin-top: 10px;'>\n",
    "    <strong>Explications:</strong>\n",
    "    <ul>\n",
    "    <li><strong>C</strong>: Contr√¥le le compromis entre marge large et erreur d'entra√Ænement</li>\n",
    "    <li><strong>Kernel</strong>: Fonction pour transformer les donn√©es (rbf pour non-lin√©aire)</li>\n",
    "    <li><strong>Gamma</strong>: Influence de chaque exemple (petit = influence large)</li>\n",
    "    </ul>\n",
    "    </div>\n",
    "    \"\"\")\n",
    "])\n",
    "\n",
    "# Configuration des onglets\n",
    "model_tabs.children = [tree_tab, rf_tab, svm_tab]\n",
    "model_tabs.set_title(0, 'üå≥ Arbre')\n",
    "model_tabs.set_title(1, 'üå≤ Random Forest')\n",
    "model_tabs.set_title(2, '‚ö° SVM')\n",
    "\n",
    "# === Widgets pour les caract√©ristiques de la fleur ===\n",
    "flower_title = widgets.HTML(\"<h3>üå∫ Caract√©ristiques de la Fleur √† Tester</h3>\")\n",
    "\n",
    "flower_params = widgets.VBox([\n",
    "    widgets.FloatSlider(\n",
    "        value=5.0, min=4.0, max=8.0, step=0.1,\n",
    "        description='Sepal Length (cm):',\n",
    "        style={'description_width': 'initial'}\n",
    "    ),\n",
    "    widgets.FloatSlider(\n",
    "        value=3.0, min=2.0, max=4.5, step=0.1,\n",
    "        description='Sepal Width (cm):',\n",
    "        style={'description_width': 'initial'}\n",
    "    ),\n",
    "    widgets.FloatSlider(\n",
    "        value=1.5, min=0.0, max=7.0, step=0.1,\n",
    "        description='Petal Length (cm):',\n",
    "        style={'description_width': 'initial'}\n",
    "    ),\n",
    "    widgets.FloatSlider(\n",
    "        value=0.2, min=0.0, max=2.5, step=0.1,\n",
    "        description='Petal Width (cm):',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "])\n",
    "\n",
    "# Boutons d'exemples pr√©d√©finis\n",
    "example_buttons = widgets.HBox([\n",
    "    widgets.Button(\n",
    "        description='Setosa Typique',\n",
    "        button_style='info',\n",
    "        tooltip='Sepal: 5.0x3.5, Petal: 1.4x0.2',\n",
    "        layout=widgets.Layout(width='140px')\n",
    "    ),\n",
    "    widgets.Button(\n",
    "        description='Versicolor Typique',\n",
    "        button_style='info',\n",
    "        tooltip='Sepal: 6.0x2.8, Petal: 4.5x1.5',\n",
    "        layout=widgets.Layout(width='140px')\n",
    "    ),\n",
    "    widgets.Button(\n",
    "        description='Virginica Typique',\n",
    "        button_style='info',\n",
    "        tooltip='Sepal: 6.5x3.0, Petal: 5.5x2.0',\n",
    "        layout=widgets.Layout(width='140px')\n",
    "    ),\n",
    "    widgets.Button(\n",
    "        description='Exemple Interm√©diaire',\n",
    "        button_style='warning',\n",
    "        tooltip='Valeurs moyennes',\n",
    "        layout=widgets.Layout(width='160px')\n",
    "    )\n",
    "])\n",
    "\n",
    "# === Boutons d'action ===\n",
    "action_buttons = widgets.HBox([\n",
    "    widgets.Button(\n",
    "        description='üöÄ Entra√Æner Tous les Mod√®les',\n",
    "        button_style='success',\n",
    "        icon='rocket',\n",
    "        layout=widgets.Layout(width='250px', height='40px')\n",
    "    ),\n",
    "    widgets.Button(\n",
    "        description='üîÆ Pr√©dire avec les 3 Mod√®les',\n",
    "        button_style='primary',\n",
    "        icon='magic',\n",
    "        layout=widgets.Layout(width='250px', height='40px')\n",
    "    ),\n",
    "    widgets.Button(\n",
    "        description='üîÑ R√©initialiser',\n",
    "        button_style='warning',\n",
    "        icon='refresh',\n",
    "        layout=widgets.Layout(width='150px', height='40px')\n",
    "    )\n",
    "])\n",
    "\n",
    "# === Zone d'affichage ===\n",
    "output = widgets.Output(layout=widgets.Layout(\n",
    "    width='100%',\n",
    "    height='600px',\n",
    "    overflow='auto'\n",
    "))\n",
    "\n",
    "# === Layout principal ===\n",
    "left_panel = widgets.VBox([\n",
    "    widgets.HTML(\"<h3>‚öôÔ∏è Param√®tres des Mod√®les</h3>\"),\n",
    "    model_tabs,\n",
    "    widgets.HTML(\"<hr>\"),\n",
    "    flower_title,\n",
    "    flower_params,\n",
    "    widgets.HTML(\"<h4>Exemples Pr√©d√©finis:</h4>\"),\n",
    "    example_buttons\n",
    "], layout=widgets.Layout(width='45%'))\n",
    "\n",
    "right_panel = widgets.VBox([\n",
    "    action_buttons,\n",
    "    output\n",
    "], layout=widgets.Layout(width='55%'))\n",
    "\n",
    "main_layout = widgets.HBox([left_panel, right_panel])\n",
    "\n",
    "# ============ FONCTIONS DE RAPPEL ============\n",
    "\n",
    "def on_train_button_clicked(b):\n",
    "    global current_models, current_predictions, current_accuracies, current_metrics\n",
    "    \n",
    "    with output:\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        print(\"‚öôÔ∏è Entra√Ænement des 3 mod√®les en cours...\\n\")\n",
    "        \n",
    "        # R√©cup√©ration des param√®tres\n",
    "        tree_params = {\n",
    "            'max_depth': tree_max_depth.value,\n",
    "            'min_samples_split': tree_min_samples_split.value,\n",
    "            'min_samples_leaf': tree_min_samples_leaf.value\n",
    "        }\n",
    "        \n",
    "        rf_params = {\n",
    "            'n_estimators': rf_n_estimators.value,\n",
    "            'max_depth': rf_max_depth.value,\n",
    "            'min_samples_split': rf_min_samples_split.value\n",
    "        }\n",
    "        \n",
    "        svm_params = {\n",
    "            'C': svm_C.value,\n",
    "            'kernel': svm_kernel.value,\n",
    "            'gamma': svm_gamma.value if svm_gamma.value in ['scale', 'auto'] else float(svm_gamma.value)\n",
    "        }\n",
    "        \n",
    "        # Entra√Ænement\n",
    "        current_models, current_predictions, current_accuracies, current_metrics = train_all_models(\n",
    "            tree_params, rf_params, svm_params\n",
    "        )\n",
    "        \n",
    "        print(\"‚úÖ Entra√Ænement termin√©!\\n\")\n",
    "        \n",
    "        # Affichage des r√©sultats\n",
    "        display_results()\n",
    "        \n",
    "        # Visualisations\n",
    "        display_visualizations()\n",
    "\n",
    "def on_predict_button_clicked(b):\n",
    "    with output:\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        if not current_models:\n",
    "            print(\"‚ö†Ô∏è Veuillez d'abord entra√Æner les mod√®les!\")\n",
    "            return\n",
    "        \n",
    "        # R√©cup√©ration des valeurs\n",
    "        sl = flower_params.children[0].value\n",
    "        sw = flower_params.children[1].value\n",
    "        pl = flower_params.children[2].value\n",
    "        pw = flower_params.children[3].value\n",
    "        \n",
    "        print(f\"üå∫ Caract√©ristiques de la fleur:\")\n",
    "        print(f\"   ‚Ä¢ Sepal Length: {sl:.1f} cm\")\n",
    "        print(f\"   ‚Ä¢ Sepal Width: {sw:.1f} cm\")\n",
    "        print(f\"   ‚Ä¢ Petal Length: {pl:.1f} cm\")\n",
    "        print(f\"   ‚Ä¢ Petal Width: {pw:.1f} cm\")\n",
    "        print()\n",
    "        \n",
    "        # Pr√©dictions\n",
    "        predictions, probabilities = predict_all_models(current_models, sl, sw, pl, pw)\n",
    "        \n",
    "        # Affichage des pr√©dictions\n",
    "        print(\"üîÆ Pr√©dictions des 3 mod√®les:\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        for model_name in predictions.keys():\n",
    "            pred_class = predictions[model_name]\n",
    "            proba = probabilities[model_name]\n",
    "            \n",
    "            print(f\"\\n{model_name}:\")\n",
    "            print(f\"  ‚Üí Classe pr√©dite: {target_names[pred_class]}\")\n",
    "            print(f\"  Probabilit√©s:\")\n",
    "            for i, (class_name, prob) in enumerate(zip(target_names, proba)):\n",
    "                bar_length = int(prob * 20)\n",
    "                bar = \"‚ñà\" * bar_length\n",
    "                print(f\"    ‚Ä¢ {class_name}: {prob:.3f} {bar}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        \n",
    "        # Analyse des accords/d√©saccords\n",
    "        print(\"\\nü§ù Analyse des accords:\")\n",
    "        unique_predictions = list(set(predictions.values()))\n",
    "        if len(unique_predictions) == 1:\n",
    "            print(\"  ‚úÖ Tous les mod√®les sont d'accord!\")\n",
    "        else:\n",
    "            print(\"  ‚ö†Ô∏è Les mod√®les ne sont pas tous d'accord:\")\n",
    "            for model_name, pred in predictions.items():\n",
    "                print(f\"    ‚Ä¢ {model_name}: {target_names[pred]}\")\n",
    "        \n",
    "        # Visualisation de la pr√©diction\n",
    "        display_prediction_visualization(sl, sw, pl, pw, predictions, probabilities)\n",
    "\n",
    "def on_reset_button_clicked(b):\n",
    "    # R√©initialisation des param√®tres\n",
    "    tree_max_depth.value = 3\n",
    "    tree_min_samples_split.value = 2\n",
    "    tree_min_samples_leaf.value = 1\n",
    "    \n",
    "    rf_n_estimators.value = 100\n",
    "    rf_max_depth.value = 5\n",
    "    rf_min_samples_split.value = 2\n",
    "    \n",
    "    svm_C.value = 1.0\n",
    "    svm_kernel.value = 'rbf'\n",
    "    svm_gamma.value = 'scale'\n",
    "    \n",
    "    # R√©initialisation des caract√©ristiques\n",
    "    flower_params.children[0].value = 5.0\n",
    "    flower_params.children[1].value = 3.0\n",
    "    flower_params.children[2].value = 1.5\n",
    "    flower_params.children[3].value = 0.2\n",
    "    \n",
    "    with output:\n",
    "        clear_output()\n",
    "        print(\"üîÑ Tous les param√®tres ont √©t√© r√©initialis√©s!\")\n",
    "        print(\"\\nParam√®tres par d√©faut:\")\n",
    "        print(\"‚Ä¢ Arbre: profondeur=3, min_samples_split=2\")\n",
    "        print(\"‚Ä¢ Random Forest: 100 arbres, profondeur=5\")\n",
    "        print(\"‚Ä¢ SVM: C=1, kernel=rbf, gamma=scale\")\n",
    "\n",
    "def on_example_button_clicked(b, example_type):\n",
    "    if example_type == 'setosa':\n",
    "        flower_params.children[0].value = 5.0\n",
    "        flower_params.children[1].value = 3.5\n",
    "        flower_params.children[2].value = 1.4\n",
    "        flower_params.children[3].value = 0.2\n",
    "    elif example_type == 'versicolor':\n",
    "        flower_params.children[0].value = 6.0\n",
    "        flower_params.children[1].value = 2.8\n",
    "        flower_params.children[2].value = 4.5\n",
    "        flower_params.children[3].value = 1.5\n",
    "    elif example_type == 'virginica':\n",
    "        flower_params.children[0].value = 6.5\n",
    "        flower_params.children[1].value = 3.0\n",
    "        flower_params.children[2].value = 5.5\n",
    "        flower_params.children[3].value = 2.0\n",
    "    elif example_type == 'intermediate':\n",
    "        flower_params.children[0].value = 5.8\n",
    "        flower_params.children[1].value = 3.0\n",
    "        flower_params.children[2].value = 4.0\n",
    "        flower_params.children[3].value = 1.2\n",
    "    \n",
    "    with output:\n",
    "        clear_output(wait=True)\n",
    "        print(f\"‚úÖ Exemple {example_type} charg√©!\")\n",
    "\n",
    "# ============ FONCTIONS D'AFFICHAGE ============\n",
    "\n",
    "def display_results():\n",
    "    \"\"\"Affiche les r√©sultats comparatifs des mod√®les\"\"\"\n",
    "    \n",
    "    print(\"üìä COMPARAISON DES PERFORMANCES\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Tableau comparatif\n",
    "    data = []\n",
    "    for model_name in current_accuracies.keys():\n",
    "        data.append([\n",
    "            model_name,\n",
    "            f\"{current_accuracies[model_name]:.4f}\",\n",
    "            f\"{current_metrics[model_name]['precision']:.4f}\",\n",
    "            f\"{current_metrics[model_name]['recall']:.4f}\",\n",
    "            f\"{current_metrics[model_name]['f1']:.4f}\"\n",
    "        ])\n",
    "    \n",
    "    df = pd.DataFrame(data, columns=['Mod√®le', 'Accuracy', 'Precision', 'Recall', 'F1-Score'])\n",
    "    print(df.to_string(index=False))\n",
    "    \n",
    "    # Meilleur mod√®le\n",
    "    best_model = max(current_accuracies, key=current_accuracies.get)\n",
    "    print(f\"\\nüèÜ Meilleur mod√®le: {best_model} (Accuracy: {current_accuracies[best_model]:.4f})\")\n",
    "\n",
    "def display_visualizations():\n",
    "    \"\"\"Affiche les visualisations des mod√®les\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    \n",
    "    # Matrices de confusion\n",
    "    for idx, (model_name, y_pred) in enumerate(current_predictions.items()):\n",
    "        row = idx // 3\n",
    "        col = idx % 3\n",
    "        \n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                   xticklabels=target_names,\n",
    "                   yticklabels=target_names,\n",
    "                   ax=axes[row, col])\n",
    "        axes[row, col].set_title(f'{model_name}\\nAccuracy: {current_accuracies[model_name]:.3f}')\n",
    "        axes[row, col].set_xlabel('Pr√©diction')\n",
    "        axes[row, col].set_ylabel('V√©rit√©')\n",
    "    \n",
    "    # Graphique de comparaison des m√©triques\n",
    "    axes[1, 2].clear()\n",
    "    \n",
    "    metrics_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "    x_pos = np.arange(len(metrics_names))\n",
    "    width = 0.25\n",
    "    \n",
    "    for idx, (model_name, color) in enumerate(zip(['Arbre de D√©cision', 'Random Forest', 'SVM'], \n",
    "                                                 ['#2ca02c', '#1f77b4', '#ff7f0e'])):\n",
    "        metrics_values = [\n",
    "            current_accuracies[model_name],\n",
    "            current_metrics[model_name]['precision'],\n",
    "            current_metrics[model_name]['recall'],\n",
    "            current_metrics[model_name]['f1']\n",
    "        ]\n",
    "        axes[1, 2].bar(x_pos + idx*width, metrics_values, width, \n",
    "                      label=model_name, color=color, alpha=0.7)\n",
    "    \n",
    "    axes[1, 2].set_xticks(x_pos + width)\n",
    "    axes[1, 2].set_xticklabels(metrics_names)\n",
    "    axes[1, 2].set_ylabel('Score')\n",
    "    axes[1, 2].set_title('Comparaison des M√©triques')\n",
    "    axes[1, 2].legend()\n",
    "    axes[1, 2].set_ylim([0, 1])\n",
    "    axes[1, 2].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.suptitle('Analyse Comparative des Trois Mod√®les', fontsize=16, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Arbre de d√©cision (seulement pour le premier arbre du Random Forest si disponible)\n",
    "    if 'Random Forest' in current_models:\n",
    "        fig2, ax2 = plt.subplots(figsize=(12, 8))\n",
    "        plot_tree(current_models['Arbre de D√©cision'], \n",
    "                  feature_names=feature_names,\n",
    "                  class_names=target_names,\n",
    "                  filled=True, \n",
    "                  rounded=True,\n",
    "                  ax=ax2)\n",
    "        ax2.set_title(f'Arbre de D√©cision (Profondeur max: {tree_max_depth.value})', fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def display_prediction_visualization(sl, sw, pl, pw, predictions, probabilities):\n",
    "    \"\"\"Affiche la visualisation de la pr√©diction\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # 1. Position dans l'espace des features\n",
    "    scatter_features = [\n",
    "        (0, 1, 'Sepal Length vs Sepal Width', sl, sw),\n",
    "        (2, 3, 'Petal Length vs Petal Width', pl, pw),\n",
    "        (0, 2, 'Sepal Length vs Petal Length', sl, pl),\n",
    "        (1, 3, 'Sepal Width vs Petal Width', sw, pw)\n",
    "    ]\n",
    "    \n",
    "    for idx, (feat1, feat2, title_text, val1, val2) in enumerate(scatter_features):\n",
    "        row = idx // 2\n",
    "        col = idx % 2\n",
    "        \n",
    "        scatter = axes[row, col].scatter(X[:, feat1], X[:, feat2], \n",
    "                                        c=y, cmap='viridis', alpha=0.6, s=30)\n",
    "        axes[row, col].scatter(val1, val2, c='red', s=200, \n",
    "                              marker='*', edgecolor='black', linewidth=2)\n",
    "        axes[row, col].set_xlabel(feature_names[feat1])\n",
    "        axes[row, col].set_ylabel(feature_names[feat2])\n",
    "        axes[row, col].set_title(title_text)\n",
    "        axes[row, col].legend(['Notre fleur'], loc='upper right')\n",
    "        \n",
    "        # Ajouter la pr√©diction au titre\n",
    "        pred_text = \" / \".join([target_names[predictions[m]] for m in predictions])\n",
    "        axes[row, col].text(0.05, 0.95, f\"Pr√©d: {pred_text}\", \n",
    "                           transform=axes[row, col].transAxes,\n",
    "                           fontsize=10, verticalalignment='top',\n",
    "                           bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    # 2. Graphique des probabilit√©s\n",
    "    axes_flat = axes.flatten()\n",
    "    fig2, axes2 = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    \n",
    "    for idx, (model_name, proba) in enumerate(probabilities.items()):\n",
    "        axes2[idx].bar(target_names, proba, color=['#ff9999', '#66b3ff', '#99ff99'])\n",
    "        axes2[idx].set_title(f'Probabilit√©s - {model_name}')\n",
    "        axes2[idx].set_ylabel('Probabilit√©')\n",
    "        axes2[idx].set_ylim([0, 1])\n",
    "        axes2[idx].grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # Annoter la barre max\n",
    "        max_idx = np.argmax(proba)\n",
    "        axes2[idx].annotate(f'{proba[max_idx]:.3f}', \n",
    "                           xy=(max_idx, proba[max_idx]),\n",
    "                           xytext=(0, 10),\n",
    "                           textcoords='offset points',\n",
    "                           ha='center', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    plt.suptitle(f'Pr√©diction pour: SL={sl:.1f}, SW={sw:.1f}, PL={pl:.1f}, PW={pw:.1f}', \n",
    "                fontsize=14, y=1.05)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ============ CONFIGURATION DES BOUTONS ============\n",
    "\n",
    "# Configuration des boutons d'action\n",
    "action_buttons.children[0].on_click(on_train_button_clicked)\n",
    "action_buttons.children[1].on_click(on_predict_button_clicked)\n",
    "action_buttons.children[2].on_click(on_reset_button_clicked)\n",
    "\n",
    "# Configuration des boutons d'exemples\n",
    "for i, example_type in enumerate(['setosa', 'versicolor', 'virginica', 'intermediate']):\n",
    "    example_buttons.children[i].on_click(lambda b, et=example_type: on_example_button_clicked(b, et))\n",
    "\n",
    "# ============ AFFICHAGE DE L'INTERFACE ============\n",
    "\n",
    "# Affichage de l'interface\n",
    "display(title)\n",
    "display(subtitle)\n",
    "\n",
    "# Informations sur le dataset\n",
    "display(widgets.HTML(f\"\"\"\n",
    "<div style='background-color: #f8f9fa; padding: 15px; border-radius: 8px; margin: 10px 0; border: 1px solid #dee2e6;'>\n",
    "<h4>üìö Informations sur le Dataset Iris</h4>\n",
    "<div style='display: flex; justify-content: space-between;'>\n",
    "<div style='flex: 1;'>\n",
    "<h5>üéØ Classes:</h5>\n",
    "<ul>\n",
    "<li>üåø Setosa (0)</li>\n",
    "<li>üå∫ Versicolor (1)</li>\n",
    "<li>üåπ Virginica (2)</li>\n",
    "</ul>\n",
    "</div>\n",
    "<div style='flex: 1;'>\n",
    "<h5>üìè Features:</h5>\n",
    "<ul>\n",
    "<li>Sepal Length (cm)</li>\n",
    "<li>Sepal Width (cm)</li>\n",
    "<li>Petal Length (cm)</li>\n",
    "<li>Petal Width (cm)</li>\n",
    "</ul>\n",
    "</div>\n",
    "<div style='flex: 1;'>\n",
    "<h5>üìä Statistiques:</h5>\n",
    "<ul>\n",
    "<li>Total: {len(X)} √©chantillons</li>\n",
    "<li>Train: {len(X_train)} √©chantillons</li>\n",
    "<li>Test: {len(X_test)} √©chantillons</li>\n",
    "</ul>\n",
    "</div>\n",
    "</div>\n",
    "</div>\n",
    "\"\"\"))\n",
    "\n",
    "display(main_layout)\n",
    "\n",
    "# Instructions\n",
    "display(widgets.HTML(\"\"\"\n",
    "<div style='background-color: #fff3cd; padding: 15px; border-radius: 8px; margin: 20px 0; border: 1px solid #ffeaa7;'>\n",
    "<h4>üìã Mode d'emploi:</h4>\n",
    "<ol>\n",
    "<li><strong>1. Choisissez les param√®tres</strong> pour chaque mod√®le dans les onglets</li>\n",
    "<li><strong>2. Cliquez sur \"üöÄ Entra√Æner Tous les Mod√®les\"</strong> pour voir les performances compar√©es</li>\n",
    "<li><strong>3. Ajustez les caract√©ristiques</strong> de la fleur avec les curseurs</li>\n",
    "<li><strong>4. Utilisez les boutons d'exemples pr√©d√©finis</strong> pour tester rapidement</li>\n",
    "<li><strong>5. Cliquez sur \"üîÆ Pr√©dire avec les 3 Mod√®les\"</strong> pour voir les pr√©dictions</li>\n",
    "<li><strong>6. Comparez</strong> les r√©sultats et visualisations des diff√©rents mod√®les</li>\n",
    "</ol>\n",
    "<p><strong>üí° Conseil:</strong> Testez diff√©rents param√®tres pour voir comment ils affectent la performance!</p>\n",
    "</div>\n",
    "\"\"\"))\n",
    "\n",
    "# Message initial\n",
    "with output:\n",
    "    print(\"üéØ Interface pr√™te!\")\n",
    "    print(\"\\nCliquez sur 'üöÄ Entra√Æner Tous les Mod√®les' pour commencer.\")\n",
    "    print(\"\\nOu utilisez directement les boutons d'exemples pr√©d√©finis pour tester rapidement.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
