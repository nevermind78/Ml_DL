{
  "hash": "e79727ce0b50ed27880c15258890d9ee",
  "result": {
    "engine": "jupyter",
    "markdown": "# Séance 3: TP1 - Pipeline de Classification Binaire\n\n::: {.callout-note icon=false}\n## Informations de la séance\n- **Type**: Travaux Pratiques\n- **Durée**: 2h\n- **Objectifs**: Obj6, Obj7\n- **Dataset**: Titanic (prédiction de survie)\n:::\n\n## Objectifs du TP\n\nÀ la fin de ce TP, vous serez capable de:\n\n1. Charger et explorer un dataset\n2. Préparer les données pour l'apprentissage\n3. Créer un pipeline de prétraitement avec Scikit-learn\n4. Entraîner un modèle de classification binaire\n5. Évaluer les performances du modèle\n\n## 1. Configuration de l'Environnement\n\n::: {#54971bfc .cell execution_count=1}\n``` {.python .cell-code}\n# Installation des bibliothèques (si nécessaire)\n# !pip install scikit-learn pandas numpy matplotlib seaborn\n\n# Imports\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom sklearn.pipeline import Pipeline\n\n# Configuration\nplt.style.use('default')\nsns.set_palette(\"husl\")\nnp.random.seed(42)\n\nprint(\"✓ Bibliothèques importées avec succès\")\n```\n:::\n\n\n## 2. Chargement et Exploration des Données\n\n### 2.1 Chargement du Dataset Titanic\n\n::: {#7824cdf1 .cell execution_count=2}\n``` {.python .cell-code}\n# Chargement depuis seaborn\ntitanic = sns.load_dataset('titanic')\n\n# Affichage des premières lignes\nprint(\"Aperçu des données:\")\nprint(titanic.head())\n\nprint(f\"\\nDimensions: {titanic.shape}\")\nprint(f\"Colonnes: {titanic.columns.tolist()}\")\n```\n:::\n\n\n### 2.2 Exploration Initiale\n\n::: {#1bcf617f .cell execution_count=3}\n``` {.python .cell-code}\n# Informations générales\nprint(\"Informations sur le dataset:\")\nprint(titanic.info())\n\nprint(\"\\nStatistiques descriptives:\")\nprint(titanic.describe())\n\n# Vérification des valeurs manquantes\nprint(\"\\nValeurs manquantes:\")\nprint(titanic.isnull().sum())\n\n# Distribution de la variable cible\nprint(\"\\nDistribution de la survie:\")\nprint(titanic['survived'].value_counts())\nprint(f\"\\nTaux de survie: {titanic['survived'].mean():.2%}\")\n```\n:::\n\n\n### 2.3 Visualisations Exploratoires\n\n::: {#0198247b .cell execution_count=4}\n``` {.python .cell-code}\n# Figure 1: Distribution de la survie\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\n\n# Survie globale\naxes[0, 0].pie(\n    titanic['survived'].value_counts(), \n    labels=['Décédé', 'Survivant'],\n    autopct='%1.1f%%',\n    startangle=90,\n    colors=['#ff6b6b', '#51cf66']\n)\naxes[0, 0].set_title('Distribution de la Survie')\n\n# Survie par sexe\nsurvival_by_sex = titanic.groupby(['sex', 'survived']).size().unstack()\nsurvival_by_sex.plot(kind='bar', ax=axes[0, 1], color=['#ff6b6b', '#51cf66'])\naxes[0, 1].set_title('Survie par Sexe')\naxes[0, 1].set_xlabel('Sexe')\naxes[0, 1].set_ylabel('Nombre de passagers')\naxes[0, 1].legend(['Décédé', 'Survivant'])\naxes[0, 1].tick_params(axis='x', rotation=0)\n\n# Survie par classe\nsurvival_by_class = titanic.groupby(['pclass', 'survived']).size().unstack()\nsurvival_by_class.plot(kind='bar', ax=axes[1, 0], color=['#ff6b6b', '#51cf66'])\naxes[1, 0].set_title('Survie par Classe')\naxes[1, 0].set_xlabel('Classe')\naxes[1, 0].set_ylabel('Nombre de passagers')\naxes[1, 0].legend(['Décédé', 'Survivant'])\n\n# Distribution de l'âge\naxes[1, 1].hist(titanic[titanic['survived']==0]['age'].dropna(), \n                alpha=0.5, label='Décédé', bins=30, color='#ff6b6b')\naxes[1, 1].hist(titanic[titanic['survived']==1]['age'].dropna(), \n                alpha=0.5, label='Survivant', bins=30, color='#51cf66')\naxes[1, 1].set_title('Distribution de l\\'âge par survie')\naxes[1, 1].set_xlabel('Âge')\naxes[1, 1].set_ylabel('Fréquence')\naxes[1, 1].legend()\n\nplt.tight_layout()\nplt.show()\n```\n:::\n\n\n## 3. Préparation des Données\n\n### 3.1 Sélection des Features\n\n::: {#71383296 .cell execution_count=5}\n``` {.python .cell-code}\n# Sélection des colonnes pertinentes\nfeatures = ['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked']\ntarget = 'survived'\n\n# Création du dataset de travail\ndf = titanic[features + [target]].copy()\n\nprint(f\"Dataset de travail: {df.shape}\")\nprint(f\"\\nValeurs manquantes:\")\nprint(df.isnull().sum())\n```\n:::\n\n\n### 3.2 Traitement des Valeurs Manquantes\n\n::: {#716413de .cell execution_count=6}\n``` {.python .cell-code}\n# Stratégies de traitement\n# 1. Age: remplir avec la médiane\ndf['age'].fillna(df['age'].median(), inplace=True)\n\n# 2. Embarked: remplir avec le mode (valeur la plus fréquente)\ndf['embarked'].fillna(df['embarked'].mode()[0], inplace=True)\n\n# 3. Fare: remplir avec la médiane (si manquant)\ndf['fare'].fillna(df['fare'].median(), inplace=True)\n\n# Vérification\nprint(\"Après traitement:\")\nprint(df.isnull().sum())\n```\n:::\n\n\n### 3.3 Encodage des Variables Catégorielles\n\n::: {#eb9402c9 .cell execution_count=7}\n``` {.python .cell-code}\n# Encodage de 'sex'\ndf['sex'] = df['sex'].map({'male': 0, 'female': 1})\n\n# Encodage de 'embarked' (One-Hot Encoding)\ndf = pd.get_dummies(df, columns=['embarked'], prefix='embarked', drop_first=True)\n\nprint(\"Dataset après encodage:\")\nprint(df.head())\nprint(f\"\\nNouvelles dimensions: {df.shape}\")\n```\n:::\n\n\n### 3.4 Séparation Features / Target\n\n::: {#5b7c0676 .cell execution_count=8}\n``` {.python .cell-code}\n# Séparation X (features) et y (target)\nX = df.drop('survived', axis=1)\ny = df['survived']\n\nprint(f\"X shape: {X.shape}\")\nprint(f\"y shape: {y.shape}\")\nprint(f\"\\nFeatures utilisées:\\n{X.columns.tolist()}\")\n```\n:::\n\n\n## 4. Split Train/Validation/Test\n\n### 4.1 Split Train/Test\n\n::: {#b0d4cdb8 .cell execution_count=9}\n``` {.python .cell-code}\n# Split 80/20\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, \n    test_size=0.2,      # 20% pour le test\n    random_state=42,    # reproductibilité\n    stratify=y          # préserver la distribution des classes\n)\n\nprint(f\"Train set: {X_train.shape}\")\nprint(f\"Test set:  {X_test.shape}\")\n\n# Vérification de la distribution\nprint(f\"\\nDistribution train: {y_train.value_counts(normalize=True)}\")\nprint(f\"Distribution test:  {y_test.value_counts(normalize=True)}\")\n```\n:::\n\n\n### 4.2 Split Train/Validation (optionnel)\n\n::: {#1af4c964 .cell execution_count=10}\n``` {.python .cell-code}\n# Optionnel: créer un ensemble de validation\nX_train_full, X_val, y_train_full, y_val = train_test_split(\n    X_train, y_train,\n    test_size=0.2,  # 20% du train pour validation\n    random_state=42,\n    stratify=y_train\n)\n\nprint(f\"Train full: {X_train_full.shape}\")\nprint(f\"Validation: {X_val.shape}\")\nprint(f\"Test:       {X_test.shape}\")\n```\n:::\n\n\n## 5. Pipeline de Prétraitement et Entraînement\n\n### 5.1 Création du Pipeline\n\n::: {#886273dd .cell execution_count=11}\n``` {.python .cell-code}\n# Pipeline: Standardisation + Modèle\npipeline = Pipeline([\n    ('scaler', StandardScaler()),  # Étape 1: Standardisation\n    ('classifier', LogisticRegression(max_iter=1000, random_state=42))  # Étape 2: Modèle\n])\n\nprint(\"Pipeline créé:\")\nprint(pipeline)\n```\n:::\n\n\n### 5.2 Entraînement du Modèle\n\n::: {#e9f82f7e .cell execution_count=12}\n``` {.python .cell-code}\n# Entraînement\nprint(\"Entraînement en cours...\")\npipeline.fit(X_train, y_train)\nprint(\"✓ Entraînement terminé\")\n\n# Prédictions\ny_train_pred = pipeline.predict(X_train)\ny_test_pred = pipeline.predict(X_test)\n\nprint(\"✓ Prédictions effectuées\")\n```\n:::\n\n\n## 6. Évaluation Initiale\n\n### 6.1 Accuracy\n\n::: {#e3d18a88 .cell execution_count=13}\n``` {.python .cell-code}\n# Calcul de l'accuracy\ntrain_accuracy = accuracy_score(y_train, y_train_pred)\ntest_accuracy = accuracy_score(y_test, y_test_pred)\n\nprint(f\"Accuracy Train: {train_accuracy:.4f} ({train_accuracy*100:.2f}%)\")\nprint(f\"Accuracy Test:  {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n\n# Analyse de l'overfitting\ndiff = train_accuracy - test_accuracy\nprint(f\"\\nDifférence Train-Test: {diff:.4f}\")\nif diff < 0.05:\n    print(\"→ Bon équilibre biais-variance\")\nelif diff < 0.10:\n    print(\"→ Léger overfitting\")\nelse:\n    print(\"→ Overfitting significatif\")\n```\n:::\n\n\n### 6.2 Matrice de Confusion\n\n::: {#d651eee2 .cell execution_count=14}\n``` {.python .cell-code}\n# Calcul de la matrice de confusion\ncm = confusion_matrix(y_test, y_test_pred)\n\n# Visualisation\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n            xticklabels=['Décédé', 'Survivant'],\n            yticklabels=['Décédé', 'Survivant'])\nplt.title('Matrice de Confusion - Test Set')\nplt.ylabel('Vraie Classe')\nplt.xlabel('Classe Prédite')\nplt.tight_layout()\nplt.show()\n\n# Interprétation\ntn, fp, fn, tp = cm.ravel()\nprint(f\"\\nVrais Négatifs (TN):  {tn}\")\nprint(f\"Faux Positifs (FP):   {fp}\")\nprint(f\"Faux Négatifs (FN):   {fn}\")\nprint(f\"Vrais Positifs (TP):  {tp}\")\n```\n:::\n\n\n### 6.3 Rapport de Classification\n\n::: {#65430c13 .cell execution_count=15}\n``` {.python .cell-code}\n# Rapport détaillé\nprint(\"\\nRapport de Classification:\")\nprint(classification_report(y_test, y_test_pred, \n                          target_names=['Décédé', 'Survivant']))\n```\n:::\n\n\n## 7. Comparaison de Plusieurs Modèles\n\n::: {#c98ea53f .cell execution_count=16}\n``` {.python .cell-code}\n# Définition des modèles\nmodels = {\n    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n    'Decision Tree': DecisionTreeClassifier(max_depth=5, random_state=42),\n    'Random Forest': RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n}\n\n# Entraînement et évaluation\nresults = {}\nfor name, model in models.items():\n    # Pipeline pour chaque modèle\n    pipe = Pipeline([\n        ('scaler', StandardScaler()),\n        ('classifier', model)\n    ])\n    \n    # Entraînement\n    pipe.fit(X_train, y_train)\n    \n    # Évaluation\n    train_score = pipe.score(X_train, y_train)\n    test_score = pipe.score(X_test, y_test)\n    \n    results[name] = {\n        'train': train_score,\n        'test': test_score,\n        'diff': train_score - test_score\n    }\n    \n    print(f\"\\n{name}:\")\n    print(f\"  Train Accuracy: {train_score:.4f}\")\n    print(f\"  Test Accuracy:  {test_score:.4f}\")\n    print(f\"  Différence:     {train_score - test_score:.4f}\")\n\n# Visualisation comparative\ndf_results = pd.DataFrame(results).T\ndf_results[['train', 'test']].plot(kind='bar', figsize=(10, 6))\nplt.title('Comparaison des Performances des Modèles')\nplt.xlabel('Modèle')\nplt.ylabel('Accuracy')\nplt.legend(['Train', 'Test'])\nplt.xticks(rotation=45, ha='right')\nplt.ylim([0, 1])\nplt.grid(axis='y', alpha=0.3)\nplt.tight_layout()\nplt.show()\n```\n:::\n\n\n## 8. Analyse des Prédictions\n\n### 8.1 Exemples de Prédictions\n\n::: {#86c54924 .cell execution_count=17}\n``` {.python .cell-code}\n# Prédictions avec probabilités\ny_proba = pipeline.predict_proba(X_test)\n\n# Affichage de quelques exemples\nn_samples = 5\nindices = np.random.choice(len(X_test), n_samples, replace=False)\n\nprint(\"Exemples de prédictions:\\n\")\nfor idx in indices:\n    actual = y_test.iloc[idx]\n    predicted = y_test_pred[idx]\n    proba = y_proba[idx]\n    \n    print(f\"Passager {idx}:\")\n    print(f\"  Vraie classe:     {'Survivant' if actual == 1 else 'Décédé'}\")\n    print(f\"  Prédiction:       {'Survivant' if predicted == 1 else 'Décédé'}\")\n    print(f\"  Probabilités:     Décédé={proba[0]:.2%}, Survivant={proba[1]:.2%}\")\n    print(f\"  Correct:          {'+' if actual == predicted else '+'}\")\n    print()\n```\n:::\n\n\n### 8.2 Analyse des Erreurs\n\n::: {#47b6ffb8 .cell execution_count=18}\n``` {.python .cell-code}\n# Identification des erreurs\nerrors = X_test[y_test != y_test_pred].copy()\nerrors['actual'] = y_test[y_test != y_test_pred]\nerrors['predicted'] = y_test_pred[y_test != y_test_pred]\n\nprint(f\"Nombre d'erreurs: {len(errors)}\")\nprint(f\"Taux d'erreur: {len(errors)/len(X_test):.2%}\")\n\nprint(\"\\nQuelques erreurs:\")\nprint(errors.head())\n\n# Analyse des caractéristiques des erreurs\nprint(\"\\nCaractéristiques moyennes des erreurs vs correctes:\")\ncorrect = X_test[y_test == y_test_pred]\n\ncomparison = pd.DataFrame({\n    'Erreurs': errors.drop(['actual', 'predicted'], axis=1).mean(),\n    'Correctes': correct.mean()\n})\nprint(comparison)\n```\n:::\n\n\n## Exercices Pratiques\n\n::: {.callout-warning icon=false collapse=\"true\"}\n## Exercice 1: Feature Engineering\n\nCréez une nouvelle feature `family_size` = `sibsp` + `parch` + 1, puis ré-entraînez le modèle. La performance s'améliore-t-elle ?\n\n### Solution\n\n::: {#86c178ed .cell execution_count=19}\n``` {.python .cell-code code-fold=\"true\"}\n# Création de la nouvelle feature\ndf['family_size'] = df['sibsp'] + df['parch'] + 1\n\n# Refaire le split et l'entraînement\nX_new = df.drop('survived', axis=1)\ny_new = df['survived']\n\nX_train_new, X_test_new, y_train_new, y_test_new = train_test_split(\n    X_new, y_new, test_size=0.2, random_state=42, stratify=y_new\n)\n\npipeline_new = Pipeline([\n    ('scaler', StandardScaler()),\n    ('classifier', LogisticRegression(max_iter=1000, random_state=42))\n])\n\npipeline_new.fit(X_train_new, y_train_new)\nnew_score = pipeline_new.score(X_test_new, y_test_new)\n\nprint(f\"Accuracy avec family_size: {new_score:.4f}\")\nprint(f\"Accuracy sans family_size: {test_accuracy:.4f}\")\nprint(f\"Amélioration: {new_score - test_accuracy:.4f}\")\n```\n:::\n\n\n:::\n\n::: {.callout-warning icon=false collapse=\"true\"}\n## Exercice 2: Optimisation des Hyperparamètres\n\nTestez différentes valeurs de `max_depth` pour le Decision Tree (3, 5, 7, 10, None). Quelle valeur donne les meilleures performances sur le test set ?\n\n### Solution\n\n::: {#10b03e9d .cell execution_count=20}\n``` {.python .cell-code code-fold=\"true\"}\ndepths = [3, 5, 7, 10, None]\nresults_depth = []\n\nfor depth in depths:\n    pipe = Pipeline([\n        ('scaler', StandardScaler()),\n        ('classifier', DecisionTreeClassifier(max_depth=depth, random_state=42))\n    ])\n    \n    pipe.fit(X_train, y_train)\n    train_score = pipe.score(X_train, y_train)\n    test_score = pipe.score(X_test, y_test)\n    \n    results_depth.append({\n        'max_depth': depth,\n        'train': train_score,\n        'test': test_score,\n        'diff': train_score - test_score\n    })\n    \ndf_depth = pd.DataFrame(results_depth)\nprint(df_depth)\n\n# Meilleure valeur\nbest_depth = df_depth.loc[df_depth['test'].idxmax(), 'max_depth']\nprint(f\"\\nMeilleur max_depth: {best_depth}\")\n```\n:::\n\n\n:::\n\n::: {.callout-warning icon=false collapse=\"true\"}\n## Exercice 3: Analyse d'Importance\n\nPour le Random Forest, affichez l'importance des features. Quelles sont les 3 features les plus importantes ?\n\n### Solution\n\n::: {#7207341b .cell execution_count=21}\n``` {.python .cell-code code-fold=\"true\"}\n# Entraîner Random Forest\nrf = RandomForestClassifier(n_estimators=100, random_state=42)\nrf.fit(X_train, y_train)\n\n# Importance des features\nimportances = pd.DataFrame({\n    'feature': X_train.columns,\n    'importance': rf.feature_importances_\n}).sort_values('importance', ascending=False)\n\nprint(\"Importance des features:\")\nprint(importances)\n\n# Visualisation\nplt.figure(figsize=(10, 6))\nplt.barh(importances['feature'], importances['importance'])\nplt.xlabel('Importance')\nplt.title('Importance des Features - Random Forest')\nplt.tight_layout()\nplt.show()\n\nprint(f\"\\nTop 3 features:\")\nprint(importances.head(3))\n```\n:::\n\n\n:::\n\n## Résumé du TP\n\n::: {.callout-important icon=false}\n## Ce que vous avez appris\n\n1. **Chargement et exploration** de données avec pandas\n2. **Prétraitement** des données:\n   - Traitement des valeurs manquantes\n   - Encodage des variables catégorielles\n   - Standardisation\n3. **Pipeline Scikit-learn** pour automatiser le workflow\n4. **Split Train/Test** avec stratification\n5. **Entraînement et évaluation** de modèles de classification\n6. **Comparaison** de plusieurs algorithmes\n7. **Analyse des résultats** et des erreurs\n:::\n\n## Checklist de Validation\n\n- [ ] Dataset chargé et exploré\n- [ ] Valeurs manquantes traitées\n- [ ] Variables catégorielles encodées\n- [ ] Pipeline créé avec StandardScaler\n- [ ] Modèle entraîné avec succès\n- [ ] Accuracy calculée (train et test)\n- [ ] Matrice de confusion générée\n- [ ] Comparaison de plusieurs modèles effectuée\n- [ ] Analyse des erreurs réalisée\n\n## Pour Aller Plus Loin\n\n1. Testez d'autres features (titre extrait du nom, cabine, etc.)\n2. Expérimentez avec le seuil de décision (au lieu de 0.5)\n3. Utilisez la validation croisée (voir TP2)\n4. Essayez d'autres algorithmes (SVM, Gradient Boosting)\n\n",
    "supporting": [
      "seance3_files"
    ],
    "filters": [],
    "includes": {}
  }
}